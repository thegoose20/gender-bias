{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs the files:\n",
    "  * `../data/analysis_data/descriptions_with_counts.csv`: adds columns to `descriptions.csv` for word counts and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `../data/analysis_data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "  * `../data/crc_metadata/all_descs_with_offsets.csv`: contains one row for every description in the annotated datasets with columns for the descriptions' corresponding id, eadid, file, start offset, and end offset\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Loading\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Descriptions\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "### 0. Loading\n",
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.9 from \"/Users/lucy/Desktop/repos/gender-bias/env/bin/python\"\n  * The NumPy version is: \"1.23.4\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/_multiarray_umath.cpython-39-darwin.so, 0x0002): Library not loaded: '@rpath/libmkl_rt.1.dylib'\n  Referenced from: '/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/_multiarray_umath.cpython-39-darwin.so'\n  Reason: tried: '/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/../../../../libmkl_rt.1.dylib' (no such file), '/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/../../../../libmkl_rt.1.dylib' (no such file), '/Users/lucy/Desktop/repos/gender-bias/env/bin/../lib/libmkl_rt.1.dylib' (no such file), '/Users/lucy/Desktop/repos/gender-bias/env/bin/../lib/libmkl_rt.1.dylib' (no such file), '/usr/local/lib/libmkl_rt.1.dylib' (no such file), '/usr/lib/libmkl_rt.1.dylib' (no such file)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m  \u001b[38;5;66;03m# import custom functions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/gender-bias/analysis/utils.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthefuzz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuzz, process\n",
      "File \u001b[0;32m~/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/pandas/__init__.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.9 from \"/Users/lucy/Desktop/repos/gender-bias/env/bin/python\"\n  * The NumPy version is: \"1.23.4\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/_multiarray_umath.cpython-39-darwin.so, 0x0002): Library not loaded: '@rpath/libmkl_rt.1.dylib'\n  Referenced from: '/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/_multiarray_umath.cpython-39-darwin.so'\n  Reason: tried: '/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/../../../../libmkl_rt.1.dylib' (no such file), '/Users/lucy/Desktop/repos/gender-bias/env/lib/python3.9/site-packages/numpy/core/../../../../libmkl_rt.1.dylib' (no such file), '/Users/lucy/Desktop/repos/gender-bias/env/bin/../lib/libmkl_rt.1.dylib' (no such file), '/Users/lucy/Desktop/repos/gender-bias/env/bin/../lib/libmkl_rt.1.dylib' (no such file), '/usr/local/lib/libmkl_rt.1.dylib' (no such file), '/usr/lib/libmkl_rt.1.dylib' (no such file)\n"
     ]
    }
   ],
   "source": [
    "import utils  # import custom functions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from . import _distributor_init  # for mkl-service (Intel(r) MKL initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = \"../data/aggregated_data/\"\n",
    "# data_files = [\"aggregated_final.csv\", \"aggregated_with_annotator_eadid_note_cols.csv\", \n",
    "#               \"aggregated_with_eadid_descid_desc_cols.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(dir_path+data_files[2], index_col=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Rows:\",df.shape[0], \"\\nColumns:\",df.shape[1])  # Rows: 55260, Columns: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_path = \"../data/crc_metadata/all_descriptions.csv\"     # descriptions in column of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid                                        description  \\\n",
       "0   AA5  Professor James Aitken White was a leading Sco...   \n",
       "1   AA5  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "2   AA6  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "3   AA6            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "4   AA7  Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                       field  desc_id  \n",
       "0  Biographical / Historical        0  \n",
       "1                      Title        1  \n",
       "2  Biographical / Historical        2  \n",
       "3                      Title        3  \n",
       "4  Biographical / Historical        4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(descs_path, index_col=0)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove metadata field name from each description\n",
    "# new_descs = []\n",
    "# descs = list(desc_df.description)\n",
    "# fields = list(desc_df.field)\n",
    "# i = 0\n",
    "# maxI = len(descs)\n",
    "# while i < maxI:\n",
    "#     d, f = descs[i], fields[i]\n",
    "#     to_remove = f+\":\\n\"\n",
    "#     d = d.replace(to_remove,\"\")\n",
    "#     new_descs += [d]\n",
    "#     i += 1\n",
    "# assert len(new_descs) == len(descs)\n",
    "# # new_descs[:10]            # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Update the CSV file\n",
    "# desc_df.description = new_descs\n",
    "# desc_df.head()\n",
    "# desc_df.to_csv(descs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each description to a txt file named with desc_id\n",
    "ids = list(desc_df.desc_id)\n",
    "zero_padding = len(str(ids[-1]))\n",
    "desc_txt_dir = \"data/descriptions/\"\n",
    "i, maxI = 0, len(ids)\n",
    "while i < maxI:\n",
    "    d_id = str(ids[i])\n",
    "    padding = zero_padding - len(d_id)  # pad with zeros so file order aligns with DataFrame order\n",
    "    id_str = (\"0\"*padding) + d_id\n",
    "    filename = \"description\"+id_str+\".txt\"\n",
    "    f = open((desc_txt_dir+filename), \"w\", encoding=\"utf8\")\n",
    "    f.write(new_descs[i])\n",
    "    f.close()\n",
    "    i += 1\n",
    "print(\"Files written to \"+desc_txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader(\"data/descriptions/\", \"description\\d+.txt\", encoding=\"utf8\")\n",
    "# print(len(corpus.fileids()), desc_df.shape[0])  # Looks good\n",
    "print(corpus.fileids()[-20:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good\n",
    "# len(desc_sents[2]) # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.insert(len(desc_df.columns), \"word_count\", word_count)\n",
    "desc_df.insert(len(desc_df.columns), \"sent_count\", sent_count)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"descriptions_with_counts.csv\")  # write a new CSV file with the word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.reset_index()\n",
    "desc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", desc_df)\n",
    "desc_df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengths per Metadata Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Biographical / Historical\"\n",
    "bh_stats = utils.makeDescribeDf(field, desc_df)\n",
    "bh_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Scope and Contents\"\n",
    "sc_stats = utils.makeDescribeDf(field, desc_df)\n",
    "sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Processing Information\"\n",
    "pi_stats = utils.makeDescribeDf(field, desc_df)\n",
    "pi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Title\"\n",
    "t_stats = utils.makeDescribeDf(field, desc_df)\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for visualization in Observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descs = pd.read_csv(\"../data/analysis_data/descriptions_with_counts.csv\", index_col=0)\n",
    "df_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "### 2. Offsets of Descriptions\n",
    "\n",
    "**Get the start and end offset of every description so that automated labels can be exported as .ann files for visualization with brat.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we need to determinen the intermediate start and end offsets as well, which we'll add as a column to the file `../data/crc_metadata/all_descriptions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: RE-ASSIGN DESC IDS TO ANNOTATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"../data/crc_metadata/descriptions_brat/\"\n",
    "file_type = \".txt\"  # Read in only the PlainText files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll-227_00100.txt', 'La_03600.txt', 'PJM_03000.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(doc_path)\n",
    "filenames = [f for f in filenames if f[-4:] == file_type] # the descriptions are in the txt files\n",
    "print(filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_names = [\"Title\", \"Scope and Contents\", \"Biographical / Historical\", \"Processing Information\"]\n",
    "            \n",
    "# INPUT: file path to a document of metadata descriptions (str)\n",
    "# OUTPUT: a dictionary of metadata description ids and the associated \n",
    "#         description text, field name and offsets contained in the input file\n",
    "def getDescriptionsInFiles(dirpath, file_list, fieldnames=metadata_field_names):\n",
    "    desc_dict = dict()\n",
    "    did = 0\n",
    "    for filename in file_list:\n",
    "\n",
    "        # Get a string of the input file's text (metadata descriptions)\n",
    "        f_string = open(os.path.join(dirpath+filename),'r').read()\n",
    "        \n",
    "        for fieldname in fieldnames:\n",
    "            pattern = \"(?<={}:\\n).+\".format(fieldname)\n",
    "            match_list = re.findall(pattern, f_string)\n",
    "            if len(match_list) > 0:\n",
    "                for match in match_list:\n",
    "                    desc_dict[did] = dict.fromkeys([\"description\", \"field\", \"file\", \"start_offset\", \"end_offset\"])\n",
    "                    desc_dict[did][\"description\"] = match\n",
    "                    desc_dict[did][\"field\"] = fieldname\n",
    "                    desc_dict[did][\"file\"] = filename\n",
    "                    desc_dict[did][\"start_offset\"] = f_string.find(match)\n",
    "                    desc_dict[did][\"end_offset\"] = f_string.find(match) + len(match) + 1\n",
    "                    did += 1\n",
    "                    \n",
    "    return desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_details = getDescriptionsInFiles(doc_path, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now create a DataFrame of the description data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_col = list(descs_details.keys())\n",
    "desc_col, field_col, file_col, eadid_col, start_offset_col, end_offset_col = [], [], [], [], [], []\n",
    "for desc_id in ids_col:\n",
    "    desc_dict = descs_details[desc_id]\n",
    "    \n",
    "    eadid = (re.findall(\"^.*(?=_\\d+.txt)\", desc_dict[\"file\"]))[0]\n",
    "    eadid_col += [eadid]\n",
    "    \n",
    "    field_col += [desc_dict[\"field\"]]\n",
    "    \n",
    "    file_col += [desc_dict[\"file\"]]\n",
    "    \n",
    "    desc_col += [desc_dict[\"description\"]]\n",
    "    \n",
    "    start_offset_col += [desc_dict[\"start_offset\"]]\n",
    "    end_offset_col += [desc_dict[\"end_offset\"]]\n",
    "\n",
    "new_descs_df = pd.DataFrame({\n",
    "    \"desc_id\":ids_col, \"eadid\":eadid_col, \"field\":field_col, \"file\":file_col, \n",
    "    \"description\":desc_col, \"desc_start_offset\":start_offset_col, \"desc_end_offset\":end_offset_col\n",
    "})\n",
    "\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_descs_df.to_csv(\"../data/crc_metadata/descs_with_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assign description IDs from this DataFrame to the aggregated annotated datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../data/aggregated_data/\"\n",
    "df_grouped = pd.read_csv(dir_path+\"desc_field_descid_label_eadid.csv\", index_col=0)\n",
    "df_agg = pd.read_csv(dir_path+\"aggregated_with_eadid_descid_desc_cols.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Occupation', 'Stereotype', 'Masculine', 'Gen...</td>\n",
       "      <td>AA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Stereotype', 'Masculine', 'Unknown'}</td>\n",
       "      <td>AA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "      <td>{'Gendered-Pronoun', 'Stereotype', 'Unknown', ...</td>\n",
       "      <td>AA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>AA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "      <td>{'Gendered-Pronoun', 'Stereotype', 'Unknown', ...</td>\n",
       "      <td>AA7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "8054  Professor James Aitken White was a leading Sco...   \n",
       "5560  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "8321  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "5550            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "633   Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                          field  desc_id  \\\n",
       "8054  Biographical / Historical        0   \n",
       "5560                      Title        1   \n",
       "8321  Biographical / Historical        2   \n",
       "5550                      Title        3   \n",
       "633   Biographical / Historical        4   \n",
       "\n",
       "                                                  label eadid  \n",
       "8054  {'Occupation', 'Stereotype', 'Masculine', 'Gen...   AA5  \n",
       "5560             {'Stereotype', 'Masculine', 'Unknown'}   AA5  \n",
       "8321  {'Gendered-Pronoun', 'Stereotype', 'Unknown', ...   AA6  \n",
       "5550                           {'Masculine', 'Unknown'}   AA6  \n",
       "633   {'Gendered-Pronoun', 'Stereotype', 'Unknown', ...   AA7  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indeces1 = [\"description\", \"field\", \"eadid\"]\n",
    "# new_descs_subdf = new_descs_df.drop(columns=[\"file\",\"desc_start_offset\",\"desc_end_offset\"])\n",
    "# df_grouped = df_grouped.drop(columns=[\"desc_id\"])\n",
    "df_grouped_joined = df_grouped.set_index([\"description\",\"field\",\"eadid\"]).join(new_descs_df.set_index([\"description\",\"field\",\"eadid\"]), how=\"outer\", lsuffix=\"_old\", rsuffix=\"_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>desc_id_old</th>\n",
       "      <th>label</th>\n",
       "      <th>desc_id_new</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>eadid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\" \"He is an immature looking boy who has had a good deal of physical illness during the last few years. His home conditions are not favourable in so far as his relatives are over-anxious and over-protective. He never mixed with other children while he was small and developed an anxiety neurosis as soon as he started school. At present it seems advisable for him to go to school mornings only and our Social Worker will get in touch with the teacher to discuss the problem of improving his adjustment at school. He will also need to have psychotherapy for a considerable period and I have arranged for him to come to the Clinic once a week.\" Had aptosis which the doctor could not account for – encephalitis? – now all right. His mother was 15 or 16 when he was born and his father was the same age. A peculiar family, all a little queer. They were entertainers.\"</th>\n",
       "      <th>Scope and Contents</th>\n",
       "      <th>EUA_IN1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41051.0</td>\n",
       "      <td>EUA_IN1_46900.txt</td>\n",
       "      <td>2654.0</td>\n",
       "      <td>3519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" \"No control\", was definitely silly, attended Special Class for a time. Nomadic family, have now moved? Should be in an institution? Got into trouble for window breaking, a hopeless looking child. Illegitimate.\"Relatives in survey: Mother 7.52; sibling 7.14</th>\n",
       "      <th>Scope and Contents</th>\n",
       "      <th>EUA_IN1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31584.0</td>\n",
       "      <td>EUA_IN1_47600.txt</td>\n",
       "      <td>3077.0</td>\n",
       "      <td>3336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" \"No just thorough, light-headed\". Has been on a charge for stealing a bicycle which he destroyed; also suspected of breaking shop windows but this was never proved. Sits for hours in front of the fire with his head in his hands. Solitary, no mates. Now working in the mill. Father, decent. Mother dead. Siblings all OK. Steady work record.\"</th>\n",
       "      <th>Scope and Contents</th>\n",
       "      <th>EUA_IN1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34014.0</td>\n",
       "      <td>EUA_IN1_47200.txt</td>\n",
       "      <td>9976.0</td>\n",
       "      <td>10319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" \"This appears to be a reaction to her mother's fostering and mollycoddling. The mother appears to be convinced that her daughter is physcially and nervously much below par and even during a short interview it was obvious that she constantly strengthens these tendencies in her daughtr, so much so that the girl herself is now convinced that she is unable to stand up to everyday life\". Dr confirms - spoilt by mother, complains of tiredness and backache. PC - very decent family, give no trouble.\"</th>\n",
       "      <th>Scope and Contents</th>\n",
       "      <th>EUA_IN1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63099.0</td>\n",
       "      <td>EUA_IN1_41900.txt</td>\n",
       "      <td>7301.0</td>\n",
       "      <td>7801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"\"A big fat dirty lump\" - Dr. Nurse says she is decent but never gets out of the bit. Dr says she is \"haughly\".\"Husband 18.20, son 18.22</th>\n",
       "      <th>Scope and Contents</th>\n",
       "      <th>EUA_IN1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30479.0</td>\n",
       "      <td>EUA_IN1_38200.txt</td>\n",
       "      <td>3666.0</td>\n",
       "      <td>3803.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               desc_id_old  \\\n",
       "description                                        field              eadid                  \n",
       "\" \"He is an immature looking boy who has had a ... Scope and Contents EUA_IN1          NaN   \n",
       "\" \"No control\", was definitely silly, attended ... Scope and Contents EUA_IN1          NaN   \n",
       "\" \"No just thorough, light-headed\". Has been on... Scope and Contents EUA_IN1          NaN   \n",
       "\" \"This appears to be a reaction to her mother'... Scope and Contents EUA_IN1          NaN   \n",
       "\"\"A big fat dirty lump\" - Dr. Nurse says she is... Scope and Contents EUA_IN1          NaN   \n",
       "\n",
       "                                                                              label  \\\n",
       "description                                        field              eadid           \n",
       "\" \"He is an immature looking boy who has had a ... Scope and Contents EUA_IN1   NaN   \n",
       "\" \"No control\", was definitely silly, attended ... Scope and Contents EUA_IN1   NaN   \n",
       "\" \"No just thorough, light-headed\". Has been on... Scope and Contents EUA_IN1   NaN   \n",
       "\" \"This appears to be a reaction to her mother'... Scope and Contents EUA_IN1   NaN   \n",
       "\"\"A big fat dirty lump\" - Dr. Nurse says she is... Scope and Contents EUA_IN1   NaN   \n",
       "\n",
       "                                                                               desc_id_new  \\\n",
       "description                                        field              eadid                  \n",
       "\" \"He is an immature looking boy who has had a ... Scope and Contents EUA_IN1      41051.0   \n",
       "\" \"No control\", was definitely silly, attended ... Scope and Contents EUA_IN1      31584.0   \n",
       "\" \"No just thorough, light-headed\". Has been on... Scope and Contents EUA_IN1      34014.0   \n",
       "\" \"This appears to be a reaction to her mother'... Scope and Contents EUA_IN1      63099.0   \n",
       "\"\"A big fat dirty lump\" - Dr. Nurse says she is... Scope and Contents EUA_IN1      30479.0   \n",
       "\n",
       "                                                                                            file  \\\n",
       "description                                        field              eadid                        \n",
       "\" \"He is an immature looking boy who has had a ... Scope and Contents EUA_IN1  EUA_IN1_46900.txt   \n",
       "\" \"No control\", was definitely silly, attended ... Scope and Contents EUA_IN1  EUA_IN1_47600.txt   \n",
       "\" \"No just thorough, light-headed\". Has been on... Scope and Contents EUA_IN1  EUA_IN1_47200.txt   \n",
       "\" \"This appears to be a reaction to her mother'... Scope and Contents EUA_IN1  EUA_IN1_41900.txt   \n",
       "\"\"A big fat dirty lump\" - Dr. Nurse says she is... Scope and Contents EUA_IN1  EUA_IN1_38200.txt   \n",
       "\n",
       "                                                                               desc_start_offset  \\\n",
       "description                                        field              eadid                        \n",
       "\" \"He is an immature looking boy who has had a ... Scope and Contents EUA_IN1             2654.0   \n",
       "\" \"No control\", was definitely silly, attended ... Scope and Contents EUA_IN1             3077.0   \n",
       "\" \"No just thorough, light-headed\". Has been on... Scope and Contents EUA_IN1             9976.0   \n",
       "\" \"This appears to be a reaction to her mother'... Scope and Contents EUA_IN1             7301.0   \n",
       "\"\"A big fat dirty lump\" - Dr. Nurse says she is... Scope and Contents EUA_IN1             3666.0   \n",
       "\n",
       "                                                                               desc_end_offset  \n",
       "description                                        field              eadid                     \n",
       "\" \"He is an immature looking boy who has had a ... Scope and Contents EUA_IN1           3519.0  \n",
       "\" \"No control\", was definitely silly, attended ... Scope and Contents EUA_IN1           3336.0  \n",
       "\" \"No just thorough, light-headed\". Has been on... Scope and Contents EUA_IN1          10319.0  \n",
       "\" \"This appears to be a reaction to her mother'... Scope and Contents EUA_IN1           7801.0  \n",
       "\"\"A big fat dirty lump\" - Dr. Nurse says she is... Scope and Contents EUA_IN1           3803.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

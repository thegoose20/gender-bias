{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs the files:\n",
    "  * `annot-post/data/descriptions_with_counts.csv`: adds columns to `descriptions.csv` for word counts and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `annot-post/data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Loading\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Descriptions\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "### 0. Loading\n",
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # import custom functions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = \"data/\"\n",
    "# data_files = [\"aggregated_final.csv\", \"aggregated_with_annotator_eadid_note_cols.csv\", \n",
    "#               \"aggregated_with_eadid_descid_desc_cols.csv\", \"descriptions.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(dir_path+data_files[2], index_col=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Rows:\",df.shape[0], \"\\nColumns:\",df.shape[1])  # Rows: 55260, Columns: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_path = \"../data/crc_metadata/all_descriptions.csv\"     # descriptions in column of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid                                        description  \\\n",
       "0   AA5  Professor James Aitken White was a leading Sco...   \n",
       "1   AA5  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "2   AA6  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "3   AA6            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "4   AA7  Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                       field  desc_id  \n",
       "0  Biographical / Historical        0  \n",
       "1                      Title        1  \n",
       "2  Biographical / Historical        2  \n",
       "3                      Title        3  \n",
       "4  Biographical / Historical        4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(descs_path, index_col=0)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove metadata field name from each description\n",
    "# new_descs = []\n",
    "# descs = list(desc_df.description)\n",
    "# fields = list(desc_df.field)\n",
    "# i = 0\n",
    "# maxI = len(descs)\n",
    "# while i < maxI:\n",
    "#     d, f = descs[i], fields[i]\n",
    "#     to_remove = f+\":\\n\"\n",
    "#     d = d.replace(to_remove,\"\")\n",
    "#     new_descs += [d]\n",
    "#     i += 1\n",
    "# assert len(new_descs) == len(descs)\n",
    "# # new_descs[:10]            # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Update the CSV file\n",
    "# desc_df.description = new_descs\n",
    "# desc_df.head()\n",
    "# desc_df.to_csv(descs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each description to a txt file named with desc_id\n",
    "ids = list(desc_df.desc_id)\n",
    "zero_padding = len(str(ids[-1]))\n",
    "desc_txt_dir = \"data/descriptions/\"\n",
    "i, maxI = 0, len(ids)\n",
    "while i < maxI:\n",
    "    d_id = str(ids[i])\n",
    "    padding = zero_padding - len(d_id)  # pad with zeros so file order aligns with DataFrame order\n",
    "    id_str = (\"0\"*padding) + d_id\n",
    "    filename = \"description\"+id_str+\".txt\"\n",
    "    f = open((desc_txt_dir+filename), \"w\", encoding=\"utf8\")\n",
    "    f.write(new_descs[i])\n",
    "    f.close()\n",
    "    i += 1\n",
    "print(\"Files written to \"+desc_txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader(\"data/descriptions/\", \"description\\d+.txt\", encoding=\"utf8\")\n",
    "# print(len(corpus.fileids()), desc_df.shape[0])  # Looks good\n",
    "print(corpus.fileids()[-20:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good\n",
    "# len(desc_sents[2]) # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.insert(len(desc_df.columns), \"word_count\", word_count)\n",
    "desc_df.insert(len(desc_df.columns), \"sent_count\", sent_count)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"descriptions_with_counts.csv\")  # write a new CSV file with the word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.reset_index()\n",
    "desc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", desc_df)\n",
    "desc_df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengths per Metadata Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Biographical / Historical\"\n",
    "bh_stats = utils.makeDescribeDf(field, desc_df)\n",
    "bh_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Scope and Contents\"\n",
    "sc_stats = utils.makeDescribeDf(field, desc_df)\n",
    "sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Processing Information\"\n",
    "pi_stats = utils.makeDescribeDf(field, desc_df)\n",
    "pi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Title\"\n",
    "t_stats = utils.makeDescribeDf(field, desc_df)\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for visualization in Observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descs = pd.read_csv(\"../data/analysis_data/descriptions_with_counts.csv\", index_col=0)\n",
    "df_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "### 2. Offsets of Descriptions\n",
    "\n",
    "**Get the start and end offset of every description so that automated labels can be exported as .ann files for visualization with brat.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we need to determinen the intermediate start and end offsets as well, which we'll add as a column to the file `../data/crc_metadata/all_descriptions.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>AA6</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA6_00100.ann</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>AA6</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.ann</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>AA7</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA7_00100.ann</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    desc_id eadid                      field           file  \\\n",
       "0         0   AA5  Biographical / Historical  AA5_00100.ann   \n",
       "6         1   AA5                      Title  AA5_00100.ann   \n",
       "19        2   AA6  Biographical / Historical  AA6_00100.ann   \n",
       "50        3   AA6                      Title  AA6_00100.ann   \n",
       "62        4   AA7  Biographical / Historical  AA7_00100.ann   \n",
       "\n",
       "                                          description  \n",
       "0   Professor James Aitken White was a leading Sco...  \n",
       "6   Papers of The Very Rev Prof James Whyte (1920-...  \n",
       "19  Rev Thomas Allan was born on 16 August 1916 in...  \n",
       "50            Papers of Rev Tom Allan (1916-1965)\\n\\n  \n",
       "62  Alec Cheyne was born on 1 June 1924 in Errol i...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/aggregated_data/aggregated_with_eadid_descid_desc_cols.csv\"\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "df = df.drop(columns=[\"offsets\",\"text\",\"label\",\"category\",\"id\"])\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = list(df.description)\n",
    "ann_files = list(set(list(df.file)))\n",
    "# Replace .ann with .txt in each file's name\n",
    "txt_files = [f[:-4]+\".txt\" for f in ann_files]\n",
    "file_dict = dict(zip(txt_files,ann_files))\n",
    "assert file_dict[\"AA5_00100.txt\"] == \"AA5_00100.ann\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_start_offsets, desc_end_offsets = [], []\n",
    "start_offset, end_offset = 0, 0\n",
    "desc_id_order = []\n",
    "for filename in txt_files:\n",
    "    with open(doc_path+filename, \"r\") as f:\n",
    "        f_string = f.read()\n",
    "        subdf = df.loc[df.file == file_dict[filename]]\n",
    "        descs = list(subdf.description)\n",
    "        desc_ids = list(subdf.desc_id)\n",
    "        desc_id_order = desc_id_order+desc_ids\n",
    "        for d in descs:\n",
    "            # If there is no description text, don't record\n",
    "            # any offsets, instead record 'None'\n",
    "            if type(d) != str:\n",
    "                desc_start_offsets += [None]\n",
    "                desc_end_offsets += [None]\n",
    "            # If there is text for this description, use the index of the first\n",
    "            # character of the text as the start offset and the index of the character\n",
    "            # immediately following the last character of the text as the end offset\n",
    "            else:\n",
    "                start_offset = f_string.find(d)\n",
    "                # Make sure the description is found in the file \n",
    "                # (if str.find(substr) == -1, the substring wasn't found)\n",
    "                if (start_offset >= 0):\n",
    "                    end_offset = start_offset+len(d)+1\n",
    "                    desc_start_offsets += [start_offset]\n",
    "                    desc_end_offsets += [end_offset]\n",
    "                else:\n",
    "                    desc_start_offsets += [\"not_found\"]\n",
    "                    desc_end_offsets += [\"not_found\"]\n",
    "    f.close()\n",
    "assert len(desc_start_offsets) == len(descriptions)\n",
    "assert len(desc_end_offsets) == len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>284</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>592</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>726</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>765</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>832</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id desc_start_offset desc_end_offset\n",
       "0       59               284             337\n",
       "1       60               592             647\n",
       "2       61               726             759\n",
       "3       62               765             826\n",
       "4       63               832             898"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_df = pd.DataFrame({\"desc_id\":desc_id_order, \"desc_start_offset\":desc_start_offsets, \"desc_end_offset\":desc_end_offsets})\n",
    "offset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>24</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA6_00100.ann</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>588</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.ann</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA7_00100.ann</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>445</td>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        eadid                      field           file  \\\n",
       "desc_id                                                   \n",
       "0         AA5  Biographical / Historical  AA5_00100.ann   \n",
       "1         AA5                      Title  AA5_00100.ann   \n",
       "2         AA6  Biographical / Historical  AA6_00100.ann   \n",
       "3         AA6                      Title  AA6_00100.ann   \n",
       "4         AA7  Biographical / Historical  AA7_00100.ann   \n",
       "\n",
       "                                               description desc_start_offset  \\\n",
       "desc_id                                                                        \n",
       "0        Professor James Aitken White was a leading Sco...               661   \n",
       "1        Papers of The Very Rev Prof James Whyte (1920-...                24   \n",
       "2        Rev Thomas Allan was born on 16 August 1916 in...               588   \n",
       "3                  Papers of Rev Tom Allan (1916-1965)\\n\\n                24   \n",
       "4        Alec Cheyne was born on 1 June 1924 in Errol i...               445   \n",
       "\n",
       "        desc_end_offset  \n",
       "desc_id                  \n",
       "0                  1724  \n",
       "1                    78  \n",
       "2                  2512  \n",
       "3                    62  \n",
       "4                  2441  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = df.set_index(\"desc_id\").join(offset_df.set_index(\"desc_id\"))\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (joined.loc[joined.desc_start_offset == None]).shape[0] == 0\n",
    "assert (joined.loc[joined.desc_end_offset == None]).shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34118, 6)\n",
      "(11, 6)\n"
     ]
    }
   ],
   "source": [
    "joined_found = joined.loc[(joined.desc_start_offset != \"not_found\")]\n",
    "joined_notfound = joined.loc[(joined.desc_start_offset == \"not_found\")]\n",
    "\n",
    "# Check that any \"not_found\" start offsets have correspondings \"not_found\" end offsets\n",
    "joined_found_end = joined.loc[(joined.desc_end_offset != \"not_found\")]\n",
    "assert joined_found_end.shape == joined_found.shape\n",
    "joined_notfound_end = joined.loc[(joined.desc_end_offset == \"not_found\")]\n",
    "assert joined_notfound_end.shape == joined_notfound.shape\n",
    "\n",
    "print(joined_found.shape)\n",
    "print(joined_notfound.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Coll-1036</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00500.ann</td>\n",
       "      <td>Miscellaneous proofs of Songs of the Hebrides,...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Coll-1036</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00500.ann</td>\n",
       "      <td>Miscellaneous proofs of Songs of the Hebrides,...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Coll-1036</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00700.ann</td>\n",
       "      <td>Miscellaneous proofs of Songs of the Hebrides,...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Coll-1036</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00700.ann</td>\n",
       "      <td>Miscellaneous proofs of Songs of the Hebrides,...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Coll-1057</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00400.ann</td>\n",
       "      <td>Page mounted with photograph of the farm of F....</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>Coll-13</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-13_00900.ann</td>\n",
       "      <td>Plan of Roofing of the Building at the South W...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>Coll-13</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-13_01300.ann</td>\n",
       "      <td>Plan of the socket, section, plan elevation an...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>Coll-1320</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1320_01600.ann</td>\n",
       "      <td>Contains:\\nletters concerning the reproduction...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>Coll-1434</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-1434_13300.ann</td>\n",
       "      <td>William White Anderson was born on 17 March 18...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-146_12100.ann</td>\n",
       "      <td>Robert McCheyne was born in Edinburgh on 21 Ma...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-146_21400.ann</td>\n",
       "      <td>James Kirkwood was born in Dunbar, East Lothia...</td>\n",
       "      <td>not_found</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eadid                      field                 file  \\\n",
       "desc_id                                                              \n",
       "591      Coll-1036         Scope and Contents  Coll-1036_00500.ann   \n",
       "591      Coll-1036         Scope and Contents  Coll-1036_00500.ann   \n",
       "591      Coll-1036         Scope and Contents  Coll-1036_00700.ann   \n",
       "591      Coll-1036         Scope and Contents  Coll-1036_00700.ann   \n",
       "732      Coll-1057                      Title  Coll-1057_00400.ann   \n",
       "2261       Coll-13         Scope and Contents    Coll-13_00900.ann   \n",
       "2274       Coll-13         Scope and Contents    Coll-13_01300.ann   \n",
       "3501     Coll-1320         Scope and Contents  Coll-1320_01600.ann   \n",
       "5197     Coll-1434  Biographical / Historical  Coll-1434_13300.ann   \n",
       "7804      Coll-146  Biographical / Historical   Coll-146_12100.ann   \n",
       "9478      Coll-146  Biographical / Historical   Coll-146_21400.ann   \n",
       "\n",
       "                                               description desc_start_offset  \\\n",
       "desc_id                                                                        \n",
       "591      Miscellaneous proofs of Songs of the Hebrides,...         not_found   \n",
       "591      Miscellaneous proofs of Songs of the Hebrides,...         not_found   \n",
       "591      Miscellaneous proofs of Songs of the Hebrides,...         not_found   \n",
       "591      Miscellaneous proofs of Songs of the Hebrides,...         not_found   \n",
       "732      Page mounted with photograph of the farm of F....         not_found   \n",
       "2261     Plan of Roofing of the Building at the South W...         not_found   \n",
       "2274     Plan of the socket, section, plan elevation an...         not_found   \n",
       "3501     Contains:\\nletters concerning the reproduction...         not_found   \n",
       "5197     William White Anderson was born on 17 March 18...         not_found   \n",
       "7804     Robert McCheyne was born in Edinburgh on 21 Ma...         not_found   \n",
       "9478     James Kirkwood was born in Dunbar, East Lothia...         not_found   \n",
       "\n",
       "        desc_end_offset  \n",
       "desc_id                  \n",
       "591           not_found  \n",
       "591           not_found  \n",
       "591           not_found  \n",
       "591           not_found  \n",
       "732           not_found  \n",
       "2261          not_found  \n",
       "2274          not_found  \n",
       "3501          not_found  \n",
       "5197          not_found  \n",
       "7804          not_found  \n",
       "9478          not_found  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_notfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid                                        description  \\\n",
       "0   AA5  Professor James Aitken White was a leading Sco...   \n",
       "1   AA5  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "2   AA6  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "3   AA6            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "4   AA7  Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                       field  desc_id  \n",
       "0  Biographical / Historical        0  \n",
       "1                      Title        1  \n",
       "2  Biographical / Historical        2  \n",
       "3                      Title        3  \n",
       "4  Biographical / Historical        4  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs_path = \"../data/crc_metadata/all_descriptions.csv\"\n",
    "descs_df = pd.read_csv(descs_path, index_col=0)\n",
    "descs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "all_desc_ids = list(descs_df.desc_id)\n",
    "joinedfound_desc_ids = list(joined_found.index)\n",
    "missing = [d for d in all_desc_ids if d not in joinedfound_desc_ids]\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Coll-1000</td>\n",
       "      <td>Compiled by Graeme D. Eddie, Edinburgh Univers...</td>\n",
       "      <td>Processing Information</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Coll-1010</td>\n",
       "      <td>Compiled by Graeme D. Eddie, Edinburgh Univers...</td>\n",
       "      <td>Processing Information</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Coll-1014</td>\n",
       "      <td>Compiled by Graeme D. Eddie, Edinburgh Univers...</td>\n",
       "      <td>Processing Information</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Coll-1018</td>\n",
       "      <td>Compiled by Graeme D. Eddie, Edinburgh Univers...</td>\n",
       "      <td>Processing Information</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Coll-1024</td>\n",
       "      <td>Compiled by Graeme D. Eddie, Edinburgh Univers...</td>\n",
       "      <td>Processing Information</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         eadid                                        description  \\\n",
       "469  Coll-1000  Compiled by Graeme D. Eddie, Edinburgh Univers...   \n",
       "481  Coll-1010  Compiled by Graeme D. Eddie, Edinburgh Univers...   \n",
       "483  Coll-1014  Compiled by Graeme D. Eddie, Edinburgh Univers...   \n",
       "488  Coll-1018  Compiled by Graeme D. Eddie, Edinburgh Univers...   \n",
       "531  Coll-1024  Compiled by Graeme D. Eddie, Edinburgh Univers...   \n",
       "\n",
       "                      field  desc_id  \n",
       "469  Processing Information      469  \n",
       "481  Processing Information      481  \n",
       "483  Processing Information      483  \n",
       "488  Processing Information      488  \n",
       "531  Processing Information      531  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = descs_df.loc[descs_df.desc_id.isin(missing)]\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [eadid, description, field, desc_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df.loc[missing_df.description.isna() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no empty descriptions.\n",
    "\n",
    "To retrieve the remaining file names and offsets, use the `eadid` column values to find the possible files each missing description could be in, then locate that description by its offsets within one of those files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"../data/crc_metadata/descriptions_brat/\"\n",
    "file_type = \".txt\"  # Read in only the PlainText files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll-227_00100.txt', 'La_03600.txt', 'PJM_03000.txt', 'La_07300.txt', 'Coll-1434_07400.txt', 'Coll-1434_03100.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(doc_path)\n",
    "filenames = [f for f in filenames if f[-4:] == file_type] # the descriptions are in the txt files\n",
    "print(filenames[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "eadids = list(missing_df.eadid)\n",
    "descs = list(missing_df.description)\n",
    "fields = list(missing_df.field)\n",
    "desc_ids = list(missing_df.desc_id)\n",
    "missing_eadids, missing_descs, missing_fields, missing_desc_ids = [], [], [], []\n",
    "missing_filenames, desc_start_offsets, desc_end_offsets = [], [], []\n",
    "for i,d in enumerate(descs):\n",
    "    eadid = eadids[i]\n",
    "    for filename in filenames:\n",
    "        if eadid in filename:\n",
    "            # Make sure each description is associated with ONE file only\n",
    "            if filename not in missing_filenames:\n",
    "                with open(doc_path+filename, \"r\") as f:\n",
    "                    f_string = f.read()\n",
    "                    # Use the index of the first character of the text as the start offset\n",
    "                    # and the index of the character immediately following the last \n",
    "                    # character of the text as the end offset\n",
    "                    start_offset = f_string.find(d)\n",
    "                    # Make sure the description is found in the file \n",
    "                    # (if str.find(substr) == -1, the substring wasn't found)\n",
    "                    if (start_offset >= 0):\n",
    "                        end_offset = start_offset+len(d)+1\n",
    "                        desc_start_offsets += [start_offset]\n",
    "                        desc_end_offsets += [end_offset]\n",
    "                        missing_filenames += [filename]\n",
    "                        missing_eadids += [eadid]\n",
    "                        missing_descs += [d]\n",
    "                        missing_desc_ids += [desc_ids[i]]\n",
    "                        missing_fields += [fields[i]]\n",
    "                    f.close()\n",
    "        \n",
    "\n",
    "assert len(missing_filenames) == len(desc_start_offsets)\n",
    "assert len(missing_filenames) == len(desc_end_offsets)\n",
    "# NOTE: descriptions can be repeated within the same collection (identified with an eadid),\n",
    "# so there can be more missing_filenames than there were rows in missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11892</th>\n",
       "      <td>Coll-1310</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1310_01900.txt</td>\n",
       "      <td>\\n</td>\n",
       "      <td>302</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11892</th>\n",
       "      <td>Coll-1310</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1310_02400.txt</td>\n",
       "      <td>\\n</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11892</th>\n",
       "      <td>Coll-1310</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1310_02600.txt</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11892</th>\n",
       "      <td>Coll-1310</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1310_00200.txt</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11893</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-146_28800.txt</td>\n",
       "      <td>TS signed1p. At head of paper: E Gellhorn, MD ...</td>\n",
       "      <td>728</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eadid               field                 file  \\\n",
       "desc_id                                                       \n",
       "11892    Coll-1310               Title  Coll-1310_01900.txt   \n",
       "11892    Coll-1310               Title  Coll-1310_02400.txt   \n",
       "11892    Coll-1310               Title  Coll-1310_02600.txt   \n",
       "11892    Coll-1310               Title  Coll-1310_00200.txt   \n",
       "11893     Coll-146  Scope and Contents   Coll-146_28800.txt   \n",
       "\n",
       "                                               description  desc_start_offset  \\\n",
       "desc_id                                                                         \n",
       "11892                                                   \\n                302   \n",
       "11892                                                   \\n                 19   \n",
       "11892                                                   \\n                  0   \n",
       "11892                                                   \\n                  0   \n",
       "11893    TS signed1p. At head of paper: E Gellhorn, MD ...                728   \n",
       "\n",
       "         desc_end_offset  \n",
       "desc_id                   \n",
       "11892                304  \n",
       "11892                 21  \n",
       "11892                  2  \n",
       "11892                  2  \n",
       "11893                913  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df_with_offsets = pd.DataFrame({\"desc_id\":missing_desc_ids, \"eadid\":missing_eadids, \n",
    "                                        \"field\":missing_fields, \"file\":missing_filenames, \n",
    "                                        \"description\":missing_descs, \"desc_start_offset\":desc_start_offsets, \n",
    "                                        \"desc_end_offset\":desc_end_offsets})\n",
    "missing_df_with_offsets = missing_df_with_offsets.set_index(\"desc_id\")\n",
    "missing_df_with_offsets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty descriptions: 30\n",
      "Eadids of empty descriptions: ['Coll-1310']\n",
      "Files of empty descriptions:\n",
      " ['Coll-1310_01700.txt' 'Coll-1310_02800.txt' 'Coll-1310_01500.txt'\n",
      " 'Coll-1310_00800.txt' 'Coll-1310_01100.txt' 'Coll-1310_01300.txt'\n",
      " 'Coll-1310_01400.txt' 'Coll-1310_02900.txt' 'Coll-1310_03000.txt'\n",
      " 'Coll-1310_01600.txt' 'Coll-1310_01200.txt' 'Coll-1310_00900.txt'\n",
      " 'Coll-1310_01000.txt' 'Coll-1310_02100.txt' 'Coll-1310_00500.txt'\n",
      " 'Coll-1310_00700.txt' 'Coll-1310_02300.txt' 'Coll-1310_02700.txt'\n",
      " 'Coll-1310_00300.txt' 'Coll-1310_00100.txt' 'Coll-1310_02500.txt'\n",
      " 'Coll-1310_01800.txt' 'Coll-1310_00600.txt' 'Coll-1310_02200.txt'\n",
      " 'Coll-1310_02000.txt' 'Coll-1310_00400.txt' 'Coll-1310_01900.txt'\n",
      " 'Coll-1310_02400.txt' 'Coll-1310_02600.txt' 'Coll-1310_00200.txt']\n"
     ]
    }
   ],
   "source": [
    "empty_descs_df = missing_df_with_offsets.loc[missing_df_with_offsets.description == \"\\n\"]\n",
    "print(\"Total empty descriptions:\",empty_descs_df.shape[0])\n",
    "print(\"Eadids of empty descriptions:\",empty_descs_df.eadid.unique())\n",
    "print(\"Files of empty descriptions:\\n\",empty_descs_df.file.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO:** manually add the correct titles into these files!\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>24</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA6_00100.ann</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>588</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.ann</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA7_00100.ann</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>445</td>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        eadid                      field           file  \\\n",
       "desc_id                                                   \n",
       "0         AA5  Biographical / Historical  AA5_00100.ann   \n",
       "1         AA5                      Title  AA5_00100.ann   \n",
       "2         AA6  Biographical / Historical  AA6_00100.ann   \n",
       "3         AA6                      Title  AA6_00100.ann   \n",
       "4         AA7  Biographical / Historical  AA7_00100.ann   \n",
       "\n",
       "                                               description desc_start_offset  \\\n",
       "desc_id                                                                        \n",
       "0        Professor James Aitken White was a leading Sco...               661   \n",
       "1        Papers of The Very Rev Prof James Whyte (1920-...                24   \n",
       "2        Rev Thomas Allan was born on 16 August 1916 in...               588   \n",
       "3                  Papers of Rev Tom Allan (1916-1965)\\n\\n                24   \n",
       "4        Alec Cheyne was born on 1 June 1924 in Errol i...               445   \n",
       "\n",
       "        desc_end_offset  \n",
       "desc_id                  \n",
       "0                  1724  \n",
       "1                    78  \n",
       "2                  2512  \n",
       "3                    62  \n",
       "4                  2441  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_desc_offsets_df = pd.concat([joined_found,missing_df_with_offsets])\n",
    "all_desc_offsets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_desc_offsets_df.to_csv(\"../data/crc_metadata/all_descs_with_offsets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

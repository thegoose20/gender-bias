{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs the files:\n",
    "  * `../data/analysis_data/descriptions_with_counts.csv`: adds columns to `descriptions.csv` for word counts and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `../data/analysis_data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "  * `../data/crc_metadata/all_descs_with_offsets.csv`: contains one row for every description in the annotated datasets with columns for the descriptions' corresponding id, eadid, file, start offset, and end offset\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Loading\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Descriptions\n",
    "\n",
    "[3.](#3) Offsets of Tokens\n",
    "    \n",
    "  * [BIO Tags](#3.1)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "### 0. Loading\n",
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # import custom functions\n",
    "import config # import directory path variables\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_path = config.crc_meta_path+\"all_descriptions.csv\"     # descriptions in column of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid                                        description  \\\n",
       "0   AA5  Professor James Aitken White was a leading Sco...   \n",
       "1   AA5  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "2   AA6  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "3   AA6            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "4   AA7  Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                       field  desc_id  \n",
       "0  Biographical / Historical        0  \n",
       "1                      Title        1  \n",
       "2  Biographical / Historical        2  \n",
       "3                      Title        3  \n",
       "4  Biographical / Historical        4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(descs_path, index_col=0)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove metadata field name from each description\n",
    "# new_descs = []\n",
    "# descs = list(desc_df.description)\n",
    "# fields = list(desc_df.field)\n",
    "# i = 0\n",
    "# maxI = len(descs)\n",
    "# while i < maxI:\n",
    "#     d, f = descs[i], fields[i]\n",
    "#     to_remove = f+\":\\n\"\n",
    "#     d = d.replace(to_remove,\"\")\n",
    "#     new_descs += [d]\n",
    "#     i += 1\n",
    "# assert len(new_descs) == len(descs)\n",
    "# # new_descs[:10]            # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Update the CSV file\n",
    "# desc_df.description = new_descs\n",
    "# desc_df.head()\n",
    "# desc_df.to_csv(descs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each description to a txt file named with desc_id\n",
    "ids = list(desc_df.desc_id)\n",
    "descs = list(desc_df.description)\n",
    "desc_txt_dir = config.crc_meta_path+\"descriptions_brat/\"\n",
    "utils.strToTxt(ids, descs, \"description\", desc_txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader(desc_txt_dir, \"description\\d+.txt\", encoding=\"utf8\")\n",
    "# print(len(corpus.fileids()), desc_df.shape[0])  # Looks good\n",
    "print(corpus.fileids()[-20:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good\n",
    "# len(desc_sents[2]) # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.insert(len(desc_df.columns), \"word_count\", word_count)\n",
    "desc_df.insert(len(desc_df.columns), \"sent_count\", sent_count)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"descriptions_with_counts.csv\")  # write a new CSV file with the word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.reset_index()\n",
    "desc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", desc_df)\n",
    "desc_df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengths per Metadata Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Biographical / Historical\"\n",
    "bh_stats = utils.makeDescribeDf(field, desc_df)\n",
    "bh_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Scope and Contents\"\n",
    "sc_stats = utils.makeDescribeDf(field, desc_df)\n",
    "sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Processing Information\"\n",
    "pi_stats = utils.makeDescribeDf(field, desc_df)\n",
    "pi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Title\"\n",
    "t_stats = utils.makeDescribeDf(field, desc_df)\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for visualization in Observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descs = pd.read_csv(\"../data/analysis_data/descriptions_with_counts.csv\", index_col=0)\n",
    "df_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Offsets of Descriptions\n",
    "\n",
    "**Get the start and end offset of every description so that automated labels can be exported as .ann files for visualization with brat.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we need to determinen the intermediate start and end offsets as well, which we'll add as a column to the file `../data/crc_metadata/all_descriptions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-block alert-class alert-warning\">\n",
    "    <p><b>NOTE:</b> Need to re-assign description IDs to files in annotation_data directory (already reassigned to crc_metadata and aggregated_data files)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = \".txt\"  # Read in only the PlainText files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll-227_00100.txt', 'La_03600.txt', 'PJM_03000.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(config.doc_path)\n",
    "filenames = [f for f in filenames if f[-4:] == file_type] # the descriptions are in the txt files\n",
    "print(filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_details = utils.getDescriptionsInFiles(config.doc_path, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now create a DataFrame of the description data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_col = list(descs_details.keys())\n",
    "desc_col, field_col, file_col, eadid_col, start_offset_col, end_offset_col = [], [], [], [], [], []\n",
    "for desc_id in ids_col:\n",
    "    desc_dict = descs_details[desc_id]\n",
    "    \n",
    "    eadid = (re.findall(\"^.*(?=_\\d+.txt)\", desc_dict[\"file\"]))[0]\n",
    "    eadid_col += [eadid]\n",
    "    \n",
    "    field_col += [desc_dict[\"field\"]]\n",
    "    \n",
    "    file_col += [desc_dict[\"file\"]]\n",
    "    \n",
    "    desc_col += [desc_dict[\"description\"]]\n",
    "    \n",
    "    start_offset_col += [desc_dict[\"start_offset\"]]\n",
    "    end_offset_col += [desc_dict[\"end_offset\"]]\n",
    "\n",
    "new_descs_df = pd.DataFrame({\n",
    "    \"desc_id\":ids_col, \"eadid\":eadid_col, \"field\":field_col, \"file\":file_col, \n",
    "    \"description\":desc_col, \"desc_start_offset\":start_offset_col, \"desc_end_offset\":end_offset_col\n",
    "})\n",
    "\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_descs_df.to_csv(config.crc_meta_path+\"descs_with_offsets.csv\")\n",
    "new_descs_df = pd.read_csv(config.crc_meta_path+\"descs_with_offsets.csv\", index_col=0)\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assign description IDs from this DataFrame to the aggregated annotated datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.read_csv(config.agg_path+\"desc_field_descid_label_eadid.csv\", index_col=0)\n",
    "# df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id_x</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id_y</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>Title</td>\n",
       "      <td>68</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>143</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family photographs consist of:photographs of f...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>221</td>\n",
       "      <td>{'Masculine', 'Unknown', 'Feminine'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>81505</td>\n",
       "      <td>BAI_01600.txt</td>\n",
       "      <td>5967</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence and related items, including le...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>292</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>33009</td>\n",
       "      <td>BAI_01900.txt</td>\n",
       "      <td>5297</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From 1927-1930 John Baillie was Professor of S...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>361</td>\n",
       "      <td>{'Gendered-Pronoun', 'Unknown', 'Masculine', '...</td>\n",
       "      <td>BAI</td>\n",
       "      <td>43372</td>\n",
       "      <td>BAI_02200.txt</td>\n",
       "      <td>15180</td>\n",
       "      <td>15419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                           John Baillie: posthumous   \n",
       "1  Letters received from Henry Sloane Coffin, wit...   \n",
       "2  Family photographs consist of:photographs of f...   \n",
       "3  Correspondence and related items, including le...   \n",
       "4  From 1927-1930 John Baillie was Professor of S...   \n",
       "\n",
       "                       field  desc_id_x  \\\n",
       "0                      Title         68   \n",
       "1         Scope and Contents        143   \n",
       "2         Scope and Contents        221   \n",
       "3         Scope and Contents        292   \n",
       "4  Biographical / Historical        361   \n",
       "\n",
       "                                               label eadid  desc_id_y  \\\n",
       "0                                        {'Unknown'}   BAI      70381   \n",
       "1                           {'Masculine', 'Unknown'}   BAI      47675   \n",
       "2               {'Masculine', 'Unknown', 'Feminine'}   BAI      81505   \n",
       "3                                        {'Unknown'}   BAI      33009   \n",
       "4  {'Gendered-Pronoun', 'Unknown', 'Masculine', '...   BAI      43372   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01600.txt               5967             6202  \n",
       "3  BAI_01900.txt               5297             5506  \n",
       "4  BAI_02200.txt              15180            15419  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_grouped.merge(new_descs_df, left_on=[\"description\", \"field\", \"eadid\"], right_on=[\"description\", \"field\", \"eadid\"])\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now we want to keep the *right* DataFrame's description IDs, so we'll drop `desc_id_x` and remove the `_y` from `desc_id_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>Title</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family photographs consist of:photographs of f...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown', 'Feminine'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>81505</td>\n",
       "      <td>BAI_01600.txt</td>\n",
       "      <td>5967</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence and related items, including le...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>33009</td>\n",
       "      <td>BAI_01900.txt</td>\n",
       "      <td>5297</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From 1927-1930 John Baillie was Professor of S...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>{'Gendered-Pronoun', 'Unknown', 'Masculine', '...</td>\n",
       "      <td>BAI</td>\n",
       "      <td>43372</td>\n",
       "      <td>BAI_02200.txt</td>\n",
       "      <td>15180</td>\n",
       "      <td>15419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                           John Baillie: posthumous   \n",
       "1  Letters received from Henry Sloane Coffin, wit...   \n",
       "2  Family photographs consist of:photographs of f...   \n",
       "3  Correspondence and related items, including le...   \n",
       "4  From 1927-1930 John Baillie was Professor of S...   \n",
       "\n",
       "                       field  \\\n",
       "0                      Title   \n",
       "1         Scope and Contents   \n",
       "2         Scope and Contents   \n",
       "3         Scope and Contents   \n",
       "4  Biographical / Historical   \n",
       "\n",
       "                                               label eadid  desc_id  \\\n",
       "0                                        {'Unknown'}   BAI    70381   \n",
       "1                           {'Masculine', 'Unknown'}   BAI    47675   \n",
       "2               {'Masculine', 'Unknown', 'Feminine'}   BAI    81505   \n",
       "3                                        {'Unknown'}   BAI    33009   \n",
       "4  {'Gendered-Pronoun', 'Unknown', 'Masculine', '...   BAI    43372   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01600.txt               5967             6202  \n",
       "3  BAI_01900.txt               5297             5506  \n",
       "4  BAI_02200.txt              15180            15419  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged.drop(columns=[\"desc_id_x\"])\n",
    "df_merged = df_merged.rename(columns={\"desc_id_y\":\"desc_id\"})\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(config.agg_path+\"desc_field_descid_label_eadid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Offsets of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scope and Contents:\n",
      "Letters of congratulation to staff members on their work and external appointments.\n",
      "\n",
      "Scope and Contents:\n",
      "Correspondence about planning and budgeting issues for the Student Advisory and Counselling Service (SACS), about an individual student complaint about how SACS had dealt with her case, about the management structure and staffing of SACS. Includes a copy of the 1992/93 SACS annual report.\n",
      "\n",
      "Scope and Contents:\n",
      "Copy of the University's submissions to the 2001 Research Assessment Exercise for Classics, Ancient History, Byzantine and Modern Greek Studies, Archaeology, History, History of Art, Architecture and Design, and Philosophy.\n",
      "\n",
      "Scope and Contents:\n",
      "Certificate of Social Study 1948. File contains: Enrolment form, correspondence, job adverts for Supervisor of boarded out children for Fife County Council, Woman Assistant for County Public Assistance Officer for Gloucestershire County Council. Details of practical placements are located at the back of the file and include reports from Mary F. Gregor, South Bridge and James Clark Schools; Evelyn Buchan, District Secretary, Edinburgh Council of Social Service.\n",
      "\n",
      "Scope and Contents:\n",
      "Agendas, papers and minutes for meetings of the Business Committee, and correspondence about issues raised at the meetings.\n",
      "\n",
      "Scope and Contents:\n",
      "Copy of the University's submissions to the ESRC for their 1997 Submission Rates Survey, copy of the ESRC's Guidance Notes for Applicants and application forms for 1998 Studentships, and a list of Edinburgh's 1997 ESRC Studentship Allocations.\n",
      "\n",
      "Scope and Contents:\n",
      "Correspondence with other universities about a proposal for the development of the Connect programme (to support technology-based enterprise), correspondence about the arrangements for the 1995 Jubilee Lecture in the Department of Business Studies, correspondence about accreditation for the University's Management School's AMBA course.\n",
      "\n",
      "Scope and Contents:\n",
      "Dip. Social Study 1955. File contains: Enrolment form, application form, correspondence, placement reports.Thesis: \"A Study of the Household Expenditure in a Post-war Housing Scheme\" [NB a copy of this does not survive in the file].\n",
      "\n",
      "Scope and Contents:\n",
      "\"This woman is weakminded; has never been away from home, never able to work. She lives alone. Inherited £200 from her father. She is living on that. [Male informant] this girl was over-protected and spoilt by her parents; ended up bossing them completely, spent most of her time in bed, did not do any work. When they died her relations suggested the poorhouse - this had an excellent effect - she is now able to do her own shopping, but not yet able to work. [Female informant] confirms, when her mother died she was in bed for 3 weeks in all her clothes, and had had no attention. Sergt. says she will never be right, but imagines things. Dr - she did not go out of doors for 20 years. Her mother was crackers before she died.\"\n",
      "\n",
      "Scope and Contents:\n",
      "\"This man is a timber hauler. He was tested for the Navy - OT score 25. He is described as a poor-like creature, not robust, a bit slow on the uptake. Has a good work record. No information about relations. Home clean and tidy, not overcrowded, harmonious. No P.A. [Public Assistance]. Police Constable says these are very decent people but cannot add anything. Doctor -  not too bad, quite sensible.\"\n",
      "\n",
      "Scope and Contents:\n",
      "Notes of discussions between the Principal, Vice-Principals, Secretary and the Deans of various Faculties.\n",
      "\n",
      "Scope and Contents:\n",
      "Large format chart showing breakdown of cases according to home conditions, illegitimacy, overcrowding, family life, and delinquency.\n",
      "\n",
      "Scope and Contents:\n",
      "Interview postponed for a number of months until son returns.\n",
      "\n",
      "Scope and Contents:\n",
      "'This girl is said to be odd-looking, filthy, steals, always on the roads, chased German prisoners. A tinker, has been sleeping out. Very deepset eyes. Recently walked from Penpont to Ecclefechan in the snow. It took her a week, sleeping in barns etc.'Relatives in survey: Mother 20.10 father 20.9 siblings 20.14, 20.16, 20.12, 20.11\n",
      "\n",
      "Scope and Contents:\n",
      "Varied correspondence including Scottish enterprise funding docs for Microelectronics Imaging and Analysis Centre\n",
      "\n",
      "Scope and Contents:\n",
      "'Bible of Documents' - lever arch file containing copies of documentation pertaining to the bid\n",
      "\n",
      "Scope and Contents:\n",
      "\"This woman has something queer about her. Several children \"a great squatter of daughters\" all with illegitimate children and all a nuisance. Housing was appalling, now quite good.\"\n",
      "\n",
      "Scope and Contents:\n",
      "Copies of the University of Hong Kong Bulletin and the University of New South Wales Uniken newsletter issued in 2000, correspondence about improving student mobility between U21 universities, copies of event programmes and minutes for the meetings of various U21 groups, and correspondence about the visit of an academic from another U21 university to Edinburgh.\n",
      "\n",
      "Scope and Contents:\n",
      "Cuttings from The Times newspaper relating mainly to industry, trade and employment.ContentsBook I: Children and Young Persons; Co-operation and Profit Sharing; Drink; Education., 1925-1937Book II: Emigration; Factories; Finance; Food Prices, 1925-1939\tBook III: Housing, 1925-1938\t Book IV: Industries - Cotton, 1925-1938Book V: Industries - Coal, 1925-1938\tBook VI: Industries, 1925-1938 Book VII: Industrial Hours and Wages, 1926-1938 Book VIII: Industry and Trade, 1927-1939 Book IX: Industries Abroad, 1927-1933Book X: International Labour Legislation; Local Government; Mental Deficiency; Penal Reform, 1925-1936Book XI: Poor Law; Population; Public Health, 1925-1938 Book XII: Social Insurance; Social Service; Trade Unions; Transport, 1925-1933\tBook XIII: Unemployment, 1925-1938Book XIV: Welfare; Women in Industry; Miscellaneous, 1925-1938Cuttings relating to parliamentary debate on Unemployment Assistance, July 1936, 1936-1937\tIndex\n",
      "\n",
      "Scope and Contents:\n",
      "\"Admitted CRI. High grade imbecile. Working in the laundry. Rate-aided.\"Parents: 18.64, 18.62\n",
      "\n",
      "Scope and Contents:\n",
      "File contains: Enrolment from and letter of reference from The City of Glasgow Society of Social Service.\n",
      "\n",
      "Scope and Contents:\n",
      "N/A\n",
      "\n",
      "Scope and Contents:\n",
      "\"This boy is very nervy. Excitable, highly strung, always tumbling about the house.\"\n",
      "\n",
      "Scope and Contents:\n",
      "Topics discussed include: Living accommodation; extended family; neighbourhood and quarrels about children; Gorgie; work; money; leisure; shopping.The interview was conducted entirely on the doorstep which INTVER notes is a difficulty for unannounced calls in particular when the interviewer is male and interviewee female. She lives with her husband and three children (8, 5 and 3 yrs) in a three-apartment ground floor flat in a block of four. They previously lived in furnished rooms for £2 10s a week, they had no bath but an inside WC but it got too overcrowded with the children so applied for a corporation house. She prefers their new house, it is not as noisy, there are fewer children and more old people but not as handy for the shops. The bedrooms can be cold, the heating is through a back boiler fire in the sitting room. INTVEE says she likes to be by herself but INTVER thinks she is quite lonely and typical of a home-tied young mother with children to keep her at home but not enough to interest her there. INTVEE says there are always rows with the neighbours about the children. There are 13 children on her stair and 18 on the stair next door. She received no information about the house or neighbourhood before moving in.  Her husband goes out to work early and comes back at 8 or 9 at night, he is active in the union. She thinks he has settled better and likes the neighbourhood but he doesn't have to live in it all day. She would like to go out to work part time when her youngest goes to school. The woman across the road looks after children during the day and three of them are coloured - their parents work at the university, there is also a coloured teacher at the new West Pilton School and she is very good. These are the only coloured people she is aware of, she thinks it's stupid that some people don't want to mix with them.  On child discipline she is quoted as saying \"Well if they absolutely just won't do what they're told I do hit them\". Generally she thinks children are much cheekier than they used to be and parents don't seem to care. They have not been on holiday this year but she thinks it is important to have regular holidays, they like hiring a car and caravan and going round the highlands. Her husband earns £14 a week and gives her £7 a week. She likes the television - she watches Wagon Train and Emergency Ward 10. She feels a bit guilty about letting her children stay up in their pyjamas to watch the television, they go to bed when it finishes at 9.30pm. She shops at Hays in Davidsons Mains because it's cheaper.\n",
      "\n",
      "Scope and Contents:\n",
      "File contains: enrolment form, Institute of Hospital Almoners application form.\n",
      "\n",
      "Scope and Contents:\n",
      "Draft copy of a University-level Risk Register, draft copy of a Risk Register for Administration, Communications and Student Services Support Group together with comments on the draft, correspondence about new management arrangements for Student Services, and correspondence about the provision of student support services for Edinburgh College of Art students.\n",
      "\n",
      "Scope and Contents:\n",
      "Note by Monica Rushforth on labour allocation at Leith Docks.\n",
      "\n",
      "Scope and Contents:\n",
      "INTVEEs live in a ten-storey block of flats. They are married with no children. INTVER describes the common vestibule as \"scrappy looking, draughty and bare, the name board has an incongruous air of quality\". The flat is described as \"pleasantly deocrated in the modern style and well furnished with rugs and sitting suite and table and nice new wireless and 17\" television.  INTVER explains to the INTVEEs that the project aims to study the changing patterns of suburban life, life and work in the district from the point of view of both residents and the services and organised groups in the area. Their rent is £1. 19. 7d a week which they think is expensive. It is a two apartment flat with bathroom and kitchen. The noise transmission is very bad up and down the stairs, the noise deadening sideways is very good.  They think people would move out if given the chance, the house is alright but surroundings are important, people with children spoil it for others. The corporation says children are not allowed to play in the grounds of the flats themselves and should go through to the playing fields but mothers don't send their children there because they were not sure they would come back in one piece. They can't send small children out because of other tough children in the neighbourhood. INTVER suggests their views aren't typical because they have had experience of better areas. They don't think people in the district are poor but think that they don't have the same ideas on controlling children or looking after the district as they do. They think residents are selfish, they don't seem to care about the effect of what they do on other people. INTVEEs have a car but have to constantly check on it. They moved in 10 months after the flats had been built, the lifts were a novelty and kids kept playing in them. They think the flats should have a caretaker and complain about the layout - the flats have four entrances and are too open which encourages kids to use them as pathways. There is however very little damage, some chalking on the walls, and this is down to the vigilance of the few who bother. They have asked for a transfer but have been told they don't have a chance unless they have a doctor's certificate. They think the council policy of grouping rough people all together, for example at Niddrie after Lochinvar Camp was cleared, is very bad. Boys take a short cut through the back gardens of the Swedish houses near the little road bridge that goes from Pilton Gardens to Crewe Road North. The corporation put up chestnut paling to stop them, there used to be chestnut palings in the semi-circle by the shops opposite the flats. The shops here put a halfpenny or penny on all the prices. They refer to a screening process which they had to pass before getting the flat, if they had failed they thought they would be sent to Niddrie, they thought people should be mixed up. The only people who've managed to keep a garden have managed to do it by standing in the garden with a shotgun. Female INTVEE says she always opens her front door wide, but others don't - they are afraid of gossip or that people will peer in and see what's going on inside. There is a lot of gossip, it's easy to see into the kitchen door and through a flat. Their dream is to find a little cottage that needs done up. They moved in in 1958. They had previously lived in a room in Leith. It wasn't very nice, they paid 35/- a week. They found it odd adjusting to not always being in the same room as each other after they moved.\n",
      "\n",
      "Scope and Contents:\n",
      "13.01: Burgess, M A, Silent Reading Scale, 1922;13.02: Gray, W.S, Oral Reading Paragraphs, c1920s;13.03: Oglesby, E F, Detroit Word Recognition Test, 1925-1929;13.04: Fleming, C M, P A Reading I, c mid 20th century;13.06: Haggerty, M.E, Reading Examination, 1920;13.06: Haggerty, M E, Standard Educational Tests, Reading, 1920;13.08: Lee and Clark, Reading Readiness Test, 1943;13.09: Misc Reading Tests, c1950s;13.10: Kelley et al., New Stanford Reading Test, 1929;13.11: First Grade Word Reading Test, c1950s;13.12: Sangren-Woody Reading Test, 1927-1928;13.13: Schonell, Prose Reading Test, 1940;13.14: Stone, R S, Narrative Reading Tests, 1922;13.16: Van Wagenen Reading Scales, c1950s;13.17: Northumberland Reading, 7+ assessment, c1950s;13.18: ACER Reading Tests, c1950s;13.20: ACER Test Division Catalogue, 1950-1954;13.21: ACER Test News, 1953;13.22: Schonell Reading Tests, c1950s;13.40: South African reading tests and associated literature, 1947-1948;13.40: South Africa, report of the National Council of Social Research, and tests regarding silent reading, comprehension, verbal reasoning, 1947-1948.\n",
      "\n",
      "Scope and Contents:\n",
      "References to IRCs in; atmospheric science, deep crustal studies, environmental change, land use, marine science\n",
      "\n",
      "Scope and Contents:\n",
      "\"Admitted CRI as a private patient, voluntary. Senile Dementia. Husband died many years ago. Had been living alone for several years. then tried living with her son and his wife - this was unsuccessful and there was much quarrelling - then admitted to CRI. Fractured wrist.\"\n",
      "\n",
      "Scope and Contents:\n",
      "\"This man never would work, was a \"street corner boy\". Now in the army, not a very good soldier, dodges everything, hates continuity. Deserted. For a time his wife thought he was dead and drew a widow's pension. Dr confirms that this lad is unsatisfactory, never had a job for any length of time. Was a blackshirt.\"\n",
      "\n",
      "Scope and Contents:\n",
      "'This lad is at present a tractor driver. Before that he embezzled some money which his aunt paid up for him. He is lazy and dull.'Relatives in survey: Mother 19.20, siblings 19.22, 19.24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(config.crc_meta_path+\"all_descriptions.csv\", index_col=0)\n",
    "# df.loc[df.desc_id == 57361]\n",
    "files = os.listdir(\"../data/crc_metadata/descriptions_brat/\")\n",
    "assert \"EUA_IN1_56700.txt\" in files\n",
    "with open(\"../data/crc_metadata/descriptions_brat/EUA_IN1_56700.txt\", \"r\") as f:\n",
    "    f_string = f.read()\n",
    "    print(f_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc = pd.read_csv(config.crc_meta_path+\"descs_with_offsets.csv\", index_col=0)\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57361</th>\n",
       "      <td>57361</td>\n",
       "      <td>EUA_IN1</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>EUA_IN1_56700.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6137</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc_id    eadid               field               file description  \\\n",
       "57361    57361  EUA_IN1  Scope and Contents  EUA_IN1_56700.txt         NaN   \n",
       "\n",
       "       desc_start_offset  desc_end_offset  \n",
       "57361               6137             6141  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.loc[df_desc.description.isna() == True]\n",
    "# df_desc.loc[df_desc.description == \"N/A\"]\n",
    "# df_desc.loc[df_desc.file == \"EUA_IN1_56700.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57361</th>\n",
       "      <td>57361</td>\n",
       "      <td>EUA_IN1</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>EUA_IN1_56700.txt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>6137</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc_id    eadid               field               file description  \\\n",
       "57361    57361  EUA_IN1  Scope and Contents  EUA_IN1_56700.txt         N/A   \n",
       "\n",
       "       desc_start_offset  desc_end_offset  \n",
       "57361               6137             6141  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.description = df_desc.description.fillna(\"N/A\")\n",
    "df_desc.loc[df_desc.desc_id == 57361]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Write the corrected description to the `descs_with_offsets.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_desc.to_csv(config.crc_meta_path+\"descs_with_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the offsets of the tokens in every description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = list(df_desc.description)\n",
    "desc_ids = list(df_desc.desc_id)\n",
    "desc_start_offsets = list(df_desc.desc_start_offset)\n",
    "desc_end_offsets = list(df_desc.desc_end_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dict, offsets_dict = getTokensAndOffsetsFromStrings(descs, desc_ids, desc_start_offsets, desc_end_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_col, offsets_col, desc_ids_col = [], [], []\n",
    "for desc_id,token_list in tokens_dict.items():\n",
    "    tokens_col += token_list\n",
    "    offsets_list = offsets_dict[desc_id]\n",
    "    offsets_col += offsets_list\n",
    "    assert len(token_list) == len(offsets_list)\n",
    "    desc_ids_col += [desc_id]*len(token_list)\n",
    "\n",
    "assert len(tokens_col) == len(offsets_col)\n",
    "assert len(tokens_col) == len(desc_ids_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Records', 'of', 'the', 'Phrenological', 'Society']\n",
      "[(29, 36), (37, 39), (40, 43), (44, 57), (58, 65)]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for col_list in [tokens_col, offsets_col, desc_ids_col]:\n",
    "    print(col_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  Now create a DataFrame with these lists as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Records</td>\n",
       "      <td>(29, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>(37, 39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>(40, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Phrenological</td>\n",
       "      <td>(44, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Society</td>\n",
       "      <td>(58, 65)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id          token   offsets\n",
       "0        0        Records  (29, 36)\n",
       "1        0             of  (37, 39)\n",
       "2        0            the  (40, 43)\n",
       "3        0  Phrenological  (44, 57)\n",
       "4        0        Society  (58, 65)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.DataFrame({\"desc_id\":desc_ids_col, \"token\":tokens_col, \"offsets\":offsets_col})\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2239703</th>\n",
       "      <td>88596</td>\n",
       "      <td>on</td>\n",
       "      <td>(465, 467)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239704</th>\n",
       "      <td>88596</td>\n",
       "      <td>12</td>\n",
       "      <td>(468, 470)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239705</th>\n",
       "      <td>88596</td>\n",
       "      <td>January</td>\n",
       "      <td>(471, 478)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239706</th>\n",
       "      <td>88596</td>\n",
       "      <td>1937</td>\n",
       "      <td>(479, 483)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239707</th>\n",
       "      <td>88596</td>\n",
       "      <td>.</td>\n",
       "      <td>(483, 484)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         desc_id    token     offsets\n",
       "2239703    88596       on  (465, 467)\n",
       "2239704    88596       12  (468, 470)\n",
       "2239705    88596  January  (471, 478)\n",
       "2239706    88596     1937  (479, 483)\n",
       "2239707    88596        .  (483, 484)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now write the DataFrame to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.to_csv(config.agg_path+\"descid_token_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### 3.1 BIO Tags\n",
    "\n",
    "Compare the descriptions' tokens' offsets to the annotated text spans' offsets to determine which tokens to mark as the beginning of an annotation (`B-[LABELNAME]`), inside an annotation (`I-[LABELNAME]`), and unannotated, or outisde of an annotation (`O`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s15/s1545703/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_tokens = pd.read_csv(config.agg_path+\"descid_token_offsets.csv\", index_col=0)\n",
    "token_desc_ids = list(df_tokens.desc_id)\n",
    "tokens = list(df_tokens.token)\n",
    "token_offsets = list(df_tokens.offsets)\n",
    "token_offsets_clean = [offsets[1:-1].split(\", \") for offsets in token_offsets]\n",
    "token_offsets_tuples = [tuple((int(offsets[0]), int(offsets[1]))) for offsets in token_offsets_clean]\n",
    "# print(token_offsets_tuples[:5])  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>id</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>(1032, 1043)</td>\n",
       "      <td>James Whyte</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>(1129, 1177)</td>\n",
       "      <td>chair of practical theology and Christian ethics</td>\n",
       "      <td>Occupation</td>\n",
       "      <td>Contextual</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>(1217, 1219)</td>\n",
       "      <td>he</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>(1241, 1244)</td>\n",
       "      <td>His</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AA5_00100.ann</td>\n",
       "      <td>(1315, 1317)</td>\n",
       "      <td>he</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file       offsets  \\\n",
       "9   AA5_00100.ann  (1032, 1043)   \n",
       "16  AA5_00100.ann  (1129, 1177)   \n",
       "4   AA5_00100.ann  (1217, 1219)   \n",
       "5   AA5_00100.ann  (1241, 1244)   \n",
       "6   AA5_00100.ann  (1315, 1317)   \n",
       "\n",
       "                                                text             label  \\\n",
       "9                                        James Whyte         Masculine   \n",
       "16  chair of practical theology and Christian ethics        Occupation   \n",
       "4                                                 he  Gendered-Pronoun   \n",
       "5                                                His  Gendered-Pronoun   \n",
       "6                                                 he  Gendered-Pronoun   \n",
       "\n",
       "       category eadid                      field  id  desc_id  \n",
       "9   Person-Name   AA5  Biographical / Historical   0        0  \n",
       "16   Contextual   AA5  Biographical / Historical   1        0  \n",
       "4    Linguistic   AA5  Biographical / Historical   2        0  \n",
       "5    Linguistic   AA5  Biographical / Historical   3        0  \n",
       "6    Linguistic   AA5  Biographical / Historical   4        0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # cols_to_read = ['offsets_ann','text_ann','label','id', \"desc_id\"]\n",
    "# df_merged = pd.read_csv(config.agg_path+\"aggregated_with_eadid_descid_desc_cols.csv\", index_col=0)#usecols=cols_to_read)\n",
    "# # df_merged.sort_values(by=[\"desc_id\",\"desc_start_offset\"], ascending=True)\n",
    "# df_merged = df_merged.drop_duplicates()\n",
    "# df_merged.head()\n",
    "df_ann = pd.read_csv(config.agg_path+\"aggregated_with_eadid_descid_cols.csv\", index_col=0) #aggregated_final.csv\n",
    "df_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "NEED TO FIX MERGING OF ANNOTATIONS AND DESCRIPTIONS THEY'RE IN FOR ALL AGGREGATED DATA WITH DESCID OR DESC COLUMN!!!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file_ann</th>\n",
       "      <th>offsets_ann</th>\n",
       "      <th>text_ann</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>file_desc</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_00400.ann</td>\n",
       "      <td>(1279, 1295)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>39824</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5175</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_00400.ann</td>\n",
       "      <td>(1279, 1295)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>39824</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_07700.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_00400.ann</td>\n",
       "      <td>(1279, 1295)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>39824</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_03200.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14255</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_00400.ann</td>\n",
       "      <td>(1279, 1295)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>39824</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_05300.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17887</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_00400.ann</td>\n",
       "      <td>(1279, 1295)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>39824</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_01600.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19768703</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_14800.ann</td>\n",
       "      <td>(10, 26)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>44967</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_14200.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19773243</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_14800.ann</td>\n",
       "      <td>(10, 26)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>44967</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_10700.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19774151</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_14800.ann</td>\n",
       "      <td>(10, 26)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>44967</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_12300.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19782323</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_14800.ann</td>\n",
       "      <td>(10, 26)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>44967</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_08600.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19787771</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-146_14800.ann</td>\n",
       "      <td>(10, 26)</td>\n",
       "      <td>Koestler, Arthur</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>44967</td>\n",
       "      <td>Letter :: Koestler, Arthur</td>\n",
       "      <td>Coll-146_00300.txt</td>\n",
       "      <td>610</td>\n",
       "      <td>Coll-146_11200.txt</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2808 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             eadid  field            file_ann   offsets_ann          text_ann  \\\n",
       "3359      Coll-146  Title  Coll-146_00400.ann  (1279, 1295)  Koestler, Arthur   \n",
       "5175      Coll-146  Title  Coll-146_00400.ann  (1279, 1295)  Koestler, Arthur   \n",
       "6991      Coll-146  Title  Coll-146_00400.ann  (1279, 1295)  Koestler, Arthur   \n",
       "14255     Coll-146  Title  Coll-146_00400.ann  (1279, 1295)  Koestler, Arthur   \n",
       "17887     Coll-146  Title  Coll-146_00400.ann  (1279, 1295)  Koestler, Arthur   \n",
       "...            ...    ...                 ...           ...               ...   \n",
       "19768703  Coll-146  Title  Coll-146_14800.ann      (10, 26)  Koestler, Arthur   \n",
       "19773243  Coll-146  Title  Coll-146_14800.ann      (10, 26)  Koestler, Arthur   \n",
       "19774151  Coll-146  Title  Coll-146_14800.ann      (10, 26)  Koestler, Arthur   \n",
       "19782323  Coll-146  Title  Coll-146_14800.ann      (10, 26)  Koestler, Arthur   \n",
       "19787771  Coll-146  Title  Coll-146_14800.ann      (10, 26)  Koestler, Arthur   \n",
       "\n",
       "            label     category     id                 description  \\\n",
       "3359      Unknown  Person-Name  39824  Letter :: Koestler, Arthur   \n",
       "5175      Unknown  Person-Name  39824  Letter :: Koestler, Arthur   \n",
       "6991      Unknown  Person-Name  39824  Letter :: Koestler, Arthur   \n",
       "14255     Unknown  Person-Name  39824  Letter :: Koestler, Arthur   \n",
       "17887     Unknown  Person-Name  39824  Letter :: Koestler, Arthur   \n",
       "...           ...          ...    ...                         ...   \n",
       "19768703  Unknown  Person-Name  44967  Letter :: Koestler, Arthur   \n",
       "19773243  Unknown  Person-Name  44967  Letter :: Koestler, Arthur   \n",
       "19774151  Unknown  Person-Name  44967  Letter :: Koestler, Arthur   \n",
       "19782323  Unknown  Person-Name  44967  Letter :: Koestler, Arthur   \n",
       "19787771  Unknown  Person-Name  44967  Letter :: Koestler, Arthur   \n",
       "\n",
       "                   file_desc  desc_id                file  desc_start_offset  \\\n",
       "3359      Coll-146_11200.txt      610  Coll-146_11200.txt                127   \n",
       "5175      Coll-146_07700.txt      610  Coll-146_11200.txt                127   \n",
       "6991      Coll-146_03200.txt      610  Coll-146_11200.txt                127   \n",
       "14255     Coll-146_05300.txt      610  Coll-146_11200.txt                127   \n",
       "17887     Coll-146_01600.txt      610  Coll-146_11200.txt                127   \n",
       "...                      ...      ...                 ...                ...   \n",
       "19768703  Coll-146_14200.txt      610  Coll-146_11200.txt                127   \n",
       "19773243  Coll-146_10700.txt      610  Coll-146_11200.txt                127   \n",
       "19774151  Coll-146_12300.txt      610  Coll-146_11200.txt                127   \n",
       "19782323  Coll-146_08600.txt      610  Coll-146_11200.txt                127   \n",
       "19787771  Coll-146_00300.txt      610  Coll-146_11200.txt                127   \n",
       "\n",
       "          desc_end_offset  \n",
       "3359                  154  \n",
       "5175                  154  \n",
       "6991                  154  \n",
       "14255                 154  \n",
       "17887                 154  \n",
       "...                   ...  \n",
       "19768703              154  \n",
       "19773243              154  \n",
       "19774151              154  \n",
       "19782323              154  \n",
       "19787771              154  \n",
       "\n",
       "[2808 rows x 14 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tokens.loc[df_tokens.desc_id == 610]\n",
    "df_merged.loc[df_merged.desc_id == 610]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efficiency, create dictionaries with the DataFrames' data, associating text and offsets to description IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the opposite of DataFrame.explode(), creating one row with for each\n",
    "# value in the cols_to_groupby (list of one or more items) and lists of \n",
    "# values in the other columns, and setting the cols_to_groupby as the Index\n",
    "# or MultiIndex in the resulting DataFrame\n",
    "def implodeDataFrame(df, cols_to_groupby):\n",
    "    cols_to_agg = list(df.columns)\n",
    "    for col in cols_to_groupby:\n",
    "        cols_to_agg.remove(col)\n",
    "    agg_dict = dict.fromkeys(cols_to_agg, lambda x: x.tolist())\n",
    "    return df.groupby(cols_to_groupby).agg(agg_dict).reset_index().set_index(cols_to_groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                                   offsets  \n",
       "desc_id                                                     \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...  \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...  \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...  \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...  \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens_imploded = implodeDataFrame(df_tokens, [\"desc_id\"])\n",
    "df_tokens_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offsets_ann</th>\n",
       "      <th>text_ann</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[(1436, 1444), (1436, 1444)]</td>\n",
       "      <td>[Beardman, Beardman]</td>\n",
       "      <td>[Omission, Unknown]</td>\n",
       "      <td>[31928, 31929]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>[(3105, 3111)]</td>\n",
       "      <td>[editor]</td>\n",
       "      <td>[Occupation]</td>\n",
       "      <td>[28226]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>[(1279, 1295), (1279, 1295), (1279, 1295), (12...</td>\n",
       "      <td>[Koestler, Arthur, Koestler, Arthur, Koestler,...</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown, Unknown, ...</td>\n",
       "      <td>[39824, 39824, 39824, 39824, 39824, 39824, 398...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>[(1279, 1295), (1279, 1295), (1279, 1295), (12...</td>\n",
       "      <td>[Koestler, Arthur, Koestler, Arthur, Koestler,...</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown, Unknown, ...</td>\n",
       "      <td>[39824, 39824, 39824, 39824, 39824, 39824, 398...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>[(2118, 2122), (2118, 2127), (2118, 2127), (22...</td>\n",
       "      <td>[Lady, Lady Luck, Lady Luck, Weaver, Warren]</td>\n",
       "      <td>[Gendered-Role, Stereotype, Feminine, Unknown]</td>\n",
       "      <td>[43620, 43621, 43622, 43623]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               offsets_ann  \\\n",
       "desc_id                                                      \n",
       "167                           [(1436, 1444), (1436, 1444)]   \n",
       "508                                         [(3105, 3111)]   \n",
       "610      [(1279, 1295), (1279, 1295), (1279, 1295), (12...   \n",
       "611      [(1279, 1295), (1279, 1295), (1279, 1295), (12...   \n",
       "640      [(2118, 2122), (2118, 2127), (2118, 2127), (22...   \n",
       "\n",
       "                                                  text_ann  \\\n",
       "desc_id                                                      \n",
       "167                                   [Beardman, Beardman]   \n",
       "508                                               [editor]   \n",
       "610      [Koestler, Arthur, Koestler, Arthur, Koestler,...   \n",
       "611      [Koestler, Arthur, Koestler, Arthur, Koestler,...   \n",
       "640           [Lady, Lady Luck, Lady Luck, Weaver, Warren]   \n",
       "\n",
       "                                                     label  \\\n",
       "desc_id                                                      \n",
       "167                                    [Omission, Unknown]   \n",
       "508                                           [Occupation]   \n",
       "610      [Unknown, Unknown, Unknown, Unknown, Unknown, ...   \n",
       "611      [Unknown, Unknown, Unknown, Unknown, Unknown, ...   \n",
       "640         [Gendered-Role, Stereotype, Feminine, Unknown]   \n",
       "\n",
       "                                                        id  \n",
       "desc_id                                                     \n",
       "167                                         [31928, 31929]  \n",
       "508                                                [28226]  \n",
       "610      [39824, 39824, 39824, 39824, 39824, 39824, 398...  \n",
       "611      [39824, 39824, 39824, 39824, 39824, 39824, 398...  \n",
       "640                           [43620, 43621, 43622, 43623]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_imploded = implodeDataFrame(df_merged, [\"desc_id\"])\n",
    "df_merged_imploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: O tags**\n",
    "\n",
    "Compare description IDs in the two DataFrames above to determine which descriptions (from `df_tokens_imploded`) do not have annotations (thus are are not in `df_merged_imploded`), and assign all those descriptions' tokens an `O` tag (for *outside* of an annotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign tag 'O': 86742\n"
     ]
    }
   ],
   "source": [
    "all_desc_ids = list(df_tokens_imploded.index)\n",
    "ann_desc_ids = list(df_merged_imploded.index)\n",
    "unannotated = [desc_id for desc_id in all_desc_ids if not desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign tag 'O':\", len(unannotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(unannotated)]\n",
    "assert o_df.shape[0] == len(unannotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "      <th>ann_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                                   offsets  \\\n",
       "desc_id                                                      \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...   \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...   \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...   \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...   \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...   \n",
       "\n",
       "                                                   ann_tag  \n",
       "desc_id                                                     \n",
       "0                                    [O, O, O, O, O, O, O]  \n",
       "1        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list = list(o_df.token)\n",
    "tags = [[\"O\"]*len(tokens) for tokens in tokens_list]\n",
    "assert len(tags) == len(tokens_list)\n",
    "o_df.insert(len(o_df.columns), \"ann_tag\", tags)\n",
    "o_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(o_df.token[100]) == len(o_df.ann_tag[100])\n",
    "assert len(o_df.token[488]) == len(o_df.ann_tag[488])\n",
    "assert len(o_df.token[0]) == len(o_df.ann_tag[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: B- and I- tags**\n",
    "\n",
    "For description IDs that do have annotations (and thus are in `df_merged_imploded`), assign their tokens tags of `B-[LABELNAME]` and `I-[LABELNAME]` for *beginning* and *inside* of an annotation, replacing `[LABELNAME]` with the name of the annotation's label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign 'B-' or 'I-'': 1855\n"
     ]
    }
   ],
   "source": [
    "annotated = [desc_id for desc_id in all_desc_ids if desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign 'B-' or 'I-'':\", len(annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(annotated)]\n",
    "assert bi_df.shape[0] == len(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[Brick, Burning, ,, Beardman, 's]</td>\n",
       "      <td>[(1421, 1426), (1427, 1434), (1434, 1435), (14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>[Interpreting, sequence, motifs, [, Letter, to...</td>\n",
       "      <td>[(3064, 3076), (3077, 3085), (3086, 3092), (30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>[Lady, Luck, :, the, theory, of, probability, ...</td>\n",
       "      <td>[(2118, 2122), (2123, 2127), (2127, 2128), (21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "167                      [Brick, Burning, ,, Beardman, 's]   \n",
       "508      [Interpreting, sequence, motifs, [, Letter, to...   \n",
       "610                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "611                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "640      [Lady, Luck, :, the, theory, of, probability, ...   \n",
       "\n",
       "                                                   offsets  \n",
       "desc_id                                                     \n",
       "167      [(1421, 1426), (1427, 1434), (1434, 1435), (14...  \n",
       "508      [(3064, 3076), (3077, 3085), (3086, 3092), (30...  \n",
       "610      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "611      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "640      [(2118, 2122), (2123, 2127), (2127, 2128), (21...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Brick', 'Burning', ',', 'Beardman', \"'s\"], 'offsets': ['(1421, 1426)', '(1427, 1434)', '(1434, 1435)', '(1436, 1444)', '(1444, 1446)']}\n"
     ]
    }
   ],
   "source": [
    "bi_dict = bi_df.to_dict('index')\n",
    "print(bi_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'offsets_ann': ['(1436, 1444)', '(1436, 1444)'], 'text_ann': ['Beardman', 'Beardman'], 'label': ['Omission', 'Unknown'], 'id': [31928, 31929]}\n"
     ]
    }
   ],
   "source": [
    "ann_dict = df_merged_imploded.to_dict('index')\n",
    "print(ann_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a string of offsets into a tuple with each offset of type int\n",
    "# \"(1436, 1444)\" --> (1436, 1444)\n",
    "def offsetsStrToTuple(offsets_str):\n",
    "    offsets_list = offsets_str[1:-1].split(\", \")\n",
    "    offsets_ints = [int(o) for o in offsets_list]\n",
    "    return tuple((offsets_ints))\n",
    "\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')) == tuple\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[0]) == int\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[1]) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned tags for 100 descriptions\n"
     ]
    }
   ],
   "source": [
    "desc_ids = list(bi_dict.keys())[:100]  # START WITH SAMPLE\n",
    "assert len(set(desc_ids)) == len(desc_ids)  # Make sure every description ID is unique\n",
    "log = 0\n",
    "descid_to_tag = dict.fromkeys(desc_ids)\n",
    "for desc_id in desc_ids:\n",
    "    text_spans = ann_dict[desc_id][\"text_ann\"]\n",
    "    desc_tokens = bi_dict[desc_id]['token']\n",
    "    desc_tokens_offsets = bi_dict[desc_id]['offsets']\n",
    "    desc_tags = []\n",
    "    for i,desc_token in enumerate(desc_tokens):\n",
    "        token_offset_pair = offsetsStrToTuple(desc_tokens_offsets[i])\n",
    "        span_indeces, tags = [], []  # Note: one token may have multiple tags\n",
    "        \n",
    "        # Record the indeces of every item in text_spans with the desc_token\n",
    "        for j,text_span in enumerate(text_spans):\n",
    "            span_offset_pair = offsetsStrToTuple(ann_dict[desc_id][\"offsets_ann\"][j])    \n",
    "            # Be sure a matching token's offsets are within the annotated text span\n",
    "            if (desc_token in text_span\n",
    "               ) and (\n",
    "                token_offset_pair[0] >= span_offset_pair[0]\n",
    "                ) and (\n",
    "                token_offset_pair[1] <= span_offset_pair[1]):\n",
    "                    span_indeces += [j] \n",
    "            else:\n",
    "                span_indeces += [\"unannotated\"]\n",
    "        for j in span_indeces:\n",
    "            # If the token is annotated, assign it a B- or I- tag with a label\n",
    "            if type(j) == int:\n",
    "            # If the start offsets are the same, assign a 'B-' tag\n",
    "                if token_offset_pair[0] == span_offset_pair[0]:\n",
    "                    tags += ['B-'+ann_dict[desc_id][\"label\"][j]]\n",
    "                # Otherwise, assign an 'I-' tag\n",
    "                else:\n",
    "                    tags += ['I-'+ann_dict[desc_id][\"label\"][j]]\n",
    "            # If the description token isn't annotated, assign it an O tag\n",
    "            elif j == \"unannotated\":\n",
    "                tags += [\"O\"]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid j value: {}\".format(j))\n",
    "        \n",
    "        desc_tags += [set(tags)]\n",
    "    \n",
    "    assert len(desc_tokens) == len(desc_tags)\n",
    "    descid_to_tag[desc_id] = desc_tags\n",
    "    \n",
    "    log += 1\n",
    "    if log % 100 == 0:\n",
    "        print(\"Assigned tags for {} descriptions\".format(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Letter', ':', ':', 'Koestler', ',', 'Arthur'], 'offsets': ['(127, 133)', '(134, 135)', '(135, 136)', '(137, 145)', '(145, 146)', '(147, 153)']}\n"
     ]
    }
   ],
   "source": [
    "did = 610 #508 #167\n",
    "# print(ann_dict[did])\n",
    "print(bi_dict[did])\n",
    "# print(descid_to_tag[did])\n",
    "\n",
    "# spans = ['Beardman', 'Beardman']\n",
    "# spans2 = [\"Brick Burning\"]\n",
    "# tokens = ['Brick', 'Burning', ',', 'Beardman', \"'s\"]\n",
    "# # print(spans.count('Beardman'))\n",
    "# # # print(spans.index('Beardman'))\n",
    "# # # print(tokens.index('Beardman'))\n",
    "# # for k in range(0,3):\n",
    "# #     print(k)\n",
    "# indeces = [index for index in range(len(spans)) if spans[index] == 'Beardman']\n",
    "# print(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m token \u001b[38;5;241m=\u001b[39m tokens[i]\n\u001b[1;32m      7\u001b[0m token_start, token_end \u001b[38;5;241m=\u001b[39m token_offsets_tuples[i][\u001b[38;5;241m0\u001b[39m], token_offsets_tuples[i][\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m----> 9\u001b[0m ann_df \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdesc_id\u001b[49m]\n\u001b[1;32m     10\u001b[0m ann_id_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m     11\u001b[0m ann_offsets_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39moffsets_ann)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:290\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:106\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    103\u001b[0m b_value \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mop_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m b_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_value\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# numexpr raises eg for array ** array with integers\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pydata/numexpr/issues/379)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/numexpr/necompiler.py:835\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m _numexpr_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ex\u001b[38;5;241m=\u001b[39mcompiled_ex, argnames\u001b[38;5;241m=\u001b[39mnames, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m evaluate_lock:\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# is_annotated_col = []\n",
    "# annotated_id = []\n",
    "# i, maxI = 0, len(token_desc_ids)  #1188478, 1189478\n",
    "# while i < maxI:\n",
    "#     desc_id = token_desc_ids[i]\n",
    "#     token = tokens[i]\n",
    "#     token_start, token_end = token_offsets_tuples[i][0], token_offsets_tuples[i][1] \n",
    "    \n",
    "#     ann_df = df_merged.loc[df_merged.desc_id == desc_id]\n",
    "#     ann_id_list = list(ann_df.id)\n",
    "#     ann_offsets_list = list(ann_df.offsets_ann)\n",
    "#     ann_offsets_clean = [ann_offsets[1:-1].split(\", \") for ann_offsets in ann_offsets_list]\n",
    "#     ann_offsets_tuples = [tuple((int(ann_offsets[0]), int(ann_offsets[1]))) for ann_offsets in ann_offsets_clean]\n",
    "    \n",
    "#     for j,ann_offsets in enumerate(ann_offsets_tuples):\n",
    "#         ann_start = ann_offsets[0]\n",
    "#         ann_end = ann_offsets[1]\n",
    "#         if token_start == ann_start:\n",
    "#             is_annotated_col += [\"B\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         elif (token_start > ann_start) and (token_start <= ann_end):\n",
    "#             is_annotated_col += [\"I\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         else:\n",
    "#             is_annotated_col += [\"O\"]\n",
    "#             annotated_id += [\"None\"]\n",
    "    \n",
    "#     i += 1\n",
    "\n",
    "# assert len(is_annotated_col) == len(token_desc_ids)\n",
    "# assert len(is_annotated_col) == len(annotated_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.insert(len(df_tokens.columns),\"is_annotated\",is_annotated_col)\n",
    "df_tokens.insert(len(df_tokens.columns),\"ann_id\",annotated_id)\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(is_annotated_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(annotated_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

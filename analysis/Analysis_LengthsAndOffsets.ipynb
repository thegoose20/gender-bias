{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs the files:\n",
    "  * `../data/analysis_data/descriptions_with_counts.csv`: adds columns to `descriptions.csv` for word counts and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `../data/analysis_data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "  * `../data/crc_metadata/all_descs_with_offsets.csv`: contains one row for every description in the annotated datasets with columns for the descriptions' corresponding id, eadid, file, start offset, and end offset\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Loading\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Descriptions\n",
    "\n",
    "[3.](#3) Offsets of Tokens\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "### 0. Loading\n",
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # import custom functions\n",
    "import config # import directory path variables\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_path = config.crc_meta_path+\"all_descriptions.csv\"     # descriptions in column of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid                                        description  \\\n",
       "0   AA5  Professor James Aitken White was a leading Sco...   \n",
       "1   AA5  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "2   AA6  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "3   AA6            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "4   AA7  Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                       field  desc_id  \n",
       "0  Biographical / Historical        0  \n",
       "1                      Title        1  \n",
       "2  Biographical / Historical        2  \n",
       "3                      Title        3  \n",
       "4  Biographical / Historical        4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(descs_path, index_col=0)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove metadata field name from each description\n",
    "# new_descs = []\n",
    "# descs = list(desc_df.description)\n",
    "# fields = list(desc_df.field)\n",
    "# i = 0\n",
    "# maxI = len(descs)\n",
    "# while i < maxI:\n",
    "#     d, f = descs[i], fields[i]\n",
    "#     to_remove = f+\":\\n\"\n",
    "#     d = d.replace(to_remove,\"\")\n",
    "#     new_descs += [d]\n",
    "#     i += 1\n",
    "# assert len(new_descs) == len(descs)\n",
    "# # new_descs[:10]            # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Update the CSV file\n",
    "# desc_df.description = new_descs\n",
    "# desc_df.head()\n",
    "# desc_df.to_csv(descs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each description to a txt file named with desc_id\n",
    "ids = list(desc_df.desc_id)\n",
    "descs = list(desc_df.description)\n",
    "desc_txt_dir = config.crc_meta_path+\"descriptions_brat/\"\n",
    "utils.strToTxt(ids, descs, \"description\", desc_txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader(desc_txt_dir, \"description\\d+.txt\", encoding=\"utf8\")\n",
    "# print(len(corpus.fileids()), desc_df.shape[0])  # Looks good\n",
    "print(corpus.fileids()[-20:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good\n",
    "# len(desc_sents[2]) # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.insert(len(desc_df.columns), \"word_count\", word_count)\n",
    "desc_df.insert(len(desc_df.columns), \"sent_count\", sent_count)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"descriptions_with_counts.csv\")  # write a new CSV file with the word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.reset_index()\n",
    "desc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", desc_df)\n",
    "desc_df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengths per Metadata Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Biographical / Historical\"\n",
    "bh_stats = utils.makeDescribeDf(field, desc_df)\n",
    "bh_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Scope and Contents\"\n",
    "sc_stats = utils.makeDescribeDf(field, desc_df)\n",
    "sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Processing Information\"\n",
    "pi_stats = utils.makeDescribeDf(field, desc_df)\n",
    "pi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Title\"\n",
    "t_stats = utils.makeDescribeDf(field, desc_df)\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for visualization in Observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descs = pd.read_csv(\"../data/analysis_data/descriptions_with_counts.csv\", index_col=0)\n",
    "df_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Offsets of Descriptions\n",
    "\n",
    "**Get the start and end offset of every description so that automated labels can be exported as .ann files for visualization with brat.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we need to determinen the intermediate start and end offsets as well, which we'll add as a column to the file `../data/crc_metadata/all_descriptions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-block alert-class alert-warning\">\n",
    "    <p><b>NOTE:</b> Need to re-assign description IDs to files in annotation_data directory (already reassigned to crc_metadata and aggregated_data files)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = \".txt\"  # Read in only the PlainText files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll-227_00100.txt', 'La_03600.txt', 'PJM_03000.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(config.doc_path)\n",
    "filenames = [f for f in filenames if f[-4:] == file_type] # the descriptions are in the txt files\n",
    "print(filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_names = [\"Title\", \"Scope and Contents\", \"Biographical / Historical\", \"Processing Information\"]\n",
    "            \n",
    "# INPUT: file path to a document of metadata descriptions (str)\n",
    "# OUTPUT: a dictionary of metadata description ids and the associated \n",
    "#         description text, field name and offsets contained in the input file\n",
    "def getDescriptionsInFiles(dirpath, file_list, fieldnames=metadata_field_names):\n",
    "    desc_dict = dict()\n",
    "    did = 0\n",
    "    for filename in file_list:\n",
    "\n",
    "        # Get a string of the input file's text (metadata descriptions)\n",
    "        f_string = open(os.path.join(dirpath+filename),'r').read()\n",
    "        \n",
    "        for fieldname in fieldnames:\n",
    "            pattern = \"(?<={}:\\n).+\".format(fieldname)\n",
    "            match_list = re.findall(pattern, f_string)\n",
    "            if len(match_list) > 0:\n",
    "                for match in match_list:\n",
    "                    desc_dict[did] = dict.fromkeys([\"description\", \"field\", \"file\", \"start_offset\", \"end_offset\"])\n",
    "                    desc_dict[did][\"description\"] = match\n",
    "                    desc_dict[did][\"field\"] = fieldname\n",
    "                    desc_dict[did][\"file\"] = filename\n",
    "                    desc_dict[did][\"start_offset\"] = f_string.find(match)\n",
    "                    desc_dict[did][\"end_offset\"] = f_string.find(match) + len(match) + 1\n",
    "                    did += 1\n",
    "                    \n",
    "    return desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_details = getDescriptionsInFiles(config.doc_path, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now create a DataFrame of the description data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_col = list(descs_details.keys())\n",
    "desc_col, field_col, file_col, eadid_col, start_offset_col, end_offset_col = [], [], [], [], [], []\n",
    "for desc_id in ids_col:\n",
    "    desc_dict = descs_details[desc_id]\n",
    "    \n",
    "    eadid = (re.findall(\"^.*(?=_\\d+.txt)\", desc_dict[\"file\"]))[0]\n",
    "    eadid_col += [eadid]\n",
    "    \n",
    "    field_col += [desc_dict[\"field\"]]\n",
    "    \n",
    "    file_col += [desc_dict[\"file\"]]\n",
    "    \n",
    "    desc_col += [desc_dict[\"description\"]]\n",
    "    \n",
    "    start_offset_col += [desc_dict[\"start_offset\"]]\n",
    "    end_offset_col += [desc_dict[\"end_offset\"]]\n",
    "\n",
    "new_descs_df = pd.DataFrame({\n",
    "    \"desc_id\":ids_col, \"eadid\":eadid_col, \"field\":field_col, \"file\":file_col, \n",
    "    \"description\":desc_col, \"desc_start_offset\":start_offset_col, \"desc_end_offset\":end_offset_col\n",
    "})\n",
    "\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_descs_df.to_csv(config.crc_meta_path+\"descs_with_offsets.csv\")\n",
    "new_descs_df = pd.read_csv(config.crc_meta_path+\"descs_with_offsets.csv\", index_col=0)\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assign description IDs from this DataFrame to the aggregated annotated datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.read_csv(config.agg_path+\"desc_field_descid_label_eadid.csv\", index_col=0)\n",
    "df_agg = pd.read_csv(config.agg_path+\"aggregated_with_eadid_descid_desc_cols.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id_x</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id_y</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>Title</td>\n",
       "      <td>68</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>143</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family photographs consist of:photographs of f...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>221</td>\n",
       "      <td>{'Masculine', 'Unknown', 'Feminine'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>81505</td>\n",
       "      <td>BAI_01600.txt</td>\n",
       "      <td>5967</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence and related items, including le...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>292</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>33009</td>\n",
       "      <td>BAI_01900.txt</td>\n",
       "      <td>5297</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From 1927-1930 John Baillie was Professor of S...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>361</td>\n",
       "      <td>{'Gendered-Pronoun', 'Unknown', 'Masculine', '...</td>\n",
       "      <td>BAI</td>\n",
       "      <td>43372</td>\n",
       "      <td>BAI_02200.txt</td>\n",
       "      <td>15180</td>\n",
       "      <td>15419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                           John Baillie: posthumous   \n",
       "1  Letters received from Henry Sloane Coffin, wit...   \n",
       "2  Family photographs consist of:photographs of f...   \n",
       "3  Correspondence and related items, including le...   \n",
       "4  From 1927-1930 John Baillie was Professor of S...   \n",
       "\n",
       "                       field  desc_id_x  \\\n",
       "0                      Title         68   \n",
       "1         Scope and Contents        143   \n",
       "2         Scope and Contents        221   \n",
       "3         Scope and Contents        292   \n",
       "4  Biographical / Historical        361   \n",
       "\n",
       "                                               label eadid  desc_id_y  \\\n",
       "0                                        {'Unknown'}   BAI      70381   \n",
       "1                           {'Masculine', 'Unknown'}   BAI      47675   \n",
       "2               {'Masculine', 'Unknown', 'Feminine'}   BAI      81505   \n",
       "3                                        {'Unknown'}   BAI      33009   \n",
       "4  {'Gendered-Pronoun', 'Unknown', 'Masculine', '...   BAI      43372   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01600.txt               5967             6202  \n",
       "3  BAI_01900.txt               5297             5506  \n",
       "4  BAI_02200.txt              15180            15419  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_grouped.merge(new_descs_df, left_on=[\"description\", \"field\", \"eadid\"], right_on=[\"description\", \"field\", \"eadid\"])\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now we want to keep the *right* DataFrame's description IDs, so we'll drop `desc_id_x` and remove the `_y` from `desc_id_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>Title</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family photographs consist of:photographs of f...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown', 'Feminine'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>81505</td>\n",
       "      <td>BAI_01600.txt</td>\n",
       "      <td>5967</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence and related items, including le...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>33009</td>\n",
       "      <td>BAI_01900.txt</td>\n",
       "      <td>5297</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From 1927-1930 John Baillie was Professor of S...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>{'Gendered-Pronoun', 'Unknown', 'Masculine', '...</td>\n",
       "      <td>BAI</td>\n",
       "      <td>43372</td>\n",
       "      <td>BAI_02200.txt</td>\n",
       "      <td>15180</td>\n",
       "      <td>15419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                           John Baillie: posthumous   \n",
       "1  Letters received from Henry Sloane Coffin, wit...   \n",
       "2  Family photographs consist of:photographs of f...   \n",
       "3  Correspondence and related items, including le...   \n",
       "4  From 1927-1930 John Baillie was Professor of S...   \n",
       "\n",
       "                       field  \\\n",
       "0                      Title   \n",
       "1         Scope and Contents   \n",
       "2         Scope and Contents   \n",
       "3         Scope and Contents   \n",
       "4  Biographical / Historical   \n",
       "\n",
       "                                               label eadid  desc_id  \\\n",
       "0                                        {'Unknown'}   BAI    70381   \n",
       "1                           {'Masculine', 'Unknown'}   BAI    47675   \n",
       "2               {'Masculine', 'Unknown', 'Feminine'}   BAI    81505   \n",
       "3                                        {'Unknown'}   BAI    33009   \n",
       "4  {'Gendered-Pronoun', 'Unknown', 'Masculine', '...   BAI    43372   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01600.txt               5967             6202  \n",
       "3  BAI_01900.txt               5297             5506  \n",
       "4  BAI_02200.txt              15180            15419  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged.drop(columns=[\"desc_id_x\"])\n",
    "df_merged = df_merged.rename(columns={\"desc_id_y\":\"desc_id\"})\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(config.agg_path+\"desc_field_descid_label_eadid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same operations on the aggregated dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file_ann</th>\n",
       "      <th>offsets_ann</th>\n",
       "      <th>text_ann</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>file_desc</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Title</td>\n",
       "      <td>BAI_01000.ann</td>\n",
       "      <td>(1290, 1302)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>211</td>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5875, 5894)</td>\n",
       "      <td>Henry Sloane Coffin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>524</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5925, 5936)</td>\n",
       "      <td>Hugh Martin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>525</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5951, 5963)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>526</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5951, 5963)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>527</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid               field       file_ann   offsets_ann             text_ann  \\\n",
       "0   BAI               Title  BAI_01000.ann  (1290, 1302)         John Baillie   \n",
       "1   BAI  Scope and Contents  BAI_01300.ann  (5875, 5894)  Henry Sloane Coffin   \n",
       "2   BAI  Scope and Contents  BAI_01300.ann  (5925, 5936)          Hugh Martin   \n",
       "3   BAI  Scope and Contents  BAI_01300.ann  (5951, 5963)         John Baillie   \n",
       "4   BAI  Scope and Contents  BAI_01300.ann  (5951, 5963)         John Baillie   \n",
       "\n",
       "       label     category   id  \\\n",
       "0    Unknown  Person-Name  211   \n",
       "1    Unknown  Person-Name  524   \n",
       "2    Unknown  Person-Name  525   \n",
       "3  Masculine  Person-Name  526   \n",
       "4    Unknown  Person-Name  527   \n",
       "\n",
       "                                         description      file_desc  desc_id  \\\n",
       "0                           John Baillie: posthumous  BAI_01000.txt    70381   \n",
       "1  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "2  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "3  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "4  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01300.txt               5853             5983  \n",
       "3  BAI_01300.txt               5853             5983  \n",
       "4  BAI_01300.txt               5853             5983  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_agg.merge(new_descs_df, left_on=[\"description\", \"field\", \"eadid\"], right_on=[\"description\", \"field\", \"eadid\"])\n",
    "df_merged = df_merged.drop(columns=[\"desc_id_x\"])\n",
    "df_merged = df_merged.rename(columns={\"desc_id_y\":\"desc_id\", \"file_x\":\"file_ann\", \"offsets\":\"offsets_ann\", \"file_y\":\"file_desc\", \"text\":\"text_ann\"})\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(config.agg_path+\"aggregated_with_eadid_descid_desc_cols.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Offsets of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv(config.agg_path+\"aggregated_with_eadid_descid_desc_cols.csv\")\n",
    "text_ann_list = list(df_merged.text_ann)\n",
    "ann_id_list = list(df_merged.id)\n",
    "desc_list = list(df_merged.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1290, 1302), (5875, 5894), (5925, 5936), (5951, 5963), (5951, 5963)]\n"
     ]
    }
   ],
   "source": [
    "ann_offsets_list = list(df_merged.offsets_ann)\n",
    "ann_offsets_clean = [ann_offsets[1:-1].split(\", \") for ann_offsets in ann_offsets_list]\n",
    "ann_offsets_tuples = [tuple((int(ann_offsets[0]), int(ann_offsets[1]))) for ann_offsets in ann_offsets_clean]\n",
    "print(ann_offsets_tuples[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baillie (1290, 1297)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m ann_tokens[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m     16\u001b[0m     desc \u001b[38;5;241m=\u001b[39m desc[token_end_offset\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 17\u001b[0m     token_start_offset \u001b[38;5;241m=\u001b[39m \u001b[43mdesc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39mtoken_end_offset\n\u001b[1;32m     18\u001b[0m     token_end_offset \u001b[38;5;241m=\u001b[39m token_start_offset \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(token)\n\u001b[1;32m     19\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "tokens, token_offsets = [], []\n",
    "i, maxI = 0, 5  # START WITH A SAMPLE, THEN: len(text_ann_list)\n",
    "while i < maxI:\n",
    "    start_offset, end_offset = ann_offsets_tuples[i][0], ann_offsets_tuples[i][1]\n",
    "    ann_tokens = word_tokenize(text_ann_list[i])\n",
    "    desc = desc_list[i][start_offset:end_offset+1]\n",
    "    print(desc)\n",
    "\n",
    "    token_start_offset = start_offset\n",
    "    token_end_offset = start_offset+len(token)\n",
    "    # tokens += [token]\n",
    "    # token_offsets += [tuple((token_start_offset, token_end_offset))]\n",
    "    print(token, tuple((token_start_offset, token_end_offset)))\n",
    "    \n",
    "    for token in ann_tokens[1:]:\n",
    "        desc = desc[token_end_offset+1:]\n",
    "        token_start_offset = desc.index(token)+token_end_offset\n",
    "        token_end_offset = token_start_offset + len(token)\n",
    "        i+= 1\n",
    "        # tokens += [token]\n",
    "        # token_offsets += [tuple((token_start_offset, token_end_offset))]\n",
    "        print(token, tuple((token_start_offset, token_end_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_list[0][1290:1303]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

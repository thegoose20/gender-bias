{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs the files:\n",
    "  * `../data/analysis_data/descriptions_with_counts.csv`: adds columns to `descriptions.csv` for word counts and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `../data/analysis_data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "  * `../data/doc_clf_data/desc_field_descid_label_eadid.csv`: contains one row per description with the description's labels from the manual annotation process\n",
    "  * `../data/crc_metadata/descs_with_offsets.csv`: contains one row for every description in the annotated datasets with columns for the descriptions' corresponding id, eadid, file, start offset, and end offset\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Loading\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Descriptions\n",
    "\n",
    "[3.](#3) Offsets of Tokens\n",
    "    \n",
    "  * TO REMOVE: [BIO Tags](#3.1)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "### 0. Loading\n",
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # import custom functions\n",
    "import config # import directory path variables\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_path = config.crc_meta_path+\"all_descriptions.csv\"     # descriptions in column of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid                                        description  \\\n",
       "0   AA5  Professor James Aitken White was a leading Sco...   \n",
       "1   AA5  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "2   AA6  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "3   AA6            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "4   AA7  Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                       field  desc_id  \n",
       "0  Biographical / Historical        0  \n",
       "1                      Title        1  \n",
       "2  Biographical / Historical        2  \n",
       "3                      Title        3  \n",
       "4  Biographical / Historical        4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(descs_path, index_col=0)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove metadata field name from each description\n",
    "# new_descs = []\n",
    "# descs = list(desc_df.description)\n",
    "# fields = list(desc_df.field)\n",
    "# i = 0\n",
    "# maxI = len(descs)\n",
    "# while i < maxI:\n",
    "#     d, f = descs[i], fields[i]\n",
    "#     to_remove = f+\":\\n\"\n",
    "#     d = d.replace(to_remove,\"\")\n",
    "#     new_descs += [d]\n",
    "#     i += 1\n",
    "# assert len(new_descs) == len(descs)\n",
    "# # new_descs[:10]            # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Update the CSV file\n",
    "# desc_df.description = new_descs\n",
    "# desc_df.head()\n",
    "# desc_df.to_csv(descs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each description to a txt file named with desc_id\n",
    "ids = list(desc_df.desc_id)\n",
    "descs = list(desc_df.description)\n",
    "desc_txt_dir = config.crc_meta_path+\"descriptions_brat/\"\n",
    "utils.strToTxt(ids, descs, \"description\", desc_txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader(desc_txt_dir, \"description\\d+.txt\", encoding=\"utf8\")\n",
    "# print(len(corpus.fileids()), desc_df.shape[0])  # Looks good\n",
    "print(corpus.fileids()[-20:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good\n",
    "# len(desc_sents[2]) # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.insert(len(desc_df.columns), \"word_count\", word_count)\n",
    "desc_df.insert(len(desc_df.columns), \"sent_count\", sent_count)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"descriptions_with_counts.csv\")  # write a new CSV file with the word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.reset_index()\n",
    "desc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", desc_df)\n",
    "desc_df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengths per Metadata Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Biographical / Historical\"\n",
    "bh_stats = utils.makeDescribeDf(field, desc_df)\n",
    "bh_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Scope and Contents\"\n",
    "sc_stats = utils.makeDescribeDf(field, desc_df)\n",
    "sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Processing Information\"\n",
    "pi_stats = utils.makeDescribeDf(field, desc_df)\n",
    "pi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Title\"\n",
    "t_stats = utils.makeDescribeDf(field, desc_df)\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for visualization in Observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descs = pd.read_csv(\"../data/analysis_data/descriptions_with_counts.csv\", index_col=0)\n",
    "df_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Offsets of Descriptions\n",
    "\n",
    "**Get the start and end offset of every description so that automated labels can be exported as .ann files for visualization with brat.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we need to determinen the intermediate start and end offsets as well, which we'll add as a column to the file `../data/crc_metadata/all_descriptions.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = \".txt\"  # Read in only the PlainText files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(config.doc_path)\n",
    "filenames = [f for f in filenames if f[-4:] == file_type] # the descriptions are in the txt files\n",
    "# print(filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_details = utils.getDescriptionsInFiles(config.doc_path, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now create a DataFrame of the description data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_col = list(descs_details.keys())\n",
    "desc_col, field_col, file_col, eadid_col, start_offset_col, end_offset_col = [], [], [], [], [], []\n",
    "for desc_id in ids_col:\n",
    "    desc_dict = descs_details[desc_id]\n",
    "    \n",
    "    eadid = (re.findall(\"^.*(?=_\\d+.txt)\", desc_dict[\"file\"]))[0]\n",
    "    eadid_col += [eadid]\n",
    "    \n",
    "    field_col += [desc_dict[\"field\"]]\n",
    "    \n",
    "    file_col += [desc_dict[\"file\"]]\n",
    "    \n",
    "    desc_col += [desc_dict[\"description\"]]\n",
    "    \n",
    "    start_offset_col += [desc_dict[\"start_offset\"]]\n",
    "    end_offset_col += [desc_dict[\"end_offset\"]]\n",
    "\n",
    "new_descs_df = pd.DataFrame({\n",
    "    \"desc_id\":ids_col, \"eadid\":eadid_col, \"field\":field_col, \"file\":file_col, \n",
    "    \"description\":desc_col, \"desc_start_offset\":start_offset_col, \"desc_end_offset\":end_offset_col\n",
    "})\n",
    "\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_descs_df.to_csv(config.crc_meta_path+\"descs_with_offsets.csv\")\n",
    "# new_descs_df = pd.read_csv(config.crc_meta_path+\"descs_with_offsets.csv\", index_col=0)\n",
    "# new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now assign description IDs from this DataFrame to the aggregated annotated datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.read_csv(config.docc_path+\"desc_field_descid_label_eadid.csv\", index_col=0)\n",
    "# df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_id_x</th>\n",
       "      <th>field</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "      <th>desc_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coll-1320</td>\n",
       "      <td>Coll-1320_00400.txt</td>\n",
       "      <td>3247</td>\n",
       "      <td>Title</td>\n",
       "      <td>'Effect of an inhibitor of 3ß-hydroxysteroid d...</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>19370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Coll-146_28000.txt</td>\n",
       "      <td>11317</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>3 photographs : negative, col.Sent from: [Cap ...</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>4731.0</td>\n",
       "      <td>4810.0</td>\n",
       "      <td>63842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Coll-146_20500.txt</td>\n",
       "      <td>9233</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>4 photographs : negative, col.. 1 stripSent fr...</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>4387.0</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>66124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coll-1130</td>\n",
       "      <td>Coll-1130_00100.txt</td>\n",
       "      <td>1465</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>A collection of copied letters, mainly from th...</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>20367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coll-1143</td>\n",
       "      <td>Coll-1143_00100.txt</td>\n",
       "      <td>1493</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Alexander Herbert Main studied Law at Edinburg...</td>\n",
       "      <td>{'Gendered-Pronoun', 'Stereotype', 'Masculine'...</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>48433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eadid                 file  desc_id_x                      field  \\\n",
       "0  Coll-1320  Coll-1320_00400.txt       3247                      Title   \n",
       "1   Coll-146   Coll-146_28000.txt      11317         Scope and Contents   \n",
       "2   Coll-146   Coll-146_20500.txt       9233         Scope and Contents   \n",
       "3  Coll-1130  Coll-1130_00100.txt       1465  Biographical / Historical   \n",
       "4  Coll-1143  Coll-1143_00100.txt       1493  Biographical / Historical   \n",
       "\n",
       "                                         description  \\\n",
       "0  'Effect of an inhibitor of 3ß-hydroxysteroid d...   \n",
       "1  3 photographs : negative, col.Sent from: [Cap ...   \n",
       "2  4 photographs : negative, col.. 1 stripSent fr...   \n",
       "3  A collection of copied letters, mainly from th...   \n",
       "4  Alexander Herbert Main studied Law at Edinburg...   \n",
       "\n",
       "                                               label  desc_start_offset  \\\n",
       "0                           {'Masculine', 'Unknown'}             5040.0   \n",
       "1                                        {'Unknown'}             4731.0   \n",
       "2                                        {'Unknown'}             4387.0   \n",
       "3                                        {'Unknown'}             1262.0   \n",
       "4  {'Gendered-Pronoun', 'Stereotype', 'Masculine'...             1170.0   \n",
       "\n",
       "   desc_end_offset  desc_id_y  \n",
       "0           5281.0      19370  \n",
       "1           4810.0      63842  \n",
       "2           4592.0      66124  \n",
       "3           1434.0      20367  \n",
       "4           1559.0      48433  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_grouped.merge(new_descs_df, left_on=[\"description\", \"field\", \"eadid\", \"file\", \"desc_start_offset\", \"desc_end_offset\"], right_on=[\"description\", \"field\", \"eadid\", \"file\", \"desc_start_offset\", \"desc_end_offset\"])\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now we want to keep the *right* DataFrame's description IDs, so we'll drop `desc_id_x` and remove the `_y` from `desc_id_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>file</th>\n",
       "      <th>field</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coll-1320</td>\n",
       "      <td>Coll-1320_00400.txt</td>\n",
       "      <td>Title</td>\n",
       "      <td>'Effect of an inhibitor of 3ß-hydroxysteroid d...</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>19370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Coll-146_28000.txt</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>3 photographs : negative, col.Sent from: [Cap ...</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>4731.0</td>\n",
       "      <td>4810.0</td>\n",
       "      <td>63842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coll-146</td>\n",
       "      <td>Coll-146_20500.txt</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>4 photographs : negative, col.. 1 stripSent fr...</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>4387.0</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>66124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coll-1130</td>\n",
       "      <td>Coll-1130_00100.txt</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>A collection of copied letters, mainly from th...</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>20367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coll-1143</td>\n",
       "      <td>Coll-1143_00100.txt</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Alexander Herbert Main studied Law at Edinburg...</td>\n",
       "      <td>{'Gendered-Pronoun', 'Stereotype', 'Masculine'...</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>48433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eadid                 file                      field  \\\n",
       "0  Coll-1320  Coll-1320_00400.txt                      Title   \n",
       "1   Coll-146   Coll-146_28000.txt         Scope and Contents   \n",
       "2   Coll-146   Coll-146_20500.txt         Scope and Contents   \n",
       "3  Coll-1130  Coll-1130_00100.txt  Biographical / Historical   \n",
       "4  Coll-1143  Coll-1143_00100.txt  Biographical / Historical   \n",
       "\n",
       "                                         description  \\\n",
       "0  'Effect of an inhibitor of 3ß-hydroxysteroid d...   \n",
       "1  3 photographs : negative, col.Sent from: [Cap ...   \n",
       "2  4 photographs : negative, col.. 1 stripSent fr...   \n",
       "3  A collection of copied letters, mainly from th...   \n",
       "4  Alexander Herbert Main studied Law at Edinburg...   \n",
       "\n",
       "                                               label  desc_start_offset  \\\n",
       "0                           {'Masculine', 'Unknown'}             5040.0   \n",
       "1                                        {'Unknown'}             4731.0   \n",
       "2                                        {'Unknown'}             4387.0   \n",
       "3                                        {'Unknown'}             1262.0   \n",
       "4  {'Gendered-Pronoun', 'Stereotype', 'Masculine'...             1170.0   \n",
       "\n",
       "   desc_end_offset  desc_id  \n",
       "0           5281.0    19370  \n",
       "1           4810.0    63842  \n",
       "2           4592.0    66124  \n",
       "3           1434.0    20367  \n",
       "4           1559.0    48433  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged.drop(columns=[\"desc_id_x\"])\n",
    "df_merged = df_merged.rename(columns={\"desc_id_y\":\"desc_id\"})\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(config.agg_path+\"desc_field_descid_label_eadid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Offsets of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc = pd.read_csv(config.crc_meta_path+\"descs_with_offsets.csv\", index_col=0)\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57361</th>\n",
       "      <td>57361</td>\n",
       "      <td>EUA_IN1</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>EUA_IN1_56700.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6137</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc_id    eadid               field               file description  \\\n",
       "57361    57361  EUA_IN1  Scope and Contents  EUA_IN1_56700.txt         NaN   \n",
       "\n",
       "       desc_start_offset  desc_end_offset  \n",
       "57361               6137             6141  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.loc[df_desc.description.isna() == True]\n",
    "# df_desc.loc[df_desc.description == \"N/A\"]\n",
    "# df_desc.loc[df_desc.file == \"EUA_IN1_56700.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57361</th>\n",
       "      <td>57361</td>\n",
       "      <td>EUA_IN1</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>EUA_IN1_56700.txt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>6137</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc_id    eadid               field               file description  \\\n",
       "57361    57361  EUA_IN1  Scope and Contents  EUA_IN1_56700.txt         N/A   \n",
       "\n",
       "       desc_start_offset  desc_end_offset  \n",
       "57361               6137             6141  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.description = df_desc.description.fillna(\"N/A\")\n",
    "df_desc.loc[df_desc.desc_id == 57361]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Write the corrected description to the `descs_with_offsets.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_desc.to_csv(config.crc_meta_path+\"descs_with_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the offsets of the tokens in every description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = list(df_desc.description)\n",
    "desc_ids = list(df_desc.desc_id)\n",
    "desc_start_offsets = list(df_desc.desc_start_offset)\n",
    "desc_end_offsets = list(df_desc.desc_end_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dict, offsets_dict = utils.getTokensAndOffsetsFromStrings(descs, desc_ids, desc_start_offsets, desc_end_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_col, offsets_col, desc_ids_col = [], [], []\n",
    "for desc_id,token_list in tokens_dict.items():\n",
    "    tokens_col += token_list\n",
    "    offsets_list = offsets_dict[desc_id]\n",
    "    offsets_col += offsets_list\n",
    "    assert len(token_list) == len(offsets_list)\n",
    "    desc_ids_col += [desc_id]*len(token_list)\n",
    "\n",
    "assert len(tokens_col) == len(offsets_col)\n",
    "assert len(tokens_col) == len(desc_ids_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Records', 'of', 'the', 'Phrenological', 'Society']\n",
      "[(29, 36), (37, 39), (40, 43), (44, 57), (58, 65)]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for col_list in [tokens_col, offsets_col, desc_ids_col]:\n",
    "    print(col_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  Now create a DataFrame with these lists as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Records</td>\n",
       "      <td>(29, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>(37, 39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>(40, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Phrenological</td>\n",
       "      <td>(44, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Society</td>\n",
       "      <td>(58, 65)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id          token   offsets\n",
       "0        0        Records  (29, 36)\n",
       "1        0             of  (37, 39)\n",
       "2        0            the  (40, 43)\n",
       "3        0  Phrenological  (44, 57)\n",
       "4        0        Society  (58, 65)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.DataFrame({\"desc_id\":desc_ids_col, \"token\":tokens_col, \"offsets\":offsets_col})\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now write the DataFrame to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.to_csv(config.agg_path+\"descid_token_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "# DELETE CODE BELOW (MOVING TO NEW NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### 3.1 BIO Tags\n",
    "\n",
    "**Compare the descriptions' tokens' offsets to the annotated text spans' offsets to determine which tokens to mark as the beginning of an annotation (`B-[LABELNAME]`), inside an annotation (`I-[LABELNAME]`), and unannotated, or outisde of an annotation (`O`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: convert the three dataframes to dictionaries, \n",
    "#        for each filename, check whether each token_offset pair contained within each ann_offset pair and desc_,\n",
    "#        recording which description (using indeces) annotation appears within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29, 36), (37, 39), (40, 43), (44, 57), (58, 65)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.read_csv(config.tokc_path+\"descid_token_offsets.csv\", index_col=0)\n",
    "token_desc_ids = list(df_tokens.desc_id)\n",
    "tokens = list(df_tokens.token)\n",
    "token_offsets = list(df_tokens.offsets)\n",
    "token_offsets_clean = [offsets[1:-1].split(\", \") for offsets in token_offsets]\n",
    "token_offsets_tuples = [tuple((int(offsets[0]), int(offsets[1]))) for offsets in token_offsets_clean]\n",
    "token_offsets_tuples[:5]  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate description tokens and annotated text spans' text and offsets to description IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                             token_offsets  \n",
       "desc_id                                                     \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...  \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...  \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...  \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...  \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tokens_imploded = utils.implodeDataFrame(df_tokens, [\"desc_id\"])\n",
    "df_tokens_imploded = df_tokens_imploded.rename(columns={\"offsets\":\"token_offsets\"})\n",
    "df_tokens_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens_imploded.to_csv(config.tokc_path+\"token_data_imploded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data associating description and annotation IDs to offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>desc_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAI_01000</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[68]</td>\n",
       "      <td>[(1290, 1315)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01300</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[(5853, 5983)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01600</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[221]</td>\n",
       "      <td>[(5967, 6202)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01900</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[292]</td>\n",
       "      <td>[(5297, 5506)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_02200</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[361]</td>\n",
       "      <td>[(15180, 15419)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eadid desc_id      desc_offsets\n",
       "filename                                    \n",
       "BAI_01000  ['BAI']    [68]    [(1290, 1315)]\n",
       "BAI_01300  ['BAI']   [143]    [(5853, 5983)]\n",
       "BAI_01600  ['BAI']   [221]    [(5967, 6202)]\n",
       "BAI_01900  ['BAI']   [292]    [(5297, 5506)]\n",
       "BAI_02200  ['BAI']   [361]  [(15180, 15419)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descs_imploded = pd.read_csv(config.agg_path+\"description_data_imploded.csv\", index_col=0)\n",
    "df_descs_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>ann_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA5_00100</th>\n",
       "      <td>[14377, 14378, 14379, 14380, 14381, 14382, 143...</td>\n",
       "      <td>['(789, 791)', '(871, 873)', '(913, 916)', '(9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA6_00100</th>\n",
       "      <td>[55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...</td>\n",
       "      <td>['(1778, 1790)', '(677, 679)', '(920, 922)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA7_00100</th>\n",
       "      <td>[127, 13987, 13988, 13989, 13990, 13991, 13992...</td>\n",
       "      <td>['(2399, 2415)', '(505, 508)', '(614, 620)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00100</th>\n",
       "      <td>[17473, 17474, 17475, 17476, 17477, 17478, 416...</td>\n",
       "      <td>['(371, 388)', '(393, 405)', '(34, 56)', '(102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00200</th>\n",
       "      <td>[20496, 20497, 20498, 20499, 20500, 20501, 205...</td>\n",
       "      <td>['(215, 221)', '(226, 232)', '(250, 255)', '(2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  agg_ann_id  \\\n",
       "filename                                                       \n",
       "AA5_00100  [14377, 14378, 14379, 14380, 14381, 14382, 143...   \n",
       "AA6_00100  [55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...   \n",
       "AA7_00100  [127, 13987, 13988, 13989, 13990, 13991, 13992...   \n",
       "BAI_00100  [17473, 17474, 17475, 17476, 17477, 17478, 416...   \n",
       "BAI_00200  [20496, 20497, 20498, 20499, 20500, 20501, 205...   \n",
       "\n",
       "                                                 ann_offsets  \n",
       "filename                                                      \n",
       "AA5_00100  ['(789, 791)', '(871, 873)', '(913, 916)', '(9...  \n",
       "AA6_00100  ['(1778, 1790)', '(677, 679)', '(920, 922)', '...  \n",
       "AA7_00100  ['(2399, 2415)', '(505, 508)', '(614, 620)', '...  \n",
       "BAI_00100  ['(371, 388)', '(393, 405)', '(34, 56)', '(102...  \n",
       "BAI_00200  ['(215, 221)', '(226, 232)', '(250, 255)', '(2...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anns_imploded = pd.read_csv(config.agg_path+\"annotation_data_imploded.csv\", index_col=0)\n",
    "df_anns_imploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: O tags**\n",
    "\n",
    "Compare description IDs in the two DataFrames above to determine which descriptions (from `df_tokens_imploded`) do not have annotations, and assign all those descriptions' tokens an `O` tag (for *outside* of an annotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign tag 'O': 86742\n"
     ]
    }
   ],
   "source": [
    "all_desc_ids = list(df_tokens_imploded.index)\n",
    "ann_desc_ids = list(df_merged_imploded.index)\n",
    "unannotated = [desc_id for desc_id in all_desc_ids if not desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign tag 'O':\", len(unannotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(unannotated)]\n",
    "assert o_df.shape[0] == len(unannotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "      <th>ann_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                                   offsets  \\\n",
       "desc_id                                                      \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...   \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...   \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...   \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...   \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...   \n",
       "\n",
       "                                                   ann_tag  \n",
       "desc_id                                                     \n",
       "0                                    [O, O, O, O, O, O, O]  \n",
       "1        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list = list(o_df.token)\n",
    "tags = [[\"O\"]*len(tokens) for tokens in tokens_list]\n",
    "assert len(tags) == len(tokens_list)\n",
    "o_df.insert(len(o_df.columns), \"ann_tag\", tags)\n",
    "o_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(o_df.token[100]) == len(o_df.ann_tag[100])\n",
    "assert len(o_df.token[488]) == len(o_df.ann_tag[488])\n",
    "assert len(o_df.token[0]) == len(o_df.ann_tag[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: B- and I- tags**\n",
    "\n",
    "For description IDs that do have annotations (and thus are in `df_merged_imploded`), assign their tokens tags of `B-[LABELNAME]` and `I-[LABELNAME]` for *beginning* and *inside* of an annotation, replacing `[LABELNAME]` with the name of the annotation's label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign 'B-' or 'I-'': 1855\n"
     ]
    }
   ],
   "source": [
    "annotated = [desc_id for desc_id in all_desc_ids if desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign 'B-' or 'I-'':\", len(annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(annotated)]\n",
    "assert bi_df.shape[0] == len(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[Brick, Burning, ,, Beardman, 's]</td>\n",
       "      <td>[(1421, 1426), (1427, 1434), (1434, 1435), (14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>[Interpreting, sequence, motifs, [, Letter, to...</td>\n",
       "      <td>[(3064, 3076), (3077, 3085), (3086, 3092), (30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>[Lady, Luck, :, the, theory, of, probability, ...</td>\n",
       "      <td>[(2118, 2122), (2123, 2127), (2127, 2128), (21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "167                      [Brick, Burning, ,, Beardman, 's]   \n",
       "508      [Interpreting, sequence, motifs, [, Letter, to...   \n",
       "610                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "611                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "640      [Lady, Luck, :, the, theory, of, probability, ...   \n",
       "\n",
       "                                                   offsets  \n",
       "desc_id                                                     \n",
       "167      [(1421, 1426), (1427, 1434), (1434, 1435), (14...  \n",
       "508      [(3064, 3076), (3077, 3085), (3086, 3092), (30...  \n",
       "610      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "611      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "640      [(2118, 2122), (2123, 2127), (2127, 2128), (21...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Brick', 'Burning', ',', 'Beardman', \"'s\"], 'offsets': ['(1421, 1426)', '(1427, 1434)', '(1434, 1435)', '(1436, 1444)', '(1444, 1446)']}\n"
     ]
    }
   ],
   "source": [
    "bi_dict = bi_df.to_dict('index')\n",
    "print(bi_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'offsets_ann': ['(1436, 1444)', '(1436, 1444)'], 'text_ann': ['Beardman', 'Beardman'], 'label': ['Omission', 'Unknown'], 'id': [31928, 31929]}\n"
     ]
    }
   ],
   "source": [
    "ann_dict = df_merged_imploded.to_dict('index')\n",
    "print(ann_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a string of offsets into a tuple with each offset of type int\n",
    "# \"(1436, 1444)\" --> (1436, 1444)\n",
    "def offsetsStrToTuple(offsets_str):\n",
    "    offsets_list = offsets_str[1:-1].split(\", \")\n",
    "    offsets_ints = [int(o) for o in offsets_list]\n",
    "    return tuple((offsets_ints))\n",
    "\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')) == tuple\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[0]) == int\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[1]) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned tags for 100 descriptions\n"
     ]
    }
   ],
   "source": [
    "desc_ids = list(bi_dict.keys())[:100]  # START WITH SAMPLE\n",
    "assert len(set(desc_ids)) == len(desc_ids)  # Make sure every description ID is unique\n",
    "log = 0\n",
    "descid_to_tag = dict.fromkeys(desc_ids)\n",
    "for desc_id in desc_ids:\n",
    "    text_spans = ann_dict[desc_id][\"text_ann\"]\n",
    "    desc_tokens = bi_dict[desc_id]['token']\n",
    "    desc_tokens_offsets = bi_dict[desc_id]['offsets']\n",
    "    desc_tags = []\n",
    "    for i,desc_token in enumerate(desc_tokens):\n",
    "        token_offset_pair = offsetsStrToTuple(desc_tokens_offsets[i])\n",
    "        span_indeces, tags = [], []  # Note: one token may have multiple tags\n",
    "        \n",
    "        # Record the indeces of every item in text_spans with the desc_token\n",
    "        for j,text_span in enumerate(text_spans):\n",
    "            span_offset_pair = offsetsStrToTuple(ann_dict[desc_id][\"offsets_ann\"][j])    \n",
    "            # Be sure a matching token's offsets are within the annotated text span\n",
    "            if (desc_token in text_span\n",
    "               ) and (\n",
    "                token_offset_pair[0] >= span_offset_pair[0]\n",
    "                ) and (\n",
    "                token_offset_pair[1] <= span_offset_pair[1]):\n",
    "                    span_indeces += [j] \n",
    "            else:\n",
    "                span_indeces += [\"unannotated\"]\n",
    "        for j in span_indeces:\n",
    "            # If the token is annotated, assign it a B- or I- tag with a label\n",
    "            if type(j) == int:\n",
    "            # If the start offsets are the same, assign a 'B-' tag\n",
    "                if token_offset_pair[0] == span_offset_pair[0]:\n",
    "                    tags += ['B-'+ann_dict[desc_id][\"label\"][j]]\n",
    "                # Otherwise, assign an 'I-' tag\n",
    "                else:\n",
    "                    tags += ['I-'+ann_dict[desc_id][\"label\"][j]]\n",
    "            # If the description token isn't annotated, assign it an O tag\n",
    "            elif j == \"unannotated\":\n",
    "                tags += [\"O\"]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid j value: {}\".format(j))\n",
    "        \n",
    "        desc_tags += [set(tags)]\n",
    "    \n",
    "    assert len(desc_tokens) == len(desc_tags)\n",
    "    descid_to_tag[desc_id] = desc_tags\n",
    "    \n",
    "    log += 1\n",
    "    if log % 100 == 0:\n",
    "        print(\"Assigned tags for {} descriptions\".format(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Letter', ':', ':', 'Koestler', ',', 'Arthur'], 'offsets': ['(127, 133)', '(134, 135)', '(135, 136)', '(137, 145)', '(145, 146)', '(147, 153)']}\n"
     ]
    }
   ],
   "source": [
    "did = 610 #508 #167\n",
    "# print(ann_dict[did])\n",
    "print(bi_dict[did])\n",
    "# print(descid_to_tag[did])\n",
    "\n",
    "# spans = ['Beardman', 'Beardman']\n",
    "# spans2 = [\"Brick Burning\"]\n",
    "# tokens = ['Brick', 'Burning', ',', 'Beardman', \"'s\"]\n",
    "# # print(spans.count('Beardman'))\n",
    "# # # print(spans.index('Beardman'))\n",
    "# # # print(tokens.index('Beardman'))\n",
    "# # for k in range(0,3):\n",
    "# #     print(k)\n",
    "# indeces = [index for index in range(len(spans)) if spans[index] == 'Beardman']\n",
    "# print(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m token \u001b[38;5;241m=\u001b[39m tokens[i]\n\u001b[1;32m      7\u001b[0m token_start, token_end \u001b[38;5;241m=\u001b[39m token_offsets_tuples[i][\u001b[38;5;241m0\u001b[39m], token_offsets_tuples[i][\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m----> 9\u001b[0m ann_df \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdesc_id\u001b[49m]\n\u001b[1;32m     10\u001b[0m ann_id_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m     11\u001b[0m ann_offsets_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39moffsets_ann)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:290\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:106\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    103\u001b[0m b_value \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mop_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m b_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_value\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# numexpr raises eg for array ** array with integers\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pydata/numexpr/issues/379)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/numexpr/necompiler.py:835\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m _numexpr_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ex\u001b[38;5;241m=\u001b[39mcompiled_ex, argnames\u001b[38;5;241m=\u001b[39mnames, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m evaluate_lock:\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# is_annotated_col = []\n",
    "# annotated_id = []\n",
    "# i, maxI = 0, len(token_desc_ids)  #1188478, 1189478\n",
    "# while i < maxI:\n",
    "#     desc_id = token_desc_ids[i]\n",
    "#     token = tokens[i]\n",
    "#     token_start, token_end = token_offsets_tuples[i][0], token_offsets_tuples[i][1] \n",
    "    \n",
    "#     ann_df = df_merged.loc[df_merged.desc_id == desc_id]\n",
    "#     ann_id_list = list(ann_df.id)\n",
    "#     ann_offsets_list = list(ann_df.offsets_ann)\n",
    "#     ann_offsets_clean = [ann_offsets[1:-1].split(\", \") for ann_offsets in ann_offsets_list]\n",
    "#     ann_offsets_tuples = [tuple((int(ann_offsets[0]), int(ann_offsets[1]))) for ann_offsets in ann_offsets_clean]\n",
    "    \n",
    "#     for j,ann_offsets in enumerate(ann_offsets_tuples):\n",
    "#         ann_start = ann_offsets[0]\n",
    "#         ann_end = ann_offsets[1]\n",
    "#         if token_start == ann_start:\n",
    "#             is_annotated_col += [\"B\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         elif (token_start > ann_start) and (token_start <= ann_end):\n",
    "#             is_annotated_col += [\"I\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         else:\n",
    "#             is_annotated_col += [\"O\"]\n",
    "#             annotated_id += [\"None\"]\n",
    "    \n",
    "#     i += 1\n",
    "\n",
    "# assert len(is_annotated_col) == len(token_desc_ids)\n",
    "# assert len(is_annotated_col) == len(annotated_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.insert(len(df_tokens.columns),\"is_annotated\",is_annotated_col)\n",
    "df_tokens.insert(len(df_tokens.columns),\"ann_id\",annotated_id)\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(is_annotated_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(annotated_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

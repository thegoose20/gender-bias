{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs or updates the files:\n",
    "  * `../data/crc_metadata/annot_descs.csv`: adds columns for description offsets, word counts, and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `../data/analysis_data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "  * `../data/crc_metadata/descriptions_annotated/`: contains one file for every description in the annotated datasets with file names as zero-padded description IDs\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Annotated Descriptions Data\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Tokens\n",
    "\n",
    "[3.](#3) Description and Annotation Linking\n",
    "    \n",
    "  * TO REMOVE: [BIO Tags](#3.1)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # import custom functions\n",
    "import config # import directory path variables\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Annotated Descriptions Data\n",
    "\n",
    "Create a CSV dataset of the descriptions that were annotated in brat, including the descriptions' file name and offsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll-227_00100.txt', 'La_03600.txt', 'PJM_03000.txt', 'La_07300.txt', 'Coll-1434_07400.txt', 'Coll-1434_03100.txt', 'MS_BOX_25.5_00100.txt', 'EUA_IN1_38300.txt', 'Coll-14_05900.txt', 'Coll-1694_00100.txt']\n",
      "3649\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(config.doc_path)\n",
    "print(filenames[:10])\n",
    "print(len(filenames))  # descs_with_offsets has 3645, not 3649"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that every annotation's file is in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55260, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-1157_00100.ann</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>knighted</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-1310_02300.ann</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-1281_00100.ann</td>\n",
       "      <td>(2426, 2439)</td>\n",
       "      <td>Prince Regent</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>Coll-1310_02700.ann</td>\n",
       "      <td>(9993, 10003)</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>Coll-1310_02900.ann</td>\n",
       "      <td>(7192, 7195)</td>\n",
       "      <td>Sir</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agg_ann_id                 file        offsets           text  \\\n",
       "12           0  Coll-1157_00100.ann   (1407, 1415)       knighted   \n",
       "22           1  Coll-1310_02300.ann   (9625, 9635)     knighthood   \n",
       "23           2  Coll-1281_00100.ann   (2426, 2439)  Prince Regent   \n",
       "24           3  Coll-1310_02700.ann  (9993, 10003)     knighthood   \n",
       "25           4  Coll-1310_02900.ann   (7192, 7195)            Sir   \n",
       "\n",
       "            label    category associated_genders  \n",
       "12  Gendered-Role  Linguistic            Unclear  \n",
       "22  Gendered-Role  Linguistic            Unclear  \n",
       "23  Gendered-Role  Linguistic            Unclear  \n",
       "24  Gendered-Role  Linguistic            Unclear  \n",
       "25  Gendered-Role  Linguistic            Unclear  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df = pd.read_csv(\"../data/aggregated_data/aggregated_final.csv\", index_col=0)\n",
    "print(agg_df.shape)\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_files = list(agg_df.file)\n",
    "agg_files = [f.replace(\".ann\", \".txt\") for f in agg_files]\n",
    "agg_files = list(set(agg_files))\n",
    "agg_files.sort()\n",
    "missing = []\n",
    "for f in agg_files:\n",
    "    if not f in filenames:\n",
    "        missing += [f]\n",
    "assert len(missing) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`agg_files` is list of the file names in `descriptions/brat` that should be included in CSV of the annotated description data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING FUNCTIONS ###\n",
    "# test_file = open(os.path.join(config.doc_path, \"Coll-1036_00300.txt\"), \"r\").read()\n",
    "# desc_dict, did, field_for_next_file = getFieldDescriptions(dict(), test_file, \"Scope and Contents\", [\"Title\", \"Biographical / Historical\", \"Processing Information\"], 0, \"Coll-1036_00300.txt\")\n",
    "# test_files = agg_files[:5]\n",
    "desc_dict = utils.getDescriptionsInFiles(config.doc_path, agg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Page mounted with three photographs of the site of the Poultry Research Centre sub-station at the Easter Bush estate\n",
      "\n",
      "Title:\n",
      "Page mounted with four photographs\n",
      "\n",
      "Title:\n",
      "Page mounted with two photographs of the Poultry Research Centre sub-station at the Easter Bush estate\n",
      "\n",
      "Title:\n",
      "Page mounted with programme of the Scottish Poultry Conference, Stirling (16 November 1955) and group photograph from the conference\n",
      "\n",
      "Title:\n",
      "Page mounted with five photographs\n",
      "\n",
      "Title:\n",
      "Page mounted with four items\n",
      "\n",
      "Title:\n",
      "Page mounted with seven photographs of Alan Greenwood at the Massachusetts Institute of Technology, February 1961\n",
      "\n",
      "Title:\n",
      "Group photograph of staff and students outside the Institute of Animal Genetics\n",
      "\n",
      "Title:\n",
      "Four items found loose among photographs\n",
      "\n",
      "Title:\n",
      "Page mounted with two photographs of Alan Greenwood\n",
      "\n",
      "Title:\n",
      "Album of postcards from Greenwood's trip to Canada, the USA and Mexico\n",
      "\n",
      "Scope and Contents:\n",
      "The article is concerned with the death of a particularly high-producing hen, L1641, who equalled the world's record production of 1515 eggs during her lifetime. This appears to place the article after 1948.\n",
      "\n",
      "Scope and Contents:\n",
      "Recto: photograph showing Alan Greenwood, Dr Fraps and Mrs Fraps on a bench in the garden of the Cosmos Club, Washington DC; photograph of an unidentified house, presumably where Greenwood was staying. Verso: two photographs of a house interior, presumably where Greenwood was staying.\n",
      "\n",
      "Scope and Contents:\n",
      "The handwritten notebook details 22 experiments on poultry, including adrenalin injections and ovary and testis grafts, covering the period 1925-1929. Also present are some photographic inserts. The spine of the book bears the inscription 'Abandon Hope All Ye Who Enter Here.' The notebook is only partially filled.\n",
      "\n",
      "Scope and Contents:\n",
      "The first photograph depicts Ahmed Abd-El-Ghaffar Yousef Saleh in academic gown (annotated 'graduated PhD 1948, University of Edinburgh'); the second photograph depicts W. Marshall, R. Coles, F.Hutt and Alan Greenwood taken at the Conference of Poultry Instructresses for Scotland held at the Poultry Research Centre, 08-09 August 1950.\n",
      "\n",
      "Scope and Contents:\n",
      "Recto: photograph of Josephine Peace in Constant Temperature Room at the Poultry Research Centre; photograph of chickens in a pen (both November 1955). Verso: two photographs from a social event at the Institute of Animal Genetics: the first photograph shows Alick Buchanan-Smith, Hugh Donald, Charlotte Auerbach and Geoffrey Beale; the second photograph shows C.H Waddington, Helen Turner, Alan Greenwood and Eric Lucey. Pictures signed 'M.L.'\n",
      "\n",
      "Scope and Contents:\n",
      "The photographs show an area of cleared woodland with some felled trees.\n",
      "\n",
      "Scope and Contents:\n",
      "Title page annotated with Alan Greenwood's initials.\n",
      "\n",
      "Scope and Contents:\n",
      "The title page notes: 'Address given by Dr Greenwood, DSc, PhD, in London on June 12th, 1946, at the first meeting of the Stock Improvement Congress, organised by the National Association of Poultry Breeders.'\n",
      "\n",
      "Scope and Contents:\n",
      "Recto: Alan Greenwood reading at a desk (1954); photograph of chickens being fed with an apple captioned 'Dr Greenwood tempts his Adam and Eves with an apple in the Climatic Chamber.' Verso: Dr Bolton in a laboratory coat, with a caption explaining that he is filling a 'bomb' with oxygen and measuring the pressure in a Bomb Calorimeter.\n",
      "\n",
      "Scope and Contents:\n",
      "The title page notes: 'paper read at the World's Poultry Science Association Conference: Paris, August 1951.'\n",
      "\n",
      "Scope and Contents:\n",
      "Recto: photograph of a brick building under construction, with rows of poultry huts behind; photograph of three rows of poultry huts, with the corner of a brick building in shot. Verso: Alan Greenwood and Josephine Peace seated with five unidentified females outside the Poultry Research Centre; photograph of a single-storey stone building (possibly the building adjacent to Kellogg Hall, which once housed the ESCA Crop Production Advisory and Development Department).\n",
      "\n",
      "Scope and Contents:\n",
      "The volume lists the menus for various guest and staff lunches and dinners hosted at the British Empire Cancer Campaign Environment Unit. Guests include various key figures in the City and University of Edinburgh, including Edward Appleton, George L. Montgomery and Duncan M. Weatherstone, as well as academics and visitors from research institutions all over the world. The volume also contains various 'thank you' letters.  The volume is only half-filled.\n",
      "\n",
      "Scope and Contents:\n",
      "This item is a direct photocopy of Coll-1057/3/6/1.\n",
      "\n",
      "Scope and Contents:\n",
      "The memorandum appears to consist of two separate parts: the first being titled 'The Poultry Research Centre of the Agricultural Research Council 1947-1962: A Director's Story (compiled as memory serves, and perhaps as conscience dictates'; and the second a shorter summary of the Poultry Research Centre's involvement with the Agricultural Research Council (which begins with a W.H Auden quote beginning 'Thou shalt not worship Projects...'), together with a list of publications sorted by subject, a list of PRC staff, a short history titled 'The Animal Supply and Research Unit of the British Empire Cancer Campaign' and 'The Directors' Club'.\n",
      "\n",
      "Scope and Contents:\n",
      "Title page annotated 'Blackpool N.A.B conference, July 14th 1948.'\n",
      "\n",
      "Scope and Contents:\n",
      "Contains typescript papers, many with handwritten annotations regarding where the lecture was given. There is also a bound volume of lectures for the period 1946-1949, which contains final copies of many of the same lectures as are also found in loose form here.\n",
      "\n",
      "Scope and Contents:\n",
      "Contains reprints of articles by Alan Greenwood, including those produced in collaboration with Janet S.S. Blyth and other collaborators.\n",
      "\n",
      "Scope and Contents:\n",
      "Verso: print of a photograph showing the 10th World's Poultry Congress organising committee and others grouped around a table. The photograph is captioned: 'Mr Adair, Mr Chalmers-Watson, Mr Whittle, Alan Greenwood, J.E Wilson, Major MacDougall; Mr McCallum, Lady Elphinstone, Mr Glen, Mrs Campbell, Miss McLeod.' A second photograph appears to have been removed. Recto: invitation card to Alan Greenwood from the Government for dinner on 16 August 1954; invitation card to Alan Greenwood and his wife from the Lord, Provost, Magistrates and the City of Edinburgh to a garden party on 17 August 1954; invitation card to Alan Greenwood and wife from the University of Edinburgh to an evening reception on 18 August 1954.\n",
      "\n",
      "Scope and Contents:\n",
      "Recto: three photographs depicting developmental capons. Verso: One photograph of a 'half sider' chicken.\n",
      "\n",
      "Scope and Contents:\n",
      "The first press cutting concerns the tenth World's Poultry Congress, under the headline 'Edinburgh Congress Will Put Scotland 'On Poultry Map' (Edinburgh Evening News, 15 March 1954); the second cutting concerns the logo of the Congress, which depicted a brown Leghorn cockerel inside a thistle (Scottish Daily Mail, 27 April 1954).\n",
      "\n",
      "Scope and Contents:\n",
      "Contains:'The Growth Rate in Hypophysectomised Salamander Larvae' by Alan Greenwood, reprinted from the British Journal of Experimental Biology, Vol. II (October 1924);'Biological Methods of Diagnosing Equine Pregnancy I. The Mouse Test' by W.C Miller and II. The Capon Test by A.W Greenwood and J.S.S Blyth, reprinted from the Proceedings of the Royal Society of London, Series B No. 798 vol. 116 pp. 237-258 (November 1934);Typescript titled 'Institute of Animal Genetics - Scientific Publications Relating to Poultry' (1922-1945);single page synopsis of Alan Greenwood's career (c.1967).\n",
      "\n",
      "Scope and Contents:\n",
      "Includes 48 postcards from places, hotels and attractions around Canada, Mexico and the United States of America.\n",
      "\n",
      "Scope and Contents:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(open(config.doc_path+\"Coll-1057_00600.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Descriptions: 26875\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Descriptions:\", len(desc_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>97</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>81</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                        description  \\\n",
       "0               0  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "1               1  Sermons and addresses, 1948-1996; lectures, 19...   \n",
       "2               2  Professor James Aitken White was a leading Sco...   \n",
       "3               3                Papers of Rev Tom Allan (1916-1965)   \n",
       "4               4  Sermons and addresses, 1947-1963; essays and l...   \n",
       "\n",
       "                       field           file  start_offset  end_offset  \n",
       "0                      Title  AA5_00100.txt            24          76  \n",
       "1         Scope and Contents  AA5_00100.txt            97         633  \n",
       "2  Biographical / Historical  AA5_00100.txt           661        1724  \n",
       "3                      Title  AA6_00100.txt            24          60  \n",
       "4         Scope and Contents  AA6_00100.txt            81         560  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df = pd.DataFrame.from_dict(desc_dict, orient=\"index\")\n",
    "# Give the descriptions a unique identifier\n",
    "ann_desc_df = ann_desc_df.reset_index()\n",
    "ann_desc_df = ann_desc_df.rename(columns={\"index\":\"description_id\"})\n",
    "ann_desc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all the description values have text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ann_desc_df.loc[ann_desc_df.description.isnull() == True].shape[0] == 0\n",
    "assert ann_desc_df.loc[ann_desc_df.description.isna() == True].shape[0] == 0\n",
    "assert ann_desc_df.loc[ann_desc_df.description == \"\"].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>General addresses</td>\n",
       "      <td>Title</td>\n",
       "      <td>BAI_00400.txt</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id        description  field           file  start_offset  \\\n",
       "108             108  General addresses  Title  BAI_00400.txt            28   \n",
       "\n",
       "     end_offset  \n",
       "108          46  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df.loc[ann_desc_df.description_id == 108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1286</td>\n",
       "      <td>Page mounted with three photographs of the sit...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1287</td>\n",
       "      <td>Page mounted with four photographs</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>132</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1288</td>\n",
       "      <td>Page mounted with two photographs of the Poult...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1289</td>\n",
       "      <td>Page mounted with programme of the Scottish Po...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>286</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>Page mounted with five photographs</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>427</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1291</td>\n",
       "      <td>Page mounted with four items</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>470</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1292</td>\n",
       "      <td>Page mounted with seven photographs of Alan Gr...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>507</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1293</td>\n",
       "      <td>Group photograph of staff and students outside...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>629</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1294</td>\n",
       "      <td>Four items found loose among photographs</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>717</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1295</td>\n",
       "      <td>Page mounted with two photographs of Alan Gree...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>766</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1296</td>\n",
       "      <td>Album of postcards from Greenwood's trip to Ca...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>826</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1297</td>\n",
       "      <td>The article is concerned with the death of a p...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>918</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1298</td>\n",
       "      <td>Recto: photograph showing Alan Greenwood, Dr F...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>1147</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1299</td>\n",
       "      <td>The handwritten notebook details 22 experiment...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>1454</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1300</td>\n",
       "      <td>The first photograph depicts Ahmed Abd-El-Ghaf...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>1791</td>\n",
       "      <td>2128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1301</td>\n",
       "      <td>Recto: photograph of Josephine Peace in Consta...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>2149</td>\n",
       "      <td>2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1302</td>\n",
       "      <td>The photographs show an area of cleared woodla...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>2615</td>\n",
       "      <td>2688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1303</td>\n",
       "      <td>Title page annotated with Alan Greenwood's ini...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>2709</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1304</td>\n",
       "      <td>The title page notes: 'Address given by Dr Gre...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>2783</td>\n",
       "      <td>2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1305</td>\n",
       "      <td>Recto: Alan Greenwood reading at a desk (1954)...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>3014</td>\n",
       "      <td>3353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1306</td>\n",
       "      <td>The title page notes: 'paper read at the World...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>3374</td>\n",
       "      <td>3484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1307</td>\n",
       "      <td>Recto: photograph of a brick building under co...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>3505</td>\n",
       "      <td>3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1308</td>\n",
       "      <td>The volume lists the menus for various guest a...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>3997</td>\n",
       "      <td>4455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1309</td>\n",
       "      <td>This item is a direct photocopy of Coll-1057/3...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>4476</td>\n",
       "      <td>4528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1310</td>\n",
       "      <td>The memorandum appears to consist of two separ...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>4549</td>\n",
       "      <td>5196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1311</td>\n",
       "      <td>Title page annotated 'Blackpool N.A.B conferen...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>5217</td>\n",
       "      <td>5284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1312</td>\n",
       "      <td>Contains typescript papers, many with handwrit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>5305</td>\n",
       "      <td>5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1313</td>\n",
       "      <td>Contains reprints of articles by Alan Greenwoo...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>5589</td>\n",
       "      <td>5727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1314</td>\n",
       "      <td>Verso: print of a photograph showing the 10th ...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>5748</td>\n",
       "      <td>6467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1315</td>\n",
       "      <td>Recto: three photographs depicting development...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>6488</td>\n",
       "      <td>6594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1316</td>\n",
       "      <td>The first press cutting concerns the tenth Wor...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>6615</td>\n",
       "      <td>6948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>1317</td>\n",
       "      <td>Contains:'The Growth Rate in Hypophysectomised...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>6969</td>\n",
       "      <td>7560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1318</td>\n",
       "      <td>Includes 48 postcards from places, hotels and ...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>7581</td>\n",
       "      <td>7695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      description_id                                        description  \\\n",
       "1286            1286  Page mounted with three photographs of the sit...   \n",
       "1287            1287                 Page mounted with four photographs   \n",
       "1288            1288  Page mounted with two photographs of the Poult...   \n",
       "1289            1289  Page mounted with programme of the Scottish Po...   \n",
       "1290            1290                 Page mounted with five photographs   \n",
       "1291            1291                       Page mounted with four items   \n",
       "1292            1292  Page mounted with seven photographs of Alan Gr...   \n",
       "1293            1293  Group photograph of staff and students outside...   \n",
       "1294            1294           Four items found loose among photographs   \n",
       "1295            1295  Page mounted with two photographs of Alan Gree...   \n",
       "1296            1296  Album of postcards from Greenwood's trip to Ca...   \n",
       "1297            1297  The article is concerned with the death of a p...   \n",
       "1298            1298  Recto: photograph showing Alan Greenwood, Dr F...   \n",
       "1299            1299  The handwritten notebook details 22 experiment...   \n",
       "1300            1300  The first photograph depicts Ahmed Abd-El-Ghaf...   \n",
       "1301            1301  Recto: photograph of Josephine Peace in Consta...   \n",
       "1302            1302  The photographs show an area of cleared woodla...   \n",
       "1303            1303  Title page annotated with Alan Greenwood's ini...   \n",
       "1304            1304  The title page notes: 'Address given by Dr Gre...   \n",
       "1305            1305  Recto: Alan Greenwood reading at a desk (1954)...   \n",
       "1306            1306  The title page notes: 'paper read at the World...   \n",
       "1307            1307  Recto: photograph of a brick building under co...   \n",
       "1308            1308  The volume lists the menus for various guest a...   \n",
       "1309            1309  This item is a direct photocopy of Coll-1057/3...   \n",
       "1310            1310  The memorandum appears to consist of two separ...   \n",
       "1311            1311  Title page annotated 'Blackpool N.A.B conferen...   \n",
       "1312            1312  Contains typescript papers, many with handwrit...   \n",
       "1313            1313  Contains reprints of articles by Alan Greenwoo...   \n",
       "1314            1314  Verso: print of a photograph showing the 10th ...   \n",
       "1315            1315  Recto: three photographs depicting development...   \n",
       "1316            1316  The first press cutting concerns the tenth Wor...   \n",
       "1317            1317  Contains:'The Growth Rate in Hypophysectomised...   \n",
       "1318            1318  Includes 48 postcards from places, hotels and ...   \n",
       "\n",
       "                   field                 file  start_offset  end_offset  \n",
       "1286               Title  Coll-1057_00600.txt             7         124  \n",
       "1287               Title  Coll-1057_00600.txt           132         167  \n",
       "1288               Title  Coll-1057_00600.txt           175         278  \n",
       "1289               Title  Coll-1057_00600.txt           286         419  \n",
       "1290               Title  Coll-1057_00600.txt           427         462  \n",
       "1291               Title  Coll-1057_00600.txt           470         499  \n",
       "1292               Title  Coll-1057_00600.txt           507         621  \n",
       "1293               Title  Coll-1057_00600.txt           629         709  \n",
       "1294               Title  Coll-1057_00600.txt           717         758  \n",
       "1295               Title  Coll-1057_00600.txt           766         818  \n",
       "1296               Title  Coll-1057_00600.txt           826         897  \n",
       "1297  Scope and Contents  Coll-1057_00600.txt           918        1126  \n",
       "1298  Scope and Contents  Coll-1057_00600.txt          1147        1433  \n",
       "1299  Scope and Contents  Coll-1057_00600.txt          1454        1770  \n",
       "1300  Scope and Contents  Coll-1057_00600.txt          1791        2128  \n",
       "1301  Scope and Contents  Coll-1057_00600.txt          2149        2594  \n",
       "1302  Scope and Contents  Coll-1057_00600.txt          2615        2688  \n",
       "1303  Scope and Contents  Coll-1057_00600.txt          2709        2762  \n",
       "1304  Scope and Contents  Coll-1057_00600.txt          2783        2993  \n",
       "1305  Scope and Contents  Coll-1057_00600.txt          3014        3353  \n",
       "1306  Scope and Contents  Coll-1057_00600.txt          3374        3484  \n",
       "1307  Scope and Contents  Coll-1057_00600.txt          3505        3976  \n",
       "1308  Scope and Contents  Coll-1057_00600.txt          3997        4455  \n",
       "1309  Scope and Contents  Coll-1057_00600.txt          4476        4528  \n",
       "1310  Scope and Contents  Coll-1057_00600.txt          4549        5196  \n",
       "1311  Scope and Contents  Coll-1057_00600.txt          5217        5284  \n",
       "1312  Scope and Contents  Coll-1057_00600.txt          5305        5568  \n",
       "1313  Scope and Contents  Coll-1057_00600.txt          5589        5727  \n",
       "1314  Scope and Contents  Coll-1057_00600.txt          5748        6467  \n",
       "1315  Scope and Contents  Coll-1057_00600.txt          6488        6594  \n",
       "1316  Scope and Contents  Coll-1057_00600.txt          6615        6948  \n",
       "1317  Scope and Contents  Coll-1057_00600.txt          6969        7560  \n",
       "1318  Scope and Contents  Coll-1057_00600.txt          7581        7695  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df.loc[ann_desc_df.file == \"Coll-1057_00600.txt\"]  #Coll-1036_00400.txt   # Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we have calculated the intermediate start and end offsets as well, which are all in the DataFrame above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the file of annotated descritions with their start and end offsets to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_desc_filepath = config.crc_meta_path+\"annot_descs.csv\"\n",
    "ann_desc_df.to_csv(annot_desc_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write each description to a TXT file for later analysis with NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "26875 files finished writing!\n"
     ]
    }
   ],
   "source": [
    "dir_path = config.crc_meta_path+\"descriptions_annotated/\"\n",
    "# Make sure the directory exists\n",
    "Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write one TXT file per descrpition (utf-8 encoded by default), with the description ID as the file name\n",
    "description_list = list(ann_desc_df.description)\n",
    "id_list = list(ann_desc_df.description_id)\n",
    "# For zero padding so files are ordered correctly\n",
    "max_digits = len(str(max(id_list)))\n",
    "counter = 0\n",
    "for i in range(len(description_list)):\n",
    "    d = description_list[i]\n",
    "    did = id_list[i]\n",
    "    zeros = max_digits - len(str(did))\n",
    "    filename = (\"0\"*zeros)+str(did)+\".txt\"\n",
    "    f = open(dir_path+filename, \"w\")\n",
    "    f.write(d)\n",
    "    f.close()\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"10000 new files written\")\n",
    "print(\"{} files finished writing!\".format(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment if need to reload data\n",
    "# # --------------------------------\n",
    "# annot_desc_filepath = config.crc_meta_path+\"annot_descs.csv\"\n",
    "# ann_desc_df = pd.read_csv(annot_desc_filepath)\n",
    "# ann_desc_df = ann_desc_df.drop(columns=[\"Unnamed: 0\"])\n",
    "# dir_path = config.crc_meta_path+\"descriptions_annotated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000.txt', '00001.txt', '00002.txt', '00003.txt', '00004.txt', '00005.txt', '00006.txt', '00007.txt', '00008.txt', '00009.txt']\n",
      "['26865.txt', '26866.txt', '26867.txt', '26868.txt', '26869.txt', '26870.txt', '26871.txt', '26872.txt', '26873.txt', '26874.txt']\n"
     ]
    }
   ],
   "source": [
    "corpus = PlaintextCorpusReader(dir_path, \"\\w*.txt\", encoding=\"utf8\")\n",
    "print(corpus.fileids()[:10]) # Looks good\n",
    "print(corpus.fileids()[-10:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Papers', 'of', 'The', 'Very', 'Rev', 'Prof', 'James', 'Whyte', '1920-2005']\n",
      "['papers', 'of', 'the', 'very', 'rev', 'prof', 'james', 'whyte', '1920-2005']\n",
      "['Papers of The Very Rev Prof James Whyte (1920-2005)']\n"
     ]
    }
   ],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 62] [1, 1, 8, 1]\n"
     ]
    }
   ],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>97</td>\n",
       "      <td>633</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>81</td>\n",
       "      <td>560</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                        description  \\\n",
       "0               0  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "1               1  Sermons and addresses, 1948-1996; lectures, 19...   \n",
       "2               2  Professor James Aitken White was a leading Sco...   \n",
       "3               3                Papers of Rev Tom Allan (1916-1965)   \n",
       "4               4  Sermons and addresses, 1947-1963; essays and l...   \n",
       "\n",
       "                       field           file  start_offset  end_offset  \\\n",
       "0                      Title  AA5_00100.txt            24          76   \n",
       "1         Scope and Contents  AA5_00100.txt            97         633   \n",
       "2  Biographical / Historical  AA5_00100.txt           661        1724   \n",
       "3                      Title  AA6_00100.txt            24          60   \n",
       "4         Scope and Contents  AA6_00100.txt            81         560   \n",
       "\n",
       "   word_count  sent_count  \n",
       "0           9           1  \n",
       "1          62           1  \n",
       "2         179           8  \n",
       "3           6           1  \n",
       "4          59           2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df.insert(len(ann_desc_df.columns), \"word_count\", word_count)\n",
    "ann_desc_df.insert(len(ann_desc_df.columns), \"sent_count\", sent_count)\n",
    "ann_desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_desc_df.to_csv(annot_desc_filepath)  # add to the counts to the existing CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate summary stats for word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", ann_desc_df)\n",
    "bh_stats = utils.makeDescribeDf(\"Biographical / Historical\", ann_desc_df)\n",
    "sc_stats = utils.makeDescribeDf(\"Scope and Contents\", ann_desc_df)\n",
    "pi_stats = utils.makeDescribeDf(\"Processing Information\", ann_desc_df)\n",
    "t_stats = utils.makeDescribeDf(\"Title\", ann_desc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_descriptions</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata_field</th>\n",
       "      <th>by</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">All</th>\n",
       "      <th>word_count</th>\n",
       "      <td>26875.0</td>\n",
       "      <td>18.672298</td>\n",
       "      <td>87.842174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>26875.0</td>\n",
       "      <td>1.519479</td>\n",
       "      <td>5.422002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Title</th>\n",
       "      <th>word_count</th>\n",
       "      <td>14862.0</td>\n",
       "      <td>7.253061</td>\n",
       "      <td>5.623145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>14862.0</td>\n",
       "      <td>1.116001</td>\n",
       "      <td>0.498569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Scope and Contents</th>\n",
       "      <th>word_count</th>\n",
       "      <td>11056.0</td>\n",
       "      <td>28.425018</td>\n",
       "      <td>129.541254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>11056.0</td>\n",
       "      <td>1.809877</td>\n",
       "      <td>8.190972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Biographical / Historical</th>\n",
       "      <th>word_count</th>\n",
       "      <td>655.0</td>\n",
       "      <td>117.453435</td>\n",
       "      <td>135.133575</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>655.0</td>\n",
       "      <td>5.975573</td>\n",
       "      <td>6.566015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Processing Information</th>\n",
       "      <th>word_count</th>\n",
       "      <td>302.0</td>\n",
       "      <td>9.350993</td>\n",
       "      <td>10.534360</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>302.0</td>\n",
       "      <td>1.079470</td>\n",
       "      <td>0.346279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      total_descriptions        mean  \\\n",
       "metadata_field            by                                           \n",
       "All                       word_count             26875.0   18.672298   \n",
       "                          sent_count             26875.0    1.519479   \n",
       "Title                     word_count             14862.0    7.253061   \n",
       "                          sent_count             14862.0    1.116001   \n",
       "Scope and Contents        word_count             11056.0   28.425018   \n",
       "                          sent_count             11056.0    1.809877   \n",
       "Biographical / Historical word_count               655.0  117.453435   \n",
       "                          sent_count               655.0    5.975573   \n",
       "Processing Information    word_count               302.0    9.350993   \n",
       "                          sent_count               302.0    1.079470   \n",
       "\n",
       "                                             std  min      max  \n",
       "metadata_field            by                                    \n",
       "All                       word_count   87.842174  0.0  12340.0  \n",
       "                          sent_count    5.422002  1.0    742.0  \n",
       "Title                     word_count    5.623145  0.0     51.0  \n",
       "                          sent_count    0.498569  1.0     15.0  \n",
       "Scope and Contents        word_count  129.541254  0.0  12340.0  \n",
       "                          sent_count    8.190972  1.0    742.0  \n",
       "Biographical / Historical word_count  135.133575  6.0   1110.0  \n",
       "                          sent_count    6.566015  1.0     45.0  \n",
       "Processing Information    word_count   10.534360  4.0    177.0  \n",
       "                          sent_count    0.346279  1.0      4.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "## 2. Offsets of Tokens\n",
    "\n",
    "**Get the offsets of the tokens in every description.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>97</td>\n",
       "      <td>633</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>81</td>\n",
       "      <td>560</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                        description  \\\n",
       "0               0  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "1               1  Sermons and addresses, 1948-1996; lectures, 19...   \n",
       "2               2  Professor James Aitken White was a leading Sco...   \n",
       "3               3                Papers of Rev Tom Allan (1916-1965)   \n",
       "4               4  Sermons and addresses, 1947-1963; essays and l...   \n",
       "\n",
       "                       field           file  start_offset  end_offset  \\\n",
       "0                      Title  AA5_00100.txt            24          76   \n",
       "1         Scope and Contents  AA5_00100.txt            97         633   \n",
       "2  Biographical / Historical  AA5_00100.txt           661        1724   \n",
       "3                      Title  AA6_00100.txt            24          60   \n",
       "4         Scope and Contents  AA6_00100.txt            81         560   \n",
       "\n",
       "   word_count  sent_count  \n",
       "0           9           1  \n",
       "1          62           1  \n",
       "2         179           8  \n",
       "3           6           1  \n",
       "4          59           2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_desc_filepath = config.crc_meta_path+\"annot_descs.csv\"\n",
    "df_desc = pd.read_csv(annot_desc_filepath, index_col=0)\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = list(df_desc.description)\n",
    "desc_ids = list(df_desc.description_id)\n",
    "desc_start_offsets = list(df_desc.start_offset)\n",
    "desc_end_offsets = list(df_desc.end_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dict, offsets_dict = utils.getTokensAndOffsetsFromStrings(descs, desc_ids, desc_start_offsets, desc_end_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_col, offsets_col, desc_ids_col = [], [], []\n",
    "for desc_id,token_list in tokens_dict.items():\n",
    "    tokens_col += token_list\n",
    "    offsets_list = offsets_dict[desc_id]\n",
    "    offsets_col += offsets_list\n",
    "    assert len(token_list) == len(offsets_list)\n",
    "    desc_ids_col += [desc_id]*len(token_list)\n",
    "\n",
    "assert len(tokens_col) == len(offsets_col)\n",
    "assert len(tokens_col) == len(desc_ids_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Papers', 'of', 'The', 'Very', 'Rev']\n",
      "[(24, 30), (31, 33), (34, 37), (38, 42), (43, 46)]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for col_list in [tokens_col, offsets_col, desc_ids_col]:\n",
    "    print(col_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  Now create a DataFrame with these lists as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Very</td>\n",
       "      <td>(38, 42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Rev</td>\n",
       "      <td>(43, 46)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id   token   offsets\n",
       "0        0  Papers  (24, 30)\n",
       "1        0      of  (31, 33)\n",
       "2        0     The  (34, 37)\n",
       "3        0    Very  (38, 42)\n",
       "4        0     Rev  (43, 46)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.DataFrame({\"desc_id\":desc_ids_col, \"token\":tokens_col, \"offsets\":offsets_col})\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666242, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now write the DataFrame to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.to_csv(config.crc_meta_path+\"descid_token_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Description and Annotation Linking\n",
    "\n",
    "**Assign a description ID to every annotation, using the file names and offsets to determine within which description each annotated text span appears.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:** Convert all offsets to tuples of integers and create a `filename` column to match up the descriptions' .txt files and annotated text spans' .ann files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_offsets</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AA5_00100</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>(24, 76)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AA5_00100</td>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>(97, 633)</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AA5_00100</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>(661, 1724)</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AA6_00100</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>(24, 60)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AA6_00100</td>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>(81, 560)</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id   filename  \\\n",
       "0               0  AA5_00100   \n",
       "1               1  AA5_00100   \n",
       "2               2  AA5_00100   \n",
       "3               3  AA6_00100   \n",
       "4               4  AA6_00100   \n",
       "\n",
       "                                         description desc_offsets  \\\n",
       "0  Papers of The Very Rev Prof James Whyte (1920-...     (24, 76)   \n",
       "1  Sermons and addresses, 1948-1996; lectures, 19...    (97, 633)   \n",
       "2  Professor James Aitken White was a leading Sco...  (661, 1724)   \n",
       "3                Papers of Rev Tom Allan (1916-1965)     (24, 60)   \n",
       "4  Sermons and addresses, 1947-1963; essays and l...    (81, 560)   \n",
       "\n",
       "                       field           file  \n",
       "0                      Title  AA5_00100.txt  \n",
       "1         Scope and Contents  AA5_00100.txt  \n",
       "2  Biographical / Historical  AA5_00100.txt  \n",
       "3                      Title  AA6_00100.txt  \n",
       "4         Scope and Contents  AA6_00100.txt  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descs = pd.read_csv(config.crc_meta_path+\"annot_descs.csv\", index_col=0)\n",
    "\n",
    "# Remove file extensions\n",
    "desc_filenames = list(df_descs.file)\n",
    "desc_filenames = [f[:-4] for f in desc_filenames]\n",
    "df_descs.insert(1, \"filename\", desc_filenames)\n",
    "\n",
    "# Get offsets as tuples of ints\n",
    "start_offsets = list(df_descs.start_offset)\n",
    "end_offsets = list(df_descs.end_offset)\n",
    "offsets_strs = list(zip(list(df_descs.start_offset),list(df_descs.end_offset)))\n",
    "desc_offsets_int_tuples = utils.turnStrTuplesToIntTuples(offsets_strs)\n",
    "df_descs = df_descs.drop(columns=[\"start_offset\", \"end_offset\", \"word_count\", \"sent_count\"])\n",
    "df_descs.insert(, \"desc_offsets\", offsets_int_tuples)\n",
    "\n",
    "df_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-1157_00100</td>\n",
       "      <td>Coll-1157_00100.ann</td>\n",
       "      <td>knighted</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-1310_02300</td>\n",
       "      <td>Coll-1310_02300.ann</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-1281_00100</td>\n",
       "      <td>Coll-1281_00100.ann</td>\n",
       "      <td>Prince Regent</td>\n",
       "      <td>(2426, 2439)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>Coll-1310_02700</td>\n",
       "      <td>Coll-1310_02700.ann</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>(9993, 10003)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>Coll-1310_02900</td>\n",
       "      <td>Coll-1310_02900.ann</td>\n",
       "      <td>Sir</td>\n",
       "      <td>(7192, 7195)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agg_ann_id         filename                 file           text  \\\n",
       "12           0  Coll-1157_00100  Coll-1157_00100.ann       knighted   \n",
       "22           1  Coll-1310_02300  Coll-1310_02300.ann     knighthood   \n",
       "23           2  Coll-1281_00100  Coll-1281_00100.ann  Prince Regent   \n",
       "24           3  Coll-1310_02700  Coll-1310_02700.ann     knighthood   \n",
       "25           4  Coll-1310_02900  Coll-1310_02900.ann            Sir   \n",
       "\n",
       "      ann_offsets          label    category associated_genders  \n",
       "12   (1407, 1415)  Gendered-Role  Linguistic            Unclear  \n",
       "22   (9625, 9635)  Gendered-Role  Linguistic            Unclear  \n",
       "23   (2426, 2439)  Gendered-Role  Linguistic            Unclear  \n",
       "24  (9993, 10003)  Gendered-Role  Linguistic            Unclear  \n",
       "25   (7192, 7195)  Gendered-Role  Linguistic            Unclear  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ann = pd.read_csv(\"../data/aggregated_data/aggregated_final.csv\", index_col=0)\n",
    "\n",
    "# Remove file extensions\n",
    "ann_filenames = list(df_ann.file)\n",
    "ann_filenames = [f[:-4] for f in ann_filenames]\n",
    "df_ann.insert(1, \"filename\", ann_filenames)\n",
    "\n",
    "# Get offsets as tuples of ints\n",
    "ann_offsets_strs = list(df_ann.offsets)\n",
    "ann_offsets_strs = [pair[1:-1].split(\",\") for pair in ann_offsets_strs]\n",
    "ann_offsets_ints = [tuple((int(pair[0].strip()), int(pair[1].strip()))) for pair in ann_offsets_strs]\n",
    "df_ann = df_ann.drop(columns=[\"offsets\"])\n",
    "df_ann.insert(4, \"ann_offsets\", ann_offsets_ints)\n",
    "\n",
    "df_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2:** Associate each file to IDs and offsets, for ease of comparison of the annotations' files and offsets to the descriptions' files and offsets to determine which description ID to assign to each annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA5_00100</th>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Papers of The Very Rev Prof James Whyte (1920...</td>\n",
       "      <td>[(24, 76), (97, 633), (661, 1724)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA6_00100</th>\n",
       "      <td>[3, 4, 5]</td>\n",
       "      <td>[Papers of Rev Tom Allan (1916-1965), Sermons ...</td>\n",
       "      <td>[(24, 60), (81, 560), (588, 2512)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA7_00100</th>\n",
       "      <td>[6, 7, 8]</td>\n",
       "      <td>[Papers of Rev Prof Alec Campbell Cheyne (1924...</td>\n",
       "      <td>[(24, 76), (97, 417), (445, 2441)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00100</th>\n",
       "      <td>[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20...</td>\n",
       "      <td>[Papers of Professor John Baillie, and Baillie...</td>\n",
       "      <td>[(24, 84), (92, 115), (123, 143), (151, 210), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00200</th>\n",
       "      <td>[42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...</td>\n",
       "      <td>[New Testament (senior), Apologetics (senior),...</td>\n",
       "      <td>[(8, 31), (39, 60), (68, 97), (105, 134), (142...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description_id  \\\n",
       "filename                                                       \n",
       "AA5_00100                                          [0, 1, 2]   \n",
       "AA6_00100                                          [3, 4, 5]   \n",
       "AA7_00100                                          [6, 7, 8]   \n",
       "BAI_00100  [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20...   \n",
       "BAI_00200  [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...   \n",
       "\n",
       "                                                 description  \\\n",
       "filename                                                       \n",
       "AA5_00100  [Papers of The Very Rev Prof James Whyte (1920...   \n",
       "AA6_00100  [Papers of Rev Tom Allan (1916-1965), Sermons ...   \n",
       "AA7_00100  [Papers of Rev Prof Alec Campbell Cheyne (1924...   \n",
       "BAI_00100  [Papers of Professor John Baillie, and Baillie...   \n",
       "BAI_00200  [New Testament (senior), Apologetics (senior),...   \n",
       "\n",
       "                                                desc_offsets  \n",
       "filename                                                      \n",
       "AA5_00100                 [(24, 76), (97, 633), (661, 1724)]  \n",
       "AA6_00100                 [(24, 60), (81, 560), (588, 2512)]  \n",
       "AA7_00100                 [(24, 76), (97, 417), (445, 2441)]  \n",
       "BAI_00100  [(24, 84), (92, 115), (123, 143), (151, 210), ...  \n",
       "BAI_00200  [(8, 31), (39, 60), (68, 97), (105, 134), (142...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_descs = df_descs.drop(columns=[\"field\",\"file\"])\n",
    "df_descs_imploded = utils.implodeDataFrame(subdf_descs, [\"filename\"])\n",
    "df_descs_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description_id': [0, 1, 2], 'description': ['Papers of The Very Rev Prof James Whyte (1920-2005)', 'Sermons and addresses, 1948-1996; lectures, 1949-1982; class notes and lecture notes, 1949-1982; correspondence, 1988-1989 and 1964-1970; newspaper cuttings, 1988-1989 and 1964-1969; publications and articles, 1902-1970; church magazines, 1929-1993; conference papers, 1978; moderatorial papers, 1988-1989; University Christian Consultative Group papers, 1970-1972; Church of Scotland and the Congregational Union of Scotland papers, 1959-1967; personal papers, 1848-1983; photographs 1911 and 1960.See also External Documents (below).', \"Professor James Aitken White was a leading Scottish Theologian and Moderator of the General Assembly of the Church of Scotland. He was educated at Daniel Stewart's College and the University of Edinburgh where he studied philosophy and divinity. After his ordination he spent three years as an army Chaplain and then in 1948 was inducted to Dunollie Road Church in Oban. James Whyte moved to Mayfield North Church in Edinburgh in 1954 and in 1958 was appointed to the chair of practical theology and Christian ethics at the University of St Andrew's where he remained until 1987. His primary interests were in liturgy and ecclesiastical architecture and he also lectured on pastoral care.\\nJames Whyte was called upon to preach at the memorial service for the victims of the Lockerbie disaster on 4th January 1989. The service was relayed around the world and was widely cited in the press having had a great impact. The full text of this sermon was published in Laughter and Tears: Thoughts on Faith in the Face of Suffering (Edinburgh, St Andrew's Press, 1993).\"], 'desc_offsets': [(24, 76), (97, 633), (661, 1724)]}\n"
     ]
    }
   ],
   "source": [
    "descs_dict = df_descs_imploded.to_dict(orient=\"index\")\n",
    "print(descs_dict[\"AA5_00100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA5_00100</th>\n",
       "      <td>[14377, 14378, 14379, 14380, 14381, 14382, 143...</td>\n",
       "      <td>[He, he, his, he, he, His, he, The Very Rev Pr...</td>\n",
       "      <td>[(789, 791), (871, 873), (913, 916), (928, 930...</td>\n",
       "      <td>[Gendered-Pronoun, Gendered-Pronoun, Gendered-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA6_00100</th>\n",
       "      <td>[55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...</td>\n",
       "      <td>[Billy Graham, He, he, he, he, He, his, his, h...</td>\n",
       "      <td>[(1778, 1790), (677, 679), (920, 922), (1222, ...</td>\n",
       "      <td>[Masculine, Gendered-Pronoun, Gendered-Pronoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA7_00100</th>\n",
       "      <td>[127, 13987, 13988, 13989, 13990, 13991, 13992...</td>\n",
       "      <td>[Professor Cheyne, son, sister, brother, His, ...</td>\n",
       "      <td>[(2399, 2415), (505, 508), (614, 620), (647, 6...</td>\n",
       "      <td>[Masculine, Gendered-Role, Gendered-Role, Gend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00100</th>\n",
       "      <td>[17473, 17474, 17475, 17476, 17477, 17478, 416...</td>\n",
       "      <td>[Jacques Chevalier, Lloyd Morgan, Professor Jo...</td>\n",
       "      <td>[(371, 388), (393, 405), (34, 56), (102, 114),...</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown, Unknown, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00200</th>\n",
       "      <td>[20496, 20497, 20498, 20499, 20500, 20501, 205...</td>\n",
       "      <td>[Barker, Garvie, Busch, Adolf Jülicher, Johann...</td>\n",
       "      <td>[(215, 221), (226, 232), (250, 255), (285, 299...</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown, Unknown, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  agg_ann_id  \\\n",
       "filename                                                       \n",
       "AA5_00100  [14377, 14378, 14379, 14380, 14381, 14382, 143...   \n",
       "AA6_00100  [55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...   \n",
       "AA7_00100  [127, 13987, 13988, 13989, 13990, 13991, 13992...   \n",
       "BAI_00100  [17473, 17474, 17475, 17476, 17477, 17478, 416...   \n",
       "BAI_00200  [20496, 20497, 20498, 20499, 20500, 20501, 205...   \n",
       "\n",
       "                                                        text  \\\n",
       "filename                                                       \n",
       "AA5_00100  [He, he, his, he, he, His, he, The Very Rev Pr...   \n",
       "AA6_00100  [Billy Graham, He, he, he, he, He, his, his, h...   \n",
       "AA7_00100  [Professor Cheyne, son, sister, brother, His, ...   \n",
       "BAI_00100  [Jacques Chevalier, Lloyd Morgan, Professor Jo...   \n",
       "BAI_00200  [Barker, Garvie, Busch, Adolf Jülicher, Johann...   \n",
       "\n",
       "                                                 ann_offsets  \\\n",
       "filename                                                       \n",
       "AA5_00100  [(789, 791), (871, 873), (913, 916), (928, 930...   \n",
       "AA6_00100  [(1778, 1790), (677, 679), (920, 922), (1222, ...   \n",
       "AA7_00100  [(2399, 2415), (505, 508), (614, 620), (647, 6...   \n",
       "BAI_00100  [(371, 388), (393, 405), (34, 56), (102, 114),...   \n",
       "BAI_00200  [(215, 221), (226, 232), (250, 255), (285, 299...   \n",
       "\n",
       "                                                       label  \n",
       "filename                                                      \n",
       "AA5_00100  [Gendered-Pronoun, Gendered-Pronoun, Gendered-...  \n",
       "AA6_00100  [Masculine, Gendered-Pronoun, Gendered-Pronoun...  \n",
       "AA7_00100  [Masculine, Gendered-Role, Gendered-Role, Gend...  \n",
       "BAI_00100  [Unknown, Unknown, Unknown, Unknown, Unknown, ...  \n",
       "BAI_00200  [Unknown, Unknown, Unknown, Unknown, Unknown, ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_ann = df_ann.drop(columns=[\"file\",\"category\",\"associated_genders\"])\n",
    "df_ann_imploded = utils.implodeDataFrame(subdf_ann, [\"filename\"])\n",
    "df_ann_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agg_ann_id': [14377, 14378, 14379, 14380, 14381, 14382, 14383, 14384, 14385, 14386, 14387, 24275, 26233, 41260, 41261, 41262, 41263, 52952, 52953], 'text': ['He', 'he', 'his', 'he', 'he', 'His', 'he', 'The Very Rev Prof James Whyte', 'Professor James Aitken White', 'James Whyte', 'James Whyte', 'The Very Rev Prof James Whyte', 'Rev Prof James Whyte', 'Scottish Theologian', 'Moderator of the General Assembly of the Church of Scotland', 'army Chaplain', 'chair of practical theology and Christian ethics', 'The Very Rev Prof James Whyte', 'leading Scottish Theologian'], 'ann_offsets': [(789, 791), (871, 873), (913, 916), (928, 930), (1217, 1219), (1241, 1244), (1315, 1317), (34, 63), (661, 689), (1032, 1043), (1350, 1361), (34, 63), (43, 63), (704, 723), (728, 787), (955, 968), (1129, 1177), (34, 63), (696, 723)], 'label': ['Gendered-Pronoun', 'Gendered-Pronoun', 'Gendered-Pronoun', 'Gendered-Pronoun', 'Gendered-Pronoun', 'Gendered-Pronoun', 'Gendered-Pronoun', 'Unknown', 'Masculine', 'Masculine', 'Masculine', 'Masculine', 'Unknown', 'Occupation', 'Occupation', 'Occupation', 'Occupation', 'Stereotype', 'Stereotype']}\n"
     ]
    }
   ],
   "source": [
    "anns_dict = df_ann_imploded.to_dict(orient=\"index\")\n",
    "print(anns_dict[\"AA5_00100\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3:** File by file, determine which description's offsets each annotation occurs within and associate the corresponding description IDs and annotation IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "annid_to_descid = dict.fromkeys(list(df_ann.agg_ann_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(df_ann_imploded.index)\n",
    "assert list(df_ann_imploded.index).sort() == list(df_descs_imploded.index).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = files[:10]\n",
    "# sample_annids = list(df_ann.loc[df_ann.file.isin(sample)].agg_ann_id)\n",
    "# sample_annid_to_descid = dict.fromkeys(sample_annids)\n",
    "for f in files:  #sample\n",
    "    ann_ids, ann_offsets = anns_dict[f][\"agg_ann_id\"], anns_dict[f][\"ann_offsets\"]\n",
    "    desc_ids, desc_offsets = descs_dict[f][\"description_id\"], descs_dict[f][\"desc_offsets\"]\n",
    "    for i,ann_id in enumerate(ann_ids):\n",
    "        ann_offset_pair = ann_offsets[i]\n",
    "        for j,desc_id in enumerate(desc_ids):\n",
    "            desc_offset_pair = desc_offsets[j]\n",
    "            # If the annotation offsets are within the description offsets, assign that description ID to that annotation \n",
    "            if (ann_offset_pair[0] >= desc_offset_pair[0]) and (ann_offset_pair[0] <= desc_offset_pair[1]):\n",
    "                if (ann_offset_pair[1] >= desc_offset_pair[0]) and (ann_offset_pair[1] <= desc_offset_pair[1]):\n",
    "                    annid_to_descid[ann_id] = desc_id  #sample_annid_to_descid[ann_id] = desc_id\n",
    "# print(sample_annid_to_descid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4349.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agg_ann_id  description_id\n",
       "0           0          2112.0\n",
       "1           1          4163.0\n",
       "2           2          3320.0\n",
       "3           3          4297.0\n",
       "4           4          4349.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_df = pd.DataFrame({\"agg_ann_id\":list(sample_annid_to_descid.keys()), \"description_id\":list(sample_annid_to_descid.values())})\n",
    "# sample_df.head()\n",
    "df_ids = pd.DataFrame({\"agg_ann_id\":list(annid_to_descid.keys()), \"description_id\":list(annid_to_descid.values())})\n",
    "df_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n",
      "(4659, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_ids.loc[df_ids.agg_ann_id.isna() == True].shape)\n",
    "print(df_ids.loc[df_ids.description_id.isna() == True].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>34</td>\n",
       "      <td>Coll-1057_00600</td>\n",
       "      <td>Coll-1057_00600.ann</td>\n",
       "      <td>J.E Wilson</td>\n",
       "      <td>(5963, 5973)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>35</td>\n",
       "      <td>Coll-1057_00600</td>\n",
       "      <td>Coll-1057_00600.ann</td>\n",
       "      <td>Major MacDougall</td>\n",
       "      <td>(5975, 5991)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>36</td>\n",
       "      <td>Coll-1057_00700</td>\n",
       "      <td>Coll-1057_00700.ann</td>\n",
       "      <td>Professor I. Michael Lerner</td>\n",
       "      <td>(9683, 9710)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>51</td>\n",
       "      <td>Coll-1057_00900</td>\n",
       "      <td>Coll-1057_00900.ann</td>\n",
       "      <td>Mrs Campbell</td>\n",
       "      <td>(5511, 5523)</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>75</td>\n",
       "      <td>Coll-1057_00800</td>\n",
       "      <td>Coll-1057_00800.ann</td>\n",
       "      <td>Duncan Weatherstone</td>\n",
       "      <td>(11529, 11548)</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Multiple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     agg_ann_id         filename                 file  \\\n",
       "73           34  Coll-1057_00600  Coll-1057_00600.ann   \n",
       "74           35  Coll-1057_00600  Coll-1057_00600.ann   \n",
       "75           36  Coll-1057_00700  Coll-1057_00700.ann   \n",
       "91           51  Coll-1057_00900  Coll-1057_00900.ann   \n",
       "116          75  Coll-1057_00800  Coll-1057_00800.ann   \n",
       "\n",
       "                            text     ann_offsets      label     category  \\\n",
       "73                    J.E Wilson    (5963, 5973)    Unknown  Person-Name   \n",
       "74              Major MacDougall    (5975, 5991)    Unknown  Person-Name   \n",
       "75   Professor I. Michael Lerner    (9683, 9710)    Unknown  Person-Name   \n",
       "91                  Mrs Campbell    (5511, 5523)   Feminine  Person-Name   \n",
       "116          Duncan Weatherstone  (11529, 11548)  Masculine  Person-Name   \n",
       "\n",
       "    associated_genders  \n",
       "73             Unclear  \n",
       "74             Unclear  \n",
       "75             Unclear  \n",
       "91             Unclear  \n",
       "116           Multiple  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns_without_desc = list(df_ids.loc[df_ids.description_id.isna() == True].agg_ann_id)\n",
    "df_anns_without_desc = df_ann.loc[df_ann.agg_ann_id.isin(anns_without_desc)]\n",
    "df_anns_without_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1286</td>\n",
       "      <td>Page mounted with three photographs of the sit...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1287</td>\n",
       "      <td>Page mounted with four photographs</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>132</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1288</td>\n",
       "      <td>Page mounted with two photographs of the Poult...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1289</td>\n",
       "      <td>Page mounted with programme of the Scottish Po...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>286</td>\n",
       "      <td>419</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>Page mounted with five photographs</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>427</td>\n",
       "      <td>462</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1291</td>\n",
       "      <td>Page mounted with four items</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>470</td>\n",
       "      <td>499</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1292</td>\n",
       "      <td>Page mounted with seven photographs of Alan Gr...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>507</td>\n",
       "      <td>621</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1293</td>\n",
       "      <td>Group photograph of staff and students outside...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>629</td>\n",
       "      <td>709</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1294</td>\n",
       "      <td>Four items found loose among photographs</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>717</td>\n",
       "      <td>758</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1295</td>\n",
       "      <td>Page mounted with two photographs of Alan Gree...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>766</td>\n",
       "      <td>818</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1296</td>\n",
       "      <td>Album of postcards from Greenwood's trip to Ca...</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>826</td>\n",
       "      <td>897</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1297</td>\n",
       "      <td>The article is concerned with the death of a p...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>918</td>\n",
       "      <td>1126</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1298</td>\n",
       "      <td>Recto: photograph showing Alan Greenwood, Dr F...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>1147</td>\n",
       "      <td>1433</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1299</td>\n",
       "      <td>The handwritten notebook details 22 experiment...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>1454</td>\n",
       "      <td>1770</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1300</td>\n",
       "      <td>The first photograph depicts Ahmed Abd-El-Ghaf...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>1791</td>\n",
       "      <td>2128</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1301</td>\n",
       "      <td>Recto: photograph of Josephine Peace in Consta...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>2149</td>\n",
       "      <td>2594</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1302</td>\n",
       "      <td>The photographs show an area of cleared woodla...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1057_00600.txt</td>\n",
       "      <td>2615</td>\n",
       "      <td>2688</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      description_id                                        description  \\\n",
       "1286            1286  Page mounted with three photographs of the sit...   \n",
       "1287            1287                 Page mounted with four photographs   \n",
       "1288            1288  Page mounted with two photographs of the Poult...   \n",
       "1289            1289  Page mounted with programme of the Scottish Po...   \n",
       "1290            1290                 Page mounted with five photographs   \n",
       "1291            1291                       Page mounted with four items   \n",
       "1292            1292  Page mounted with seven photographs of Alan Gr...   \n",
       "1293            1293  Group photograph of staff and students outside...   \n",
       "1294            1294           Four items found loose among photographs   \n",
       "1295            1295  Page mounted with two photographs of Alan Gree...   \n",
       "1296            1296  Album of postcards from Greenwood's trip to Ca...   \n",
       "1297            1297  The article is concerned with the death of a p...   \n",
       "1298            1298  Recto: photograph showing Alan Greenwood, Dr F...   \n",
       "1299            1299  The handwritten notebook details 22 experiment...   \n",
       "1300            1300  The first photograph depicts Ahmed Abd-El-Ghaf...   \n",
       "1301            1301  Recto: photograph of Josephine Peace in Consta...   \n",
       "1302            1302  The photographs show an area of cleared woodla...   \n",
       "\n",
       "                   field                 file  start_offset  end_offset  \\\n",
       "1286               Title  Coll-1057_00600.txt             7         124   \n",
       "1287               Title  Coll-1057_00600.txt           132         167   \n",
       "1288               Title  Coll-1057_00600.txt           175         278   \n",
       "1289               Title  Coll-1057_00600.txt           286         419   \n",
       "1290               Title  Coll-1057_00600.txt           427         462   \n",
       "1291               Title  Coll-1057_00600.txt           470         499   \n",
       "1292               Title  Coll-1057_00600.txt           507         621   \n",
       "1293               Title  Coll-1057_00600.txt           629         709   \n",
       "1294               Title  Coll-1057_00600.txt           717         758   \n",
       "1295               Title  Coll-1057_00600.txt           766         818   \n",
       "1296               Title  Coll-1057_00600.txt           826         897   \n",
       "1297  Scope and Contents  Coll-1057_00600.txt           918        1126   \n",
       "1298  Scope and Contents  Coll-1057_00600.txt          1147        1433   \n",
       "1299  Scope and Contents  Coll-1057_00600.txt          1454        1770   \n",
       "1300  Scope and Contents  Coll-1057_00600.txt          1791        2128   \n",
       "1301  Scope and Contents  Coll-1057_00600.txt          2149        2594   \n",
       "1302  Scope and Contents  Coll-1057_00600.txt          2615        2688   \n",
       "\n",
       "      word_count  sent_count  \n",
       "1286          18           1  \n",
       "1287           5           1  \n",
       "1288          15           1  \n",
       "1289          19           1  \n",
       "1290           5           1  \n",
       "1291           5           1  \n",
       "1292          16           1  \n",
       "1293          12           1  \n",
       "1294           6           1  \n",
       "1295           8           1  \n",
       "1296          12           1  \n",
       "1297          31           2  \n",
       "1298          44           2  \n",
       "1299          46           4  \n",
       "1300          43           1  \n",
       "1301          62           3  \n",
       "1302          12           1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.loc[df_desc.file == \"Coll-1057_00600.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Parts of description files still aren't being included...why???***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44635</th>\n",
       "      <td>194</td>\n",
       "      <td>BAI_00600</td>\n",
       "      <td>BAI_00600.ann</td>\n",
       "      <td>Moderator Designate</td>\n",
       "      <td>(655, 674)</td>\n",
       "      <td>Omission</td>\n",
       "      <td>Contextual</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>214</td>\n",
       "      <td>BAI_00700</td>\n",
       "      <td>BAI_00700.ann</td>\n",
       "      <td>Elizabeth II</td>\n",
       "      <td>(246, 258)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>234</td>\n",
       "      <td>BAI_00700</td>\n",
       "      <td>BAI_00700.ann</td>\n",
       "      <td>Jesus Christ</td>\n",
       "      <td>(959, 971)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17770</th>\n",
       "      <td>221</td>\n",
       "      <td>BAI_00700</td>\n",
       "      <td>BAI_00700.ann</td>\n",
       "      <td>Woman</td>\n",
       "      <td>(472, 477)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51135</th>\n",
       "      <td>223</td>\n",
       "      <td>BAI_00700</td>\n",
       "      <td>BAI_00700.ann</td>\n",
       "      <td>Companion of Honour</td>\n",
       "      <td>(516, 535)</td>\n",
       "      <td>Stereotype</td>\n",
       "      <td>Contextual</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            description_id   filename           file                 text  \\\n",
       "agg_ann_id                                                                  \n",
       "44635                  194  BAI_00600  BAI_00600.ann  Moderator Designate   \n",
       "17768                  214  BAI_00700  BAI_00700.ann         Elizabeth II   \n",
       "17769                  234  BAI_00700  BAI_00700.ann         Jesus Christ   \n",
       "17770                  221  BAI_00700  BAI_00700.ann                Woman   \n",
       "51135                  223  BAI_00700  BAI_00700.ann  Companion of Honour   \n",
       "\n",
       "           ann_offsets          label     category associated_genders  \n",
       "agg_ann_id                                                             \n",
       "44635       (655, 674)       Omission   Contextual            Unclear  \n",
       "17768       (246, 258)        Unknown  Person-Name            Unclear  \n",
       "17769       (959, 971)        Unknown  Person-Name            Unclear  \n",
       "17770       (472, 477)  Gendered-Role   Linguistic           Feminine  \n",
       "51135       (516, 535)     Stereotype   Contextual            Unclear  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = sample_df.set_index(\"agg_ann_id\")\n",
    "sample_df_joined = sample_df.join(df_ann.set_index(\"agg_ann_id\"), on=\"agg_ann_id\", how=\"inner\")\n",
    "assert sample_df_joined.loc[sample_df_joined.description_id.isna() == True].shape[0] == 0\n",
    "sample_df_joined.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "# DELETE CODE BELOW (MOVING TO NEW NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### 3.1 BIO Tags\n",
    "\n",
    "**Compare the descriptions' tokens' offsets to the annotated text spans' offsets to determine which tokens to mark as the beginning of an annotation (`B-[LABELNAME]`), inside an annotation (`I-[LABELNAME]`), and unannotated, or outisde of an annotation (`O`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: convert the three dataframes to dictionaries, \n",
    "#        for each filename, check whether each token_offset pair contained within each ann_offset pair and desc_,\n",
    "#        recording which description (using indeces) annotation appears within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29, 36), (37, 39), (40, 43), (44, 57), (58, 65)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.read_csv(config.tokc_path+\"descid_token_offsets.csv\", index_col=0)\n",
    "token_desc_ids = list(df_tokens.desc_id)\n",
    "tokens = list(df_tokens.token)\n",
    "token_offsets = list(df_tokens.offsets)\n",
    "token_offsets_clean = [offsets[1:-1].split(\", \") for offsets in token_offsets]\n",
    "token_offsets_tuples = [tuple((int(offsets[0]), int(offsets[1]))) for offsets in token_offsets_clean]\n",
    "token_offsets_tuples[:5]  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate description tokens and annotated text spans' text and offsets to description IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                             token_offsets  \n",
       "desc_id                                                     \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...  \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...  \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...  \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...  \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tokens_imploded = utils.implodeDataFrame(df_tokens, [\"desc_id\"])\n",
    "df_tokens_imploded = df_tokens_imploded.rename(columns={\"offsets\":\"token_offsets\"})\n",
    "df_tokens_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens_imploded.to_csv(config.tokc_path+\"token_data_imploded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data associating description and annotation IDs to offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>desc_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAI_01000</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[68]</td>\n",
       "      <td>[(1290, 1315)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01300</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[(5853, 5983)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01600</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[221]</td>\n",
       "      <td>[(5967, 6202)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01900</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[292]</td>\n",
       "      <td>[(5297, 5506)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_02200</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[361]</td>\n",
       "      <td>[(15180, 15419)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eadid desc_id      desc_offsets\n",
       "filename                                    \n",
       "BAI_01000  ['BAI']    [68]    [(1290, 1315)]\n",
       "BAI_01300  ['BAI']   [143]    [(5853, 5983)]\n",
       "BAI_01600  ['BAI']   [221]    [(5967, 6202)]\n",
       "BAI_01900  ['BAI']   [292]    [(5297, 5506)]\n",
       "BAI_02200  ['BAI']   [361]  [(15180, 15419)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descs_imploded = pd.read_csv(config.agg_path+\"description_data_imploded.csv\", index_col=0)\n",
    "df_descs_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>ann_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA5_00100</th>\n",
       "      <td>[14377, 14378, 14379, 14380, 14381, 14382, 143...</td>\n",
       "      <td>['(789, 791)', '(871, 873)', '(913, 916)', '(9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA6_00100</th>\n",
       "      <td>[55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...</td>\n",
       "      <td>['(1778, 1790)', '(677, 679)', '(920, 922)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA7_00100</th>\n",
       "      <td>[127, 13987, 13988, 13989, 13990, 13991, 13992...</td>\n",
       "      <td>['(2399, 2415)', '(505, 508)', '(614, 620)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00100</th>\n",
       "      <td>[17473, 17474, 17475, 17476, 17477, 17478, 416...</td>\n",
       "      <td>['(371, 388)', '(393, 405)', '(34, 56)', '(102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00200</th>\n",
       "      <td>[20496, 20497, 20498, 20499, 20500, 20501, 205...</td>\n",
       "      <td>['(215, 221)', '(226, 232)', '(250, 255)', '(2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  agg_ann_id  \\\n",
       "filename                                                       \n",
       "AA5_00100  [14377, 14378, 14379, 14380, 14381, 14382, 143...   \n",
       "AA6_00100  [55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...   \n",
       "AA7_00100  [127, 13987, 13988, 13989, 13990, 13991, 13992...   \n",
       "BAI_00100  [17473, 17474, 17475, 17476, 17477, 17478, 416...   \n",
       "BAI_00200  [20496, 20497, 20498, 20499, 20500, 20501, 205...   \n",
       "\n",
       "                                                 ann_offsets  \n",
       "filename                                                      \n",
       "AA5_00100  ['(789, 791)', '(871, 873)', '(913, 916)', '(9...  \n",
       "AA6_00100  ['(1778, 1790)', '(677, 679)', '(920, 922)', '...  \n",
       "AA7_00100  ['(2399, 2415)', '(505, 508)', '(614, 620)', '...  \n",
       "BAI_00100  ['(371, 388)', '(393, 405)', '(34, 56)', '(102...  \n",
       "BAI_00200  ['(215, 221)', '(226, 232)', '(250, 255)', '(2...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anns_imploded = pd.read_csv(config.agg_path+\"annotation_data_imploded.csv\", index_col=0)\n",
    "df_anns_imploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: O tags**\n",
    "\n",
    "Compare description IDs in the two DataFrames above to determine which descriptions (from `df_tokens_imploded`) do not have annotations, and assign all those descriptions' tokens an `O` tag (for *outside* of an annotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign tag 'O': 86742\n"
     ]
    }
   ],
   "source": [
    "all_desc_ids = list(df_tokens_imploded.index)\n",
    "ann_desc_ids = list(df_merged_imploded.index)\n",
    "unannotated = [desc_id for desc_id in all_desc_ids if not desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign tag 'O':\", len(unannotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(unannotated)]\n",
    "assert o_df.shape[0] == len(unannotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "      <th>ann_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                                   offsets  \\\n",
       "desc_id                                                      \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...   \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...   \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...   \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...   \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...   \n",
       "\n",
       "                                                   ann_tag  \n",
       "desc_id                                                     \n",
       "0                                    [O, O, O, O, O, O, O]  \n",
       "1        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list = list(o_df.token)\n",
    "tags = [[\"O\"]*len(tokens) for tokens in tokens_list]\n",
    "assert len(tags) == len(tokens_list)\n",
    "o_df.insert(len(o_df.columns), \"ann_tag\", tags)\n",
    "o_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(o_df.token[100]) == len(o_df.ann_tag[100])\n",
    "assert len(o_df.token[488]) == len(o_df.ann_tag[488])\n",
    "assert len(o_df.token[0]) == len(o_df.ann_tag[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: B- and I- tags**\n",
    "\n",
    "For description IDs that do have annotations (and thus are in `df_merged_imploded`), assign their tokens tags of `B-[LABELNAME]` and `I-[LABELNAME]` for *beginning* and *inside* of an annotation, replacing `[LABELNAME]` with the name of the annotation's label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign 'B-' or 'I-'': 1855\n"
     ]
    }
   ],
   "source": [
    "annotated = [desc_id for desc_id in all_desc_ids if desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign 'B-' or 'I-'':\", len(annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(annotated)]\n",
    "assert bi_df.shape[0] == len(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[Brick, Burning, ,, Beardman, 's]</td>\n",
       "      <td>[(1421, 1426), (1427, 1434), (1434, 1435), (14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>[Interpreting, sequence, motifs, [, Letter, to...</td>\n",
       "      <td>[(3064, 3076), (3077, 3085), (3086, 3092), (30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>[Lady, Luck, :, the, theory, of, probability, ...</td>\n",
       "      <td>[(2118, 2122), (2123, 2127), (2127, 2128), (21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "167                      [Brick, Burning, ,, Beardman, 's]   \n",
       "508      [Interpreting, sequence, motifs, [, Letter, to...   \n",
       "610                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "611                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "640      [Lady, Luck, :, the, theory, of, probability, ...   \n",
       "\n",
       "                                                   offsets  \n",
       "desc_id                                                     \n",
       "167      [(1421, 1426), (1427, 1434), (1434, 1435), (14...  \n",
       "508      [(3064, 3076), (3077, 3085), (3086, 3092), (30...  \n",
       "610      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "611      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "640      [(2118, 2122), (2123, 2127), (2127, 2128), (21...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Brick', 'Burning', ',', 'Beardman', \"'s\"], 'offsets': ['(1421, 1426)', '(1427, 1434)', '(1434, 1435)', '(1436, 1444)', '(1444, 1446)']}\n"
     ]
    }
   ],
   "source": [
    "bi_dict = bi_df.to_dict('index')\n",
    "print(bi_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'offsets_ann': ['(1436, 1444)', '(1436, 1444)'], 'text_ann': ['Beardman', 'Beardman'], 'label': ['Omission', 'Unknown'], 'id': [31928, 31929]}\n"
     ]
    }
   ],
   "source": [
    "ann_dict = df_merged_imploded.to_dict('index')\n",
    "print(ann_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a string of offsets into a tuple with each offset of type int\n",
    "# \"(1436, 1444)\" --> (1436, 1444)\n",
    "def offsetsStrToTuple(offsets_str):\n",
    "    offsets_list = offsets_str[1:-1].split(\", \")\n",
    "    offsets_ints = [int(o) for o in offsets_list]\n",
    "    return tuple((offsets_ints))\n",
    "\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')) == tuple\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[0]) == int\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[1]) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned tags for 100 descriptions\n"
     ]
    }
   ],
   "source": [
    "desc_ids = list(bi_dict.keys())[:100]  # START WITH SAMPLE\n",
    "assert len(set(desc_ids)) == len(desc_ids)  # Make sure every description ID is unique\n",
    "log = 0\n",
    "descid_to_tag = dict.fromkeys(desc_ids)\n",
    "for desc_id in desc_ids:\n",
    "    text_spans = ann_dict[desc_id][\"text_ann\"]\n",
    "    desc_tokens = bi_dict[desc_id]['token']\n",
    "    desc_tokens_offsets = bi_dict[desc_id]['offsets']\n",
    "    desc_tags = []\n",
    "    for i,desc_token in enumerate(desc_tokens):\n",
    "        token_offset_pair = offsetsStrToTuple(desc_tokens_offsets[i])\n",
    "        span_indeces, tags = [], []  # Note: one token may have multiple tags\n",
    "        \n",
    "        # Record the indeces of every item in text_spans with the desc_token\n",
    "        for j,text_span in enumerate(text_spans):\n",
    "            span_offset_pair = offsetsStrToTuple(ann_dict[desc_id][\"offsets_ann\"][j])    \n",
    "            # Be sure a matching token's offsets are within the annotated text span\n",
    "            if (desc_token in text_span\n",
    "               ) and (\n",
    "                token_offset_pair[0] >= span_offset_pair[0]\n",
    "                ) and (\n",
    "                token_offset_pair[1] <= span_offset_pair[1]):\n",
    "                    span_indeces += [j] \n",
    "            else:\n",
    "                span_indeces += [\"unannotated\"]\n",
    "        for j in span_indeces:\n",
    "            # If the token is annotated, assign it a B- or I- tag with a label\n",
    "            if type(j) == int:\n",
    "            # If the start offsets are the same, assign a 'B-' tag\n",
    "                if token_offset_pair[0] == span_offset_pair[0]:\n",
    "                    tags += ['B-'+ann_dict[desc_id][\"label\"][j]]\n",
    "                # Otherwise, assign an 'I-' tag\n",
    "                else:\n",
    "                    tags += ['I-'+ann_dict[desc_id][\"label\"][j]]\n",
    "            # If the description token isn't annotated, assign it an O tag\n",
    "            elif j == \"unannotated\":\n",
    "                tags += [\"O\"]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid j value: {}\".format(j))\n",
    "        \n",
    "        desc_tags += [set(tags)]\n",
    "    \n",
    "    assert len(desc_tokens) == len(desc_tags)\n",
    "    descid_to_tag[desc_id] = desc_tags\n",
    "    \n",
    "    log += 1\n",
    "    if log % 100 == 0:\n",
    "        print(\"Assigned tags for {} descriptions\".format(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Letter', ':', ':', 'Koestler', ',', 'Arthur'], 'offsets': ['(127, 133)', '(134, 135)', '(135, 136)', '(137, 145)', '(145, 146)', '(147, 153)']}\n"
     ]
    }
   ],
   "source": [
    "did = 610 #508 #167\n",
    "# print(ann_dict[did])\n",
    "print(bi_dict[did])\n",
    "# print(descid_to_tag[did])\n",
    "\n",
    "# spans = ['Beardman', 'Beardman']\n",
    "# spans2 = [\"Brick Burning\"]\n",
    "# tokens = ['Brick', 'Burning', ',', 'Beardman', \"'s\"]\n",
    "# # print(spans.count('Beardman'))\n",
    "# # # print(spans.index('Beardman'))\n",
    "# # # print(tokens.index('Beardman'))\n",
    "# # for k in range(0,3):\n",
    "# #     print(k)\n",
    "# indeces = [index for index in range(len(spans)) if spans[index] == 'Beardman']\n",
    "# print(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m token \u001b[38;5;241m=\u001b[39m tokens[i]\n\u001b[1;32m      7\u001b[0m token_start, token_end \u001b[38;5;241m=\u001b[39m token_offsets_tuples[i][\u001b[38;5;241m0\u001b[39m], token_offsets_tuples[i][\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m----> 9\u001b[0m ann_df \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdesc_id\u001b[49m]\n\u001b[1;32m     10\u001b[0m ann_id_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m     11\u001b[0m ann_offsets_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39moffsets_ann)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:290\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:106\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    103\u001b[0m b_value \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mop_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m b_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_value\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# numexpr raises eg for array ** array with integers\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pydata/numexpr/issues/379)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/numexpr/necompiler.py:835\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m _numexpr_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ex\u001b[38;5;241m=\u001b[39mcompiled_ex, argnames\u001b[38;5;241m=\u001b[39mnames, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m evaluate_lock:\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# is_annotated_col = []\n",
    "# annotated_id = []\n",
    "# i, maxI = 0, len(token_desc_ids)  #1188478, 1189478\n",
    "# while i < maxI:\n",
    "#     desc_id = token_desc_ids[i]\n",
    "#     token = tokens[i]\n",
    "#     token_start, token_end = token_offsets_tuples[i][0], token_offsets_tuples[i][1] \n",
    "    \n",
    "#     ann_df = df_merged.loc[df_merged.desc_id == desc_id]\n",
    "#     ann_id_list = list(ann_df.id)\n",
    "#     ann_offsets_list = list(ann_df.offsets_ann)\n",
    "#     ann_offsets_clean = [ann_offsets[1:-1].split(\", \") for ann_offsets in ann_offsets_list]\n",
    "#     ann_offsets_tuples = [tuple((int(ann_offsets[0]), int(ann_offsets[1]))) for ann_offsets in ann_offsets_clean]\n",
    "    \n",
    "#     for j,ann_offsets in enumerate(ann_offsets_tuples):\n",
    "#         ann_start = ann_offsets[0]\n",
    "#         ann_end = ann_offsets[1]\n",
    "#         if token_start == ann_start:\n",
    "#             is_annotated_col += [\"B\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         elif (token_start > ann_start) and (token_start <= ann_end):\n",
    "#             is_annotated_col += [\"I\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         else:\n",
    "#             is_annotated_col += [\"O\"]\n",
    "#             annotated_id += [\"None\"]\n",
    "    \n",
    "#     i += 1\n",
    "\n",
    "# assert len(is_annotated_col) == len(token_desc_ids)\n",
    "# assert len(is_annotated_col) == len(annotated_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.insert(len(df_tokens.columns),\"is_annotated\",is_annotated_col)\n",
    "df_tokens.insert(len(df_tokens.columns),\"ann_id\",annotated_id)\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(is_annotated_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(annotated_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

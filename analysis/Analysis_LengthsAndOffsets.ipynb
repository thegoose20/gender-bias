{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs the files:\n",
    "  * `../data/analysis_data/descriptions_with_counts.csv`: adds columns to `descriptions.csv` for word counts and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `../data/analysis_data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "  * `../data/crc_metadata/all_descs_with_offsets.csv`: contains one row for every description in the annotated datasets with columns for the descriptions' corresponding id, eadid, file, start offset, and end offset\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Loading\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Descriptions\n",
    "\n",
    "[3.](#3) Offsets of Tokens\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "### 0. Loading\n",
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # import custom functions\n",
    "import config # import directory path variables\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_path = config.crc_meta_path+\"all_descriptions.csv\"     # descriptions in column of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid                                        description  \\\n",
       "0   AA5  Professor James Aitken White was a leading Sco...   \n",
       "1   AA5  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "2   AA6  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "3   AA6            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "4   AA7  Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                       field  desc_id  \n",
       "0  Biographical / Historical        0  \n",
       "1                      Title        1  \n",
       "2  Biographical / Historical        2  \n",
       "3                      Title        3  \n",
       "4  Biographical / Historical        4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(descs_path, index_col=0)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove metadata field name from each description\n",
    "# new_descs = []\n",
    "# descs = list(desc_df.description)\n",
    "# fields = list(desc_df.field)\n",
    "# i = 0\n",
    "# maxI = len(descs)\n",
    "# while i < maxI:\n",
    "#     d, f = descs[i], fields[i]\n",
    "#     to_remove = f+\":\\n\"\n",
    "#     d = d.replace(to_remove,\"\")\n",
    "#     new_descs += [d]\n",
    "#     i += 1\n",
    "# assert len(new_descs) == len(descs)\n",
    "# # new_descs[:10]            # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Update the CSV file\n",
    "# desc_df.description = new_descs\n",
    "# desc_df.head()\n",
    "# desc_df.to_csv(descs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each description to a txt file named with desc_id\n",
    "ids = list(desc_df.desc_id)\n",
    "descs = list(desc_df.description)\n",
    "desc_txt_dir = config.crc_meta_path+\"descriptions_brat/\"\n",
    "utils.strToTxt(ids, descs, \"description\", desc_txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader(desc_txt_dir, \"description\\d+.txt\", encoding=\"utf8\")\n",
    "# print(len(corpus.fileids()), desc_df.shape[0])  # Looks good\n",
    "print(corpus.fileids()[-20:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good\n",
    "# len(desc_sents[2]) # 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.insert(len(desc_df.columns), \"word_count\", word_count)\n",
    "desc_df.insert(len(desc_df.columns), \"sent_count\", sent_count)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df.to_csv(\"descriptions_with_counts.csv\")  # write a new CSV file with the word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = desc_df.reset_index()\n",
    "desc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", desc_df)\n",
    "desc_df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengths per Metadata Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Biographical / Historical\"\n",
    "bh_stats = utils.makeDescribeDf(field, desc_df)\n",
    "bh_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Scope and Contents\"\n",
    "sc_stats = utils.makeDescribeDf(field, desc_df)\n",
    "sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Processing Information\"\n",
    "pi_stats = utils.makeDescribeDf(field, desc_df)\n",
    "pi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"Title\"\n",
    "t_stats = utils.makeDescribeDf(field, desc_df)\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for visualization in Observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descs = pd.read_csv(\"../data/analysis_data/descriptions_with_counts.csv\", index_col=0)\n",
    "df_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Offsets of Descriptions\n",
    "\n",
    "**Get the start and end offset of every description so that automated labels can be exported as .ann files for visualization with brat.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we need to determinen the intermediate start and end offsets as well, which we'll add as a column to the file `../data/crc_metadata/all_descriptions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-block alert-class alert-warning\">\n",
    "    <p><b>NOTE:</b> Need to re-assign description IDs to files in annotation_data directory (already reassigned to crc_metadata and aggregated_data files)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = \".txt\"  # Read in only the PlainText files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll-227_00100.txt', 'La_03600.txt', 'PJM_03000.txt']\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(config.doc_path)\n",
    "filenames = [f for f in filenames if f[-4:] == file_type] # the descriptions are in the txt files\n",
    "print(filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_names = [\"Title\", \"Scope and Contents\", \"Biographical / Historical\", \"Processing Information\"]\n",
    "            \n",
    "# INPUT: file path to a document of metadata descriptions (str)\n",
    "# OUTPUT: a dictionary of metadata description ids and the associated \n",
    "#         description text, field name and offsets contained in the input file\n",
    "def getDescriptionsInFiles(dirpath, file_list, fieldnames=metadata_field_names):\n",
    "    desc_dict = dict()\n",
    "    did = 0\n",
    "    for filename in file_list:\n",
    "\n",
    "        # Get a string of the input file's text (metadata descriptions)\n",
    "        f_string = open(os.path.join(dirpath+filename),'r').read()\n",
    "        \n",
    "        for fieldname in fieldnames:\n",
    "            pattern = \"(?<={}:\\n).+\".format(fieldname)\n",
    "            match_list = re.findall(pattern, f_string)\n",
    "            if len(match_list) > 0:\n",
    "                for match in match_list:\n",
    "                    desc_dict[did] = dict.fromkeys([\"description\", \"field\", \"file\", \"start_offset\", \"end_offset\"])\n",
    "                    desc_dict[did][\"description\"] = match\n",
    "                    desc_dict[did][\"field\"] = fieldname\n",
    "                    desc_dict[did][\"file\"] = filename\n",
    "                    desc_dict[did][\"start_offset\"] = f_string.find(match)\n",
    "                    desc_dict[did][\"end_offset\"] = f_string.find(match) + len(match) + 1\n",
    "                    did += 1\n",
    "                    \n",
    "    return desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_details = getDescriptionsInFiles(config.doc_path, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now create a DataFrame of the description data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_col = list(descs_details.keys())\n",
    "desc_col, field_col, file_col, eadid_col, start_offset_col, end_offset_col = [], [], [], [], [], []\n",
    "for desc_id in ids_col:\n",
    "    desc_dict = descs_details[desc_id]\n",
    "    \n",
    "    eadid = (re.findall(\"^.*(?=_\\d+.txt)\", desc_dict[\"file\"]))[0]\n",
    "    eadid_col += [eadid]\n",
    "    \n",
    "    field_col += [desc_dict[\"field\"]]\n",
    "    \n",
    "    file_col += [desc_dict[\"file\"]]\n",
    "    \n",
    "    desc_col += [desc_dict[\"description\"]]\n",
    "    \n",
    "    start_offset_col += [desc_dict[\"start_offset\"]]\n",
    "    end_offset_col += [desc_dict[\"end_offset\"]]\n",
    "\n",
    "new_descs_df = pd.DataFrame({\n",
    "    \"desc_id\":ids_col, \"eadid\":eadid_col, \"field\":field_col, \"file\":file_col, \n",
    "    \"description\":desc_col, \"desc_start_offset\":start_offset_col, \"desc_end_offset\":end_offset_col\n",
    "})\n",
    "\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_descs_df.to_csv(config.crc_meta_path+\"descs_with_offsets.csv\")\n",
    "new_descs_df = pd.read_csv(config.crc_meta_path+\"descs_with_offsets.csv\", index_col=0)\n",
    "new_descs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assign description IDs from this DataFrame to the aggregated annotated datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.read_csv(config.agg_path+\"desc_field_descid_label_eadid.csv\", index_col=0)\n",
    "df_agg = pd.read_csv(config.agg_path+\"aggregated_with_eadid_descid_desc_cols.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id_x</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id_y</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>Title</td>\n",
       "      <td>68</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>143</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family photographs consist of:photographs of f...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>221</td>\n",
       "      <td>{'Masculine', 'Unknown', 'Feminine'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>81505</td>\n",
       "      <td>BAI_01600.txt</td>\n",
       "      <td>5967</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence and related items, including le...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>292</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>33009</td>\n",
       "      <td>BAI_01900.txt</td>\n",
       "      <td>5297</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From 1927-1930 John Baillie was Professor of S...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>361</td>\n",
       "      <td>{'Gendered-Pronoun', 'Unknown', 'Masculine', '...</td>\n",
       "      <td>BAI</td>\n",
       "      <td>43372</td>\n",
       "      <td>BAI_02200.txt</td>\n",
       "      <td>15180</td>\n",
       "      <td>15419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                           John Baillie: posthumous   \n",
       "1  Letters received from Henry Sloane Coffin, wit...   \n",
       "2  Family photographs consist of:photographs of f...   \n",
       "3  Correspondence and related items, including le...   \n",
       "4  From 1927-1930 John Baillie was Professor of S...   \n",
       "\n",
       "                       field  desc_id_x  \\\n",
       "0                      Title         68   \n",
       "1         Scope and Contents        143   \n",
       "2         Scope and Contents        221   \n",
       "3         Scope and Contents        292   \n",
       "4  Biographical / Historical        361   \n",
       "\n",
       "                                               label eadid  desc_id_y  \\\n",
       "0                                        {'Unknown'}   BAI      70381   \n",
       "1                           {'Masculine', 'Unknown'}   BAI      47675   \n",
       "2               {'Masculine', 'Unknown', 'Feminine'}   BAI      81505   \n",
       "3                                        {'Unknown'}   BAI      33009   \n",
       "4  {'Gendered-Pronoun', 'Unknown', 'Masculine', '...   BAI      43372   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01600.txt               5967             6202  \n",
       "3  BAI_01900.txt               5297             5506  \n",
       "4  BAI_02200.txt              15180            15419  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_grouped.merge(new_descs_df, left_on=[\"description\", \"field\", \"eadid\"], right_on=[\"description\", \"field\", \"eadid\"])\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now we want to keep the *right* DataFrame's description IDs, so we'll drop `desc_id_x` and remove the `_y` from `desc_id_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>Title</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family photographs consist of:photographs of f...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown', 'Feminine'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>81505</td>\n",
       "      <td>BAI_01600.txt</td>\n",
       "      <td>5967</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence and related items, including le...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>33009</td>\n",
       "      <td>BAI_01900.txt</td>\n",
       "      <td>5297</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From 1927-1930 John Baillie was Professor of S...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>{'Gendered-Pronoun', 'Unknown', 'Masculine', '...</td>\n",
       "      <td>BAI</td>\n",
       "      <td>43372</td>\n",
       "      <td>BAI_02200.txt</td>\n",
       "      <td>15180</td>\n",
       "      <td>15419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                           John Baillie: posthumous   \n",
       "1  Letters received from Henry Sloane Coffin, wit...   \n",
       "2  Family photographs consist of:photographs of f...   \n",
       "3  Correspondence and related items, including le...   \n",
       "4  From 1927-1930 John Baillie was Professor of S...   \n",
       "\n",
       "                       field  \\\n",
       "0                      Title   \n",
       "1         Scope and Contents   \n",
       "2         Scope and Contents   \n",
       "3         Scope and Contents   \n",
       "4  Biographical / Historical   \n",
       "\n",
       "                                               label eadid  desc_id  \\\n",
       "0                                        {'Unknown'}   BAI    70381   \n",
       "1                           {'Masculine', 'Unknown'}   BAI    47675   \n",
       "2               {'Masculine', 'Unknown', 'Feminine'}   BAI    81505   \n",
       "3                                        {'Unknown'}   BAI    33009   \n",
       "4  {'Gendered-Pronoun', 'Unknown', 'Masculine', '...   BAI    43372   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01600.txt               5967             6202  \n",
       "3  BAI_01900.txt               5297             5506  \n",
       "4  BAI_02200.txt              15180            15419  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_merged.drop(columns=[\"desc_id_x\"])\n",
    "df_merged = df_merged.rename(columns={\"desc_id_y\":\"desc_id\"})\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(config.agg_path+\"desc_field_descid_label_eadid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same operations on the aggregated dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file_ann</th>\n",
       "      <th>offsets_ann</th>\n",
       "      <th>text_ann</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>file_desc</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Title</td>\n",
       "      <td>BAI_01000.ann</td>\n",
       "      <td>(1290, 1302)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>211</td>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5875, 5894)</td>\n",
       "      <td>Henry Sloane Coffin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>524</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5925, 5936)</td>\n",
       "      <td>Hugh Martin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>525</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5951, 5963)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>526</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5951, 5963)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>527</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid               field       file_ann   offsets_ann             text_ann  \\\n",
       "0   BAI               Title  BAI_01000.ann  (1290, 1302)         John Baillie   \n",
       "1   BAI  Scope and Contents  BAI_01300.ann  (5875, 5894)  Henry Sloane Coffin   \n",
       "2   BAI  Scope and Contents  BAI_01300.ann  (5925, 5936)          Hugh Martin   \n",
       "3   BAI  Scope and Contents  BAI_01300.ann  (5951, 5963)         John Baillie   \n",
       "4   BAI  Scope and Contents  BAI_01300.ann  (5951, 5963)         John Baillie   \n",
       "\n",
       "       label     category   id  \\\n",
       "0    Unknown  Person-Name  211   \n",
       "1    Unknown  Person-Name  524   \n",
       "2    Unknown  Person-Name  525   \n",
       "3  Masculine  Person-Name  526   \n",
       "4    Unknown  Person-Name  527   \n",
       "\n",
       "                                         description      file_desc  desc_id  \\\n",
       "0                           John Baillie: posthumous  BAI_01000.txt    70381   \n",
       "1  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "2  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "3  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "4  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01300.txt               5853             5983  \n",
       "3  BAI_01300.txt               5853             5983  \n",
       "4  BAI_01300.txt               5853             5983  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_agg.merge(new_descs_df, left_on=[\"description\", \"field\", \"eadid\"], right_on=[\"description\", \"field\", \"eadid\"])\n",
    "df_merged = df_merged.drop(columns=[\"desc_id_x\"])\n",
    "df_merged = df_merged.rename(columns={\"desc_id_y\":\"desc_id\", \"file_x\":\"file_ann\", \"offsets\":\"offsets_ann\", \"file_y\":\"file_desc\", \"text\":\"text_ann\"})\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(config.agg_path+\"aggregated_with_eadid_descid_desc_cols.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Offsets of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scope and Contents:\n",
      "Letters of congratulation to staff members on their work and external appointments.\n",
      "\n",
      "Scope and Contents:\n",
      "Correspondence about planning and budgeting issues for the Student Advisory and Counselling Service (SACS), about an individual student complaint about how SACS had dealt with her case, about the management structure and staffing of SACS. Includes a copy of the 1992/93 SACS annual report.\n",
      "\n",
      "Scope and Contents:\n",
      "Copy of the University's submissions to the 2001 Research Assessment Exercise for Classics, Ancient History, Byzantine and Modern Greek Studies, Archaeology, History, History of Art, Architecture and Design, and Philosophy.\n",
      "\n",
      "Scope and Contents:\n",
      "Certificate of Social Study 1948. File contains: Enrolment form, correspondence, job adverts for Supervisor of boarded out children for Fife County Council, Woman Assistant for County Public Assistance Officer for Gloucestershire County Council. Details of practical placements are located at the back of the file and include reports from Mary F. Gregor, South Bridge and James Clark Schools; Evelyn Buchan, District Secretary, Edinburgh Council of Social Service.\n",
      "\n",
      "Scope and Contents:\n",
      "Agendas, papers and minutes for meetings of the Business Committee, and correspondence about issues raised at the meetings.\n",
      "\n",
      "Scope and Contents:\n",
      "Copy of the University's submissions to the ESRC for their 1997 Submission Rates Survey, copy of the ESRC's Guidance Notes for Applicants and application forms for 1998 Studentships, and a list of Edinburgh's 1997 ESRC Studentship Allocations.\n",
      "\n",
      "Scope and Contents:\n",
      "Correspondence with other universities about a proposal for the development of the Connect programme (to support technology-based enterprise), correspondence about the arrangements for the 1995 Jubilee Lecture in the Department of Business Studies, correspondence about accreditation for the University's Management School's AMBA course.\n",
      "\n",
      "Scope and Contents:\n",
      "Dip. Social Study 1955. File contains: Enrolment form, application form, correspondence, placement reports.Thesis: \"A Study of the Household Expenditure in a Post-war Housing Scheme\" [NB a copy of this does not survive in the file].\n",
      "\n",
      "Scope and Contents:\n",
      "\"This woman is weakminded; has never been away from home, never able to work. She lives alone. Inherited £200 from her father. She is living on that. [Male informant] this girl was over-protected and spoilt by her parents; ended up bossing them completely, spent most of her time in bed, did not do any work. When they died her relations suggested the poorhouse - this had an excellent effect - she is now able to do her own shopping, but not yet able to work. [Female informant] confirms, when her mother died she was in bed for 3 weeks in all her clothes, and had had no attention. Sergt. says she will never be right, but imagines things. Dr - she did not go out of doors for 20 years. Her mother was crackers before she died.\"\n",
      "\n",
      "Scope and Contents:\n",
      "\"This man is a timber hauler. He was tested for the Navy - OT score 25. He is described as a poor-like creature, not robust, a bit slow on the uptake. Has a good work record. No information about relations. Home clean and tidy, not overcrowded, harmonious. No P.A. [Public Assistance]. Police Constable says these are very decent people but cannot add anything. Doctor -  not too bad, quite sensible.\"\n",
      "\n",
      "Scope and Contents:\n",
      "Notes of discussions between the Principal, Vice-Principals, Secretary and the Deans of various Faculties.\n",
      "\n",
      "Scope and Contents:\n",
      "Large format chart showing breakdown of cases according to home conditions, illegitimacy, overcrowding, family life, and delinquency.\n",
      "\n",
      "Scope and Contents:\n",
      "Interview postponed for a number of months until son returns.\n",
      "\n",
      "Scope and Contents:\n",
      "'This girl is said to be odd-looking, filthy, steals, always on the roads, chased German prisoners. A tinker, has been sleeping out. Very deepset eyes. Recently walked from Penpont to Ecclefechan in the snow. It took her a week, sleeping in barns etc.'Relatives in survey: Mother 20.10 father 20.9 siblings 20.14, 20.16, 20.12, 20.11\n",
      "\n",
      "Scope and Contents:\n",
      "Varied correspondence including Scottish enterprise funding docs for Microelectronics Imaging and Analysis Centre\n",
      "\n",
      "Scope and Contents:\n",
      "'Bible of Documents' - lever arch file containing copies of documentation pertaining to the bid\n",
      "\n",
      "Scope and Contents:\n",
      "\"This woman has something queer about her. Several children \"a great squatter of daughters\" all with illegitimate children and all a nuisance. Housing was appalling, now quite good.\"\n",
      "\n",
      "Scope and Contents:\n",
      "Copies of the University of Hong Kong Bulletin and the University of New South Wales Uniken newsletter issued in 2000, correspondence about improving student mobility between U21 universities, copies of event programmes and minutes for the meetings of various U21 groups, and correspondence about the visit of an academic from another U21 university to Edinburgh.\n",
      "\n",
      "Scope and Contents:\n",
      "Cuttings from The Times newspaper relating mainly to industry, trade and employment.ContentsBook I: Children and Young Persons; Co-operation and Profit Sharing; Drink; Education., 1925-1937Book II: Emigration; Factories; Finance; Food Prices, 1925-1939\tBook III: Housing, 1925-1938\t Book IV: Industries - Cotton, 1925-1938Book V: Industries - Coal, 1925-1938\tBook VI: Industries, 1925-1938 Book VII: Industrial Hours and Wages, 1926-1938 Book VIII: Industry and Trade, 1927-1939 Book IX: Industries Abroad, 1927-1933Book X: International Labour Legislation; Local Government; Mental Deficiency; Penal Reform, 1925-1936Book XI: Poor Law; Population; Public Health, 1925-1938 Book XII: Social Insurance; Social Service; Trade Unions; Transport, 1925-1933\tBook XIII: Unemployment, 1925-1938Book XIV: Welfare; Women in Industry; Miscellaneous, 1925-1938Cuttings relating to parliamentary debate on Unemployment Assistance, July 1936, 1936-1937\tIndex\n",
      "\n",
      "Scope and Contents:\n",
      "\"Admitted CRI. High grade imbecile. Working in the laundry. Rate-aided.\"Parents: 18.64, 18.62\n",
      "\n",
      "Scope and Contents:\n",
      "File contains: Enrolment from and letter of reference from The City of Glasgow Society of Social Service.\n",
      "\n",
      "Scope and Contents:\n",
      "N/A\n",
      "\n",
      "Scope and Contents:\n",
      "\"This boy is very nervy. Excitable, highly strung, always tumbling about the house.\"\n",
      "\n",
      "Scope and Contents:\n",
      "Topics discussed include: Living accommodation; extended family; neighbourhood and quarrels about children; Gorgie; work; money; leisure; shopping.The interview was conducted entirely on the doorstep which INTVER notes is a difficulty for unannounced calls in particular when the interviewer is male and interviewee female. She lives with her husband and three children (8, 5 and 3 yrs) in a three-apartment ground floor flat in a block of four. They previously lived in furnished rooms for £2 10s a week, they had no bath but an inside WC but it got too overcrowded with the children so applied for a corporation house. She prefers their new house, it is not as noisy, there are fewer children and more old people but not as handy for the shops. The bedrooms can be cold, the heating is through a back boiler fire in the sitting room. INTVEE says she likes to be by herself but INTVER thinks she is quite lonely and typical of a home-tied young mother with children to keep her at home but not enough to interest her there. INTVEE says there are always rows with the neighbours about the children. There are 13 children on her stair and 18 on the stair next door. She received no information about the house or neighbourhood before moving in.  Her husband goes out to work early and comes back at 8 or 9 at night, he is active in the union. She thinks he has settled better and likes the neighbourhood but he doesn't have to live in it all day. She would like to go out to work part time when her youngest goes to school. The woman across the road looks after children during the day and three of them are coloured - their parents work at the university, there is also a coloured teacher at the new West Pilton School and she is very good. These are the only coloured people she is aware of, she thinks it's stupid that some people don't want to mix with them.  On child discipline she is quoted as saying \"Well if they absolutely just won't do what they're told I do hit them\". Generally she thinks children are much cheekier than they used to be and parents don't seem to care. They have not been on holiday this year but she thinks it is important to have regular holidays, they like hiring a car and caravan and going round the highlands. Her husband earns £14 a week and gives her £7 a week. She likes the television - she watches Wagon Train and Emergency Ward 10. She feels a bit guilty about letting her children stay up in their pyjamas to watch the television, they go to bed when it finishes at 9.30pm. She shops at Hays in Davidsons Mains because it's cheaper.\n",
      "\n",
      "Scope and Contents:\n",
      "File contains: enrolment form, Institute of Hospital Almoners application form.\n",
      "\n",
      "Scope and Contents:\n",
      "Draft copy of a University-level Risk Register, draft copy of a Risk Register for Administration, Communications and Student Services Support Group together with comments on the draft, correspondence about new management arrangements for Student Services, and correspondence about the provision of student support services for Edinburgh College of Art students.\n",
      "\n",
      "Scope and Contents:\n",
      "Note by Monica Rushforth on labour allocation at Leith Docks.\n",
      "\n",
      "Scope and Contents:\n",
      "INTVEEs live in a ten-storey block of flats. They are married with no children. INTVER describes the common vestibule as \"scrappy looking, draughty and bare, the name board has an incongruous air of quality\". The flat is described as \"pleasantly deocrated in the modern style and well furnished with rugs and sitting suite and table and nice new wireless and 17\" television.  INTVER explains to the INTVEEs that the project aims to study the changing patterns of suburban life, life and work in the district from the point of view of both residents and the services and organised groups in the area. Their rent is £1. 19. 7d a week which they think is expensive. It is a two apartment flat with bathroom and kitchen. The noise transmission is very bad up and down the stairs, the noise deadening sideways is very good.  They think people would move out if given the chance, the house is alright but surroundings are important, people with children spoil it for others. The corporation says children are not allowed to play in the grounds of the flats themselves and should go through to the playing fields but mothers don't send their children there because they were not sure they would come back in one piece. They can't send small children out because of other tough children in the neighbourhood. INTVER suggests their views aren't typical because they have had experience of better areas. They don't think people in the district are poor but think that they don't have the same ideas on controlling children or looking after the district as they do. They think residents are selfish, they don't seem to care about the effect of what they do on other people. INTVEEs have a car but have to constantly check on it. They moved in 10 months after the flats had been built, the lifts were a novelty and kids kept playing in them. They think the flats should have a caretaker and complain about the layout - the flats have four entrances and are too open which encourages kids to use them as pathways. There is however very little damage, some chalking on the walls, and this is down to the vigilance of the few who bother. They have asked for a transfer but have been told they don't have a chance unless they have a doctor's certificate. They think the council policy of grouping rough people all together, for example at Niddrie after Lochinvar Camp was cleared, is very bad. Boys take a short cut through the back gardens of the Swedish houses near the little road bridge that goes from Pilton Gardens to Crewe Road North. The corporation put up chestnut paling to stop them, there used to be chestnut palings in the semi-circle by the shops opposite the flats. The shops here put a halfpenny or penny on all the prices. They refer to a screening process which they had to pass before getting the flat, if they had failed they thought they would be sent to Niddrie, they thought people should be mixed up. The only people who've managed to keep a garden have managed to do it by standing in the garden with a shotgun. Female INTVEE says she always opens her front door wide, but others don't - they are afraid of gossip or that people will peer in and see what's going on inside. There is a lot of gossip, it's easy to see into the kitchen door and through a flat. Their dream is to find a little cottage that needs done up. They moved in in 1958. They had previously lived in a room in Leith. It wasn't very nice, they paid 35/- a week. They found it odd adjusting to not always being in the same room as each other after they moved.\n",
      "\n",
      "Scope and Contents:\n",
      "13.01: Burgess, M A, Silent Reading Scale, 1922;13.02: Gray, W.S, Oral Reading Paragraphs, c1920s;13.03: Oglesby, E F, Detroit Word Recognition Test, 1925-1929;13.04: Fleming, C M, P A Reading I, c mid 20th century;13.06: Haggerty, M.E, Reading Examination, 1920;13.06: Haggerty, M E, Standard Educational Tests, Reading, 1920;13.08: Lee and Clark, Reading Readiness Test, 1943;13.09: Misc Reading Tests, c1950s;13.10: Kelley et al., New Stanford Reading Test, 1929;13.11: First Grade Word Reading Test, c1950s;13.12: Sangren-Woody Reading Test, 1927-1928;13.13: Schonell, Prose Reading Test, 1940;13.14: Stone, R S, Narrative Reading Tests, 1922;13.16: Van Wagenen Reading Scales, c1950s;13.17: Northumberland Reading, 7+ assessment, c1950s;13.18: ACER Reading Tests, c1950s;13.20: ACER Test Division Catalogue, 1950-1954;13.21: ACER Test News, 1953;13.22: Schonell Reading Tests, c1950s;13.40: South African reading tests and associated literature, 1947-1948;13.40: South Africa, report of the National Council of Social Research, and tests regarding silent reading, comprehension, verbal reasoning, 1947-1948.\n",
      "\n",
      "Scope and Contents:\n",
      "References to IRCs in; atmospheric science, deep crustal studies, environmental change, land use, marine science\n",
      "\n",
      "Scope and Contents:\n",
      "\"Admitted CRI as a private patient, voluntary. Senile Dementia. Husband died many years ago. Had been living alone for several years. then tried living with her son and his wife - this was unsuccessful and there was much quarrelling - then admitted to CRI. Fractured wrist.\"\n",
      "\n",
      "Scope and Contents:\n",
      "\"This man never would work, was a \"street corner boy\". Now in the army, not a very good soldier, dodges everything, hates continuity. Deserted. For a time his wife thought he was dead and drew a widow's pension. Dr confirms that this lad is unsatisfactory, never had a job for any length of time. Was a blackshirt.\"\n",
      "\n",
      "Scope and Contents:\n",
      "'This lad is at present a tractor driver. Before that he embezzled some money which his aunt paid up for him. He is lazy and dull.'Relatives in survey: Mother 19.20, siblings 19.22, 19.24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(config.crc_meta_path+\"all_descriptions.csv\", index_col=0)\n",
    "# df.loc[df.desc_id == 57361]\n",
    "files = os.listdir(\"../data/crc_metadata/descriptions_brat/\")\n",
    "assert \"EUA_IN1_56700.txt\" in files\n",
    "with open(\"../data/crc_metadata/descriptions_brat/EUA_IN1_56700.txt\", \"r\") as f:\n",
    "    f_string = f.read()\n",
    "    print(f_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Title</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>Records of the Phrenological Society of Edinburgh</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The records of the Phrenological Society inclu...</td>\n",
       "      <td>100</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-227</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Coll-227_00100.txt</td>\n",
       "      <td>The Phrenological Society of Edinburgh was for...</td>\n",
       "      <td>638</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>Title</td>\n",
       "      <td>La_03600.txt</td>\n",
       "      <td>Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...</td>\n",
       "      <td>125</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id     eadid                      field                file  \\\n",
       "0        0  Coll-227                      Title  Coll-227_00100.txt   \n",
       "1        1  Coll-227         Scope and Contents  Coll-227_00100.txt   \n",
       "2        2  Coll-227  Biographical / Historical  Coll-227_00100.txt   \n",
       "3        3        La                      Title        La_03600.txt   \n",
       "4        4        La                      Title        La_03600.txt   \n",
       "\n",
       "                                         description  desc_start_offset  \\\n",
       "0  Records of the Phrenological Society of Edinburgh                 29   \n",
       "1  The records of the Phrenological Society inclu...                100   \n",
       "2  The Phrenological Society of Edinburgh was for...                638   \n",
       "3  Letter: 1825 Jan. 10, 27 Lower Belgrave Place ...                  7   \n",
       "4  Letter: 1825 Mar. 1, 27 Lower Belgrave Place [...                125   \n",
       "\n",
       "   desc_end_offset  \n",
       "0               79  \n",
       "1              610  \n",
       "2             2277  \n",
       "3              117  \n",
       "4              223  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc = pd.read_csv(config.crc_meta_path+\"descs_with_offsets.csv\", index_col=0)\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57361</th>\n",
       "      <td>57361</td>\n",
       "      <td>EUA_IN1</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>EUA_IN1_56700.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6137</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc_id    eadid               field               file description  \\\n",
       "57361    57361  EUA_IN1  Scope and Contents  EUA_IN1_56700.txt         NaN   \n",
       "\n",
       "       desc_start_offset  desc_end_offset  \n",
       "57361               6137             6141  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.loc[df_desc.description.isna() == True]\n",
    "# df_desc.loc[df_desc.description == \"N/A\"]\n",
    "# df_desc.loc[df_desc.file == \"EUA_IN1_56700.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57361</th>\n",
       "      <td>57361</td>\n",
       "      <td>EUA_IN1</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>EUA_IN1_56700.txt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>6137</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc_id    eadid               field               file description  \\\n",
       "57361    57361  EUA_IN1  Scope and Contents  EUA_IN1_56700.txt         N/A   \n",
       "\n",
       "       desc_start_offset  desc_end_offset  \n",
       "57361               6137             6141  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.description = df_desc.description.fillna(\"N/A\")\n",
    "df_desc.loc[df_desc.desc_id == 57361]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the corrected description to the `descs_with_offsets.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc.to_csv(config.crc_meta_path+\"descs_with_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the offsets of the tokens in every description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = list(df_desc.description)\n",
    "desc_ids = list(df_desc.desc_id)\n",
    "desc_start_offsets = list(df_desc.desc_start_offset)\n",
    "desc_end_offsets = list(df_desc.desc_end_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dict, offsets_dict = getTokensAndOffsetsFromStrings(descs, desc_ids, desc_start_offsets, desc_end_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_col, offsets_col, desc_ids_col = [], [], []\n",
    "for desc_id,token_list in tokens_dict.items():\n",
    "    tokens_col += token_list\n",
    "    offsets_list = offsets_dict[desc_id]\n",
    "    offsets_col += offsets_list\n",
    "    assert len(token_list) == len(offsets_list)\n",
    "    desc_ids_col += [desc_id]*len(token_list)\n",
    "\n",
    "assert len(tokens_col) == len(offsets_col)\n",
    "assert len(tokens_col) == len(desc_ids_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Records', 'of', 'the', 'Phrenological', 'Society']\n",
      "[(29, 36), (37, 39), (40, 43), (44, 57), (58, 65)]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for col_list in [tokens_col, offsets_col, desc_ids_col]:\n",
    "    print(col_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  Now create a DataFrame with these lists as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Records</td>\n",
       "      <td>(29, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>(37, 39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>(40, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Phrenological</td>\n",
       "      <td>(44, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Society</td>\n",
       "      <td>(58, 65)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id          token   offsets\n",
       "0        0        Records  (29, 36)\n",
       "1        0             of  (37, 39)\n",
       "2        0            the  (40, 43)\n",
       "3        0  Phrenological  (44, 57)\n",
       "4        0        Society  (58, 65)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.DataFrame({\"desc_id\":desc_ids_col, \"token\":tokens_col, \"offsets\":offsets_col})\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2239703</th>\n",
       "      <td>88596</td>\n",
       "      <td>on</td>\n",
       "      <td>(465, 467)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239704</th>\n",
       "      <td>88596</td>\n",
       "      <td>12</td>\n",
       "      <td>(468, 470)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239705</th>\n",
       "      <td>88596</td>\n",
       "      <td>January</td>\n",
       "      <td>(471, 478)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239706</th>\n",
       "      <td>88596</td>\n",
       "      <td>1937</td>\n",
       "      <td>(479, 483)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239707</th>\n",
       "      <td>88596</td>\n",
       "      <td>.</td>\n",
       "      <td>(483, 484)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         desc_id    token     offsets\n",
       "2239703    88596       on  (465, 467)\n",
       "2239704    88596       12  (468, 470)\n",
       "2239705    88596  January  (471, 478)\n",
       "2239706    88596     1937  (479, 483)\n",
       "2239707    88596        .  (483, 484)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now write the DataFrame to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.to_csv(config.agg_path+\"descid_token_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compare these tokens' offsets to the annotated text spans' offsets to determine which tokens to mark as the beginning of an annotation (`B-[LABELNAME]`), inside an annotation (`I`), and unannotated, or outisde of an annotation (`O`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged = pd.read_csv(config.agg_path+\"aggregated_with_eadid_descid_desc_cols.csv\")\n",
    "# text_ann_list = list(df_merged.text_ann)\n",
    "# ann_id_list = list(df_merged.id)\n",
    "# ann_offsets_list = list(df_merged.offsets_ann)\n",
    "# ann_offsets_clean = [ann_offsets[1:-1].split(\", \") for ann_offsets in ann_offsets_list]\n",
    "# ann_offsets_tuples = [tuple((int(ann_offsets[0]), int(ann_offsets[1]))) for ann_offsets in ann_offsets_clean]\n",
    "# print(ann_offsets_tuples[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annid_tokens_offsets = dict.fromkeys(ann_id_list, []) # values are lists of dicts with key-value pairs of token-offset tuple\n",
    "\n",
    "# j, maxJ = 0, len(text_ann_list)\n",
    "# while j < maxJ:\n",
    "#     # Get the annotation ID\n",
    "#     ann_id = ann_id_list[j]\n",
    "#     # Get the start and end offsets of the annotated text span\n",
    "#     ann_start_offset, ann_end_offset = ann_offsets_tuples[j][0], ann_offsets_tuples[j][1]\n",
    "#     # Get the annotated text span string\n",
    "#     ann_text = text_ann_list[j]\n",
    "#     # Tokenize the annotated text span string\n",
    "#     ann_tokens = word_tokenize(ann_text)\n",
    "#     # Get the start and end offsets of each token\n",
    "#     tokens_offsets = []\n",
    "#     t = ann_tokens[0]\n",
    "#     t_start_offset = ann_start_offset\n",
    "#     t_end_offset = ann_start_offset + len(t)\n",
    "#     d = {t:tuple((t_start_offset, t_end_offset))}\n",
    "#     tokens_offsets += [d]\n",
    "#     prev_positions = len(t)\n",
    "#     sub_ann_text = ann_text[(t_end_offset-ann_start_offset):]\n",
    "#     remaining_tokens = ann_tokens[1:]\n",
    "#     for t in remaining_tokens:\n",
    "#         i = sub_ann_text.index(t)\n",
    "#         t_start_offset = i + ann_start_offset + prev_positions\n",
    "#         t_end_offset = t_start_offset + len(t)\n",
    "#         d = {t:tuple((t_start_offset, t_end_offset))}\n",
    "#         tokens_offsets += [d]\n",
    "#         sub_ann_text = sub_ann_text[i+len(t):]\n",
    "#         prev_positions += len(t)+i\n",
    "#     annid_tokens_offsets[ann_id] = tokens_offsets\n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next need to do same for descriptions, then can figure out which, based on offsets, to \n",
    "# classify as B-labelname, I, and O\n",
    "# SHOULD MOVE FUNCTION TO UTILS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# desc_tokens, desc_token_offsets = [], []\n",
    "# j, maxJ = 0, 5#len(desc_list)\n",
    "# while j < maxJ:\n",
    "#     # Get the start and end offsets of the description\n",
    "#     desc_start_offset = desc_start_offsets[j]\n",
    "#     # Get the description string\n",
    "#     desc_text = desc_list[j]\n",
    "#     # Tokenize the description string\n",
    "#     desc_tokens = word_tokenize(desc_text)\n",
    "#     # Get the start and end offsets of each token\n",
    "#     t = desc_tokens[0]\n",
    "#     t_start_offset = desc_start_offset\n",
    "#     t_end_offset = desc_start_offset + len(t)\n",
    "#     desc_tokens += [t]\n",
    "#     desc_token_offsets += [tuple((t_start_offset, t_end_offset))]\n",
    "#     prev_positions = len(t)\n",
    "#     sub_desc_text = desc_text[(t_end_offset-desc_start_offset):]\n",
    "#     remaining_tokens = desc_tokens[1:]\n",
    "#     for t in remaining_tokens:\n",
    "#         i = sub_desc_text.index(t)\n",
    "#         t_start_offset = i + desc_start_offset + prev_positions\n",
    "#         t_end_offset = t_start_offset + len(t)\n",
    "#         desc_tokens += [t]\n",
    "#         desc_token_offsets += [tuple((t_start_offset, t_end_offset))]\n",
    "#         sub_ann_text = sub_ann_text[i+len(t):]\n",
    "#         prev_positions += len(t)+i\n",
    "#     j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

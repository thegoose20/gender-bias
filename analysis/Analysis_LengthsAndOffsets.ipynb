{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Descriptions' and Annotations' Lengths\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "Outputs the files:\n",
    "  * `../data/analysis_data/descriptions_with_counts.csv`: adds columns to `descriptions.csv` for word counts and sentence counts, where words are alphanumeric tokens (punctuation excluded)\n",
    "  * `../data/analysis_data/descs_stats.csv`: contains the count, minimum, maximum, average, and standard deviation of all descriptions and each type of description\n",
    "  * `../data/doc_clf_data/desc_field_descid_label_eadid.csv`: contains one row per description with the description's labels from the manual annotation process\n",
    "  * `../data/crc_metadata/descs_with_offsets.csv`: contains one row for every description in the annotated datasets with columns for the descriptions' corresponding id, eadid, file, start offset, and end offset\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Loading\n",
    "\n",
    "[1.](#1) Lengths of Descriptions and Annotations\n",
    "\n",
    "  * [Lengths of Descriptions](#1.1)\n",
    "  \n",
    "  * TO DO: [Lengths of Annotations](#1.2)\n",
    "  \n",
    "[2.](#2) Offsets of Descriptions\n",
    "\n",
    "[3.](#3) Offsets of Tokens\n",
    "    \n",
    "  * TO REMOVE: [BIO Tags](#3.1)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, begin by loading Python programming libraries and the dataset to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # import custom functions\n",
    "import config # import directory path variables\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, csv, re, os, sys #,json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Annotated Descriptions Data\n",
    "\n",
    "Create a CSV dataset of the descriptions that were annotated in brat, including the descriptions' file name and offsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll-227_00100.txt', 'La_03600.txt', 'PJM_03000.txt', 'La_07300.txt', 'Coll-1434_07400.txt', 'Coll-1434_03100.txt', 'MS_BOX_25.5_00100.txt', 'EUA_IN1_38300.txt', 'Coll-14_05900.txt', 'Coll-1694_00100.txt']\n",
      "3649\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(config.doc_path)\n",
    "print(filenames[:10])\n",
    "print(len(filenames))  # descs_with_offsets has 3645, not 3649"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that every annotation's file is in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55260, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-1157_00100.ann</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>knighted</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-1310_02300.ann</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-1281_00100.ann</td>\n",
       "      <td>(2426, 2439)</td>\n",
       "      <td>Prince Regent</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>Coll-1310_02700.ann</td>\n",
       "      <td>(9993, 10003)</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>Coll-1310_02900.ann</td>\n",
       "      <td>(7192, 7195)</td>\n",
       "      <td>Sir</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agg_ann_id                 file        offsets           text  \\\n",
       "12           0  Coll-1157_00100.ann   (1407, 1415)       knighted   \n",
       "22           1  Coll-1310_02300.ann   (9625, 9635)     knighthood   \n",
       "23           2  Coll-1281_00100.ann   (2426, 2439)  Prince Regent   \n",
       "24           3  Coll-1310_02700.ann  (9993, 10003)     knighthood   \n",
       "25           4  Coll-1310_02900.ann   (7192, 7195)            Sir   \n",
       "\n",
       "            label    category associated_genders  \n",
       "12  Gendered-Role  Linguistic            Unclear  \n",
       "22  Gendered-Role  Linguistic            Unclear  \n",
       "23  Gendered-Role  Linguistic            Unclear  \n",
       "24  Gendered-Role  Linguistic            Unclear  \n",
       "25  Gendered-Role  Linguistic            Unclear  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df = pd.read_csv(\"../data/aggregated_data/aggregated_final.csv\", index_col=0)\n",
    "print(agg_df.shape)\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_files = list(agg_df.file)\n",
    "agg_files = [f.replace(\".ann\", \".txt\") for f in agg_files]\n",
    "agg_files = list(set(agg_files))\n",
    "agg_files.sort()\n",
    "missing = []\n",
    "for f in agg_files:\n",
    "    if not f in filenames:\n",
    "        missing += [f]\n",
    "assert len(missing) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`agg_files` is list of the file names in `descriptions/brat` that should be included in CSV of the annotated description data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING FUNCTIONS ###\n",
    "# test_file = open(os.path.join(config.doc_path, \"Coll-1036_00300.txt\"), \"r\").read()\n",
    "# desc_dict, did, field_for_next_file = getFieldDescriptions(dict(), test_file, \"Scope and Contents\", [\"Title\", \"Biographical / Historical\", \"Processing Information\"], 0, \"Coll-1036_00300.txt\")\n",
    "# test_files = agg_files[:5]\n",
    "desc_dict = utils.getDescriptionsInFiles(config.doc_path, agg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Descriptions: 26674\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Descriptions:\", len(desc_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>97</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>81</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                        description  \\\n",
       "0               0  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "1               1  Sermons and addresses, 1948-1996; lectures, 19...   \n",
       "2               2  Professor James Aitken White was a leading Sco...   \n",
       "3               3                Papers of Rev Tom Allan (1916-1965)   \n",
       "4               4  Sermons and addresses, 1947-1963; essays and l...   \n",
       "\n",
       "                       field           file  start_offset  end_offset  \n",
       "0                      Title  AA5_00100.txt            24          76  \n",
       "1         Scope and Contents  AA5_00100.txt            97         633  \n",
       "2  Biographical / Historical  AA5_00100.txt           661        1724  \n",
       "3                      Title  AA6_00100.txt            24          60  \n",
       "4         Scope and Contents  AA6_00100.txt            81         560  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df = pd.DataFrame.from_dict(desc_dict, orient=\"index\")\n",
    "# Give the descriptions a unique identifier\n",
    "ann_desc_df = ann_desc_df.reset_index()\n",
    "ann_desc_df = ann_desc_df.rename(columns={\"index\":\"description_id\"})\n",
    "ann_desc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all the description values have text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ann_desc_df.loc[ann_desc_df.description.isnull() == True].shape[0] == 0\n",
    "assert ann_desc_df.loc[ann_desc_df.description.isna() == True].shape[0] == 0\n",
    "assert ann_desc_df.loc[ann_desc_df.description == \"\"].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>General addresses</td>\n",
       "      <td>Title</td>\n",
       "      <td>BAI_00400.txt</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id        description  field           file  start_offset  \\\n",
       "108             108  General addresses  Title  BAI_00400.txt            28   \n",
       "\n",
       "     end_offset  \n",
       "108          46  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df.loc[ann_desc_df.description_id == 108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>Miscellaneous music.Several Marjory Kennedy-Fr...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>137</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>Miscellaneous items, Part 1, 2,  3.'Burns as a...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>1285</td>\n",
       "      <td>1563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>'Loose Leaf M.S.S. [manuscripts] of \"Book\"'. S...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>1584</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>'News Cuttings', note book. Softbound, charcoa...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>1858</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1006</td>\n",
       "      <td>Various music collections, Part 1  2. Part 1: ...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>2054</td>\n",
       "      <td>5254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1007</td>\n",
       "      <td>'Proofs  M.S.S.[manuscripts], More Songs of [t...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>5275</td>\n",
       "      <td>5552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1008</td>\n",
       "      <td>'Kennedy-Fraser MSS. [manuscripts], D. 18377 [...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>5573</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1009</td>\n",
       "      <td>'Tolmie  Gesto'. \\nBundle of various publicati...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>6004</td>\n",
       "      <td>6821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1010</td>\n",
       "      <td>Proofs of A Life of Song by Marjory Kennedy-Fr...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>6842</td>\n",
       "      <td>6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1011</td>\n",
       "      <td>Breton songs.  \\nSheet sewn onto stiffer sheet...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>6923</td>\n",
       "      <td>7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1012</td>\n",
       "      <td>Miscellaneous working material, Part 1, 2, 3, ...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>7331</td>\n",
       "      <td>12028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1013</td>\n",
       "      <td>Les 15 Modes de la Musique Bretonne, by Mauric...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>12049</td>\n",
       "      <td>12165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1014</td>\n",
       "      <td>'Printed music collections.Scots Songs: Marjor...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>12186</td>\n",
       "      <td>12388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1015</td>\n",
       "      <td>Printed music collections.Recueil de chants po...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>12409</td>\n",
       "      <td>13035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1016</td>\n",
       "      <td>Miscellaneous proofs of Songs of the Hebrides,...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>Coll-1036_00400.txt</td>\n",
       "      <td>13056</td>\n",
       "      <td>112387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      description_id                                        description  \\\n",
       "1002            1002  Miscellaneous music.Several Marjory Kennedy-Fr...   \n",
       "1003            1003  Miscellaneous items, Part 1, 2,  3.'Burns as a...   \n",
       "1004            1004  'Loose Leaf M.S.S. [manuscripts] of \"Book\"'. S...   \n",
       "1005            1005  'News Cuttings', note book. Softbound, charcoa...   \n",
       "1006            1006  Various music collections, Part 1  2. Part 1: ...   \n",
       "1007            1007  'Proofs  M.S.S.[manuscripts], More Songs of [t...   \n",
       "1008            1008  'Kennedy-Fraser MSS. [manuscripts], D. 18377 [...   \n",
       "1009            1009  'Tolmie  Gesto'. \\nBundle of various publicati...   \n",
       "1010            1010  Proofs of A Life of Song by Marjory Kennedy-Fr...   \n",
       "1011            1011  Breton songs.  \\nSheet sewn onto stiffer sheet...   \n",
       "1012            1012  Miscellaneous working material, Part 1, 2, 3, ...   \n",
       "1013            1013  Les 15 Modes de la Musique Bretonne, by Mauric...   \n",
       "1014            1014  'Printed music collections.Scots Songs: Marjor...   \n",
       "1015            1015  Printed music collections.Recueil de chants po...   \n",
       "1016            1016  Miscellaneous proofs of Songs of the Hebrides,...   \n",
       "\n",
       "                   field                 file  start_offset  end_offset  \n",
       "1002  Scope and Contents  Coll-1036_00400.txt           137        1264  \n",
       "1003  Scope and Contents  Coll-1036_00400.txt          1285        1563  \n",
       "1004  Scope and Contents  Coll-1036_00400.txt          1584        1837  \n",
       "1005  Scope and Contents  Coll-1036_00400.txt          1858        2033  \n",
       "1006  Scope and Contents  Coll-1036_00400.txt          2054        5254  \n",
       "1007  Scope and Contents  Coll-1036_00400.txt          5275        5552  \n",
       "1008  Scope and Contents  Coll-1036_00400.txt          5573        5983  \n",
       "1009  Scope and Contents  Coll-1036_00400.txt          6004        6821  \n",
       "1010  Scope and Contents  Coll-1036_00400.txt          6842        6902  \n",
       "1011  Scope and Contents  Coll-1036_00400.txt          6923        7310  \n",
       "1012  Scope and Contents  Coll-1036_00400.txt          7331       12028  \n",
       "1013  Scope and Contents  Coll-1036_00400.txt         12049       12165  \n",
       "1014  Scope and Contents  Coll-1036_00400.txt         12186       12388  \n",
       "1015  Scope and Contents  Coll-1036_00400.txt         12409       13035  \n",
       "1016  Scope and Contents  Coll-1036_00400.txt         13056      112387  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df.loc[ann_desc_df.file == \"Coll-1036_00400.txt\"]  # Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standoff format](https://brat.nlplab.org/standoff.html) that the brat rapid annotation tool uses records the start offset and end offset of annotated text spans where:\n",
    "* The **start offset** is the index of the *first character* in the annotated text span (which is also the number of characters in the document preceding the beginning of the annotated text span)\n",
    "* The **end offset** is the index of the character *after the annotated text span* (which means the end offset corresponds to the character immediately following the annotated text span)\n",
    "\n",
    "This means that the start offset of the first description of each document will be 0 and the end offset of the last description of each document will equal the length (number of characters) of the document.  There are multiple descriptions for each document, so we have calculated the intermediate start and end offsets as well, which are all in the DataFrame above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the file of annotated descritions with their start and end offsets to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_desc_filepath = config.crc_meta_path+\"annot_descs.csv\"\n",
    "ann_desc_df.to_csv(annot_desc_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write each description to a TXT file for later analysis with NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "10000 new files written\n",
      "26674 files finished writing!\n"
     ]
    }
   ],
   "source": [
    "dir_path = config.crc_meta_path+\"descriptions_annotated/\"\n",
    "# Make sure the directory exists\n",
    "Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write one TXT file per descrpition (utf-8 encoded by default), with the description ID as the file name\n",
    "description_list = list(ann_desc_df.description)\n",
    "id_list = list(ann_desc_df.description_id)\n",
    "# For zero padding so files are ordered correctly\n",
    "max_digits = len(str(max(id_list)))\n",
    "counter = 0\n",
    "for i in range(len(description_list)):\n",
    "    d = description_list[i]\n",
    "    did = id_list[i]\n",
    "    zeros = max_digits - len(str(did))\n",
    "    filename = (\"0\"*zeros)+str(did)+\".txt\"\n",
    "    f = open(dir_path+filename, \"w\")\n",
    "    f.write(d)\n",
    "    f.close()\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"10000 new files written\")\n",
    "print(\"{} files finished writing!\".format(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Lengths of Descriptions and Annotations\n",
    "**Find the minimum, maximum, average, and standard deviation of word and sentence counts...**\n",
    "* Per description (by `desc_id` - a.k.a. per \"document\" for document classifiers)\n",
    "* Per metadata field (Title, Biographical / Historical, Scope and Contents, and Processing Information)\n",
    "* Per collection (identifiable with the `eadid` column)\n",
    "* Per annotation label (Omission, Stereotype, Generalization, etc.)\n",
    "* Per annotation category (Person Name, Linguistic, Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1 Lengths of Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment if need to reload data\n",
    "# # --------------------------------\n",
    "# annot_desc_filepath = config.crc_meta_path+\"annot_descs.csv\"\n",
    "# ann_desc_df = pd.read_csv(annot_desc_filepath)\n",
    "# ann_desc_df = ann_desc_df.drop(columns=[\"Unnamed: 0\"])\n",
    "# dir_path = config.crc_meta_path+\"descriptions_annotated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000.txt', '00001.txt', '00002.txt', '00003.txt', '00004.txt', '00005.txt', '00006.txt', '00007.txt', '00008.txt', '00009.txt']\n",
      "['26664.txt', '26665.txt', '26666.txt', '26667.txt', '26668.txt', '26669.txt', '26670.txt', '26671.txt', '26672.txt', '26673.txt']\n"
     ]
    }
   ],
   "source": [
    "corpus = PlaintextCorpusReader(dir_path, \"\\w*.txt\", encoding=\"utf8\")\n",
    "print(corpus.fileids()[:10]) # Looks good\n",
    "print(corpus.fileids()[-10:]) # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length per Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Papers', 'of', 'The', 'Very', 'Rev', 'Prof', 'James', 'Whyte', '1920-2005']\n",
      "['papers', 'of', 'the', 'very', 'rev', 'prof', 'james', 'whyte', '1920-2005']\n",
      "['Papers of The Very Rev Prof James Whyte (1920-2005)']\n"
     ]
    }
   ],
   "source": [
    "desc_words, desc_lower_words, desc_sents = utils.getWordsSents(corpus)\n",
    "print(desc_words[0][:10])\n",
    "print(desc_lower_words[0][:10])\n",
    "print(desc_sents[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 62] [1, 1, 8, 1]\n"
     ]
    }
   ],
   "source": [
    "# Add word and sentence counts to DataFrame/CSV of descriptions\n",
    "word_count = [len(word_list) for word_list in desc_words]  # includes digits but not punctuation\n",
    "sent_count = [len(sent_list) for sent_list in desc_sents]\n",
    "print(word_count[:2], sent_count[:4])  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>97</td>\n",
       "      <td>633</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>81</td>\n",
       "      <td>560</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                        description  \\\n",
       "0               0  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "1               1  Sermons and addresses, 1948-1996; lectures, 19...   \n",
       "2               2  Professor James Aitken White was a leading Sco...   \n",
       "3               3                Papers of Rev Tom Allan (1916-1965)   \n",
       "4               4  Sermons and addresses, 1947-1963; essays and l...   \n",
       "\n",
       "                       field           file  start_offset  end_offset  \\\n",
       "0                      Title  AA5_00100.txt            24          76   \n",
       "1         Scope and Contents  AA5_00100.txt            97         633   \n",
       "2  Biographical / Historical  AA5_00100.txt           661        1724   \n",
       "3                      Title  AA6_00100.txt            24          60   \n",
       "4         Scope and Contents  AA6_00100.txt            81         560   \n",
       "\n",
       "   word_count  sent_count  \n",
       "0           9           1  \n",
       "1          62           1  \n",
       "2         179           8  \n",
       "3           6           1  \n",
       "4          59           2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_desc_df.insert(len(ann_desc_df.columns), \"word_count\", word_count)\n",
    "ann_desc_df.insert(len(ann_desc_df.columns), \"sent_count\", sent_count)\n",
    "ann_desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_desc_df.to_csv(annot_desc_filepath)  # add to the counts to the existing CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate summary stats for word and sentence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_df_stats = utils.makeDescribeDf(\"All\", ann_desc_df)\n",
    "bh_stats = utils.makeDescribeDf(\"Biographical / Historical\", ann_desc_df)\n",
    "sc_stats = utils.makeDescribeDf(\"Scope and Contents\", ann_desc_df)\n",
    "pi_stats = utils.makeDescribeDf(\"Processing Information\", ann_desc_df)\n",
    "t_stats = utils.makeDescribeDf(\"Title\", ann_desc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_descriptions</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata_field</th>\n",
       "      <th>by</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">All</th>\n",
       "      <th>word_count</th>\n",
       "      <td>26674.0</td>\n",
       "      <td>18.511397</td>\n",
       "      <td>88.030407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>26674.0</td>\n",
       "      <td>1.515221</td>\n",
       "      <td>5.436940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Title</th>\n",
       "      <th>word_count</th>\n",
       "      <td>14862.0</td>\n",
       "      <td>7.253061</td>\n",
       "      <td>5.623145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>14862.0</td>\n",
       "      <td>1.116001</td>\n",
       "      <td>0.498569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Scope and Contents</th>\n",
       "      <th>word_count</th>\n",
       "      <td>10855.0</td>\n",
       "      <td>28.210226</td>\n",
       "      <td>130.522502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>10855.0</td>\n",
       "      <td>1.804790</td>\n",
       "      <td>8.257919</td>\n",
       "      <td>1.0</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Biographical / Historical</th>\n",
       "      <th>word_count</th>\n",
       "      <td>655.0</td>\n",
       "      <td>117.453435</td>\n",
       "      <td>135.133575</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>655.0</td>\n",
       "      <td>5.975573</td>\n",
       "      <td>6.566015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Processing Information</th>\n",
       "      <th>word_count</th>\n",
       "      <td>302.0</td>\n",
       "      <td>9.350993</td>\n",
       "      <td>10.534360</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_count</th>\n",
       "      <td>302.0</td>\n",
       "      <td>1.079470</td>\n",
       "      <td>0.346279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      total_descriptions        mean  \\\n",
       "metadata_field            by                                           \n",
       "All                       word_count             26674.0   18.511397   \n",
       "                          sent_count             26674.0    1.515221   \n",
       "Title                     word_count             14862.0    7.253061   \n",
       "                          sent_count             14862.0    1.116001   \n",
       "Scope and Contents        word_count             10855.0   28.210226   \n",
       "                          sent_count             10855.0    1.804790   \n",
       "Biographical / Historical word_count               655.0  117.453435   \n",
       "                          sent_count               655.0    5.975573   \n",
       "Processing Information    word_count               302.0    9.350993   \n",
       "                          sent_count               302.0    1.079470   \n",
       "\n",
       "                                             std  min      max  \n",
       "metadata_field            by                                    \n",
       "All                       word_count   88.030407  0.0  12340.0  \n",
       "                          sent_count    5.436940  1.0    742.0  \n",
       "Title                     word_count    5.623145  0.0     51.0  \n",
       "                          sent_count    0.498569  1.0     15.0  \n",
       "Scope and Contents        word_count  130.522502  0.0  12340.0  \n",
       "                          sent_count    8.257919  1.0    742.0  \n",
       "Biographical / Historical word_count  135.133575  6.0   1110.0  \n",
       "                          sent_count    6.566015  1.0     45.0  \n",
       "Processing Information    word_count   10.534360  4.0    177.0  \n",
       "                          sent_count    0.346279  1.0      4.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = pd.concat([desc_df_stats, t_stats, sc_stats, bh_stats, pi_stats], axis=0)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"../data/analysis_data/descs_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2 Length of Annotations\n",
    "\n",
    "* Dataset: `annot-post/data/aggregated_final.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Offsets of Tokens\n",
    "\n",
    "**Get the offsets of the tokens in every description.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>file</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>97</td>\n",
       "      <td>633</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>661</td>\n",
       "      <td>1724</td>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>Title</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>81</td>\n",
       "      <td>560</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                        description  \\\n",
       "0               0  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "1               1  Sermons and addresses, 1948-1996; lectures, 19...   \n",
       "2               2  Professor James Aitken White was a leading Sco...   \n",
       "3               3                Papers of Rev Tom Allan (1916-1965)   \n",
       "4               4  Sermons and addresses, 1947-1963; essays and l...   \n",
       "\n",
       "                       field           file  start_offset  end_offset  \\\n",
       "0                      Title  AA5_00100.txt            24          76   \n",
       "1         Scope and Contents  AA5_00100.txt            97         633   \n",
       "2  Biographical / Historical  AA5_00100.txt           661        1724   \n",
       "3                      Title  AA6_00100.txt            24          60   \n",
       "4         Scope and Contents  AA6_00100.txt            81         560   \n",
       "\n",
       "   word_count  sent_count  \n",
       "0           9           1  \n",
       "1          62           1  \n",
       "2         179           8  \n",
       "3           6           1  \n",
       "4          59           2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_desc_filepath = config.crc_meta_path+\"annot_descs.csv\"\n",
    "df_desc = pd.read_csv(annot_desc_filepath, index_col=0)\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = list(df_desc.description)\n",
    "desc_ids = list(df_desc.description_id)\n",
    "desc_start_offsets = list(df_desc.start_offset)\n",
    "desc_end_offsets = list(df_desc.end_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dict, offsets_dict = utils.getTokensAndOffsetsFromStrings(descs, desc_ids, desc_start_offsets, desc_end_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_col, offsets_col, desc_ids_col = [], [], []\n",
    "for desc_id,token_list in tokens_dict.items():\n",
    "    tokens_col += token_list\n",
    "    offsets_list = offsets_dict[desc_id]\n",
    "    offsets_col += offsets_list\n",
    "    assert len(token_list) == len(offsets_list)\n",
    "    desc_ids_col += [desc_id]*len(token_list)\n",
    "\n",
    "assert len(tokens_col) == len(offsets_col)\n",
    "assert len(tokens_col) == len(desc_ids_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Papers', 'of', 'The', 'Very', 'Rev']\n",
      "[(24, 30), (31, 33), (34, 37), (38, 42), (43, 46)]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for col_list in [tokens_col, offsets_col, desc_ids_col]:\n",
    "    print(col_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  Now create a DataFrame with these lists as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Very</td>\n",
       "      <td>(38, 42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Rev</td>\n",
       "      <td>(43, 46)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_id   token   offsets\n",
       "0        0  Papers  (24, 30)\n",
       "1        0      of  (31, 33)\n",
       "2        0     The  (34, 37)\n",
       "3        0    Very  (38, 42)\n",
       "4        0     Rev  (43, 46)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.DataFrame({\"desc_id\":desc_ids_col, \"token\":tokens_col, \"offsets\":offsets_col})\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655977, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now write the DataFrame to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.to_csv(config.crc_meta_path+\"descid_token_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "# DELETE CODE BELOW (MOVING TO NEW NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### 3.1 BIO Tags\n",
    "\n",
    "**Compare the descriptions' tokens' offsets to the annotated text spans' offsets to determine which tokens to mark as the beginning of an annotation (`B-[LABELNAME]`), inside an annotation (`I-[LABELNAME]`), and unannotated, or outisde of an annotation (`O`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: convert the three dataframes to dictionaries, \n",
    "#        for each filename, check whether each token_offset pair contained within each ann_offset pair and desc_,\n",
    "#        recording which description (using indeces) annotation appears within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29, 36), (37, 39), (40, 43), (44, 57), (58, 65)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.read_csv(config.tokc_path+\"descid_token_offsets.csv\", index_col=0)\n",
    "token_desc_ids = list(df_tokens.desc_id)\n",
    "tokens = list(df_tokens.token)\n",
    "token_offsets = list(df_tokens.offsets)\n",
    "token_offsets_clean = [offsets[1:-1].split(\", \") for offsets in token_offsets]\n",
    "token_offsets_tuples = [tuple((int(offsets[0]), int(offsets[1]))) for offsets in token_offsets_clean]\n",
    "token_offsets_tuples[:5]  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate description tokens and annotated text spans' text and offsets to description IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                             token_offsets  \n",
       "desc_id                                                     \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...  \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...  \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...  \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...  \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tokens_imploded = utils.implodeDataFrame(df_tokens, [\"desc_id\"])\n",
    "df_tokens_imploded = df_tokens_imploded.rename(columns={\"offsets\":\"token_offsets\"})\n",
    "df_tokens_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens_imploded.to_csv(config.tokc_path+\"token_data_imploded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data associating description and annotation IDs to offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>desc_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BAI_01000</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[68]</td>\n",
       "      <td>[(1290, 1315)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01300</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[(5853, 5983)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01600</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[221]</td>\n",
       "      <td>[(5967, 6202)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_01900</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[292]</td>\n",
       "      <td>[(5297, 5506)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_02200</th>\n",
       "      <td>['BAI']</td>\n",
       "      <td>[361]</td>\n",
       "      <td>[(15180, 15419)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eadid desc_id      desc_offsets\n",
       "filename                                    \n",
       "BAI_01000  ['BAI']    [68]    [(1290, 1315)]\n",
       "BAI_01300  ['BAI']   [143]    [(5853, 5983)]\n",
       "BAI_01600  ['BAI']   [221]    [(5967, 6202)]\n",
       "BAI_01900  ['BAI']   [292]    [(5297, 5506)]\n",
       "BAI_02200  ['BAI']   [361]  [(15180, 15419)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descs_imploded = pd.read_csv(config.agg_path+\"description_data_imploded.csv\", index_col=0)\n",
    "df_descs_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>ann_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA5_00100</th>\n",
       "      <td>[14377, 14378, 14379, 14380, 14381, 14382, 143...</td>\n",
       "      <td>['(789, 791)', '(871, 873)', '(913, 916)', '(9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA6_00100</th>\n",
       "      <td>[55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...</td>\n",
       "      <td>['(1778, 1790)', '(677, 679)', '(920, 922)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA7_00100</th>\n",
       "      <td>[127, 13987, 13988, 13989, 13990, 13991, 13992...</td>\n",
       "      <td>['(2399, 2415)', '(505, 508)', '(614, 620)', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00100</th>\n",
       "      <td>[17473, 17474, 17475, 17476, 17477, 17478, 416...</td>\n",
       "      <td>['(371, 388)', '(393, 405)', '(34, 56)', '(102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAI_00200</th>\n",
       "      <td>[20496, 20497, 20498, 20499, 20500, 20501, 205...</td>\n",
       "      <td>['(215, 221)', '(226, 232)', '(250, 255)', '(2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  agg_ann_id  \\\n",
       "filename                                                       \n",
       "AA5_00100  [14377, 14378, 14379, 14380, 14381, 14382, 143...   \n",
       "AA6_00100  [55, 9516, 9517, 9518, 9519, 9520, 9521, 9522,...   \n",
       "AA7_00100  [127, 13987, 13988, 13989, 13990, 13991, 13992...   \n",
       "BAI_00100  [17473, 17474, 17475, 17476, 17477, 17478, 416...   \n",
       "BAI_00200  [20496, 20497, 20498, 20499, 20500, 20501, 205...   \n",
       "\n",
       "                                                 ann_offsets  \n",
       "filename                                                      \n",
       "AA5_00100  ['(789, 791)', '(871, 873)', '(913, 916)', '(9...  \n",
       "AA6_00100  ['(1778, 1790)', '(677, 679)', '(920, 922)', '...  \n",
       "AA7_00100  ['(2399, 2415)', '(505, 508)', '(614, 620)', '...  \n",
       "BAI_00100  ['(371, 388)', '(393, 405)', '(34, 56)', '(102...  \n",
       "BAI_00200  ['(215, 221)', '(226, 232)', '(250, 255)', '(2...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anns_imploded = pd.read_csv(config.agg_path+\"annotation_data_imploded.csv\", index_col=0)\n",
    "df_anns_imploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: O tags**\n",
    "\n",
    "Compare description IDs in the two DataFrames above to determine which descriptions (from `df_tokens_imploded`) do not have annotations, and assign all those descriptions' tokens an `O` tag (for *outside* of an annotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign tag 'O': 86742\n"
     ]
    }
   ],
   "source": [
    "all_desc_ids = list(df_tokens_imploded.index)\n",
    "ann_desc_ids = list(df_merged_imploded.index)\n",
    "unannotated = [desc_id for desc_id in all_desc_ids if not desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign tag 'O':\", len(unannotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(unannotated)]\n",
    "assert o_df.shape[0] == len(unannotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "      <th>ann_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Records, of, the, Phrenological, Society, of,...</td>\n",
       "      <td>[(29, 36), (37, 39), (40, 43), (44, 57), (58, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, records, of, the, Phrenological, Society...</td>\n",
       "      <td>[(100, 103), (104, 111), (112, 114), (115, 118...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, Phrenological, Society, of, Edinburgh, w...</td>\n",
       "      <td>[(638, 641), (642, 655), (656, 663), (664, 666...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...</td>\n",
       "      <td>[(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...</td>\n",
       "      <td>[(125, 131), (131, 132), (133, 137), (138, 141...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "0        [Records, of, the, Phrenological, Society, of,...   \n",
       "1        [The, records, of, the, Phrenological, Society...   \n",
       "2        [The, Phrenological, Society, of, Edinburgh, w...   \n",
       "3        [Letter, :, 1825, Jan., 10, ,, 27, Lower, Belg...   \n",
       "4        [Letter, :, 1825, Mar, ., 1, ,, 27, Lower, Bel...   \n",
       "\n",
       "                                                   offsets  \\\n",
       "desc_id                                                      \n",
       "0        [(29, 36), (37, 39), (40, 43), (44, 57), (58, ...   \n",
       "1        [(100, 103), (104, 111), (112, 114), (115, 118...   \n",
       "2        [(638, 641), (642, 655), (656, 663), (664, 666...   \n",
       "3        [(7, 13), (13, 14), (15, 19), (20, 24), (25, 2...   \n",
       "4        [(125, 131), (131, 132), (133, 137), (138, 141...   \n",
       "\n",
       "                                                   ann_tag  \n",
       "desc_id                                                     \n",
       "0                                    [O, O, O, O, O, O, O]  \n",
       "1        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4        [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list = list(o_df.token)\n",
    "tags = [[\"O\"]*len(tokens) for tokens in tokens_list]\n",
    "assert len(tags) == len(tokens_list)\n",
    "o_df.insert(len(o_df.columns), \"ann_tag\", tags)\n",
    "o_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(o_df.token[100]) == len(o_df.ann_tag[100])\n",
    "assert len(o_df.token[488]) == len(o_df.ann_tag[488])\n",
    "assert len(o_df.token[0]) == len(o_df.ann_tag[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: B- and I- tags**\n",
    "\n",
    "For description IDs that do have annotations (and thus are in `df_merged_imploded`), assign their tokens tags of `B-[LABELNAME]` and `I-[LABELNAME]` for *beginning* and *inside* of an annotation, replacing `[LABELNAME]` with the name of the annotation's label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to assign 'B-' or 'I-'': 1855\n"
     ]
    }
   ],
   "source": [
    "annotated = [desc_id for desc_id in all_desc_ids if desc_id in ann_desc_ids]\n",
    "print(\"Rows to assign 'B-' or 'I-'':\", len(annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_df = df_tokens_imploded.loc[df_tokens_imploded.index.isin(annotated)]\n",
    "assert bi_df.shape[0] == len(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[Brick, Burning, ,, Beardman, 's]</td>\n",
       "      <td>[(1421, 1426), (1427, 1434), (1434, 1435), (14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>[Interpreting, sequence, motifs, [, Letter, to...</td>\n",
       "      <td>[(3064, 3076), (3077, 3085), (3086, 3092), (30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>[Letter, :, :, Koestler, ,, Arthur]</td>\n",
       "      <td>[(127, 133), (134, 135), (135, 136), (137, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>[Lady, Luck, :, the, theory, of, probability, ...</td>\n",
       "      <td>[(2118, 2122), (2123, 2127), (2127, 2128), (21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     token  \\\n",
       "desc_id                                                      \n",
       "167                      [Brick, Burning, ,, Beardman, 's]   \n",
       "508      [Interpreting, sequence, motifs, [, Letter, to...   \n",
       "610                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "611                    [Letter, :, :, Koestler, ,, Arthur]   \n",
       "640      [Lady, Luck, :, the, theory, of, probability, ...   \n",
       "\n",
       "                                                   offsets  \n",
       "desc_id                                                     \n",
       "167      [(1421, 1426), (1427, 1434), (1434, 1435), (14...  \n",
       "508      [(3064, 3076), (3077, 3085), (3086, 3092), (30...  \n",
       "610      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "611      [(127, 133), (134, 135), (135, 136), (137, 145...  \n",
       "640      [(2118, 2122), (2123, 2127), (2127, 2128), (21...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Brick', 'Burning', ',', 'Beardman', \"'s\"], 'offsets': ['(1421, 1426)', '(1427, 1434)', '(1434, 1435)', '(1436, 1444)', '(1444, 1446)']}\n"
     ]
    }
   ],
   "source": [
    "bi_dict = bi_df.to_dict('index')\n",
    "print(bi_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'offsets_ann': ['(1436, 1444)', '(1436, 1444)'], 'text_ann': ['Beardman', 'Beardman'], 'label': ['Omission', 'Unknown'], 'id': [31928, 31929]}\n"
     ]
    }
   ],
   "source": [
    "ann_dict = df_merged_imploded.to_dict('index')\n",
    "print(ann_dict[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a string of offsets into a tuple with each offset of type int\n",
    "# \"(1436, 1444)\" --> (1436, 1444)\n",
    "def offsetsStrToTuple(offsets_str):\n",
    "    offsets_list = offsets_str[1:-1].split(\", \")\n",
    "    offsets_ints = [int(o) for o in offsets_list]\n",
    "    return tuple((offsets_ints))\n",
    "\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')) == tuple\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[0]) == int\n",
    "assert type(offsetsStrToTuple('(1436, 1444)')[1]) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned tags for 100 descriptions\n"
     ]
    }
   ],
   "source": [
    "desc_ids = list(bi_dict.keys())[:100]  # START WITH SAMPLE\n",
    "assert len(set(desc_ids)) == len(desc_ids)  # Make sure every description ID is unique\n",
    "log = 0\n",
    "descid_to_tag = dict.fromkeys(desc_ids)\n",
    "for desc_id in desc_ids:\n",
    "    text_spans = ann_dict[desc_id][\"text_ann\"]\n",
    "    desc_tokens = bi_dict[desc_id]['token']\n",
    "    desc_tokens_offsets = bi_dict[desc_id]['offsets']\n",
    "    desc_tags = []\n",
    "    for i,desc_token in enumerate(desc_tokens):\n",
    "        token_offset_pair = offsetsStrToTuple(desc_tokens_offsets[i])\n",
    "        span_indeces, tags = [], []  # Note: one token may have multiple tags\n",
    "        \n",
    "        # Record the indeces of every item in text_spans with the desc_token\n",
    "        for j,text_span in enumerate(text_spans):\n",
    "            span_offset_pair = offsetsStrToTuple(ann_dict[desc_id][\"offsets_ann\"][j])    \n",
    "            # Be sure a matching token's offsets are within the annotated text span\n",
    "            if (desc_token in text_span\n",
    "               ) and (\n",
    "                token_offset_pair[0] >= span_offset_pair[0]\n",
    "                ) and (\n",
    "                token_offset_pair[1] <= span_offset_pair[1]):\n",
    "                    span_indeces += [j] \n",
    "            else:\n",
    "                span_indeces += [\"unannotated\"]\n",
    "        for j in span_indeces:\n",
    "            # If the token is annotated, assign it a B- or I- tag with a label\n",
    "            if type(j) == int:\n",
    "            # If the start offsets are the same, assign a 'B-' tag\n",
    "                if token_offset_pair[0] == span_offset_pair[0]:\n",
    "                    tags += ['B-'+ann_dict[desc_id][\"label\"][j]]\n",
    "                # Otherwise, assign an 'I-' tag\n",
    "                else:\n",
    "                    tags += ['I-'+ann_dict[desc_id][\"label\"][j]]\n",
    "            # If the description token isn't annotated, assign it an O tag\n",
    "            elif j == \"unannotated\":\n",
    "                tags += [\"O\"]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid j value: {}\".format(j))\n",
    "        \n",
    "        desc_tags += [set(tags)]\n",
    "    \n",
    "    assert len(desc_tokens) == len(desc_tags)\n",
    "    descid_to_tag[desc_id] = desc_tags\n",
    "    \n",
    "    log += 1\n",
    "    if log % 100 == 0:\n",
    "        print(\"Assigned tags for {} descriptions\".format(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['Letter', ':', ':', 'Koestler', ',', 'Arthur'], 'offsets': ['(127, 133)', '(134, 135)', '(135, 136)', '(137, 145)', '(145, 146)', '(147, 153)']}\n"
     ]
    }
   ],
   "source": [
    "did = 610 #508 #167\n",
    "# print(ann_dict[did])\n",
    "print(bi_dict[did])\n",
    "# print(descid_to_tag[did])\n",
    "\n",
    "# spans = ['Beardman', 'Beardman']\n",
    "# spans2 = [\"Brick Burning\"]\n",
    "# tokens = ['Brick', 'Burning', ',', 'Beardman', \"'s\"]\n",
    "# # print(spans.count('Beardman'))\n",
    "# # # print(spans.index('Beardman'))\n",
    "# # # print(tokens.index('Beardman'))\n",
    "# # for k in range(0,3):\n",
    "# #     print(k)\n",
    "# indeces = [index for index in range(len(spans)) if spans[index] == 'Beardman']\n",
    "# print(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m token \u001b[38;5;241m=\u001b[39m tokens[i]\n\u001b[1;32m      7\u001b[0m token_start, token_end \u001b[38;5;241m=\u001b[39m token_offsets_tuples[i][\u001b[38;5;241m0\u001b[39m], token_offsets_tuples[i][\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m----> 9\u001b[0m ann_df \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdesc_id\u001b[49m]\n\u001b[1;32m     10\u001b[0m ann_id_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m     11\u001b[0m ann_offsets_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ann_df\u001b[38;5;241m.\u001b[39moffsets_ann)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:290\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/pandas/core/computation/expressions.py:106\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    103\u001b[0m b_value \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mop_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m b_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_value\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# numexpr raises eg for array ** array with integers\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pydata/numexpr/issues/379)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/gender-bias/lib/python3.9/site-packages/numexpr/necompiler.py:835\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m _numexpr_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ex\u001b[38;5;241m=\u001b[39mcompiled_ex, argnames\u001b[38;5;241m=\u001b[39mnames, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m evaluate_lock:\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# is_annotated_col = []\n",
    "# annotated_id = []\n",
    "# i, maxI = 0, len(token_desc_ids)  #1188478, 1189478\n",
    "# while i < maxI:\n",
    "#     desc_id = token_desc_ids[i]\n",
    "#     token = tokens[i]\n",
    "#     token_start, token_end = token_offsets_tuples[i][0], token_offsets_tuples[i][1] \n",
    "    \n",
    "#     ann_df = df_merged.loc[df_merged.desc_id == desc_id]\n",
    "#     ann_id_list = list(ann_df.id)\n",
    "#     ann_offsets_list = list(ann_df.offsets_ann)\n",
    "#     ann_offsets_clean = [ann_offsets[1:-1].split(\", \") for ann_offsets in ann_offsets_list]\n",
    "#     ann_offsets_tuples = [tuple((int(ann_offsets[0]), int(ann_offsets[1]))) for ann_offsets in ann_offsets_clean]\n",
    "    \n",
    "#     for j,ann_offsets in enumerate(ann_offsets_tuples):\n",
    "#         ann_start = ann_offsets[0]\n",
    "#         ann_end = ann_offsets[1]\n",
    "#         if token_start == ann_start:\n",
    "#             is_annotated_col += [\"B\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         elif (token_start > ann_start) and (token_start <= ann_end):\n",
    "#             is_annotated_col += [\"I\"]\n",
    "#             annotated_id += [ann_id_list[j]]\n",
    "#         else:\n",
    "#             is_annotated_col += [\"O\"]\n",
    "#             annotated_id += [\"None\"]\n",
    "    \n",
    "#     i += 1\n",
    "\n",
    "# assert len(is_annotated_col) == len(token_desc_ids)\n",
    "# assert len(is_annotated_col) == len(annotated_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens.insert(len(df_tokens.columns),\"is_annotated\",is_annotated_col)\n",
    "df_tokens.insert(len(df_tokens.columns),\"ann_id\",annotated_id)\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(is_annotated_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48022031\n"
     ]
    }
   ],
   "source": [
    "print(len(annotated_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

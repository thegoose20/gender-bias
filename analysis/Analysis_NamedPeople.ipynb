{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Named People\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "A comparison of automated Named Entity Recognition and manual annotation\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "  [I. Loading](#load)\n",
    "\n",
    "  [II. Named Entity Recognition with SpaCy](#ner)\n",
    "  \n",
    "  [III. Manual Annotation of People's Names](#annot)\n",
    "  \n",
    "  [IV. Comparison](#comp)\n",
    "  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "### I. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use custom functions\n",
    "import utils\n",
    "\n",
    "# To work with CSV data\n",
    "import pandas as pd\n",
    "\n",
    "# To work with TXT data\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# For named entity recognition (NER)\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "try:\n",
    "    import en_core_web_sm\n",
    "except ImportError:\n",
    "    print(\"Downlading en_core_web_sm model\")\n",
    "    import sys\n",
    "    !{sys.executable} -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# For fuzzy string matching\n",
    "# https://github.com/seatgeek/thefuzz\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "# For statistical calculations\n",
    "import numpy as np\n",
    "\n",
    "# To export JSON data\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and load the Plaintext files of archival catalog metadata descriptions used for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/crc_metadata/annot_descs.csv\", index_col=0)\n",
    "subdf = df[[\"description_id\", \"description\"]]\n",
    "df_agg = pd.read_csv(\"../data/aggregated_data/aggregated_final.csv\")\n",
    "df_joined = df_agg.set_index(\"description_id\").join(subdf, on=\"description_id\", how=\"left\")\n",
    "df_joined.shape\n",
    "assert len(set(list(df_joined.description_id))) == len(set(list(df_agg.description_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = df_joined[[\"description_id\", \"description\"]]\n",
    "df_desc = df_desc.drop_duplicates()\n",
    "descs = list(df_desc.description)\n",
    "assert len(descs) == len(set(list(df_agg.description_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14779\n"
     ]
    }
   ],
   "source": [
    "f = open(\"../data/classified_descriptions.txt\", \"w\") # create a new Plaintext file\n",
    "counter = 0\n",
    "for d in descs:\n",
    "    f.write(d+\"\\n\")\n",
    "    counter += 1\n",
    "f.close()\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/\"\n",
    "descs = PlaintextCorpusReader(datadir, \"classified_descriptions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Biographical', '/', 'Historical', ':', 'Sir', 'John', 'Scott', 'of', 'Scotstarvit', 'was', 'born', 'in', '1585', '.', 'He', 'was', 'the', 'brother', '-', 'in']\n"
     ]
    }
   ],
   "source": [
    "tokens = descs.words()\n",
    "print(tokens[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Biographical', '/', 'Historical', ':', 'Sir', 'John', 'Scott', 'of', 'Scotstarvit', 'was', 'born', 'in', '1585', '.'], ['He', 'was', 'the', 'brother', '-', 'in', '-', 'law', 'of', 'William', 'Drummond', 'of', 'Hawthornden', ',', 'the', 'poet', '.'], ['Scott', 'was', 'educated', 'at', 'St', '.', 'Leonard', \"'\", 's', 'College', ',', 'St', '.', 'Andrews', ',', 'entering', 'it', 'around', '1600', '.'], ['He', 'then', 'studied', 'abroad', 'before', 'returning', 'to', 'Scotland', 'having', 'been', 'called', 'to', 'the', 'Bar', '.'], ['In', '1611', 'he', 'acquired', 'Tarvet', 'and', 'other', 'land', 'in', 'Fife', 'to', 'which', 'he', 'gave', 'the', 'name', 'Scotstarvet', '.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = descs.sents()\n",
    "print(sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552520 16450\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens), len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26574\n",
      "391403\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=[\"file\"])\n",
    "df_joined2 = df_agg.set_index(\"description_id\").join(df, on=\"description_id\", how=\"left\")\n",
    "df_joined2 = df_joined2[[\"description_id\", \"word_count\", \"sent_count\"]].drop_duplicates()\n",
    "print(sum(list(df_joined2.sent_count)))\n",
    "print(sum(list(df_joined2.word_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ner\"></a>\n",
    "## II. Name Entity Recognition with spaCy\n",
    "Run named entity recognition (NER) to estimate the names in the dataset and get a sense for the value in manually labeling names during the annotation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = descs.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16155\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for fileid in fileids:\n",
    "    file = descs.raw(fileid)\n",
    "    sentences += nltk.sent_tokenize(file)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_person_list = []\n",
    "for s in sentences:\n",
    "    s.strip()  # remove leading and trailing whitespace\n",
    "    s_ne = nlp(s)\n",
    "    for entity in s_ne.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            spacy_person_list += [entity.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24026 7815\n"
     ]
    }
   ],
   "source": [
    "spacy_unique_persons = list(set(spacy_person_list))\n",
    "print(len(spacy_person_list), len(spacy_unique_persons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John Reid', 'M S Bartlett', 'Aunt Gertrude', \"Pr√©cis de l'art\", 'Grandin', 'Steele', 'Broglie', 'Elena L. Grigorenko', 'P. De Sousa', 'Clorinda', 'Cramond', 'Alexander Darroch', 'George Goldie', 'Dr Blyth', 'Kesting', 'David Somervell', 'James Denholm', 'L. Oppenheim', 'Behold', 'Johanna', 'Harvie', 'Thomas Tod', 'Jean-de-Dieu Soult', 'Charlotte Banks', 'Roger H L\\n', 'Keith Vickerman', 'Stanley Booth-Clibborn\\nScope', 'Muir', 'Scots Suites', 'Inscribed E. Gabritschevsky', 'Variieren', 'Dean', 'Inscribed E. [Forbes', 'Randi', 'Henry Gilbert', 'H. Monteath', 'Lyneham Lad\"', 'John Riddell', 'Anne McLaren', 'Arthur Dean', 'Leo Harrison\\n', 'Karnovsky', 'Abraham Weinshall', 'John Berry', 'Hydie', 'B. Ed', 'Buenos Aires', 'Gordon Chiled', 'Jean Giles', 'Dean Willis']\n"
     ]
    }
   ],
   "source": [
    "print(spacy_unique_persons[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect...some non-person entities labeled such as `Buenos Aires` and `Behold`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Manual Annotation of People's Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-1157_00100.ann</td>\n",
       "      <td>knighted</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-1310_02300.ann</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>4542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-1281_00100.ann</td>\n",
       "      <td>Prince Regent</td>\n",
       "      <td>(2426, 2439)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>3660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Coll-1310_02700.ann</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>(9993, 10003)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>4678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Coll-1310_02900.ann</td>\n",
       "      <td>Sir</td>\n",
       "      <td>(7192, 7195)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>4732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agg_ann_id                 file           text    ann_offsets  \\\n",
       "0           0  Coll-1157_00100.ann       knighted   (1407, 1415)   \n",
       "1           1  Coll-1310_02300.ann     knighthood   (9625, 9635)   \n",
       "2           2  Coll-1281_00100.ann  Prince Regent   (2426, 2439)   \n",
       "3           3  Coll-1310_02700.ann     knighthood  (9993, 10003)   \n",
       "4           4  Coll-1310_02900.ann            Sir   (7192, 7195)   \n",
       "\n",
       "           label    category associated_genders  description_id  \n",
       "0  Gendered-Role  Linguistic            Unclear            2364  \n",
       "1  Gendered-Role  Linguistic            Unclear            4542  \n",
       "2  Gendered-Role  Linguistic            Unclear            3660  \n",
       "3  Gendered-Role  Linguistic            Unclear            4678  \n",
       "4  Gendered-Role  Linguistic            Unclear            4732  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/aggregated_data/aggregated_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Coll-1036_00500.ann</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>(36375, 36393)</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Coll-1010_00100.ann</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>(40, 60)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14570, 14592)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy Fraser</td>\n",
       "      <td>(14698, 14720)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14924, 14946)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agg_ann_id                 file                    text     ann_offsets  \\\n",
       "7            7  Coll-1036_00500.ann      Mrs Norman Macleod  (36375, 36393)   \n",
       "14          14  Coll-1010_00100.ann    Dr. Nelly Renee Deme        (40, 60)   \n",
       "15          15  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14570, 14592)   \n",
       "16          16  Coll-1036_00300.ann  Marjory Kennedy Fraser  (14698, 14720)   \n",
       "17          17  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14924, 14946)   \n",
       "\n",
       "       label     category associated_genders  description_id  \n",
       "7   Feminine  Person-Name            Unclear            1082  \n",
       "14   Unknown  Person-Name            Unclear             855  \n",
       "15   Unknown  Person-Name            Unclear            1038  \n",
       "16   Unknown  Person-Name            Unclear            1038  \n",
       "17   Unknown  Person-Name            Unclear            1038  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ppl = df.loc[df.category == \"Person-Name\"]\n",
    "df_ppl = df_ppl.drop_duplicates()\n",
    "df_ppl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people: 29384\n",
      "Total Masculine: 6087\n",
      "Total Feminine: 1836\n",
      "Total Unknown: 23234\n"
     ]
    }
   ],
   "source": [
    "# Some instances of people's names may be annotated more than once with different labels, so \n",
    "# remove these duplicate instances when calculating total people\n",
    "dedup_df_ppl = df_ppl[[\"file\", \"text\", \"category\", \"ann_offsets\", \"description_id\"]].drop_duplicates()\n",
    "total_ppl = dedup_df_ppl.shape[0]  # without dedup: 31158\n",
    "df_mas = df_ppl.loc[df_ppl.label == \"Masculine\"]\n",
    "df_fem = df_ppl.loc[df_ppl.label == \"Feminine\"]\n",
    "df_unk = df_ppl.loc[df_ppl.label == \"Unknown\"]\n",
    "total_mas = df_mas.shape[0]\n",
    "total_fem = df_fem.shape[0]\n",
    "total_unk = df_unk.shape[0]\n",
    "print(\"Total people:\", total_ppl)\n",
    "print(\"Total Masculine:\", total_mas)\n",
    "print(\"Total Feminine:\", total_fem)\n",
    "print(\"Total Unknown:\", total_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique people names: 10288\n",
      "Unique masculine-labeled names: 2121\n",
      "Unique feminine-labeled names: 655\n",
      "Unique unknown-labeled names: 8316\n"
     ]
    }
   ],
   "source": [
    "unique_ppl = set(list(df_ppl.text))\n",
    "unique_mas = set(list(df_mas.text))\n",
    "unique_fem = set(list(df_fem.text))\n",
    "unique_unk = set(list(df_unk.text))\n",
    "print(\"Unique people names:\", len(unique_ppl))\n",
    "print(\"Unique masculine-labeled names:\", len(unique_mas))\n",
    "print(\"Unique feminine-labeled names:\", len(unique_fem))\n",
    "print(\"Unique unknown-labeled names:\", len(unique_unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Automated Annotation of People's Names\n",
    "Compare the Person Name annotations of the highest performing Person Name and Occupation classifier (with Linguistic labels as features) to the manual and spaCy annotation of Person Names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, join the original text data, from the aggregated dataset, to the classifier's prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Coll-1036_00500.ann</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>(36375, 36393)</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Coll-1010_00100.ann</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>(40, 60)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14570, 14592)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy Fraser</td>\n",
       "      <td>(14698, 14720)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14924, 14946)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agg_ann_id                 file                    text     ann_offsets  \\\n",
       "7            7  Coll-1036_00500.ann      Mrs Norman Macleod  (36375, 36393)   \n",
       "14          14  Coll-1010_00100.ann    Dr. Nelly Renee Deme        (40, 60)   \n",
       "15          15  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14570, 14592)   \n",
       "16          16  Coll-1036_00300.ann  Marjory Kennedy Fraser  (14698, 14720)   \n",
       "17          17  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14924, 14946)   \n",
       "\n",
       "       label     category associated_genders  description_id  \n",
       "7   Feminine  Person-Name            Unclear            1082  \n",
       "14   Unknown  Person-Name            Unclear             855  \n",
       "15   Unknown  Person-Name            Unclear            1038  \n",
       "16   Unknown  Person-Name            Unclear            1038  \n",
       "17   Unknown  Person-Name            Unclear            1038  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"../data/aggregated_data/aggregated_final.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df = df.loc[df.category == \"Person-Name\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65634</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66267</th>\n",
       "      <td>1038</td>\n",
       "      <td>1485</td>\n",
       "      <td>15.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>1038</td>\n",
       "      <td>1485</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       description_id  sentence_id  ann_id expected_label predicted_label  \\\n",
       "6848             1082         2590     7.0       Feminine        Feminine   \n",
       "65634             855         1097    14.0              O        Feminine   \n",
       "2709              855         1097    14.0        Unknown               O   \n",
       "66267            1038         1485    15.0              O        Feminine   \n",
       "3709             1038         1485    15.0        Unknown               O   \n",
       "\n",
       "               _merge  \n",
       "6848    true positive  \n",
       "65634  false positive  \n",
       "2709   false negative  \n",
       "66267  false positive  \n",
       "3709   false negative  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The baseline PNOC performed best for classifying with the Person Name labels (Experiment 3's first model)\n",
    "pnoc_pred = \"../data/token_clf_data/experiment3/5fold/output/crf-arow_pers_o_baseline_fastText100_annot_evaluation.csv\"\n",
    "df_pnoc = pd.read_csv(pnoc_pred, index_col=0, low_memory=False)\n",
    "df_pnoc = df_pnoc.drop_duplicates()\n",
    "df_pnoc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115201, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pnoc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>text</th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>14</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>14</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>15</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>15</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ann_id                    text  description_id  sentence_id  \\\n",
       "7.0        7      Mrs Norman Macleod          1082.0       2590.0   \n",
       "14.0      14    Dr. Nelly Renee Deme           855.0       1097.0   \n",
       "14.0      14    Dr. Nelly Renee Deme           855.0       1097.0   \n",
       "15.0      15  Marjory Kennedy-Fraser          1038.0       1485.0   \n",
       "15.0      15  Marjory Kennedy-Fraser          1038.0       1485.0   \n",
       "\n",
       "     expected_label predicted_label          _merge  \n",
       "7.0        Feminine        Feminine   true positive  \n",
       "14.0              O        Feminine  false positive  \n",
       "14.0        Unknown               O  false negative  \n",
       "15.0              O        Feminine  false positive  \n",
       "15.0        Unknown               O  false negative  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"agg_ann_id\":\"ann_id\"})\n",
    "subdf = df[[\"ann_id\", \"text\"]]\n",
    "df_pnoc = subdf.join(df_pnoc.set_index(\"ann_id\"), how=\"outer\", on=\"ann_id\")\n",
    "df_pnoc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the total predicted person names, as well as total predicted feminine, masculine, and unknown names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people: 20304\n",
      "Total Masculine: 3835\n",
      "Total Feminine: 1724\n",
      "Total Unknown: 12042\n"
     ]
    }
   ],
   "source": [
    "clf_df_ppl = df_pnoc.loc[~df_pnoc.predicted_label.isna()]\n",
    "clf_df_ppl = clf_df_ppl.loc[clf_df_ppl.predicted_label != \"O\"]\n",
    "clf_df_fem = clf_df_ppl.loc[clf_df_ppl.predicted_label == \"Feminine\"]\n",
    "clf_df_mas = clf_df_ppl.loc[clf_df_ppl.predicted_label == \"Masculine\"]\n",
    "clf_df_unk = clf_df_ppl.loc[clf_df_ppl.predicted_label == \"Unknown\"]\n",
    "\n",
    "# Note: Some instances of people's names may be annotated more than once with different labels\n",
    "clf_total_ppl = clf_df_ppl.shape[0]\n",
    "clf_total_fem = clf_df_fem.shape[0]\n",
    "clf_total_mas = clf_df_mas.shape[0]\n",
    "clf_total_unk = clf_df_unk.shape[0]\n",
    "\n",
    "print(\"Total people:\", clf_total_ppl)\n",
    "print(\"Total Masculine:\", clf_total_mas)\n",
    "print(\"Total Feminine:\", clf_total_fem)\n",
    "print(\"Total Unknown:\", clf_total_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique people names: 4305\n",
      "Unique masculine-labeled names: 1259\n",
      "Unique feminine-labeled names: 414\n",
      "Unique unknown-labeled names: 3167\n"
     ]
    }
   ],
   "source": [
    "clf_unique_ppl = set(list(clf_df_ppl.text))\n",
    "# Remove nan values\n",
    "clf_unique_ppl = list(clf_unique_ppl)\n",
    "clf_unique_people = [person for person in clf_unique_ppl if type(person) == str]\n",
    "\n",
    "clf_unique_mas = set(list(clf_df_mas.text))\n",
    "clf_unique_fem = set(list(clf_df_fem.text))\n",
    "clf_unique_unk = set(list(clf_df_unk.text))\n",
    "print(\"Unique people names:\", len(clf_unique_people))\n",
    "print(\"Unique masculine-labeled names:\", len(clf_unique_mas))\n",
    "print(\"Unique feminine-labeled names:\", len(clf_unique_fem))\n",
    "print(\"Unique unknown-labeled names:\", len(clf_unique_unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the expected (manually-annotated) Person Name labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique people names: 6460\n",
      "Unique masculine-labeled names: 1847\n",
      "Unique feminine-labeled names: 537\n",
      "Unique unknown-labeled names: 4808\n"
     ]
    }
   ],
   "source": [
    "df_ppl = df_pnoc.loc[~df_pnoc.expected_label.isna()]\n",
    "df_ppl = df_ppl.loc[df_ppl.expected_label != \"O\"]\n",
    "df_fem = df_ppl.loc[df_ppl.expected_label == \"Feminine\"]\n",
    "df_mas = df_ppl.loc[df_ppl.expected_label == \"Masculine\"]\n",
    "df_unk = df_ppl.loc[df_ppl.expected_label == \"Unknown\"]\n",
    "\n",
    "unique_ppl = set(list(df_ppl.text))\n",
    "unique_mas = set(list(df_mas.text))\n",
    "unique_fem = set(list(df_fem.text))\n",
    "unique_unk = set(list(df_unk.text))\n",
    "print(\"Unique people names:\", len(unique_ppl))\n",
    "print(\"Unique masculine-labeled names:\", len(unique_mas))\n",
    "print(\"Unique feminine-labeled names:\", len(unique_fem))\n",
    "print(\"Unique unknown-labeled names:\", len(unique_unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comp\"></a>\n",
    "## IV. Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the number of unique person names spaCy found to those the annotators and classifier found with exact and fuzzy string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique people names in spaCy:   7815\n",
      "Unique people names annotated: 6460\n",
      "Unique people names classified: 4305\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique people names in spaCy:  \", len(spacy_unique_persons))\n",
    "print(\"Unique people names annotated:\", len(unique_ppl))\n",
    "print(\"Unique people names classified:\", len(clf_unique_people))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More names of people were labeled during annotation than with spaCy, but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually-annotated names in spaCy names: 2621\n",
      "Classifier-annotated names in spaCy 1732\n",
      "Classifier-annotated names in manual-annotated names 4305\n"
     ]
    }
   ],
   "source": [
    "exact_match_ann = [person_name for person_name in unique_ppl if person_name in spacy_unique_persons]\n",
    "exact_match_clf = [person_name for person_name in clf_unique_people if person_name in spacy_unique_persons]\n",
    "exact_match_ann_clf = [person_name for person_name in clf_unique_people if person_name in unique_ppl]\n",
    "print(\"Manually-annotated names in spaCy names:\", len(exact_match_ann))\n",
    "print(\"Classifier-annotated names in spaCy\", len(exact_match_clf))\n",
    "print(\"Classifier-annotated names in manual-annotated names\", len(exact_match_ann_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feminine-labeled names found by spaCy: 227\n",
      "Masculine-labeled names found by spaCy: 676\n",
      "Unknown-labeled names found by spaCy: 2195\n"
     ]
    }
   ],
   "source": [
    "fem_match = [n for n in unique_fem if n in spacy_unique_persons]\n",
    "mas_match = [n for n in unique_mas if n in spacy_unique_persons]\n",
    "unk_match = [n for n in unique_unk if n in spacy_unique_persons]\n",
    "print(\"Feminine-labeled names found by spaCy:\", len(fem_match))\n",
    "print(\"Masculine-labeled names found by spaCy:\", len(mas_match))\n",
    "print(\"Unknown-labeled names found by spaCy:\", len(unk_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feminine-labeled names found by own classifier: 308\n",
      "Masculine-labeled names found by own classifier: 893\n",
      "Unknown-labeled names found by own classifier: 2695\n"
     ]
    }
   ],
   "source": [
    "fem_match = [n for n in unique_fem if n in clf_unique_fem]  #clf_unique_people] #433 (count where grammatical gender matched)\n",
    "mas_match = [n for n in unique_mas if n in clf_unique_mas]  #clf_unique_people] 1421 (count where grammatical gender matched)\n",
    "unk_match = [n for n in unique_unk if n in clf_unique_unk]  #clf_unique_people] 3118 (count where grammatical gender matched)\n",
    "print(\"Feminine-labeled names found by own classifier:\", len(fem_match))\n",
    "print(\"Masculine-labeled names found by own classifier:\", len(mas_match))\n",
    "print(\"Unknown-labeled names found by own classifier:\", len(unk_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy String Matching\n",
    "Evaluate overlaps more loosely using fuzzy string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7815 6459 4305\n"
     ]
    }
   ],
   "source": [
    "# Remove any non-string values\n",
    "spacy_unique_persons = [n for n in spacy_unique_persons if type(n) == str]\n",
    "unique_ppl = [n for n in unique_ppl if type(n) == str]\n",
    "clf_unique_people = [n for n in clf_unique_people if type(n) == str]\n",
    "print(len(spacy_unique_persons), len(unique_ppl), len(clf_unique_people))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare each manually annotated person name to all spaCy-labeled person names\n",
    "def getAnnotFuzzyMatches(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in unique_ppl:\n",
    "        fuzzy_matches = process.extractBests(n, spacy_unique_persons, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches\n",
    "\n",
    "# Compare each manually annotated person name to all classifier-labeled person names\n",
    "def getAnnotFuzzyMatcheswithClf(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in unique_ppl:\n",
    "        fuzzy_matches = process.extractBests(n, clf_unique_people, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches\n",
    "\n",
    "# Compare each classified person name to all spaCy-labeled person names\n",
    "def getClfFuzzyMatches(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in clf_unique_people:\n",
    "        fuzzy_matches = process.extractBests(n, spacy_unique_persons, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches\n",
    "\n",
    "# Compare each spaCy-labeled person name to all manually annotated person names\n",
    "def getSpacyFuzzyMatches(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in spacy_unique_persons:\n",
    "        fuzzy_matches = process.extractBests(n, unique_ppl, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches\n",
    "\n",
    "# Compare each spaCy-labeled person name to all classified person names\n",
    "def getSpacyFuzzyMatchesWithClf(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in spacy_unique_persons:\n",
    "        fuzzy_matches = process.extractBests(n, clf_unique_people, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of annotated person names without spaCy fuzzy matching ratios of at least 90: 3024\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 90\n",
    "no_fuzzy_match, all_fuzzy_matches = getAnnotFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of annotated person names without spaCy fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the minimum, maximum, and average fuzzy matching ratios of manually annotated person names to spaCy person names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "scores = []\n",
    "for n in unique_ppl:\n",
    "    fuzzy_matches = process.extractOne(n, spacy_unique_persons, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)\n",
    "at_least_mean_score = [score for score in scores if score >= mean_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 87.26428239665583\n",
      "Matches with minimum score of 41: 2\n",
      "Matches with maximum score of 100: 3048\n",
      "Matches with mean score (87.26428239665583) or higher: 3671\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with mean score (\"+str(mean_score)+\") or higher:\", len(at_least_mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the minimum, maximum, and average fuzzy string matching ratios of classified person names to manually annotated person names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "# no_fuzzy_match, all_fuzzy_matches = getSpacyFuzzyMatchesWithClf(score_method, mean_score)\n",
    "# print(\"Fuzzy mathes with score at least\"+str(mean_score)+\":\",all_fuzzy_matches)\n",
    "# print(\"Fuzzy mathes with score less than\"+str(mean_score)+\":\",no_fuzzy_matches)\n",
    "scores = []\n",
    "for n in unique_ppl:\n",
    "    fuzzy_matches = process.extractOne(n, clf_unique_people, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)\n",
    "at_least_mean_score = [score for score in scores if score >= mean_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 90.00959900913455\n",
      "Matches with minimum score of 36: 1\n",
      "Matches with maximum score of 100: 4329\n",
      "Matches with mean score (90.00959900913455) or higher: 4416\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with mean score (\"+str(mean_score)+\") or higher:\", len(at_least_mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the reverse... \n",
    "\n",
    "#### How many of the spaCy person names appear in the manually annotated and classified person names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621\n",
      "1732\n"
     ]
    }
   ],
   "source": [
    "ann_exact_match = [person_name for person_name in spacy_unique_persons if person_name in unique_ppl]\n",
    "clf_exact_match = [person_name for person_name in spacy_unique_persons if person_name in clf_unique_people]\n",
    "print(len(ann_exact_match))\n",
    "print(len(clf_exact_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# score_method = fuzz.ratio\n",
    "# min_score = 90\n",
    "# no_fuzzy_match, all_fuzzy_matches = getSpacyFuzzyMatches(score_method, min_score)\n",
    "# print(\"Count of spaCy names without annotated person name fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# score_method = fuzz.ratio\n",
    "# min_score = 75\n",
    "# no_fuzzy_match, all_fuzzy_matches = getSpacyFuzzyMatches(score_method, min_score)\n",
    "# print(\"Count of spaCy names without annotated person name fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the minimum, maximum, and average fuzzy matching ratios of spaCy person names to manually annotated person names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "scores = []\n",
    "for n in spacy_unique_persons:\n",
    "    fuzzy_matches = process.extractOne(n, unique_ppl, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)\n",
    "at_least_mean_score = [score for score in scores if score >= mean_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 81.23659628918746\n",
      "Matches with minimum score of 14: 1\n",
      "Matches with maximum score of 100: 2818\n",
      "Matches with mean score (81.23659628918746) or higher: 3749\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with mean score (\"+str(mean_score)+\") or higher:\", len(at_least_mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now claculate the minimum, maximum, and average fuzzy string matching ratios of spaCy person names to classified person names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "scores = []\n",
    "for n in spacy_unique_persons:\n",
    "    fuzzy_matches = process.extractOne(n, clf_unique_people, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)\n",
    "at_least_mean_score = [score for score in scores if score >= mean_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 75.82072936660269\n",
      "Matches with minimum score of 14: 1\n",
      "Matches with maximum score of 100: 1889\n",
      "Matches with mean score (75.82072936660269) or higher: 3296\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with mean score (\"+str(mean_score)+\") or higher:\", len(at_least_mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate fuzzy matches with a score cutoff of 80 between:\n",
    "* spaCy and manual annotations\n",
    "* classifier and manual annotations\n",
    "* spaCy and classifier annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 6449\n"
     ]
    }
   ],
   "source": [
    "# Compare each manually annotated person name to all spaCy-labeled person names\n",
    "# manual_to_spacy_no_match, manual_to_spacy_all_match = getAnnotFuzzyMatches(score_method, min_score)\n",
    "print(manual_to_spacy_no_match, len(set(manual_to_spacy_all_match)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770 7823\n"
     ]
    }
   ],
   "source": [
    "# Compare each manually annotated person name to classifier-labeled person names\n",
    "# manaul_to_clf_no_match, manual_to_clf_all_match = getAnnotFuzzyMatcheswithClf(score_method, min_score)\n",
    "print(manaul_to_clf_no_match, len(set(manual_to_clf_all_match)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4895 4916\n"
     ]
    }
   ],
   "source": [
    "# Compare each spaCy annotated person name to classifier-labeled person names\n",
    "# spacy_to_clf_no_match, spacy_to_clf_all_match = getSpacyFuzzyMatchesWithClf(score_method, min_score)\n",
    "print(spacy_to_clf_no_match, len(set(spacy_to_clf_all_match)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert numpty ints to python ints for JSON file writing\n",
    "# unique_scores = [int(s) for s in unique_scores]\n",
    "# score_counts = [int(c) for c in score_counts]\n",
    "\n",
    "# d_array = []\n",
    "# i, maxI = 0, len(unique_scores)\n",
    "# while i < maxI:\n",
    "#     d = dict()\n",
    "#     d[\"unique_score\"] = unique_scores[i]\n",
    "#     d[\"count\"] = score_counts[i]\n",
    "#     d_array = d_array + [d]\n",
    "#     i += 1\n",
    "\n",
    "# print(d_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_counts_json = json.dumps(d_array)\n",
    "# f = open(\"analysis_data/spacy_to_annot_ppl_fuzzy_ratios.json\", \"w\")\n",
    "# f.write(score_counts_json)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

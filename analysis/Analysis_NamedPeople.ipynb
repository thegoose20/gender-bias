{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Named People\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "A comparison of automated Named Entity Recognition and manual annotation\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "  [I. Loading](#load)\n",
    "\n",
    "  [II. Named Entity Recognition with SpaCy](#ner)\n",
    "  \n",
    "  [III. Manual Annotation of People's Names](#annot)\n",
    "  \n",
    "  [IV. Comparison](#comp)\n",
    "  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "### I. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use custom functions\n",
    "import utils\n",
    "\n",
    "# To work with CSV data\n",
    "import pandas as pd\n",
    "\n",
    "# To work with TXT data\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# For named entity recognition (NER)\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "try:\n",
    "    import en_core_web_sm\n",
    "except ImportError:\n",
    "    print(\"Downlading en_core_web_sm model\")\n",
    "    import sys\n",
    "    !{sys.executable} -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# For fuzzy string matching\n",
    "# https://github.com/seatgeek/thefuzz\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "# For statistical calculations\n",
    "import numpy as np\n",
    "\n",
    "# To export JSON data\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Plaintext files of archival catalog metadata descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/doc_clf_data/model_input/all_model_input/\"\n",
    "descs = PlaintextCorpusReader(datadir, \".+_docs\\.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Jaffrey', 'McNair', 'was', 'born', 'on', '1', 'March', '1927', '.', 'He', 'was', 'educated', 'at', 'George', 'Watson', \"'\", 's', 'College', 'in']\n"
     ]
    }
   ],
   "source": [
    "tokens = descs.words()\n",
    "print(tokens[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Thomas', 'Jaffrey', 'McNair', 'was', 'born', 'on', '1', 'March', '1927', '.'], ['He', 'was', 'educated', 'at', 'George', 'Watson', \"'\", 's', 'College', 'in', 'Edinburgh', ',', 'and', 'he', 'studied', 'at', 'Edinburgh', 'University', ',', 'graduating', 'MB', ',', 'CHB', 'in', '1949', ',', 'and', 'being', 'awarded', 'later', 'on', 'with', 'the', 'degree', 'of', 'MD', '(', '1960', ')', 'for', 'his', 'thesis', 'Observations', 'on', 'visceral', 'pain', 'with', 'special', 'reference', 'to', 'pain', 'originating', 'in', 'the', 'testis', '.'], ['In', '1951', 'he', 'married', 'Dr', '.', 'Sybil', 'Monteith', 'Dick', 'Wood', ',', 'and', 'between', '1950', 'and', '1952', 'he', 'served', 'as', 'a', 'Flight', '-', 'Lieutenant', 'in', 'the', 'RAF', '.'], ['Also', 'in', '1950', 'he', 'was', 'a', 'Medical', 'Officer', 'at', 'Marlu', 'in', 'Ghana', '(', 'then', 'called', 'the', 'Gold', 'Coast', ').'], ['McNair', 'became', 'House', 'Surgeon', ',', 'then', 'Registrar', ',', 'and', 'Clinical', 'Tutor', 'at', 'Edinburgh', 'Royal', 'Infirmary', '(', 'ERI', '),', '1949', 'to', '1960', '.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = descs.sents()\n",
    "print(sentences[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ner\"></a>\n",
    "## II. Name Entity Recognition with spaCy\n",
    "Run named entity recognition (NER) to estimate the names in the dataset and get a sense for the value in manually labeling names during the annotation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = descs.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for fileid in fileids:\n",
    "    file = descs.raw(fileid)\n",
    "    sentences += nltk.sent_tokenize(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = []\n",
    "for s in sentences:\n",
    "    s_ne = nlp(s)\n",
    "    for entity in s_ne.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            person_list += [entity.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9366\n"
     ]
    }
   ],
   "source": [
    "unique_persons = list(set(person_list))\n",
    "print(len(unique_persons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Szilard', 'Gardiner', 'Brigitta Lasky', 'Robert Lanza', 'von Thomsen', 'Brown', 'Hawthorn', 'S.K.', 'Pringle', \"Daniel Stewart's\", 'Ka', 'Bertaux', 'Lady', 'Laidlaw', 'Leitung von', 'Economic Adviser', 'Stefan KopeÄ‡', 'James Lumsden', 'Howard Orsmond', 'James Drever', 'CV', 'Coggan', 'Eric Ashby', 'Sofie Szecsi', \"Crum Brown's\", 'Giovanni Battista', 'Charles de\\n|', 'Kaikorai Woollen Factory', 'Alex J D Porteous', 'Arthur Koestler] / L.C.', 'B. Pallante', 'Clerks', 'Weidenfeld', 'Ken Pierce Butler', 'Cutting Hemp', 'Lurline Bay', 'John Bailliecorrepondence', 'Raphael Falk', 'William Calder', 'Barrett Hamilton', 'Ian Gilmour', 'Kincaid Mackenzie', \"Scottish Gaelic'Proofs\", 'Dr W. Siller', 'Maureen', 'Ascher', 'Barkin', 'Arthur C. ClarkeAlvarez', 'Lady Luck', 'HB van Dyke']\n"
     ]
    }
   ],
   "source": [
    "print(unique_persons[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect...some non-person entities labeled such as `JerusalemPalestineSelzer` and `Arithmetique`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30548\n"
     ]
    }
   ],
   "source": [
    "print(len(person_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Manual Annotation of People's Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-1157_00100.ann</td>\n",
       "      <td>knighted</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-1310_02300.ann</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>4542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-1281_00100.ann</td>\n",
       "      <td>Prince Regent</td>\n",
       "      <td>(2426, 2439)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>3660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Coll-1310_02700.ann</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>(9993, 10003)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>4678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Coll-1310_02900.ann</td>\n",
       "      <td>Sir</td>\n",
       "      <td>(7192, 7195)</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>4732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agg_ann_id                 file           text    ann_offsets  \\\n",
       "0           0  Coll-1157_00100.ann       knighted   (1407, 1415)   \n",
       "1           1  Coll-1310_02300.ann     knighthood   (9625, 9635)   \n",
       "2           2  Coll-1281_00100.ann  Prince Regent   (2426, 2439)   \n",
       "3           3  Coll-1310_02700.ann     knighthood  (9993, 10003)   \n",
       "4           4  Coll-1310_02900.ann            Sir   (7192, 7195)   \n",
       "\n",
       "           label    category associated_genders  description_id  \n",
       "0  Gendered-Role  Linguistic            Unclear            2364  \n",
       "1  Gendered-Role  Linguistic            Unclear            4542  \n",
       "2  Gendered-Role  Linguistic            Unclear            3660  \n",
       "3  Gendered-Role  Linguistic            Unclear            4678  \n",
       "4  Gendered-Role  Linguistic            Unclear            4732  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/aggregated_data/aggregated_final.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Coll-1036_00500.ann</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>(36375, 36393)</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Coll-1010_00100.ann</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>(40, 60)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14570, 14592)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy Fraser</td>\n",
       "      <td>(14698, 14720)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14924, 14946)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ann_id                 file                    text     ann_offsets  \\\n",
       "7        7  Coll-1036_00500.ann      Mrs Norman Macleod  (36375, 36393)   \n",
       "14      14  Coll-1010_00100.ann    Dr. Nelly Renee Deme        (40, 60)   \n",
       "15      15  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14570, 14592)   \n",
       "16      16  Coll-1036_00300.ann  Marjory Kennedy Fraser  (14698, 14720)   \n",
       "17      17  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14924, 14946)   \n",
       "\n",
       "       label     category associated_genders  description_id  \n",
       "7   Feminine  Person-Name            Unclear            1082  \n",
       "14   Unknown  Person-Name            Unclear             855  \n",
       "15   Unknown  Person-Name            Unclear            1038  \n",
       "16   Unknown  Person-Name            Unclear            1038  \n",
       "17   Unknown  Person-Name            Unclear            1038  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ppl = df.loc[df.category == \"Person-Name\"]\n",
    "df_ppl = df_ppl.drop_duplicates()\n",
    "df_ppl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people: 31157\n",
      "Total Masculine: 6087\n",
      "Total Feminine: 1836\n",
      "Total Unknown: 23234\n"
     ]
    }
   ],
   "source": [
    "total_ppl = df_ppl.shape[0]\n",
    "df_mas = df_ppl.loc[df_ppl.label == \"Masculine\"]\n",
    "df_fem = df_ppl.loc[df_ppl.label == \"Feminine\"]\n",
    "df_unk = df_ppl.loc[df_ppl.label == \"Unknown\"]\n",
    "total_mas = df_mas.shape[0]\n",
    "total_fem = df_fem.shape[0]\n",
    "total_unk = df_unk.shape[0]\n",
    "print(\"Total people:\", total_ppl)\n",
    "print(\"Total Masculine:\", total_mas)\n",
    "print(\"Total Feminine:\", total_fem)\n",
    "print(\"Total Unknown:\", total_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique people names: 10288\n",
      "Unique masculine-labeled names: 2121\n",
      "Unique feminine-labeled names: 655\n",
      "Unique unknown-labeled names: 8316\n"
     ]
    }
   ],
   "source": [
    "unique_ppl = set(list(df_ppl.text))\n",
    "unique_mas = set(list(df_mas.text))\n",
    "unique_fem = set(list(df_fem.text))\n",
    "unique_unk = set(list(df_unk.text))\n",
    "print(\"Unique people names:\", len(unique_ppl))\n",
    "print(\"Unique masculine-labeled names:\", len(unique_mas))\n",
    "print(\"Unique feminine-labeled names:\", len(unique_fem))\n",
    "print(\"Unique unknown-labeled names:\", len(unique_unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Automated Annotation of People's Names\n",
    "Compare the Person Name annotations of the highest performing Person Name and Occupation classifier (with Linguistic labels as features) to the manual and spaCy annotation of Person Names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, join the original text data, from the aggregated dataset, to the classifier's prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Coll-1036_00500.ann</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>(36375, 36393)</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Coll-1010_00100.ann</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>(40, 60)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14570, 14592)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy Fraser</td>\n",
       "      <td>(14698, 14720)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>(14924, 14946)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agg_ann_id                 file                    text     ann_offsets  \\\n",
       "7            7  Coll-1036_00500.ann      Mrs Norman Macleod  (36375, 36393)   \n",
       "14          14  Coll-1010_00100.ann    Dr. Nelly Renee Deme        (40, 60)   \n",
       "15          15  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14570, 14592)   \n",
       "16          16  Coll-1036_00300.ann  Marjory Kennedy Fraser  (14698, 14720)   \n",
       "17          17  Coll-1036_00300.ann  Marjory Kennedy-Fraser  (14924, 14946)   \n",
       "\n",
       "       label     category associated_genders  description_id  \n",
       "7   Feminine  Person-Name            Unclear            1082  \n",
       "14   Unknown  Person-Name            Unclear             855  \n",
       "15   Unknown  Person-Name            Unclear            1038  \n",
       "16   Unknown  Person-Name            Unclear            1038  \n",
       "17   Unknown  Person-Name            Unclear            1038  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"../data/aggregated_data/aggregated_final.csv\"\n",
    "df = pd.read_csv(f, index_col=0)\n",
    "df = df.loc[df.category == \"Person-Name\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69508</th>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>right_only</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66942</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>right_only</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>both</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67675</th>\n",
       "      <td>1038</td>\n",
       "      <td>1485</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>right_only</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       description_id  sentence_id  ann_id pred_ling_label expected_label  \\\n",
       "69508            1082         2590     7.0   Gendered-Role            NaN   \n",
       "7063             1082         2590     7.0   Gendered-Role       Feminine   \n",
       "66942             855         1097    14.0               O            NaN   \n",
       "2814              855         1097    14.0               O        Unknown   \n",
       "67675            1038         1485    15.0   Gendered-Role            NaN   \n",
       "\n",
       "      predicted_label      _merge       agreement  \n",
       "69508         Unknown  right_only  false positive  \n",
       "7063              NaN   left_only  false negative  \n",
       "66942        Feminine  right_only  false positive  \n",
       "2814          Unknown        both   true positive  \n",
       "67675        Feminine  right_only  false positive  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnoc_pred1 = \"../data/token_clf_data/experiment1/5fold/output/crf-arow_pers_o_baseline_fastText100_annot_evaluation.csv\"\n",
    "df_pnoc1 = pd.read_csv(pnoc_pred1, index_col=0, low_memory=False)\n",
    "df_pnoc1 = df_pnoc1.drop_duplicates()\n",
    "df_pnoc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103049, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pnoc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>text</th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>right_only</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>14</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>right_only</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>14</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>both</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>15</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>right_only</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ann_id                    text  description_id  sentence_id  \\\n",
       "7.0        7      Mrs Norman Macleod          1082.0       2590.0   \n",
       "7.0        7      Mrs Norman Macleod          1082.0       2590.0   \n",
       "14.0      14    Dr. Nelly Renee Deme           855.0       1097.0   \n",
       "14.0      14    Dr. Nelly Renee Deme           855.0       1097.0   \n",
       "15.0      15  Marjory Kennedy-Fraser          1038.0       1485.0   \n",
       "\n",
       "     pred_ling_label expected_label predicted_label      _merge  \\\n",
       "7.0    Gendered-Role            NaN         Unknown  right_only   \n",
       "7.0    Gendered-Role       Feminine             NaN   left_only   \n",
       "14.0               O            NaN        Feminine  right_only   \n",
       "14.0               O        Unknown         Unknown        both   \n",
       "15.0   Gendered-Role            NaN        Feminine  right_only   \n",
       "\n",
       "           agreement  \n",
       "7.0   false positive  \n",
       "7.0   false negative  \n",
       "14.0  false positive  \n",
       "14.0   true positive  \n",
       "15.0  false positive  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"agg_ann_id\":\"ann_id\"})\n",
    "subdf = df[[\"ann_id\", \"text\"]]\n",
    "df_pnoc1 = subdf.join(df_pnoc1.set_index(\"ann_id\"), how=\"outer\", on=\"ann_id\")\n",
    "df_pnoc1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the total predicted person names, as well as total predicted feminine, masculine, and unknown names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people: 15836\n",
      "Total Masculine: 5175\n",
      "Total Feminine: 1725\n",
      "Total Unknown: 7098\n"
     ]
    }
   ],
   "source": [
    "clf_df_ppl = df_pnoc1.loc[~df_pnoc1.predicted_label.isna()]\n",
    "clf_df_fem = clf_df_ppl.loc[clf_df_ppl.predicted_label == \"Feminine\"]\n",
    "clf_df_mas = clf_df_ppl.loc[clf_df_ppl.predicted_label == \"Masculine\"]\n",
    "clf_df_unk = clf_df_ppl.loc[clf_df_ppl.predicted_label == \"Unknown\"]\n",
    "\n",
    "clf_total_ppl = clf_df_ppl.shape[0]\n",
    "clf_total_fem = clf_df_fem.shape[0]\n",
    "clf_total_mas = clf_df_mas.shape[0]\n",
    "clf_total_unk = clf_df_unk.shape[0]\n",
    "\n",
    "print(\"Total people:\", clf_total_ppl)\n",
    "print(\"Total Masculine:\", clf_total_mas)\n",
    "print(\"Total Feminine:\", clf_total_fem)\n",
    "print(\"Total Unknown:\", clf_total_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique people names: 4188\n",
      "Unique masculine-labeled names: 1657\n",
      "Unique feminine-labeled names: 537\n",
      "Unique unknown-labeled names: 3013\n"
     ]
    }
   ],
   "source": [
    "clf_unique_ppl = set(list(clf_df_ppl.text))\n",
    "clf_unique_mas = set(list(clf_df_mas.text))\n",
    "clf_unique_fem = set(list(clf_df_fem.text))\n",
    "clf_unique_unk = set(list(clf_df_unk.text))\n",
    "print(\"Unique people names:\", len(clf_unique_ppl))\n",
    "print(\"Unique masculine-labeled names:\", len(clf_unique_mas))\n",
    "print(\"Unique feminine-labeled names:\", len(clf_unique_fem))\n",
    "print(\"Unique unknown-labeled names:\", len(clf_unique_unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comp\"></a>\n",
    "## IV. Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the number of total and unique names found in with the classifier to the manual annotation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct names: 11024\n",
      "Total names classified: 15836\n"
     ]
    }
   ],
   "source": [
    "clf_df_pnoc1_tp = clf_df_ppl.loc[clf_df_ppl.agreement == \"true positive\"]\n",
    "clf_df_pnoc1_fp = clf_df_ppl.loc[clf_df_ppl.agreement == \"false positive\"]\n",
    "print(\"Total correct names:\",clf_df_pnoc1_tp.shape[0])\n",
    "print(\"Total names classified:\",clf_df_pnoc1_tp.shape[0]+clf_df_pnoc1_fp.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the number of unique and total people spaCy found to those the annotators and classifier found with exact and fuzzy string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people names in spaCy:  30548\n",
      "Total people names annotated: 31157\n",
      "Total people names classified: 15836\n",
      "\n",
      "Unique people names in spaCy:   9366\n",
      "Unique people names annotated: 10288\n",
      "Unique people names classified: 4188\n"
     ]
    }
   ],
   "source": [
    "print(\"Total people names in spaCy: \", len(person_list))\n",
    "print(\"Total people names annotated:\", total_ppl)\n",
    "print(\"Total people names classified:\", clf_total_ppl)\n",
    "print(\"\\nUnique people names in spaCy:  \", len(unique_persons))\n",
    "print(\"Unique people names annotated:\", len(unique_ppl))\n",
    "print(\"Unique people names classified:\", len(clf_unique_ppl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More names of people were labeled during annotation than with spaCy, but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation names in spaCy names: 3174\n",
      "Classifier names in spaCy 1811\n"
     ]
    }
   ],
   "source": [
    "exact_match_ann = [person_name for person_name in unique_ppl if person_name in unique_persons]\n",
    "exact_match_clf = [person_name for person_name in clf_unique_ppl if person_name in unique_persons]\n",
    "print(\"Annotation names in spaCy names:\", len(exact_match_ann))\n",
    "print(\"Classifier names in spaCy\", len(exact_match_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feminine-labeled names found by spaCy: 250\n",
      "Masculine-labeled names found by spaCy: 747\n",
      "Unknown-labeled names found by spaCy: 2702\n"
     ]
    }
   ],
   "source": [
    "fem_match = [n for n in unique_fem if n in unique_persons]\n",
    "mas_match = [n for n in unique_mas if n in unique_persons]\n",
    "unk_match = [n for n in unique_unk if n in unique_persons]\n",
    "print(\"Feminine-labeled names found by spaCy:\", len(fem_match))\n",
    "print(\"Masculine-labeled names found by spaCy:\", len(mas_match))\n",
    "print(\"Unknown-labeled names found by spaCy:\", len(unk_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feminine-labeled names found by own classifier: 431\n",
      "Masculine-labeled names found by own classifier: 1363\n",
      "Unknown-labeled names found by own classifier: 3064\n"
     ]
    }
   ],
   "source": [
    "fem_match = [n for n in unique_fem if n in clf_unique_ppl] #clf_unique_fem] 305 (count where grammatical gender matched)\n",
    "mas_match = [n for n in unique_mas if n in clf_unique_ppl] #clf_unique_mas] 958 (count where grammatical gender matched)\n",
    "unk_match = [n for n in unique_unk if n in clf_unique_ppl] #clf_unique_unk] 2492 (count where grammatical gender matched)\n",
    "print(\"Feminine-labeled names found by own classifier:\", len(fem_match))\n",
    "print(\"Masculine-labeled names found by own classifier:\", len(mas_match))\n",
    "print(\"Unknown-labeled names found by own classifier:\", len(unk_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy String Matching\n",
    "Evaluate overlaps more loosely using fuzzy string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare each manually annotated person name to all spaCy-labeled person names\n",
    "def getAnnotFuzzyMatches(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in unique_ppl:\n",
    "        fuzzy_matches = process.extractBests(n, unique_persons, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches\n",
    "\n",
    "# Compare each classified person name to all spaCy-labeled person names\n",
    "def getClfFuzzyMatches(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in clf_unique_ppl:\n",
    "        fuzzy_matches = process.extractBests(n, unique_persons, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches\n",
    "\n",
    "# Compare each spaCy-labeled person name to all manually annotated person names\n",
    "def getSpacyFuzzyMatches(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in unique_persons:\n",
    "        fuzzy_matches = process.extractBests(n, unique_ppl, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches\n",
    "\n",
    "# Compare each spaCy-labeled person name to all classified person names\n",
    "def getSpacyFuzzyMatchesWithClf(score_method, min_score):\n",
    "    all_fuzzy_matches = []\n",
    "    no_fuzzy_match = 0\n",
    "    for n in unique_persons:\n",
    "        fuzzy_matches = process.extractBests(n, clf_unique_ppl, scorer=score_method, score_cutoff=min_score)\n",
    "        if len(fuzzy_matches) == 0:\n",
    "            no_fuzzy_match += 1\n",
    "        else:\n",
    "            all_fuzzy_matches = all_fuzzy_matches + fuzzy_matches\n",
    "    return no_fuzzy_match, all_fuzzy_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of annotated person names without spaCy fuzzy matching ratios of at least 90: 6209\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 90\n",
    "no_fuzzy_match, all_fuzzy_matches = getAnnotFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of annotated person names without spaCy fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of annotated person names without SpaCy fuzzy matching ratios of at least 75: 4107\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 75\n",
    "no_fuzzy_match, all_fuzzy_matches = getAnnotFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of annotated person names without SpaCy fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_method = fuzz.ratio\n",
    "# min_score = 75\n",
    "# clf_no_fuzzy_match, clf_all_fuzzy_matches = getClfFuzzyMatches(score_method, min_score)\n",
    "# print(\"Count of classified person names without SpaCy fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=clf_no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the minimum, maximum, and average fuzzy matching ratios of manually annotated person names to spaCy person names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "scores = []\n",
    "for n in unique_ppl:\n",
    "    fuzzy_matches = process.extractOne(n, unique_persons, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 82.16115863141525\n",
      "Matches with minimum score of 38: 1\n",
      "Matches with maximum score of 100: 3599\n",
      "Matches with median score of 81.0: 68\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with median score of \"+str(median_score)+\":\", score_counts[median_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the reverse... \n",
    "\n",
    "#### How many of the spaCy person names appear in the manually annotated and classified person names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3174\n",
      "1811\n"
     ]
    }
   ],
   "source": [
    "ann_exact_match = [person_name for person_name in unique_persons if person_name in unique_ppl]\n",
    "clf_exact_match = [person_name for person_name in unique_persons if person_name in clf_unique_ppl]\n",
    "print(len(ann_exact_match))  # same - looks good\n",
    "print(len(clf_exact_match))  # same - looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of spaCy names without annotated person name fuzzy matching ratios of at least 90: 5677\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 90\n",
    "no_fuzzy_match, all_fuzzy_matches = getSpacyFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of spaCy names without annotated person name fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of spaCy names without annotated person name fuzzy matching ratios of at least 75: 3701\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 75\n",
    "no_fuzzy_match, all_fuzzy_matches = getSpacyFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of spaCy names without annotated person name fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_method = fuzz.ratio\n",
    "# min_score = 75\n",
    "# clf_no_fuzzy_match, clf_all_fuzzy_matches = getSpacyFuzzyMatchesWithClf(score_method, min_score)\n",
    "# print(\"Count of spaCy names without classified person name fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=clf_no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the minimum, maximum, and average fuzzy matching ratios of spaCy person names to manually annotated person names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "scores = []\n",
    "for n in unique_persons:\n",
    "    fuzzy_matches = process.extractOne(n, unique_ppl, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 81.56993380311766\n",
      "Matches with minimum score of 14: 1\n",
      "Matches with maximum score of 100: 3336\n",
      "Matches with median score of 80.0: 315\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with median score of \"+str(median_score)+\":\", score_counts[median_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert numpty ints to python ints for JSON file writing\n",
    "# unique_scores = [int(s) for s in unique_scores]\n",
    "# score_counts = [int(c) for c in score_counts]\n",
    "\n",
    "# d_array = []\n",
    "# i, maxI = 0, len(unique_scores)\n",
    "# while i < maxI:\n",
    "#     d = dict()\n",
    "#     d[\"unique_score\"] = unique_scores[i]\n",
    "#     d[\"count\"] = score_counts[i]\n",
    "#     d_array = d_array + [d]\n",
    "#     i += 1\n",
    "\n",
    "# print(d_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_counts_json = json.dumps(d_array)\n",
    "# f = open(\"analysis_data/spacy_to_annot_ppl_fuzzy_ratios.json\", \"w\")\n",
    "# f.write(score_counts_json)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

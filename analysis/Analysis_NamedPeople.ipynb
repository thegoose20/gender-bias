{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Named People\n",
    "## Post Annotation and Aggregation\n",
    "\n",
    "A comparison of automated Named Entity Recognition and manual annotation\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "  [I. Loading](#load)\n",
    "\n",
    "  [II. Named Entity Recognition with SpaCy](#ner)\n",
    "  \n",
    "  [III. Manual Annotation of People's Names](#annot)\n",
    "  \n",
    "  [IV. Comparison](#comp)\n",
    "  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "### I. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use custom functions\n",
    "import utils\n",
    "\n",
    "# To work with CSV data\n",
    "import pandas as pd\n",
    "\n",
    "# To work with TXT data\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# For named entity recognition (NER)\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "try:\n",
    "    import en_core_web_sm\n",
    "except ImportError:\n",
    "    print(\"Downlading en_core_web_sm model\")\n",
    "    import sys\n",
    "    !{sys.executable} -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# For fuzzy string matching\n",
    "# https://github.com/seatgeek/thefuzz\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "# For statistical calculations\n",
    "import numpy as np\n",
    "\n",
    "# To export JSON data\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Plaintext files of archival catalog metadata descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data/\"\n",
    "descs = PlaintextCorpusReader(datadir+\"descriptions\", \".+\\.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Professor', 'James', 'Aitken', 'White', 'was', 'a', 'leading', 'Scottish', 'Theologian', 'and', 'Moderator', 'of', 'the', 'General', 'Assembly', 'of', 'the', 'Church', 'of', 'Scotland']\n"
     ]
    }
   ],
   "source": [
    "tokens = descs.words()\n",
    "print(tokens[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Professor', 'James', 'Aitken', 'White', 'was', 'a', 'leading', 'Scottish', 'Theologian', 'and', 'Moderator', 'of', 'the', 'General', 'Assembly', 'of', 'the', 'Church', 'of', 'Scotland', '.'], ['He', 'was', 'educated', 'at', 'Daniel', 'Stewart', \"'\", 's', 'College', 'and', 'the', 'University', 'of', 'Edinburgh', 'where', 'he', 'studied', 'philosophy', 'and', 'divinity', '.'], ['After', 'his', 'ordination', 'he', 'spent', 'three', 'years', 'as', 'an', 'army', 'Chaplain', 'and', 'then', 'in', '1948', 'was', 'inducted', 'to', 'Dunollie', 'Road', 'Church', 'in', 'Oban', '.'], ['James', 'Whyte', 'moved', 'to', 'Mayfield', 'North', 'Church', 'in', 'Edinburgh', 'in', '1954', 'and', 'in', '1958', 'was', 'appointed', 'to', 'the', 'chair', 'of', 'practical', 'theology', 'and', 'Christian', 'ethics', 'at', 'the', 'University', 'of', 'St', 'Andrew', \"'\", 's', 'where', 'he', 'remained', 'until', '1987', '.'], ['His', 'primary', 'interests', 'were', 'in', 'liturgy', 'and', 'ecclesiastical', 'architecture', 'and', 'he', 'also', 'lectured', 'on', 'pastoral', 'care', '.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = descs.sents()\n",
    "print(sentences[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ner\"></a>\n",
    "## II. Name Entity Recognition with spaCy\n",
    "Run named entity recognition (NER) to estimate the names in the dataset and get a sense for the value in manually labeling names during the annotation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = descs.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for fileid in fileids:\n",
    "    file = descs.raw(fileid)\n",
    "    sentences += nltk.sent_tokenize(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = []\n",
    "for s in sentences:\n",
    "    s_ne = nlp(s)\n",
    "    for entity in s_ne.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            person_list += [entity.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7867\n"
     ]
    }
   ],
   "source": [
    "unique_persons = list(set(person_list))\n",
    "print(len(unique_persons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['William Ord', 'Willie Johnston', 'W. J. Sedgefield', 'Herbert Mather Spoor', 'Leonora Vigoleno', 'Robert J. Sternberg', 'Johann Wolfgang von', 'Bencher', 'John Jones', 'xiv+448', 'Gomirato', 'Sheila', 'Copia Inventarii', 'Michael Wynne', 'John D. Sutherland', \"Godfrey H Thomson's\", 'Sphagnum', 'Walter Scottmanuscript', 'S. Blott', 'Robert Baillie', 'Dick Crossman', 'Smertenko', 'Syme', 'Fenwick', 'David Sainsbury', 'Ambler', 'Don', 'James D. Macgregor', 'Joseph W. Hills', 'OcynSontag', 'Peter Sharp', 'Anita', 'Andrew Broomhall', 'Basil Spence', 'Harold Braley]', 'Rev John Baillie', 'Ian Gilmour', 'Lily Jackson', 'George Stephen', 'K. M.', 'John Rhodes', 'Lucy', 'Stan Trevor', 'E. R. WardKammerer', 'Bernadotte', 'James Maidment', 'Micheal', 'Carl', 'M. Ritchie', 'James S. K. Elmslie']\n"
     ]
    }
   ],
   "source": [
    "print(unique_persons[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect...some non-person entities labeled such as `JerusalemPalestineSelzer` and `Arithmetique`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24438\n"
     ]
    }
   ],
   "source": [
    "print(len(person_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Manual Annotation of People's Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coll-1434_11900.ann</td>\n",
       "      <td>(1954, 1957)</td>\n",
       "      <td>his</td>\n",
       "      <td>Generalization</td>\n",
       "      <td>Linguistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coll-1397_00100.ann</td>\n",
       "      <td>(2633, 2638)</td>\n",
       "      <td>Lords</td>\n",
       "      <td>Generalization</td>\n",
       "      <td>Linguistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coll-1310_00800.ann</td>\n",
       "      <td>(3703, 3706)</td>\n",
       "      <td>Man</td>\n",
       "      <td>Generalization</td>\n",
       "      <td>Linguistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coll-1434_14500.ann</td>\n",
       "      <td>(5782, 5788)</td>\n",
       "      <td>cowboy</td>\n",
       "      <td>Generalization</td>\n",
       "      <td>Linguistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAI_02300.ann</td>\n",
       "      <td>(1586, 1596)</td>\n",
       "      <td>shipmaster</td>\n",
       "      <td>Generalization</td>\n",
       "      <td>Linguistic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file       offsets        text           label    category\n",
       "0  Coll-1434_11900.ann  (1954, 1957)         his  Generalization  Linguistic\n",
       "1  Coll-1397_00100.ann  (2633, 2638)       Lords  Generalization  Linguistic\n",
       "2  Coll-1310_00800.ann  (3703, 3706)         Man  Generalization  Linguistic\n",
       "3  Coll-1434_14500.ann  (5782, 5788)      cowboy  Generalization  Linguistic\n",
       "4        BAI_02300.ann  (1586, 1596)  shipmaster  Generalization  Linguistic"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(datadir+\"aggregated_final.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Coll-1036_00500.ann</td>\n",
       "      <td>(36375, 36393)</td>\n",
       "      <td>Mrs Norman Macleod</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Person-Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Coll-1010_00100.ann</td>\n",
       "      <td>(40, 60)</td>\n",
       "      <td>Dr. Nelly Renee Deme</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>(14570, 14592)</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>(14698, 14720)</td>\n",
       "      <td>Marjory Kennedy Fraser</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Coll-1036_00300.ann</td>\n",
       "      <td>(14924, 14946)</td>\n",
       "      <td>Marjory Kennedy-Fraser</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file         offsets                    text     label  \\\n",
       "31  Coll-1036_00500.ann  (36375, 36393)      Mrs Norman Macleod  Feminine   \n",
       "53  Coll-1010_00100.ann        (40, 60)    Dr. Nelly Renee Deme   Unknown   \n",
       "54  Coll-1036_00300.ann  (14570, 14592)  Marjory Kennedy-Fraser   Unknown   \n",
       "55  Coll-1036_00300.ann  (14698, 14720)  Marjory Kennedy Fraser   Unknown   \n",
       "56  Coll-1036_00300.ann  (14924, 14946)  Marjory Kennedy-Fraser   Unknown   \n",
       "\n",
       "       category  \n",
       "31  Person-Name  \n",
       "53  Person-Name  \n",
       "54  Person-Name  \n",
       "55  Person-Name  \n",
       "56  Person-Name  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ppl = df.loc[df.category == \"Person-Name\"]\n",
    "df_ppl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people: 31502\n",
      "Total Masculine: 6087\n",
      "Total Feminine: 1836\n",
      "Total Unknown: 23234\n"
     ]
    }
   ],
   "source": [
    "total_ppl = df_ppl.shape[0]\n",
    "df_mas = df_ppl.loc[df_ppl.label == \"Masculine\"]\n",
    "df_fem = df_ppl.loc[df_ppl.label == \"Feminine\"]\n",
    "df_unk = df_ppl.loc[df_ppl.label == \"Unknown\"]\n",
    "total_mas = df_mas.shape[0]\n",
    "total_fem = df_fem.shape[0]\n",
    "total_unk = df_unk.shape[0]\n",
    "print(\"Total people:\", total_ppl)\n",
    "print(\"Total Masculine:\", total_mas)\n",
    "print(\"Total Feminine:\", total_fem)\n",
    "print(\"Total Unknown:\", total_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique people names: 10294\n",
      "Unique masculine-labeled names: 2121\n",
      "Unique feminine-labeled names: 655\n",
      "Unique unknown-labeled names: 8316\n"
     ]
    }
   ],
   "source": [
    "unique_ppl = set(list(df_ppl.text))\n",
    "unique_mas = set(list(df_mas.text))\n",
    "unique_fem = set(list(df_fem.text))\n",
    "unique_unk = set(list(df_unk.text))\n",
    "print(\"Unique people names:\", len(unique_ppl))\n",
    "print(\"Unique masculine-labeled names:\", len(unique_mas))\n",
    "print(\"Unique feminine-labeled names:\", len(unique_fem))\n",
    "print(\"Unique unknown-labeled names:\", len(unique_unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comp\"></a>\n",
    "## IV. Comparison\n",
    "\n",
    "Compare the number of unique and total people spaCy found to those the annotators found with exact and fuzzy string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people names in spaCy:  24438\n",
      "Total people names annotated: 31502\n",
      "\n",
      "Unique people names in spaCy:   7867\n",
      "Unique people names annotated: 10294\n"
     ]
    }
   ],
   "source": [
    "print(\"Total people names in spaCy: \", len(person_list))\n",
    "print(\"Total people names annotated:\", total_ppl)\n",
    "print(\"\\nUnique people names in spaCy:  \", len(unique_persons))\n",
    "print(\"Unique people names annotated:\", len(unique_ppl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More names of people were labeled during annotation than with spaCy, but...\n",
    "\n",
    "#### How many of the manually-annotated names are included in the spaCy labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210\n"
     ]
    }
   ],
   "source": [
    "exact_match = [person_name for person_name in unique_ppl if person_name in unique_persons]\n",
    "print(len(exact_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feminine-labeled names found by spaCy: 253\n",
      "Masculine-labeled names found by spaCy: 747\n",
      "Unknown-labeled names found by spaCy: 2733\n"
     ]
    }
   ],
   "source": [
    "fem_match = [n for n in unique_fem if n in unique_persons]\n",
    "mas_match = [n for n in unique_mas if n in unique_persons]\n",
    "unk_match = [n for n in unique_unk if n in unique_persons]\n",
    "print(\"Feminine-labeled names found by spaCy:\", len(fem_match))\n",
    "print(\"Masculine-labeled names found by spaCy:\", len(mas_match))\n",
    "print(\"Unknown-labeled names found by spaCy:\", len(unk_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of annotated person names without spaCy fuzzy matching ratios of at least 38: 4175\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 90\n",
    "no_fuzzy_match, all_fuzzy_matches = utils.getAnnotFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of annotated person names without spaCy fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of annotated person names without SpaCy fuzzy matching ratios of at least 38: 4175\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 75\n",
    "no_fuzzy_match, all_fuzzy_matches = utils.getAnnotFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of annotated person names without SpaCy fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the minimum, maximum, and average fuzzy matching ratios of manually annotated person names to spaCy person names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "scores = []\n",
    "for n in unique_ppl:\n",
    "    fuzzy_matches = process.extractOne(n, unique_persons, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 82.00699436564989\n",
      "Matches with minimum score of 38: 1\n",
      "Matches with maximum score of 100: 3619\n",
      "Matches with median score of 80.0: 249\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with median score of \"+str(median_score)+\":\", score_counts[median_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the reverse... \n",
    "\n",
    "#### How many of the spaCy person names appear in the manually annotated person names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210\n"
     ]
    }
   ],
   "source": [
    "exact_match = [person_name for person_name in unique_persons if person_name in unique_ppl]\n",
    "print(len(exact_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of spaCy names without annotated person name fuzzy matching ratios of at least 90: 4252\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 90\n",
    "no_fuzzy_match, all_fuzzy_matches = utils.getSpacyFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of spaCy names without annotated person name fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of spaCy names without annotated person name fuzzy matching ratios of at least 75: 2570\n"
     ]
    }
   ],
   "source": [
    "score_method = fuzz.ratio\n",
    "min_score = 75\n",
    "no_fuzzy_match, all_fuzzy_matches = utils.getSpacyFuzzyMatches(score_method, min_score)\n",
    "print(\"Count of spaCy names without annotated person name fuzzy matching ratios of at least {s}: {m}\".format(s=min_score,m=no_fuzzy_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the minimum, maximum, and average fuzzy matching ratios of spaCy person names to manually annotated person names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = fuzz.ratio\n",
    "scores = []\n",
    "for n in unique_persons:\n",
    "    fuzzy_matches = process.extractOne(n, unique_ppl, scorer=score_method)  # use default score_cutoff, which is 0\n",
    "    scores += [fuzzy_matches[1]]  # first position in tuple is match string, second position in tuple is score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = np.min(scores)\n",
    "max_score = np.max(scores)\n",
    "mean_score = np.mean(scores)\n",
    "median_score = np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 84.14859539850006\n",
      "Matches with minimum score of 14: 1\n",
      "Matches with maximum score of 100: 3286\n",
      "Matches with median score of 86.0: 129\n"
     ]
    }
   ],
   "source": [
    "# Get the counts (occurrences) of each score\n",
    "unique_scores, score_counts = np.unique(scores, return_counts=True)\n",
    "score_counts = dict(zip(unique_scores, score_counts))\n",
    "print(\"Mean score: \"+str(mean_score))\n",
    "print(\"Matches with minimum score of \"+str(min_score)+\":\", score_counts[min_score])\n",
    "print(\"Matches with maximum score of \"+str(max_score)+\":\", score_counts[max_score])\n",
    "print(\"Matches with median score of \"+str(median_score)+\":\", score_counts[median_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'unique_score': 14, 'count': 14}, {'unique_score': 24, 'count': 24}, {'unique_score': 25, 'count': 25}, {'unique_score': 33, 'count': 33}, {'unique_score': 36, 'count': 36}, {'unique_score': 38, 'count': 38}, {'unique_score': 40, 'count': 40}, {'unique_score': 42, 'count': 42}, {'unique_score': 43, 'count': 43}, {'unique_score': 44, 'count': 44}, {'unique_score': 46, 'count': 46}, {'unique_score': 47, 'count': 47}, {'unique_score': 48, 'count': 48}, {'unique_score': 49, 'count': 49}, {'unique_score': 50, 'count': 50}, {'unique_score': 51, 'count': 51}, {'unique_score': 52, 'count': 52}, {'unique_score': 53, 'count': 53}, {'unique_score': 54, 'count': 54}, {'unique_score': 55, 'count': 55}, {'unique_score': 56, 'count': 56}, {'unique_score': 57, 'count': 57}, {'unique_score': 58, 'count': 58}, {'unique_score': 59, 'count': 59}, {'unique_score': 60, 'count': 60}, {'unique_score': 61, 'count': 61}, {'unique_score': 62, 'count': 62}, {'unique_score': 63, 'count': 63}, {'unique_score': 64, 'count': 64}, {'unique_score': 65, 'count': 65}, {'unique_score': 67, 'count': 67}, {'unique_score': 68, 'count': 68}, {'unique_score': 69, 'count': 69}, {'unique_score': 70, 'count': 70}, {'unique_score': 71, 'count': 71}, {'unique_score': 72, 'count': 72}, {'unique_score': 73, 'count': 73}, {'unique_score': 74, 'count': 74}, {'unique_score': 75, 'count': 75}, {'unique_score': 76, 'count': 76}, {'unique_score': 77, 'count': 77}, {'unique_score': 78, 'count': 78}, {'unique_score': 79, 'count': 79}, {'unique_score': 80, 'count': 80}, {'unique_score': 81, 'count': 81}, {'unique_score': 82, 'count': 82}, {'unique_score': 83, 'count': 83}, {'unique_score': 84, 'count': 84}, {'unique_score': 85, 'count': 85}, {'unique_score': 86, 'count': 86}, {'unique_score': 87, 'count': 87}, {'unique_score': 88, 'count': 88}, {'unique_score': 89, 'count': 89}, {'unique_score': 90, 'count': 90}, {'unique_score': 91, 'count': 91}, {'unique_score': 92, 'count': 92}, {'unique_score': 93, 'count': 93}, {'unique_score': 94, 'count': 94}, {'unique_score': 95, 'count': 95}, {'unique_score': 96, 'count': 96}, {'unique_score': 97, 'count': 97}, {'unique_score': 98, 'count': 98}, {'unique_score': 100, 'count': 100}]\n"
     ]
    }
   ],
   "source": [
    "# Convert numpty ints to python ints for JSON file writing\n",
    "unique_scores = [int(s) for s in unique_scores]\n",
    "score_counts = [int(c) for c in score_counts]\n",
    "\n",
    "d_array = []\n",
    "i, maxI = 0, len(unique_scores)\n",
    "while i < maxI:\n",
    "    d = dict()\n",
    "    d[\"unique_score\"] = unique_scores[i]\n",
    "    d[\"count\"] = score_counts[i]\n",
    "    d_array = d_array + [d]\n",
    "    i += 1\n",
    "\n",
    "print(d_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_counts_json = json.dumps(d_array)\n",
    "f = open(\"analysis_data/spacy_to_annot_ppl_fuzzy_ratios.json\", \"w\")\n",
    "f.write(score_counts_json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

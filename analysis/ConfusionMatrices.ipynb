{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices\n",
    "\n",
    "***\n",
    "**Table of Contents**\n",
    "\n",
    "[I.](#prep) Prepare the Data\n",
    "\n",
    "[II.](#agg) Inter-Annotator Agreement (IAA) Matrices with Aggregated Data\n",
    "  * [Functions](#functions)\n",
    "  * [Data Creation](#data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from intervaltree import Interval, IntervalTree\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "## I. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"../annot-post/data/\"\n",
    "# Annotation data - 1 CSV per annotator, includes annotator's notes for each label, where provided\n",
    "ann0 = \"ann0_labels_notes.csv\"\n",
    "ann1 = \"ann1_labels_notes.csv\"\n",
    "ann2 = \"ann2_labels_notes.csv\"\n",
    "ann3 = \"ann3_labels_notes.csv\"\n",
    "ann4 = \"ann4_labels_notes.csv\"\n",
    "ann_files = [ann0, ann1, ann2, ann3, ann4]\n",
    "agg = \"aggregated_with_eadid_descid_cols.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(dirpath+ann_files[0])\n",
    "df1 = pd.read_csv(dirpath+ann_files[1])\n",
    "df2 = pd.read_csv(dirpath+ann_files[2])\n",
    "df3 = pd.read_csv(dirpath+ann_files[3])\n",
    "df4 = pd.read_csv(dirpath+ann_files[4])\n",
    "dfagg = pd.read_csv(dirpath+agg, index_col=0)\n",
    "# dfagg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>file</th>\n",
       "      <th>entity</th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [annotator, file, entity, label, start, end, text, category, note]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.loc[df0.label == \"Non-binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitOffsets(df):\n",
    "    offsets = list(df.offsets)\n",
    "    start, end = [], []\n",
    "    for o in offsets:\n",
    "        pair = o[1:-1]\n",
    "        pair_list = pair.split(\",\")\n",
    "        start += [pair_list[0]]\n",
    "        end += [pair_list[1]]\n",
    "    df[\"start\"] = start\n",
    "    df[\"end\"] = end\n",
    "    df = df.astype({\"start\":int, \"end\":int})\n",
    "    return df\n",
    "dffagg = splitOffsets(dfagg)\n",
    "# dfagg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with \"None provided\"\n",
    "df0.note.fillna(\"None provided\", inplace = True)\n",
    "df1.note.fillna(\"None provided\", inplace = True)\n",
    "df2.note.fillna(\"None provided\", inplace = True)\n",
    "df3.note.fillna(\"None provided\", inplace = True)\n",
    "df4.note.fillna(\"None provided\", inplace = True)\n",
    "# df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split annotator 0's data into the two categories corresponding to the annotator pairs\n",
    "# (ann1 and ann2 = Person-Name, Linguistic; ann3 and ann4 = Contextual)\n",
    "df0PL = df0.loc[df0.category != \"Contextual\"]\n",
    "df0C = df0.loc[df0.category == \"Contextual\"]\n",
    "# df0C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the files both input annotators labeled\n",
    "def findCommonFiles(df_a, df_b):\n",
    "    common = []\n",
    "    files_a = set(list(df_a.file))\n",
    "    files_b = set(list(df_b.file))\n",
    "    for f in files_a:\n",
    "        if f in files_b:\n",
    "            common += [f]\n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files Annotators 0 & 3 labeled: 485\n",
      "Sample: ['Coll-1291_00100.ann', 'Coll-1052_00100.ann', 'Coll-1061_00300.ann', 'Coll-1091_00100.ann', 'Coll-1434_05900.ann']\n"
     ]
    }
   ],
   "source": [
    "# AGGREGATED ONLY\n",
    "commonagg = list(set(list(dfagg.file)))\n",
    "# ALL LABELS\n",
    "common0agg = findCommonFiles(df0, dfagg)\n",
    "# PERSON NAME & LINGUISTIC\n",
    "# Among annotators\n",
    "common0PL1 = findCommonFiles(df0PL, df1)\n",
    "common0PL2 = findCommonFiles(df0PL, df2)\n",
    "common12 = findCommonFiles(df1, df2)\n",
    "# With aggregated dataset\n",
    "common0PLagg = findCommonFiles(df0, dfagg)\n",
    "common1agg = findCommonFiles(df1, dfagg)\n",
    "common2agg = findCommonFiles(df2, dfagg)\n",
    "# CONTEXTUAL\n",
    "# Among annotators\n",
    "common0C3 = findCommonFiles(df0C, df3)\n",
    "print(\"Total Files Annotators 0 & 3 labeled:\",len(common0C3))\n",
    "print(\"Sample:\",common0C3[:5])\n",
    "common0C4 = findCommonFiles(df0C, df4)\n",
    "common34 = findCommonFiles(df3, df4)\n",
    "# With aggregated dataset\n",
    "common0Cagg = findCommonFiles(df0C, dfagg)\n",
    "common3agg = findCommonFiles(df4, dfagg)\n",
    "common4agg = findCommonFiles(df3, dfagg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"agg\"></a>\n",
    "## II. Inter-Annotator Agreement (IAA) Matrices with Aggregated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann0withagg = df0.loc[df0.file.isin(common0agg)]\n",
    "aggwithann0 = dfagg.loc[dfagg.file.isin(common0agg)]\n",
    "# PERSON-NAME & LINGUISTIC\n",
    "# ann0PLwithagg = df0PL.loc[df0PL.file.isin(common0PLagg)]\n",
    "ann1withagg = df1.loc[df1.file.isin(common1agg)]\n",
    "aggwithann1 = dfagg.loc[dfagg.file.isin(common1agg)]\n",
    "ann2withagg = df2.loc[df2.file.isin(common2agg)]\n",
    "aggwithann2 = dfagg.loc[dfagg.file.isin(common2agg)]\n",
    "# CONTEXTUAL\n",
    "# ann0Cwithagg = df0C.loc[df0C.file.isin(common0Cagg)]\n",
    "ann3withagg = df3.loc[df3.file.isin(common3agg)]\n",
    "aggwithann3 = dfagg.loc[dfagg.file.isin(common3agg)]\n",
    "ann4withagg = df4.loc[df4.file.isin(common4agg)]\n",
    "aggwithann4 = dfagg.loc[dfagg.file.isin(common4agg)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"functions\"></a>\n",
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interval tree for one annotator for a specified file and specified label\n",
    "def createIntervalTree(df, filename, labelname):\n",
    "    subdf = df[df.file == filename]                         # Get only rows for the input file\n",
    "    subdf = subdf[subdf.label == labelname]                 # Get only rows for that file with the input label\n",
    "    subdf = subdf.astype({\"start\":int, \"end\":int})          # Make sure the offsets are integers\n",
    "    offsets = list(zip(list(subdf.start), list(subdf.end)))\n",
    "    return IntervalTree.from_tuples(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interval tree for one annotator for a specified file and any label\n",
    "def createIntervalTreeAllLabels(df, filename):\n",
    "    subdf = df[df.file == filename]            # Get only rows for the input file\n",
    "    subdf = subdf.astype({\"start\":int, \"end\":int})  # Make sure the offsets are integers\n",
    "    offsets = list(zip(list(subdf.start), list(subdf.end)))\n",
    "    return IntervalTree.from_tuples(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many text spans for a particular label in the expected dataset have no matching or\n",
    "#  overlapping text spans in an predicted dataset, no matter what label the annotator used\n",
    "def falsePerFile(tree_exp, tree_pred):\n",
    "    return len(tree_exp.difference(tree_pred))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the false negatives (misses) if labelname is expected label\n",
    "#   OR \n",
    "# Count false positives (shouldn't have been labeled) if labelname is predicted label\n",
    "def falseAcrossFiles(df_exp, df_pred, commonfiles, labelname):\n",
    "    false = 0\n",
    "    for f in commonfiles:\n",
    "        t_exp = createIntervalTree(df_exp, f, labelname)\n",
    "        t_pred = createIntervalTreeAllLabels(df_pred, f)\n",
    "        f = falsePerFile(t_exp, t_pred)\n",
    "        false += f\n",
    "    return false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all matches including exactly matching, overlapping, and enveloping annotations\n",
    "def iaaPerFile(tree_exp, tree_pred):\n",
    "    tp = 0                              # count of true positives (overlaps & matches)\n",
    "    for annotation in tree_exp: \n",
    "        tp += len(tree_pred.overlap(annotation))\n",
    "    return tp #, fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of all true positive, false negative, and false_positive counts for all common files between \n",
    "# expected and predicted annotators for the input label\n",
    "def iaaAcrossFiles(df_exp, df_pred, commonfiles, exp_labelname, pred_labelname):\n",
    "    true_positives = [] #, false_negatives, false_positives = [], [], []\n",
    "    for f in commonfiles:\n",
    "        t_exp = createIntervalTree(df_exp, f, exp_labelname)\n",
    "        t_pred = createIntervalTree(df_pred, f, pred_labelname)\n",
    "        tp = iaaPerFile(t_exp, t_pred)   #, fn, fp\n",
    "        true_positives += [tp]\n",
    "         #false_negatives += [fn]\n",
    "         #false_positives += [fp]\n",
    "    return true_positives  #, false_negatives, false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initMatrix(labels):\n",
    "    expected = labels\n",
    "    predicted = labels\n",
    "    matrix = []\n",
    "    for e_label in expected:\n",
    "        for p_label in predicted:\n",
    "            matrix += [{\"expected\": e_label, \"predicted\": p_label, \"count\": 0}]\n",
    "    return matrix    #[:-1]  # Exclude dictionary with None as both expected and predicted  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: list of dictionaries of expected and predicted label pairs with counts of zero,\n",
    "#        DataFrame of expected labels, DataFrame of predicted labels, list of files common\n",
    "#        to both DataFrames\n",
    "# OUTPUT: list of dictionaries with the counts for each label pair filled in\n",
    "def fillMatrix(matrix_dict, exp, pred, common):\n",
    "    i = 0\n",
    "    maxI = len(matrix_dict)\n",
    "    while i < maxI:\n",
    "        pair = matrix_dict[i]\n",
    "        exp_labelname = pair[\"expected\"]\n",
    "        pred_labelname = pair[\"predicted\"]\n",
    "        if pred_labelname == \"None\":\n",
    "            fn = falseAcrossFiles(exp, pred, common, exp_labelname)  # False Negatives\n",
    "            matrix_dict[i][\"count\"] += fn\n",
    "        elif exp_labelname == \"None\":\n",
    "            fp = falseAcrossFiles(pred, exp, common, pred_labelname) # False Positives\n",
    "            matrix_dict[i][\"count\"] += fn\n",
    "        else:\n",
    "            tp_list = iaaAcrossFiles(exp, pred, common, exp_labelname, pred_labelname)\n",
    "            tp_sum = sum(tp_list)\n",
    "            matrix_dict[i][\"count\"] += tp_sum\n",
    "        i += 1\n",
    "    return matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Occupation\", \"Omission\", \"Stereotype\", \"Empowering\", \n",
    "          \"Unknown\", \"Masculine\", \"Feminine\", \"Nonbinary\", \n",
    "          \"Gendered-Role\", \"Gendered-Pronoun\", \"Generalization\",\n",
    "          \"None\"]\n",
    "matrix_dict = initMatrix(labels)\n",
    "label_no = [n for n in range(len(labels))]\n",
    "label_no_dict = dict(zip(labels,label_no))  # label_no_dict = dict(zip(label_no,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrixOfCounts(labels, matrix_dict):\n",
    "    # Create matrix of counts\n",
    "    matrix = []\n",
    "    # exp = matrix_dict[0][\"expected\"]\n",
    "    maxI = len(labels)  # 11\n",
    "    matrix_row = []\n",
    "    for pair in matrix_dict:\n",
    "        matrix_row += [pair[\"count\"]]\n",
    "        if len(matrix_row) == maxI:\n",
    "            matrix += [matrix_row]\n",
    "            matrix_row = []\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeJSON(matrix_data, filepath):\n",
    "    json_data = json.dumps(matrix_data)\n",
    "    json_file = open(filepath, \"w\")\n",
    "    json_file.write(json_data)\n",
    "    json_file.close()\n",
    "    print(\"Finished writing \"+filepath+\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the JSON data for visualiation (https://observablehq.com/d/3eab142ea747ae66)\n",
    "def reformatForViz(matrix_dict):\n",
    "    new_data = []\n",
    "    for pair in matrix_dict:\n",
    "        gt = label_no_dict[pair[\"expected\"]]\n",
    "        pt = label_no_dict[pair[\"predicted\"]]\n",
    "        occurrence = pair[\"count\"]\n",
    "        if occurrence > 0:\n",
    "            new_data += [{\"gt\": gt, \"pt\": pt}]*occurrence\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "### Data Creation\n",
    "\n",
    "* **Expected:** Aggregated\n",
    "\n",
    "* **Predicted:** Annotators 0, 1, 2, 3, & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing ../annot/data/data_iaa/0_with_agg.json!\n",
      "Finished writing ../annot/data/data_iaa/0_with_agg_numeric.json!\n"
     ]
    }
   ],
   "source": [
    "# PRED: ANNOTATOR 0\n",
    "exp = aggwithann0    # subset DataFrame with labels only for files in common with predicted DataFrame\n",
    "pred = ann0withagg   # subset DataFrame with labels only for files in common with expected DataFrame\n",
    "common = common0agg  # list of files both expected and predicted DataFrames have labels (rows) for\n",
    "matrix = initMatrix(labels)\n",
    "matrix_dict = fillMatrix(matrix, exp, pred, common)\n",
    "writeJSON(matrix_dict, \"../annot/data/data_iaa/0_with_agg.json\")\n",
    "matrix_counts = getMatrixOfCounts(labels, matrix_dict)\n",
    "matrix_numeric = reformatForViz(matrix_dict)\n",
    "writeJSON(matrix_numeric, \"../annot/data/data_iaa/0_with_agg_numeric.json\")\n",
    "# print(matrix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED: ANNOTATOR 1\n",
    "exp = aggwithann1    # subset DataFrame with labels only for files in common with predicted DataFrame\n",
    "pred = ann1withagg   # subset DataFrame with labels only for files in common with expected DataFrame\n",
    "common = common1agg  # list of files both expected and predicted DataFrames have labels (rows) for\n",
    "matrix = initMatrix(labels)\n",
    "matrix_dict = fillMatrix(matrix, exp, pred, common)\n",
    "writeJSON(matrix_dict, \"data/data_iaa/1_with_agg.json\")\n",
    "# matrix_counts = getMatrixOfCounts(labels, matrix_dict)\n",
    "matrix_numeric = reformatForViz(matrix_dict)\n",
    "writeJSON(matrix_numeric, \"data/data_iaa/1_with_agg_numeric.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED: ANNOTATOR 2\n",
    "exp = aggwithann2    # subset DataFrame with labels only for files in common with predicted DataFrame\n",
    "pred = ann2withagg   # subset DataFrame with labels only for files in common with expected DataFrame\n",
    "common = common2agg  # list of files both expected and predicted DataFrames have labels (rows) for\n",
    "matrix = initMatrix(labels)\n",
    "matrix_dict = fillMatrix(matrix, exp, pred, common)\n",
    "writeJSON(matrix_dict, \"data/data_iaa/2_with_agg.json\")\n",
    "# matrix_counts = getMatrixOfCounts(labels, matrix_dict)\n",
    "matrix_numeric = reformatForViz(matrix_dict)\n",
    "writeJSON(matrix_numeric, \"data/data_iaa/2_with_agg_numeric.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED: ANNOTATOR 3\n",
    "exp = aggwithann3    # subset DataFrame with labels only for files in common with predicted DataFrame\n",
    "pred = ann3withagg   # subset DataFrame with labels only for files in common with expected DataFrame\n",
    "common = common3agg  # list of files both expected and predicted DataFrames have labels (rows) for\n",
    "matrix = initMatrix(labels)\n",
    "matrix_dict = fillMatrix(matrix, exp, pred, common)\n",
    "writeJSON(matrix_dict, \"data/data_iaa/3_with_agg.json\")\n",
    "# matrix_counts = getMatrixOfCounts(labels, matrix_dict)\n",
    "matrix_numeric = reformatForViz(matrix_dict)\n",
    "writeJSON(matrix_numeric, \"data/data_iaa/3_with_agg_numeric.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED: ANNOTATOR 4\n",
    "exp = aggwithann4    # subset DataFrame with labels only for files in common with predicted DataFrame\n",
    "pred = ann4withagg   # subset DataFrame with labels only for files in common with expected DataFrame\n",
    "common = common4agg  # list of files both expected and predicted DataFrames have labels (rows) for\n",
    "matrix = initMatrix(labels)\n",
    "matrix_dict = fillMatrix(matrix, exp, pred, common)\n",
    "writeJSON(matrix_dict, \"data/data_iaa/4_with_agg.json\")\n",
    "# matrix_counts = getMatrixOfCounts(labels, matrix_dict)\n",
    "matrix_numeric = reformatForViz(matrix_dict)\n",
    "writeJSON(matrix_numeric, \"data/data_iaa/4_with_agg_numeric.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Expected:** Aggregated\n",
    "\n",
    "* **Predicted:** Aggregated\n",
    "\n",
    "(To study how often text spans (matching or overlapping ) have multiple labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED: AGGREGATED\n",
    "exp = dfagg\n",
    "pred = dfagg \n",
    "common = commonagg  # list of unique files\n",
    "matrix = initMatrix(labels)\n",
    "matrix_dict = fillMatrix(matrix, exp, pred, common)\n",
    "writeJSON(matrix_dict, \"data/data_iaa/agg_with_agg.json\")\n",
    "# matrix_counts = getMatrixOfCounts(labels, matrix_dict)\n",
    "matrix_numeric = reformatForViz(matrix_dict)\n",
    "writeJSON(matrix_numeric, \"data/data_iaa/agg_with_agg_numeric.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visit [Observable](https://observablehq.com/d/3eab142ea747ae66) for confusion matrices visualizing the data files created in this Notebook!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

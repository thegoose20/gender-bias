{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Biased Document Classification\n",
    "\n",
    "With aggregated and perspectivist (individual annotator's) data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 1,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 2,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dir = \"../data/crc_metadata/\"\n",
    "data_dir = \"../data/aggregated_data/\"\n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "clf_data_dir = \"../data/doc_clf_data/\"\n",
    "Path(clf_data_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"i\"></a>\n",
    "## Splitting Data into Train/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the data for classification, joining the description and annotation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_ann_id</th>\n",
       "      <th>ann_file</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>associated_genders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Coll-1157_00100.ann</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>knighted</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>Coll-1310_02300.ann</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>Coll-1281_00100.ann</td>\n",
       "      <td>(2426, 2439)</td>\n",
       "      <td>Prince Regent</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>Coll-1310_02700.ann</td>\n",
       "      <td>(9993, 10003)</td>\n",
       "      <td>knighthood</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>Coll-1310_02900.ann</td>\n",
       "      <td>(7192, 7195)</td>\n",
       "      <td>Sir</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agg_ann_id             ann_file    ann_offsets           text  \\\n",
       "12           0  Coll-1157_00100.ann   (1407, 1415)       knighted   \n",
       "22           1  Coll-1310_02300.ann   (9625, 9635)     knighthood   \n",
       "23           2  Coll-1281_00100.ann   (2426, 2439)  Prince Regent   \n",
       "24           3  Coll-1310_02700.ann  (9993, 10003)     knighthood   \n",
       "25           4  Coll-1310_02900.ann   (7192, 7195)            Sir   \n",
       "\n",
       "            label    category associated_genders  \n",
       "12  Gendered-Role  Linguistic            Unclear  \n",
       "22  Gendered-Role  Linguistic            Unclear  \n",
       "23  Gendered-Role  Linguistic            Unclear  \n",
       "24  Gendered-Role  Linguistic            Unclear  \n",
       "25  Gendered-Role  Linguistic            Unclear  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df = pd.read_csv(data_dir+\"aggregated_final.csv\", index_col=0)\n",
    "ann_df = ann_df.rename(columns={\"file\":\"ann_file\", \"offsets\":\"ann_offsets\"})\n",
    "ann_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>desc_file</th>\n",
       "      <th>desc_offsets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>(24, 76)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sermons and addresses, 1948-1996; lectures, 19...</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>(97, 633)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>AA5_00100.txt</td>\n",
       "      <td>(661, 1724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>(24, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sermons and addresses, 1947-1963; essays and l...</td>\n",
       "      <td>AA6_00100.txt</td>\n",
       "      <td>(81, 560)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      description  \\\n",
       "description_id                                                      \n",
       "0               Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "1               Sermons and addresses, 1948-1996; lectures, 19...   \n",
       "2               Professor James Aitken White was a leading Sco...   \n",
       "3                             Papers of Rev Tom Allan (1916-1965)   \n",
       "4               Sermons and addresses, 1947-1963; essays and l...   \n",
       "\n",
       "                    desc_file desc_offsets  \n",
       "description_id                              \n",
       "0               AA5_00100.txt     (24, 76)  \n",
       "1               AA5_00100.txt    (97, 633)  \n",
       "2               AA5_00100.txt  (661, 1724)  \n",
       "3               AA6_00100.txt     (24, 60)  \n",
       "4               AA6_00100.txt    (81, 560)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(desc_dir+\"annot_descs.csv\", index_col=0, usecols=[\"description_id\", \"description\", \"file\", \"start_offset\", \"end_offset\"])\n",
    "desc_df = desc_df.rename(columns={\"file\":\"desc_file\"})\n",
    "desc_offsets = list(zip(list(desc_df.start_offset), list(desc_df.end_offset)))\n",
    "desc_df = desc_df.drop(columns=[\"start_offset\", \"end_offset\"])\n",
    "desc_df.insert(len(desc_df.columns), \"desc_offsets\", desc_offsets)\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>field</th>\n",
       "      <th>file_ann</th>\n",
       "      <th>offsets_ann</th>\n",
       "      <th>text_ann</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>file_desc</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Title</td>\n",
       "      <td>BAI_01000.ann</td>\n",
       "      <td>(1290, 1302)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>211</td>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5875, 5894)</td>\n",
       "      <td>Henry Sloane Coffin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>524</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5925, 5936)</td>\n",
       "      <td>Hugh Martin</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>525</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5951, 5963)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>526</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAI</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>BAI_01300.ann</td>\n",
       "      <td>(5951, 5963)</td>\n",
       "      <td>John Baillie</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Person-Name</td>\n",
       "      <td>527</td>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid               field       file_ann   offsets_ann             text_ann  \\\n",
       "0   BAI               Title  BAI_01000.ann  (1290, 1302)         John Baillie   \n",
       "1   BAI  Scope and Contents  BAI_01300.ann  (5875, 5894)  Henry Sloane Coffin   \n",
       "2   BAI  Scope and Contents  BAI_01300.ann  (5925, 5936)          Hugh Martin   \n",
       "3   BAI  Scope and Contents  BAI_01300.ann  (5951, 5963)         John Baillie   \n",
       "4   BAI  Scope and Contents  BAI_01300.ann  (5951, 5963)         John Baillie   \n",
       "\n",
       "       label     category   id  \\\n",
       "0    Unknown  Person-Name  211   \n",
       "1    Unknown  Person-Name  524   \n",
       "2    Unknown  Person-Name  525   \n",
       "3  Masculine  Person-Name  526   \n",
       "4    Unknown  Person-Name  527   \n",
       "\n",
       "                                         description      file_desc  desc_id  \\\n",
       "0                           John Baillie: posthumous  BAI_01000.txt    70381   \n",
       "1  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "2  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "3  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "4  Letters received from Henry Sloane Coffin, wit...  BAI_01300.txt    47675   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01300.txt               5853             5983  \n",
       "3  BAI_01300.txt               5853             5983  \n",
       "4  BAI_01300.txt               5853             5983  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir+\"aggregated_with_eadid_descid_desc_cols.csv\", index_col=0)\n",
    "df.head()\n",
    "# all_anns = pd.read_csv(\"../annot-post/data/all_annotators.csv\", index_col=0)\n",
    "# df = all_anns.rename(columns={\"field2\":\"description\"})\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame above has a row for every label, so for descriptions with multiple labels, there are multiple rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every description, get the labels (non-repeating) they were annotated with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>file</th>\n",
       "      <th>desc_start_offset</th>\n",
       "      <th>desc_end_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Baillie: posthumous</td>\n",
       "      <td>Title</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>70381</td>\n",
       "      <td>BAI_01000.txt</td>\n",
       "      <td>1290</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Letters received from Henry Sloane Coffin, wit...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>47675</td>\n",
       "      <td>BAI_01300.txt</td>\n",
       "      <td>5853</td>\n",
       "      <td>5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family photographs consist of:photographs of f...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Masculine', 'Unknown', 'Feminine'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>81505</td>\n",
       "      <td>BAI_01600.txt</td>\n",
       "      <td>5967</td>\n",
       "      <td>6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correspondence and related items, including le...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>{'Unknown'}</td>\n",
       "      <td>BAI</td>\n",
       "      <td>33009</td>\n",
       "      <td>BAI_01900.txt</td>\n",
       "      <td>5297</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From 1927-1930 John Baillie was Professor of S...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>{'Gendered-Pronoun', 'Unknown', 'Masculine', '...</td>\n",
       "      <td>BAI</td>\n",
       "      <td>43372</td>\n",
       "      <td>BAI_02200.txt</td>\n",
       "      <td>15180</td>\n",
       "      <td>15419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                           John Baillie: posthumous   \n",
       "1  Letters received from Henry Sloane Coffin, wit...   \n",
       "2  Family photographs consist of:photographs of f...   \n",
       "3  Correspondence and related items, including le...   \n",
       "4  From 1927-1930 John Baillie was Professor of S...   \n",
       "\n",
       "                       field  \\\n",
       "0                      Title   \n",
       "1         Scope and Contents   \n",
       "2         Scope and Contents   \n",
       "3         Scope and Contents   \n",
       "4  Biographical / Historical   \n",
       "\n",
       "                                               label eadid  desc_id  \\\n",
       "0                                        {'Unknown'}   BAI    70381   \n",
       "1                           {'Masculine', 'Unknown'}   BAI    47675   \n",
       "2               {'Masculine', 'Unknown', 'Feminine'}   BAI    81505   \n",
       "3                                        {'Unknown'}   BAI    33009   \n",
       "4  {'Gendered-Pronoun', 'Unknown', 'Masculine', '...   BAI    43372   \n",
       "\n",
       "            file  desc_start_offset  desc_end_offset  \n",
       "0  BAI_01000.txt               1290             1315  \n",
       "1  BAI_01300.txt               5853             5983  \n",
       "2  BAI_01600.txt               5967             6202  \n",
       "3  BAI_01900.txt               5297             5506  \n",
       "4  BAI_02200.txt              15180            15419  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agg_cols = [\"description\", \"field\", \"desc_id\"]\n",
    "# anns_cols = [\"description\", \"field\", \"desc_id\", \"annotator\", \"eadid\"]\n",
    "\n",
    "# df_grouped = clf_data.groupby(anns_cols).agg(\n",
    "#     {\"label\": lambda label_name: set(label_name)}  #\",\".join(label_name)}\n",
    "#     ).reset_index()\n",
    "# df_grouped.sort_values(by=\"desc_id\", inplace=True)\n",
    "# df_grouped.head()\n",
    "\n",
    "df_grouped = pd.read_csv(data_dir+\"desc_field_descid_label_eadid.csv\", index_col=0)\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the sequences of labels in each row appear correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unknown' 'Masculine' 'Feminine' 'Occupation' 'Gendered-Pronoun'\n",
      " 'Gendered-Role' 'Stereotype' 'Generalization' 'Omission']\n"
     ]
    }
   ],
   "source": [
    "valid_label_names = df.label.unique()\n",
    "print(valid_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Unknown'], ['Masculine', 'Unknown']]\n"
     ]
    }
   ],
   "source": [
    "label_col = list(df_grouped.label)\n",
    "label_col = [(labels[2:-2]).split(\"', '\") for labels in label_col]\n",
    "print(label_col[:2]) # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid = []\n",
    "for label_list in label_col:\n",
    "    for label_name in label_list:\n",
    "        if not label_name in valid_label_names:\n",
    "            invalid += [label_name]\n",
    "assert len(invalid) == 0, \"Label names must be valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "For the aggregated data, add a column for the EADIDs (collection, or fonds, identifier) of the descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>desc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eadid  desc_id\n",
       "0   AA5        0\n",
       "1   AA5        1\n",
       "2   AA6        2\n",
       "3   AA6        3\n",
       "4   AA7        4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descs = pd.read_csv(\"../annot-post/data/all_descriptions.csv\", index_col=0)\n",
    "# eadids = descs.drop(columns=[\"description\",\"field\"])\n",
    "# eadids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>label</th>\n",
       "      <th>eadid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Professor James Aitken White was a leading Sco...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>0</td>\n",
       "      <td>{Occupation, Stereotype, Masculine, Gendered-P...</td>\n",
       "      <td>AA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>Papers of The Very Rev Prof James Whyte (1920-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1</td>\n",
       "      <td>{Stereotype, Masculine, Unknown}</td>\n",
       "      <td>AA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>Rev Thomas Allan was born on 16 August 1916 in...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>2</td>\n",
       "      <td>{Gendered-Pronoun, Stereotype, Unknown, Mascul...</td>\n",
       "      <td>AA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>Papers of Rev Tom Allan (1916-1965)\\n\\n</td>\n",
       "      <td>Title</td>\n",
       "      <td>3</td>\n",
       "      <td>{Masculine, Unknown}</td>\n",
       "      <td>AA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Alec Cheyne was born on 1 June 1924 in Errol i...</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>4</td>\n",
       "      <td>{Gendered-Pronoun, Stereotype, Unknown, Mascul...</td>\n",
       "      <td>AA7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "8054  Professor James Aitken White was a leading Sco...   \n",
       "5560  Papers of The Very Rev Prof James Whyte (1920-...   \n",
       "8321  Rev Thomas Allan was born on 16 August 1916 in...   \n",
       "5550            Papers of Rev Tom Allan (1916-1965)\\n\\n   \n",
       "633   Alec Cheyne was born on 1 June 1924 in Errol i...   \n",
       "\n",
       "                          field  desc_id  \\\n",
       "8054  Biographical / Historical        0   \n",
       "5560                      Title        1   \n",
       "8321  Biographical / Historical        2   \n",
       "5550                      Title        3   \n",
       "633   Biographical / Historical        4   \n",
       "\n",
       "                                                  label eadid  \n",
       "8054  {Occupation, Stereotype, Masculine, Gendered-P...   AA5  \n",
       "5560                   {Stereotype, Masculine, Unknown}   AA5  \n",
       "8321  {Gendered-Pronoun, Stereotype, Unknown, Mascul...   AA6  \n",
       "5550                               {Masculine, Unknown}   AA6  \n",
       "633   {Gendered-Pronoun, Stereotype, Unknown, Mascul...   AA7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key = \"desc_id\"\n",
    "# df_joined = df_grouped.join(eadids.set_index(key), on=key)\n",
    "# df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write (or read) the resulting DataFrame as a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_joined.to_csv(\"data/aggregated_data/desc_field_descid_label_eadid.csv\")\n",
    "# df_grouped.to_csv(\"data/aggregated_data/perspectivist/desc_field_descid_annot_eadid_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_joined = pd.read_csv(\"clf_data/desc_field_descid_label_eadid.csv\", index_col=0)\n",
    "# df_joined[\"label\"] = df_joined[\"label\"].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create subsets of the DataFrame for each field type and, for the perspectivist data, for each annotator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**AGGREGATED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Aggregated Data\n",
    "train, validate, test = utils.getShuffledSplitData(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**PERSPECTIVIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Perspectivist Data\n",
    "annotators = df_grouped.annotator.unique()\n",
    "annotators.sort()  # ['Annotator 0' 'Annotator 1' 'Annotator 2' 'Annotator 3' 'Annotator 4']\n",
    "df0 = df_grouped[df_grouped.annotator == annotators[0]]\n",
    "df1 = df_grouped[df_grouped.annotator == annotators[1]]\n",
    "df2 = df_grouped[df_grouped.annotator == annotators[2]]\n",
    "df3 = df_grouped[df_grouped.annotator == annotators[3]]\n",
    "df4 = df_grouped[df_grouped.annotator == annotators[4]]\n",
    "# df3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Perspectivist Data\n",
    "df_list = [df0, df1, df2, df3, df4]\n",
    "for dfa in df_list:\n",
    "    label_col = list(dfa.label)\n",
    "    invalid = []\n",
    "    for label_set in label_col:\n",
    "        label_list = list(label_set)\n",
    "        for label_name in label_list:\n",
    "            if not label_name in valid_label_names:\n",
    "                invalid += [label_name]\n",
    "    assert len(invalid) == 0, \"Label names must be valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Perspectivist Data\n",
    "\n",
    "# ************************************************************************************************\n",
    "# INPUT:  DataFrame, fraction of DF to shuffle, and random_state of shuffle\n",
    "#         Note 1 - fraction defaults to 1 to shuffle the entire DataFrame; \n",
    "#                 provide a value <1 to return that fraction of the DataFrame shuffled\n",
    "#         Note 2 -random_state_value defaults to 7 for reproducibility\n",
    "# OUTPUT: DataFrame with its rows shuffled\n",
    "def shuffleDataFrame(df, fraction=1, random_state_value=7):\n",
    "    return df.sample(frac=fraction, random_state=random_state_value)\n",
    "\n",
    "\n",
    "# INPUT:  A shuffled DataFrame for a particular metadata field\n",
    "# OUTPUT: The number of rows from the DataFrame to assign to train, validate (dev), \n",
    "#         and (blind) test sets of data f\n",
    "def getTrainValTestSizes(df):\n",
    "    indeces = list(df.index)\n",
    "    \n",
    "    train = indeces[ : int(df.shape[0]*0.6) ]\n",
    "    validate = indeces[ int(df.shape[0]*0.6) : (int(df.shape[0]*0.6) + round(df.shape[0]*0.2)) ]\n",
    "    test = indeces[ (int(df.shape[0]*0.6) + round(df.shape[0]*0.2)) : ]\n",
    "\n",
    "    return len(train), len(validate), len(test)\n",
    "\n",
    "\n",
    "# Add a column to the input DataFrame that assigns each row to train, dev, and test\n",
    "# using the three input sizes\n",
    "def assignSubsets(df, train_size, validate_size, test_size):\n",
    "    subset_col = [\"train\"]*train_size + [\"dev\"]*validate_size + [\"test\"]*test_size\n",
    "    df.insert(len(df.columns)-1, \"subset\", subset_col)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Concatenate the rows assigned to each subset to create one DataFrame each for \n",
    "# training, validation, and testing: \n",
    "def concatBySubset(df_list, subset):\n",
    "    df_all = pd.DataFrame()\n",
    "    for df in df_list:\n",
    "        df_subset = df.loc[df[\"subset\"] == subset]\n",
    "        df_all = pd.concat([df_all, df_subset], axis=0)\n",
    "    return df_all\n",
    "\n",
    "metadata_fields = ['Biographical / Historical', 'Title', 'Scope and Contents', 'Processing Information']\n",
    "def getShuffledSplitData(df, field_names=metadata_fields):\n",
    "    df_bh = df.loc[df.field == field_names[0]]\n",
    "    df_t = df.loc[df.field == field_names[1]]\n",
    "    df_sc = df.loc[df.field == field_names[2]]\n",
    "    df_pi = df.loc[df.field == field_names[3]]\n",
    "    \n",
    "    # Shuffle the DataFrames for each metadata field type\n",
    "    df_bh_shuffled = utils.shuffleDataFrame(df_bh)\n",
    "    df_t_shuffled = utils.shuffleDataFrame(df_t)\n",
    "    df_sc_shuffled = utils.shuffleDataFrame(df_sc)\n",
    "    df_pi_shuffled = utils.shuffleDataFrame(df_pi)\n",
    "    \n",
    "    # Get the indeces of rows to assign to train, dev, and test\n",
    "    train_bh, validate_bh, test_bh = utils.getTrainValTestSizes(df_bh_shuffled)\n",
    "    assert train_bh+validate_bh+test_bh == df_bh_shuffled.shape[0]\n",
    "    train_t, validate_t, test_t = utils.getTrainValTestSizes(df_t_shuffled)\n",
    "    assert train_t+validate_t+test_t == df_t_shuffled.shape[0]\n",
    "    train_sc, validate_sc, test_sc = utils.getTrainValTestSizes(df_sc_shuffled)\n",
    "    assert train_sc+validate_sc+test_sc == df_sc_shuffled.shape[0]\n",
    "    train_pi, validate_pi, test_pi = utils.getTrainValTestSizes(df_pi_shuffled)\n",
    "    assert train_pi+validate_pi+test_pi == df_pi_shuffled.shape[0]\n",
    "    \n",
    "    df_bh = utils.assignSubsets(df_bh_shuffled, train_bh, validate_bh, test_bh)\n",
    "    df_t = utils.assignSubsets(df_t_shuffled, train_t, validate_t, test_t)\n",
    "    df_sc = utils.assignSubsets(df_sc_shuffled, train_sc, validate_sc, test_sc)\n",
    "    df_pi = utils.assignSubsets(df_pi_shuffled, train_pi, validate_pi, test_pi)\n",
    "    dfs = [df_bh, df_t, df_sc, df_pi]\n",
    "    \n",
    "    # Concatenate the rows assigned to each subset to create one DataFrame each for training, validation, and testing: \n",
    "    train = utils.concatBySubset(dfs, \"train\")\n",
    "    assert train.subset.unique()[0] == \"train\"\n",
    "\n",
    "    validate = utils.concatBySubset(dfs, \"dev\")\n",
    "    assert validate.subset.unique()[0] == \"dev\"\n",
    "\n",
    "    test = utils.concatBySubset(dfs, \"test\")\n",
    "    assert test.subset.unique()[0] == \"test\"\n",
    "\n",
    "    return train, validate, test\n",
    "# ************************************************************************************************\n",
    "\n",
    "train0, validate0, test0 = getShuffledSplitData(df0)\n",
    "train1, validate1, test1 = getShuffledSplitData(df1)\n",
    "train2, validate2, test2 = getShuffledSplitData(df2)\n",
    "train3, validate3, test3 = getShuffledSplitData(df3)\n",
    "train4, validate4, test4 = getShuffledSplitData(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "perspectivist_data = [[train0, validate0, test0], [train1, validate1, test1], [train2, validate2, test2], \n",
    "                      [train3, validate3, test3], [train4, validate4, test4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that the label names are valid\n",
    "invalid = []\n",
    "for annotator_splits in perspectivist_data:\n",
    "    for df_split in annotator_splits:\n",
    "        label_col = list(df_split.label)\n",
    "        for label_set in label_col:\n",
    "            label_list = list(label_set)\n",
    "            for label_name in label_list:\n",
    "                if not label_name in valid_label_names:\n",
    "                    invalid += [label_name]\n",
    "        assert len(invalid) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n",
      "371\n",
      "373\n"
     ]
    }
   ],
   "source": [
    "splits =  [train, validate, test]  # [train1, validate1, test1]\n",
    "for split in splits:\n",
    "    print(split.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5989218328840971\n",
      "0.2\n",
      "0.20107816711590296\n"
     ]
    }
   ],
   "source": [
    "# train, validate, test = train2, validate2, test2\n",
    "print(train.shape[0]/(train.shape[0]+validate.shape[0]+test.shape[0]))\n",
    "print(validate.shape[0]/(train.shape[0]+validate.shape[0]+test.shape[0]))\n",
    "print(test.shape[0]/(train.shape[0]+validate.shape[0]+test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  We've shuffle the DataFrames and then added a column to each that assigns every row to a subset.  For each DataFrame: \n",
    "* 60% of the rows are for `training`\n",
    "* 20% of the rows are for `validation` (or dev test)\n",
    "* 20% of the rows are for `test` (or blind test)\n",
    "\n",
    "Lastly, we can write the corresponding labels and descriptions to files for creating classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the data to files\n",
    "The files will separate labels by `\\n` (a newline) and descriptions by `\\n|\\n` (a pipe character surrounded by newlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregated Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"data/aggregated_data/\"\n",
    "Path(dir_name).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your documents file has been written!\n",
      "Your labels file has been written!\n"
     ]
    }
   ],
   "source": [
    "utils.writeDocs(list(train.description), \"train_docs.txt\", dir_name)\n",
    "utils.writeLabels(list(train.label), \"train_labels.txt\", dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your documents file has been written!\n",
      "Your labels file has been written!\n"
     ]
    }
   ],
   "source": [
    "utils.writeDocs(list(validate.description), \"validate_docs.txt\", dir_name)\n",
    "utils.writeLabels(list(validate.label), \"validate_labels.txt\", dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your documents file has been written!\n",
      "Your labels file has been written!\n"
     ]
    }
   ],
   "source": [
    "utils.writeDocs(list(test.description), \"blindtest_docs.txt\", dir_name)\n",
    "utils.writeLabels(list(test.label), \"blindtest_labels.txt\", dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the train, validate, and test split DataFrames to files as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"data/aggregated_data/splits/\"\n",
    "Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
    "train.to_csv(dir_name+\"aggregated_train.csv\")\n",
    "validate.to_csv(dir_name+\"aggregated_validate.csv\")\n",
    "test.to_csv(dir_name+\"aggregated_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Perspectivist Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_name = \"data/perspectivist_data/\"\n",
    "# Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
    "# print(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(perspectivist_data)):\n",
    "#     train = perspectivist_data[i][0]\n",
    "#     validate = perspectivist_data[i][1]\n",
    "#     test = perspectivist_data[i][2]\n",
    "#     utils.writeDocs(list(train.description), \"train{}_docs.txt\".format(i), dir_name)\n",
    "#     utils.writeLabels(list(train.label), \"train{}_labels.txt\".format(i), dir_name)\n",
    "#     utils.writeDocs(list(validate.description), \"validate{}_docs.txt\".format(i), dir_name)\n",
    "#     utils.writeLabels(list(validate.label), \"validate{}_labels.txt\".format(i), dir_name)\n",
    "#     utils.writeDocs(list(test.description), \"blindtest{}_docs.txt\".format(i), dir_name)\n",
    "#     utils.writeLabels(list(test.label), \"blindtest{}_labels.txt\".format(i), dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

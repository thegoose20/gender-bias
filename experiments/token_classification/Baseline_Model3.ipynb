{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "\n",
    "#### Model Setup\n",
    "\n",
    "Run the Multilabel Stereotype + Omission Document Classifier without any additional labels from other classifiers as features.\n",
    "\n",
    "***\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/experiment_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/`\n",
    "* Word Embeddings\n",
    "    * Custom fastText (word2vec with subwords) embeddings of 100 dimensions trained on the CRC Archives catalog's descriptive metadata (harvested October 2020)\n",
    "    \n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[I.](#i) Stereotype + Omission Classifier\n",
    "* [Preprocessing](#prep)\n",
    "* [Training & Prediction](#tp)\n",
    "* [Evaluation](#eval)\n",
    "\n",
    "[II.](#ii) Predict Over All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load programming resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, utils1, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For classification\n",
    "import scipy\n",
    "import sklearn.metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix#, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# For saving model\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resources for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For 60-20-20 train-dev-test split of documents (metadata descriptions)\n",
    "Path(config.experiment_input_path).mkdir(parents=True, exist_ok=True)    # For train, devtest, and blind test data\n",
    "# Path(config.experiment1_output_path).mkdir(parents=True, exist_ok=True)  # For predictions\n",
    "# Path(config.experiment1_agmt_path).mkdir(parents=True, exist_ok=True)    # For agreement metrics\n",
    "# ----------------------\n",
    "### For features from modified 5-fold CV\n",
    "# predictions_dir = config.experiment2_path+\"5fold/output/\"\n",
    "# Path(predictions_dir).mkdir(parents=True, exist_ok=True)    # For predictions\n",
    "# agreement_dir = config.experiment2_path+\"5fold/agreement/\"\n",
    "# Path(agreement_dir).mkdir(parents=True, exist_ok=True)      # For agreement metrics\n",
    "\n",
    "# For baseline\n",
    "predictions_dir = config.tokc_path+\"baseline/output/\"\n",
    "Path(predictions_dir).mkdir(parents=True, exist_ok=True)    # For predictions\n",
    "agreement_dir = config.tokc_path+\"baseline/agreement/\"\n",
    "Path(agreement_dir).mkdir(parents=True, exist_ok=True)      # For agreement metrics\n",
    "\n",
    "# predictions_dir = config.experiment2_path+\"5fold/with_manual_labels/output/\"              # For predictions with features as manual labels\n",
    "# Path(predictions_dir).mkdir(parents=True, exist_ok=True)  \n",
    "# agreement_dir = config.experiment2_path+\"5fold/with_manual_labels/agreement/\"             # For agreement metrics with features as manual labels\n",
    "# Path(agreement_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3:\n",
    "so_label_subset = [\"B-Stereotype\", \"I-Stereotype\", \"B-Omission\", \"I-Omission\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_label_tags = {\n",
    "    \"Stereotype\": [\"B-Stereotype\", \"I-Stereotype\"], \"Omission\": [\"B-Omission\", \"I-Omission\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100               # dimensions of word embeddings (should match utils1.py) for file names\n",
    "target_labels = \"so\"  # for file names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"i\"></a>\n",
    "## I. Stereotype + Omission Classifier\n",
    "<a id=\"prep\"></a>\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the document classification model's input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>field</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4699</td>\n",
       "      <td>1853</td>\n",
       "      <td>2066</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Labelled Apparently some chapters, amounting t...</td>\n",
       "      <td>[Omission]</td>\n",
       "      <td>split3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8942</td>\n",
       "      <td>384</td>\n",
       "      <td>540</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>James Aikman of Perth signed his name to a vol...</td>\n",
       "      <td>[]</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5440</td>\n",
       "      <td>5692</td>\n",
       "      <td>5850</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>This piece was published in 'Milk Production i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>split0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3474</td>\n",
       "      <td>3608</td>\n",
       "      <td>8549</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Margaret Winifred Bartholomew was born on 21 A...</td>\n",
       "      <td>[Omission, Stereotype]</td>\n",
       "      <td>split0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4769</td>\n",
       "      <td>2378</td>\n",
       "      <td>2576</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Blacker and Thomson became close friends throu...</td>\n",
       "      <td>[Omission]</td>\n",
       "      <td>split3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  start_offset  end_offset                      field  \\\n",
       "0            4699          1853        2066  Biographical / Historical   \n",
       "1            8942           384         540  Biographical / Historical   \n",
       "2            5440          5692        5850  Biographical / Historical   \n",
       "3            3474          3608        8549  Biographical / Historical   \n",
       "4            4769          2378        2576  Biographical / Historical   \n",
       "\n",
       "                                         description                   label  \\\n",
       "0  Labelled Apparently some chapters, amounting t...              [Omission]   \n",
       "1  James Aikman of Perth signed his name to a vol...                      []   \n",
       "2  This piece was published in 'Milk Production i...                      []   \n",
       "3  Margaret Winifred Bartholomew was born on 21 A...  [Omission, Stereotype]   \n",
       "4  Blacker and Thomson became close friends throu...              [Omission]   \n",
       "\n",
       "     fold  \n",
       "0  split3  \n",
       "1  split2  \n",
       "2  split0  \n",
       "3  split0  \n",
       "4  split3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # For 60-20-20 split\n",
    "# train = pd.read_csv(config.docc_path+\"model_input/\"+\"{}_splits_as_csv/aggregated_final_train.csv\".format(target_labels), index_col=0)\n",
    "# dev = pd.read_csv(config.docc_path+\"model_input/\"+\"{}_splits_as_csv/aggregated_final_validate.csv\".format(target_labels), index_col=0)\n",
    "# test = pd.read_csv(config.docc_path+\"model_input/\"+\"{}_splits_as_csv/aggregated_final_test.csv\".format(target_labels), index_col=0)\n",
    "# df_exp = pd.concat([train, dev, test])\n",
    "# df_exp[\"label\"] = df_exp[\"label\"].fillna(\"{'None'}\")\n",
    "# df_exp = df_exp.loc[~df_exp.description.isna()]\n",
    "# df_exp = utils.getColumnValuesAsLists(df_exp, \"label\")\n",
    "# # df_exp.head()\n",
    "# ------------------------------\n",
    "# For modified 5-fold cross validation\n",
    "df = pd.read_csv(config.tokc_path+\"experiment_input/document_5fold.csv\", index_col=0)\n",
    "df = utils.getColumnValuesAsLists(df, \"label\")\n",
    "df = df.drop(columns=[\"subset\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train (80% of the data) and test (20% of the data) splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['split0' 'split1' 'split2' 'split3' 'split4']\n",
      "(['split0', 'split1', 'split2', 'split3'], 'split4')\n",
      "(['split1', 'split2', 'split3', 'split4'], 'split0')\n",
      "(['split2', 'split3', 'split4', 'split0'], 'split1')\n",
      "(['split3', 'split4', 'split0', 'split1'], 'split2')\n",
      "(['split4', 'split0', 'split1', 'split2'], 'split3')\n"
     ]
    }
   ],
   "source": [
    "split_col = \"fold\"\n",
    "splits = df[split_col].unique()\n",
    "splits.sort()\n",
    "print(splits)\n",
    "train0, test0 = list(splits[:4]), splits[4]\n",
    "train1, test1 = list(splits[1:]), splits[0]\n",
    "train2, test2 = list(splits[2:])+[splits[0]], splits[1]\n",
    "train3, test3 = list(splits[3:])+list(splits[:2]), splits[2]\n",
    "train4, test4 = [splits[4]]+list(splits[:3]), splits[3]\n",
    "runs = [(train0, test0), (train1, test1), (train2, test2), (train3, test3), (train4, test4)]\n",
    "for run in runs:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeMultilabelTrainColumn(df_col):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binarized = mlb.fit_transform(df_col)\n",
    "    return mlb, binarized\n",
    "\n",
    "def binarizeMultilabelDevColumn(mlb, df_col):\n",
    "    binarized = mlb.transform(df_col)\n",
    "    return binarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tp\"></a>\n",
    "### Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"sgd-svm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: ['split0', 'split1', 'split2', 'split3']\n",
      "Predicting on: split4\n",
      "Training on: ['split1', 'split2', 'split3', 'split4']\n",
      "Predicting on: split0\n",
      "Training on: ['split2', 'split3', 'split4', 'split0']\n",
      "Predicting on: split1\n",
      "Training on: ['split3', 'split4', 'split0', 'split1']\n",
      "Predicting on: split2\n",
      "Training on: ['split4', 'split0', 'split1', 'split2']\n",
      "Predicting on: split3\n",
      "Modified 5-fold cross-validation complete!\n",
      "(27312, 8)\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "target_col = \"label\"\n",
    "for run in runs:\n",
    "    # Get the train (80%) and test (20%) subsets of data\n",
    "    train_splits, test_split = run[0], run[1]\n",
    "    print(\"Training on:\", train_splits)\n",
    "    train_df = df.loc[df[split_col].isin(train_splits)]\n",
    "    dev_df = df.loc[df[split_col] == test_split]\n",
    "    \n",
    "    # Vectorize the documents (descriptions)\n",
    "    cvectorizer = CountVectorizer()\n",
    "    tfidf = TfidfTransformer()\n",
    "    train_docs = cvectorizer.fit_transform(train_df[\"description\"])\n",
    "    dev_docs = cvectorizer.transform(dev_df[\"description\"])\n",
    "    X_train = tfidf.fit_transform(train_docs)\n",
    "    X_dev = tfidf.transform(dev_docs)\n",
    "    \n",
    "    # Binarize targets\n",
    "    mlb_target, y_train = binarizeMultilabelTrainColumn(train_df[target_col])\n",
    "    y_dev = binarizeMultilabelDevColumn(mlb_target, dev_df[target_col])\n",
    "\n",
    "    # Train a classification model\n",
    "    clf = OneVsRestClassifier(SGDClassifier(loss=\"hinge\"))  # Support Vector Machines loss function\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict with the trained model\n",
    "    print(\"Predicting on:\", test_split)\n",
    "    predictions = clf.predict(X_dev)\n",
    "    pred_labels = mlb_target.inverse_transform(predictions)    \n",
    "    if pred_df.shape[0] > 0:\n",
    "        next_pred_df = dev_df.copy()\n",
    "        next_pred_df.insert(len(next_pred_df.columns), \"{}_label\".format(a), pred_labels)\n",
    "        pred_df = pd.concat([pred_df, next_pred_df])\n",
    "    else:\n",
    "        pred_df = dev_df.copy()\n",
    "        pred_df.insert(len(pred_df.columns), \"{}_label\".format(a), pred_labels)\n",
    "\n",
    "print(\"Modified 5-fold cross-validation complete!\")\n",
    "print(pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>field</th>\n",
       "      <th>description</th>\n",
       "      <th>manual_label</th>\n",
       "      <th>fold</th>\n",
       "      <th>sgd-svm_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3027</td>\n",
       "      <td>627</td>\n",
       "      <td>1162</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Thomas Young was probably born in 1725. By the...</td>\n",
       "      <td>[Stereotype]</td>\n",
       "      <td>split4</td>\n",
       "      <td>(Stereotype,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3397</td>\n",
       "      <td>8095</td>\n",
       "      <td>8334</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Andrew Tait worked on Paramecium in Beale's la...</td>\n",
       "      <td>[Omission]</td>\n",
       "      <td>split4</td>\n",
       "      <td>(Omission,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4736</td>\n",
       "      <td>9951</td>\n",
       "      <td>10026</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Delivered by Thomson to teachers in Darlington.</td>\n",
       "      <td>[Omission]</td>\n",
       "      <td>split4</td>\n",
       "      <td>(Omission,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4712</td>\n",
       "      <td>4199</td>\n",
       "      <td>4485</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>This was gifted by Thomson to his secretary, M...</td>\n",
       "      <td>[Omission]</td>\n",
       "      <td>split4</td>\n",
       "      <td>(Omission,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15684</td>\n",
       "      <td>845</td>\n",
       "      <td>1179</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Catherine Robina Borland was responsible for t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>split4</td>\n",
       "      <td>(,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    description_id  start_offset  end_offset                      field  \\\n",
       "6             3027           627        1162  Biographical / Historical   \n",
       "7             3397          8095        8334  Biographical / Historical   \n",
       "10            4736          9951       10026  Biographical / Historical   \n",
       "14            4712          4199        4485  Biographical / Historical   \n",
       "22           15684           845        1179  Biographical / Historical   \n",
       "\n",
       "                                          description  manual_label    fold  \\\n",
       "6   Thomas Young was probably born in 1725. By the...  [Stereotype]  split4   \n",
       "7   Andrew Tait worked on Paramecium in Beale's la...    [Omission]  split4   \n",
       "10    Delivered by Thomson to teachers in Darlington.    [Omission]  split4   \n",
       "14  This was gifted by Thomson to his secretary, M...    [Omission]  split4   \n",
       "22  Catherine Robina Borland was responsible for t...            []  split4   \n",
       "\n",
       "    sgd-svm_label  \n",
       "6   (Stereotype,)  \n",
       "7     (Omission,)  \n",
       "10    (Omission,)  \n",
       "14    (Omission,)  \n",
       "22            (,)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pred_df.rename(columns={\"label\":\"manual_label\"})\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(predictions_dir+\"aggregated_final_validate_predictions_docclf_{a}_{t}.csv\".format(a=a, t=target_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/baseline/sgd-svm_F-tfidf_T-so.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"models/baseline/\"\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "filename = model_dir+\"sgd-svm_F-tfidf_T-so.joblib\"\n",
    "dump(clf, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"eval\"></a>\n",
    "### Evaluate\n",
    "\n",
    "Calculate performance metrics for the Stochastic Gradient Descent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "['' 'Omission' 'Stereotype']\n"
     ]
    }
   ],
   "source": [
    "classes = clf.classes_  #doc_clf.classes_\n",
    "print(classes)\n",
    "original_classes = mlb_target.classes_\n",
    "print(original_classes)\n",
    "label_dict = dict(zip(original_classes, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create a [confusion matrix](https://scikit-learn.org/stable/modules/model_evaluation.html#multilabel-confusion-matrix) of the results, where, for class *i*:\n",
    "* Count of true negatives (TN) is at position *i*,0,0\n",
    "* Count of false negatives (FN) is at position *i*,1,0\n",
    "* Count of true positives (FP) is at position *i*,1,1\n",
    "* Count of false positives (PF) is at position *i*,0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = binarizeMultilabelDevColumn(mlb_target, pred_df[\"manual_label\"])\n",
    "predictions = mlb_target.transform(pred_df[\"{}_label\".format(a)])\n",
    "assert len(y_dev) == len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = multilabel_confusion_matrix(y_dev, predictions, labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>false_neg</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Omission</td>\n",
       "      <td>1857</td>\n",
       "      <td>2175</td>\n",
       "      <td>356</td>\n",
       "      <td>0.859344</td>\n",
       "      <td>0.539435</td>\n",
       "      <td>0.662807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stereotype</td>\n",
       "      <td>406</td>\n",
       "      <td>1195</td>\n",
       "      <td>77</td>\n",
       "      <td>0.939465</td>\n",
       "      <td>0.746408</td>\n",
       "      <td>0.831883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  false_neg  true_pos  false_pos  precision    recall       f_1\n",
       "1    Omission       1857      2175        356   0.859344  0.539435  0.662807\n",
       "2  Stereotype        406      1195         77   0.939465  0.746408  0.831883"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = utils.getPerformanceMetrics(y_dev, predictions, matrix, classes, original_classes, label_dict)\n",
    "scores = scores.tail(2) # Remove row for 'None'\n",
    "scores = scores.drop(columns=\"true_neg\")  # Not accurate because considers 'None' a class\n",
    "scores[\"labels\"] = original_classes[1:]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the performance results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores.to_csv(agreement_dir+\"docclf_{a}_{t}_baseline_performance.csv\".format(a=a, t=target_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

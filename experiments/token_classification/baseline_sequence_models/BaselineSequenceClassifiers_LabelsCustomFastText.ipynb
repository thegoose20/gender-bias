{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Biased Sequence Classifiers with fastText\n",
    "\n",
    "### Target: Labels\n",
    "\n",
    "### Features: Word Embeddings\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/crf_l2sgd_baseline/`\n",
    "* Sequence classification\n",
    "    * 3 categories, 9 lables (2 from original annotation taxonomy weren't applied during manual annotation):\n",
    "        1. Person Name: Unknown, Feminine, Masculine (Non-binary not applied during annotation)\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Occupation, Omission, Stereotype (Empowering only applied by one annotator and too few times for training)\n",
    "    * 1 model per category\n",
    "* Word embeddings\n",
    "    * Custom fastText (word2vec with subwords, trained on Archives' descriptive metadata extracted in October 2020)  \n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[0.](#0) Preprocessing\n",
    "\n",
    "[1.](#1) Models\n",
    "\n",
    "[2.](#2) Performance Evaluation\n",
    "\n",
    "[Appendix A](#A) Person Name Model Optimization\n",
    "\n",
    "[Appendix B](#B) Linguistic Model Optimization\n",
    "\n",
    "[Appendix C](#C) Contextual Model Optimization\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For preprocessing\n",
    "import scipy.stats\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "\n",
    "# For classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay#, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate rows with all but the same annotation ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that won't be used as features for the classifiers and remove any duplicate rows that remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"pos\", \"token\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[cols_to_keep]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev[cols_to_keep]\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate subsets of data for each category so they can be used with three separate models, replacing `NaN` tag values with `'O'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine' 'B-Gendered-Pronoun' 'B-Gendered-Role' 'B-Generalization'\n",
      " 'B-Masculine' 'B-Occupation' 'B-Omission' 'B-Stereotype' 'B-Unknown'\n",
      " 'I-Feminine' 'I-Gendered-Pronoun' 'I-Gendered-Role' 'I-Generalization'\n",
      " 'I-Masculine' 'I-Occupation' 'I-Omission' 'I-Stereotype' 'I-Unknown' 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = (df_train.tag.unique())\n",
    "tags.sort()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                     141279\n",
       "I-Unknown               3062\n",
       "B-Unknown               1886\n",
       "I-Omission              1502\n",
       "I-Masculine             1240\n",
       "B-Omission              1008\n",
       "B-Masculine              968\n",
       "I-Occupation             781\n",
       "B-Gendered-Pronoun       744\n",
       "I-Stereotype             721\n",
       "I-Feminine               675\n",
       "B-Occupation             654\n",
       "B-Gendered-Role          575\n",
       "B-Feminine               281\n",
       "B-Stereotype             252\n",
       "B-Generalization         240\n",
       "I-Generalization         145\n",
       "I-Gendered-Role          118\n",
       "I-Gendered-Pronoun        15\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = df_dev.drop_duplicates()\n",
    "df_dev.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156146, 5)\n",
      "152455\n"
     ]
    }
   ],
   "source": [
    "print(df_dev.shape)\n",
    "print(len(df_dev.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Optional** - if selecting subset of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ling_cat_tags = ['B-Gendered-Pronoun', 'B-Gendered-Role', 'B-Generalization', 'I-Gendered-Pronoun', 'I-Gendered-Role', 'I-Generalization']\n",
    "# df_train_ling = df_train.loc[df_train.tag.isin(ling_cat_tags)]\n",
    "# df_dev_ling = df_dev.loc[df_dev.tag.isin(ling_cat_tags)]\n",
    "# category = \"linguistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pers_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Unknown']\n",
    "# df_train_pers = df_train.loc[df_train.tag.isin(pers_cat_tags)]\n",
    "# df_dev_pers = df_dev.loc[df_dev.tag.isin(pers_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cont_cat_tags = ['B-Occupation', 'B-Omission', 'B-Stereotype', 'I-Occupation', 'I-Omission', 'I-Stereotype']\n",
    "# df_train_cont = df_train.loc[df_train.tag.isin(cont_cat_tags)]\n",
    "# df_dev_cont = df_dev.loc[df_dev.tag.isin(cont_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perso_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Occupation', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Occupation', 'I-Unknown']\n",
    "df_train_perso = df_train.loc[df_train.tag.isin(perso_cat_tags)]\n",
    "df_dev_perso = df_dev.loc[df_dev.tag.isin(perso_cat_tags)]\n",
    "category = \"pers_o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.drop(columns=[\"tag\"])).drop_duplicates()\n",
    "df_dev = (df_dev.drop(columns=[\"tag\"])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"sentence_id\", \"token_id\", \"pos\", \"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_ling = df_train.join(df_train_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_train_ling = df_train_ling.fillna('O')\n",
    "# # df_train_ling.head()\n",
    "# df_dev_ling = df_dev.join(df_dev_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_dev_ling = df_dev_ling.fillna('O')\n",
    "# df_dev_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_train_pers = df_train.join(df_train_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_train_pers = df_train_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "# df_train_pers = df_train_pers.fillna('O')\n",
    "# df_dev_pers = df_dev.join(df_dev_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_dev_pers = df_dev_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "# df_dev_pers = df_dev_pers.fillna('O')\n",
    "# # df_dev_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_train_cont = df_train.join(df_train_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_train_cont = df_train_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "# df_train_cont = df_train_cont.fillna('O')\n",
    "# df_dev_cont = df_dev.join(df_dev_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_dev_cont = df_dev_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "# df_dev_cont = df_dev_cont.fillna('O')\n",
    "# df_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_perso = df_train.join(df_train_perso.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_train_perso = df_train_perso.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_train_perso = df_train_perso.fillna('O')\n",
    "df_dev_perso = df_dev.join(df_dev_perso.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_dev_perso = df_dev_perso.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_dev_perso = df_dev_perso.fillna('O')\n",
    "# df_dev_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train_ling.drop_duplicates()\n",
    "# df_dev = df_dev_ling.drop_duplicates()\n",
    "df_train = df_train_perso.drop_duplicates()\n",
    "df_dev = df_dev_perso.drop_duplicates()\n",
    "# df_train = df_train_pers.drop_duplicates()\n",
    "# df_dev = df_dev_pers.drop_duplicates()\n",
    "# df_train = df_train_cont.drop_duplicates()\n",
    "# df_dev = df_dev_cont.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O               144035\n",
       "I-Unknown         3062\n",
       "B-Unknown         1886\n",
       "I-Masculine       1240\n",
       "B-Masculine        968\n",
       "I-Occupation       781\n",
       "I-Feminine         675\n",
       "B-Occupation       654\n",
       "B-Feminine         281\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train_dfs = [df_train_ling, df_train_pers, df_train_cont]\n",
    "# dev_dfs = [df_dev_ling, df_dev_pers, df_dev_cont]\n",
    "# for df in train_dfs:\n",
    "#     print(df.shape[0], len(df.token_id.unique()))\n",
    "# print()\n",
    "# for df in dev_dfs:\n",
    "#     print(df.shape[0], len(df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens can have multiple tags, so there are more rows than unique token IDs.  In order to pass the data into a CRF model, we need to have one tag per token, so we'll simply **take the first tag** when we extract features for each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings\n",
    "\n",
    "Use the custom fastText word embeddings, trained on the entire dataset of descriptive metadata from the Archives (harvested in October 2020) using the Continuous Bag-of-Words (CBOW) algorithm.  Subword embeddings (for subwords from 2 to 6 characters long, inclusive) are used to infer the embeddings for out-of-vocabulary (OOV) words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the word embedding model trained on lowercased text to 100 dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions = [\"50\", \"100\", \"200\", \"300\"]\n",
    "# d = dimensions[1]\n",
    "# file_name = config.fasttext_path+\"fasttext{}_lowercased.model\".format(d)  #get_tmpfile()\n",
    "# embedding_model = FastText.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary = list(df_train.token.unique())\n",
    "# vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "# vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "# print(\"Vocabulary size:\", len(vocabulary))\n",
    "# print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define feature dictionaries for baseline models, using only the word embeddings and token as features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a vector representation of a token from a fastText word embedding model\n",
    "# def extractEmbedding(token, fasttext_model=embedding_model):\n",
    "#     if token.isalpha():\n",
    "#         token = token.lower()\n",
    "#     embedding = fasttext_model.wv[token]\n",
    "#     return embedding\n",
    "\n",
    "def extractTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token\n",
    "    }\n",
    "    \n",
    "#     # Add each value in a token's word embedding as a separate feature\n",
    "#     embedding = extractEmbedding(token)\n",
    "#     for i,n in enumerate(embedding):\n",
    "#         features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractSentenceFeatures(sentence):\n",
    "    return [extractTokenFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def extractSentenceTargets(sentence):\n",
    "    return [tag_list[0] for token, pos, tag_list in sentence]\n",
    "\n",
    "def extractSentenceTokens(sentence):\n",
    "    return [token for token, pos, tag_list in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References:*\n",
    "* *https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html*\n",
    "* *https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"all\"></a>\n",
    "## All Labels\n",
    "\n",
    "* **Features:** custom fastText embeddings\n",
    "* **Target:** IOB tags\n",
    "* **Algorithm:** AROW, variance=1\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152455, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>5</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_id  sentence_id   pos       token  tag\n",
       "0       154            5    IN       After  [O]\n",
       "1       155            5  PRP$         his  [O]\n",
       "2       156            5    NN  ordination  [O]\n",
       "3       157            5   PRP          he  [O]\n",
       "4       158            5   VBD       spent  [O]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_dev_token_groups.shape)\n",
    "df_dev_token_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences = utils.zipFeaturesAndTarget(df_train_grouped, \"tag\")\n",
    "dev_sentences = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=1 was best-performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with 50 maximum iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn_crfsuite.CRF(algorithm='arow', variance=1, max_iterations=50, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'I-Masculine', 'B-Masculine', 'B-Occupation', 'I-Occupation', 'B-Feminine', 'I-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Summary (with O label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Macro:\n",
      "  - F1: 0.5231534463290515\n",
      "  - Prec: 0.566404777718956\n",
      "  - Rec 0.48959059685433803\n",
      "  Micro:\n",
      "  - F1: 0.5031209362808843\n",
      "  - Prec: 0.5558908045977011\n",
      "  - Rec 0.45950118764845604\n",
      "  Per Label:\n",
      "  - F1: [0.49798387 0.50869389 0.37206879 0.36728625 0.62697023 0.55892731\n",
      " 0.62753036 0.62576687]\n",
      "  - Prec: [0.57087827 0.58133087 0.378579   0.3964687  0.72469636 0.61971831\n",
      " 0.5984556  0.66111111]\n",
      "  - Rec [0.44159714 0.45219267 0.36577869 0.34210526 0.55246914 0.50899743\n",
      " 0.65957447 0.59400998]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(clf.algorithm, clf.c1, clf.c2, clf.pa_type, clf.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag\":\"tag_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_predicted\", y_pred)\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_expected</th>\n",
       "      <th>tag_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id   pos    sentence tag_expected tag_predicted\n",
       "sentence_id                                                      \n",
       "5                154    IN       After            O             O\n",
       "5                155  PRP$         his            O             O\n",
       "5                156    NN  ordination            O             O\n",
       "5                157   PRP          he            O             O\n",
       "5                158   VBD       spent            O             O"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.set_index([\"sentence_id\"])\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "# df_dev_exploded.head()\n",
    "df_dev_exploded = df_dev_exploded.explode([\"tag_expected\"])\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_exploded = df_dev_exploded.fillna(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_exploded = df_dev_exploded.rename(columns={\"sentence\":\"token\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_dev_exploded.drop(columns=[\"tag_predicted\"]).reset_index()\n",
    "pred_df = df_dev_exploded.drop(columns=[\"tag_expected\"]).reset_index()\n",
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag_expected</th>\n",
       "      <th>tag_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos tag_expected tag_predicted  \\\n",
       "0            5       154       After    IN            O             O   \n",
       "1            5       155         his  PRP$            O             O   \n",
       "2            5       156  ordination    NN            O             O   \n",
       "3            5       157          he   PRP            O             O   \n",
       "4            5       158       spent   VBD            O             O   \n",
       "\n",
       "          _merge  \n",
       "0  true negative  \n",
       "1  true negative  \n",
       "2  true negative  \n",
       "3  true negative  \n",
       "4  true negative  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    exp_df, \n",
    "    pred_df, \n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_expected\"],   # left on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_predicted\"],  # right on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_expected\", \"tag_predicted\", \"_merge\"],  # final column list\n",
    "    \"tag_expected\",\n",
    "    \"tag_predicted\", \n",
    "    \"token_id\",  # ID column\n",
    "    \"O\"          # No tag value\n",
    ")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155606, 7)\n",
      "(154479, 7)\n"
     ]
    }
   ],
   "source": [
    "print(eval_df.shape)\n",
    "eval_df = eval_df.drop_duplicates()\n",
    "print(eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"crf_arow_var1_{c}_baseline_fastText{d}_predictions.csv\".format(d=d, c=category)\n",
    "filename = \"crf_arow_var1_{c}_baseline_no_embeddings_predictions.csv\".format(c=category)\n",
    "eval_df.to_csv(config.tokc_path+\"sequence_model_output/\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if category == \"linguistic\":\n",
    "    targets = ['B-Gendered-Pronoun', 'I-Gendered-Pronoun', 'B-Gendered-Role', 'I-Gendered-Role', 'B-Generalization', 'I-Generalization']\n",
    "elif category == \"pers_o\":\n",
    "    targets = ['B-Feminine', 'I-Feminine', 'B-Masculine', 'I-Masculine', 'B-Unknown', 'I-Unknown', 'B-Occupation', 'I-Occupation']\n",
    "else:\n",
    "    print(category+\" not recognized as a category.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>358</td>\n",
       "      <td>0.875306</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.874237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>121</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.870032</td>\n",
       "      <td>0.904523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>349</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>0.806492</td>\n",
       "      <td>0.649246</td>\n",
       "      <td>0.719376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>475</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>0.770815</td>\n",
       "      <td>0.654042</td>\n",
       "      <td>0.707644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>375</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1642</td>\n",
       "      <td>0.882321</td>\n",
       "      <td>0.814080</td>\n",
       "      <td>0.846828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>590</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>2746</td>\n",
       "      <td>0.898854</td>\n",
       "      <td>0.823141</td>\n",
       "      <td>0.859333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>722</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.967180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>0.974170</td>\n",
       "      <td>0.958838</td>\n",
       "      <td>0.966443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag(s)  false negative  false positive  true negative  true positive  \\\n",
       "0    B-Feminine              52              51              0            358   \n",
       "0    I-Feminine             121              50              0            810   \n",
       "0   B-Masculine             349             155              0            646   \n",
       "0   I-Masculine             475             267              0            898   \n",
       "0     B-Unknown             375             219              0           1642   \n",
       "0     I-Unknown             590             309              0           2746   \n",
       "0  B-Occupation              28              21              0            722   \n",
       "0  I-Occupation              34              21              0            792   \n",
       "\n",
       "   precision    recall        f1  \n",
       "0   0.875306  0.873171  0.874237  \n",
       "0   0.941860  0.870032  0.904523  \n",
       "0   0.806492  0.649246  0.719376  \n",
       "0   0.770815  0.654042  0.707644  \n",
       "0   0.882321  0.814080  0.846828  \n",
       "0   0.898854  0.823141  0.859333  \n",
       "0   0.971736  0.962667  0.967180  \n",
       "0   0.974170  0.958838  0.966443  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_stats = pd.DataFrame()\n",
    "for tag in targets:\n",
    "#     getScoresByTags(df, eval_col, tags, exp_col=\"expected_tag\", pred_col=\"predicted_tag\"):\n",
    "    tag_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [tag], exp_col=\"tag_expected\", pred_col=\"tag_predicted\")\n",
    "    agmt_stats = pd.concat([agmt_stats, tag_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_arow_var1_{c}_baseline_no_embeddings_agreement.csv\".format(c=category)\n",
    "agmt_stats.to_csv(config.tokc_path+\"sequence_model_performance/\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A\"></a>\n",
    "## Appendix A: Person Name Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "\n",
    "Look for the highest-performing (based on F1 score) models by trying different algorithms and parameters.  Algorithms vailable with sklearn_crfsuite are:\n",
    " * 'lbfgs' - Gradient descent using the L-BFGS method\n",
    " * 'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
    " * 'ap' - Averaged Perceptron\n",
    " * 'pa' - Passive Aggressive (PA)\n",
    " * 'arow' - Adaptive Regularization Of Weight Vector (AROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "max_iters=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"tag_personname\"].unique()\n",
    "targets = [\n",
    "        'B-Unknown', 'I-Unknown', 'B-Feminine',\n",
    "        'I-Feminine', 'B-Masculine', 'I-Masculine'\n",
    "]\n",
    "# f1_scorer = make_scorer(\n",
    "#     metrics.flat_f1_score, average='None', \n",
    "#     labels=targets\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf0A = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0, max_iterations=max_iters, all_possible_transitions=True) # unlimited iterations\n",
    "crf0B = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf0C = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf1A = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=1.0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 1000\n",
    "crf1B = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf2 = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "\n",
    "crf3A = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf3B = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf3C = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf4A = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=1, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf4B = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=0.5, max_iterations=max_iters, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0 None None None\n",
      "  Weighted:\n",
      "  - F1: 0.25563333936374655\n",
      "  - Prec: 0.48241170869152883\n",
      "  - Rec 0.17545363623374768\n",
      "  Unweighted:\n",
      "  - F1: [0.21609604 0.24892487 0.40752351 0.28761651 0.32380952 0.23603462]\n",
      "  - Prec: [0.42631579 0.42087254 0.77380952 0.72       0.51987768 0.51020408]\n",
      "  - Rec [0.14472901 0.17672414 0.27659574 0.1797005  0.2351314  0.15353122]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0A.algorithm, crf0A.c1, crf0A.c2, crf0A.pa_type, crf0A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 None None None\n",
      "  Weighted:\n",
      "  - F1: 0.3952936125163706\n",
      "  - Prec: 0.6164456508900145\n",
      "  - Rec 0.2961851693099014\n",
      "  Unweighted:\n",
      "  - F1: [0.34542314 0.37176232 0.62222222 0.53304904 0.43134087 0.38205128]\n",
      "  - Prec: [0.62794349 0.63431542 0.74117647 0.74183976 0.5184466  0.51114923]\n",
      "  - Rec [0.23823705 0.26293103 0.53617021 0.41597338 0.36929461 0.30501535]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0B.algorithm, crf0B.c1, crf0B.c2, crf0B.pa_type, crf0B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 0.2 None None\n",
      "  Weighted:\n",
      "  - F1: 0.4505459769939627\n",
      "  - Prec: 0.6028142561062638\n",
      "  - Rec 0.36133733390484357\n",
      "  Unweighted:\n",
      "  - F1: [0.45994065 0.48070953 0.63333333 0.5320911  0.38327526 0.30410184]\n",
      "  - Prec: [0.60963618 0.62804171 0.71891892 0.70410959 0.51764706 0.49199085]\n",
      "  - Rec [0.36926742 0.38936782 0.56595745 0.42762063 0.30428769 0.22006141]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0C.algorithm, crf0C.c1, crf0C.c2, crf0C.pa_type, crf0C.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 1.0 None None\n",
      "  Weighted:\n",
      "  - F1: 0.39947172781326473\n",
      "  - Prec: 0.5390631041498564\n",
      "  - Rec 0.31975996570938703\n",
      "  Unweighted:\n",
      "  - F1: [0.37020484 0.37389855 0.5990566  0.5520728  0.44057052 0.35034657]\n",
      "  - Prec: [0.49403579 0.55477032 0.67195767 0.70360825 0.51576994 0.4557377 ]\n",
      "  - Rec [0.29600953 0.28196839 0.54042553 0.45424293 0.38450899 0.28454452]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1A.algorithm, crf1A.c1, crf1A.c2, crf1A.pa_type, crf1A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 0.2 None None\n",
      "  Weighted:\n",
      "  - F1: 0.28237156184801626\n",
      "  - Prec: 0.6289538389122998\n",
      "  - Rec 0.19402771824546364\n",
      "  Unweighted:\n",
      "  - F1: [0.26691042 0.26218487 0.63341646 0.54115226 0.31621349 0.09779482]\n",
      "  - Prec: [0.57367387 0.59541985 0.76506024 0.70889488 0.58148148 0.77272727]\n",
      "  - Rec [0.17391304 0.16810345 0.54042553 0.43760399 0.21715076 0.05220061]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1B.algorithm, crf1B.c1, crf1B.c2, crf1B.pa_type, crf1B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap None None None None\n",
      "  Weighted:\n",
      "  - F1: 0.43418543421107464\n",
      "  - Prec: 0.6506056343043833\n",
      "  - Rec 0.33190455779397054\n",
      "  Unweighted:\n",
      "  - F1: [0.41818182 0.42871094 0.6367713  0.60142712 0.46962233 0.29945694]\n",
      "  - Prec: [0.62162162 0.66920732 0.67298578 0.77631579 0.57777778 0.61858974]\n",
      "  - Rec [0.31506849 0.31537356 0.60425532 0.49084859 0.395574   0.1975435 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf2.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf2.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf2.algorithm, crf2.c1, crf2.c2, crf2.pa_type, crf2.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 0 None\n",
      "  Weighted:\n",
      "  - F1: 0.46544025425232854\n",
      "  - Prec: 0.6526455542987322\n",
      "  - Rec 0.36676668095442205\n",
      "  Unweighted:\n",
      "  - F1: [0.46613697 0.48264984 0.66350711 0.59205021 0.45128205 0.30015552]\n",
      "  - Prec: [0.63900415 0.64752116 0.7486631  0.7971831  0.59060403 0.62459547]\n",
      "  - Rec [0.36688505 0.38469828 0.59574468 0.47088186 0.36514523 0.1975435 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3A.algorithm, crf3A.c1, crf3A.c2, crf3A.pa_type, crf3A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 1 None\n",
      "  Weighted:\n",
      "  - F1: 0.46124270643488524\n",
      "  - Prec: 0.6487355256491798\n",
      "  - Rec 0.36233747678239747\n",
      "  Unweighted:\n",
      "  - F1: [0.46369138 0.47971145 0.66019417 0.58029979 0.44633731 0.29434547]\n",
      "  - Prec: [0.63523316 0.6440678  0.76836158 0.81381381 0.58093126 0.60509554]\n",
      "  - Rec [0.36509827 0.38218391 0.5787234  0.45091514 0.36237898 0.19447288]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3B.algorithm, crf3B.c1, crf3B.c2, crf3B.pa_type, crf3B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 2 None\n",
      "  Weighted:\n",
      "  - F1: 0.4648015025167207\n",
      "  - Prec: 0.6483430407678211\n",
      "  - Rec 0.36748106872410347\n",
      "  Unweighted:\n",
      "  - F1: [0.46373544 0.48826291 0.65876777 0.58201058 0.4467354  0.29439252]\n",
      "  - Prec: [0.62830957 0.64653641 0.74331551 0.7994186  0.58956916 0.61563518]\n",
      "  - Rec [0.36748064 0.39224138 0.59148936 0.45757072 0.35961272 0.19344933]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3C.algorithm, crf3C.c1, crf3C.c2, crf3C.pa_type, crf3C.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Weighted:\n",
      "  - F1: 0.4815200566676591\n",
      "  - Prec: 0.5175284691788858\n",
      "  - Rec 0.46506643806258036\n",
      "  Unweighted:\n",
      "  - F1: [0.45074415 0.48698438 0.6437247  0.59171598 0.51690294 0.38585209]\n",
      "  - Prec: [0.55643045 0.55022624 0.61389961 0.60137457 0.42664266 0.35      ]\n",
      "  - Rec [0.3787969  0.43678161 0.67659574 0.58236273 0.65560166 0.42988741]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4A.algorithm, crf4A.c1, crf4A.c2, crf4A.pa_type, crf4A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 0.5\n",
      "  Weighted:\n",
      "  - F1: 0.4947955715164867\n",
      "  - Prec: 0.5537045694622348\n",
      "  - Rec 0.44920702957565367\n",
      "  Unweighted:\n",
      "  - F1: [0.50312809 0.51784329 0.65154639 0.62031107 0.41166937 0.36140135]\n",
      "  - Prec: [0.56259205 0.56281619 0.632      0.68902439 0.49706458 0.45230769]\n",
      "  - Rec [0.45503276 0.47952586 0.67234043 0.5640599  0.35131397 0.30092119]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4B.algorithm, crf4B.c1, crf4B.c2, crf4B.pa_type, crf4B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model:** arow with variance=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"B\"></a>\n",
    "## Appendix B: Linguistic Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "\n",
    "Look for the highest-performing (based on F1 score) models by trying different algorithms and parameters.  Algorithms vailable with sklearn_crfsuite are:\n",
    " * 'lbfgs' - Gradient descent using the L-BFGS method\n",
    " * 'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
    " * 'ap' - Averaged Perceptron\n",
    " * 'pa' - Passive Aggressive (PA)\n",
    " * 'arow' - Adaptive Regularization Of Weight Vector (AROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "max_iters=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"tag_linguistic\"].unique()\n",
    "targets = [\n",
    "        'B-Gendered-Pronoun', 'I-Gendered-Pronoun', 'B-Generalization',\n",
    "        'I-Generalization', 'B-Gendered-Role', 'I-Gendered-Role'\n",
    "]\n",
    "f1_scorer = make_scorer(\n",
    "    metrics.flat_f1_score, average='None', \n",
    "    labels=targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf0A = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0, max_iterations=max_iters, all_possible_transitions=True) # unlimited iterations\n",
    "crf0B = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf0C = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf1A = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=1.0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 1000\n",
    "crf1B = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf2 = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "\n",
    "crf3A = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf3B = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf3C = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf4A = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=1, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf4B = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=0.5, max_iterations=max_iters, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0 None None None\n",
      "  Weighted:\n",
      "  - F1: 0.5220463286505957\n",
      "  - Prec: 0.6424500624544645\n",
      "  - Rec 0.4922135706340378\n",
      "  Unweighted:\n",
      "  - F1: [0.85307443 0.         0.00892857 0.         0.48390942 0.29530201]\n",
      "  - Prec: [0.81559406 0.         0.25       0.         0.74087591 0.6875    ]\n",
      "  - Rec [0.89416554 0.         0.00454545 0.         0.35929204 0.18803419]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0A.algorithm, crf0A.c1, crf0A.c2, crf0A.pa_type, crf0A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 None None None\n",
      "  Weighted:\n",
      "  - F1: 0.6083674858352446\n",
      "  - Prec: 0.7689434393136277\n",
      "  - Rec 0.60734149054505\n",
      "  Unweighted:\n",
      "  - F1: [0.87484511 0.         0.05286344 0.05298013 0.67586207 0.40993789]\n",
      "  - Prec: [0.8050171  0.         0.85714286 0.57142857 0.76222222 0.75      ]\n",
      "  - Rec [0.95793758 0.         0.02727273 0.02777778 0.60707965 0.28205128]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0B.algorithm, crf0B.c1, crf0B.c2, crf0B.pa_type, crf0B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 0.2 None None\n",
      "  Weighted:\n",
      "  - F1: 0.6427339974408373\n",
      "  - Prec: 0.7651587413557269\n",
      "  - Rec 0.6218020022246941\n",
      "  Unweighted:\n",
      "  - F1: [0.85677912 0.         0.28679245 0.15662651 0.6903164  0.41463415]\n",
      "  - Prec: [0.80695444 0.         0.84444444 0.59090909 0.75313808 0.72340426]\n",
      "  - Rec [0.91316147 0.         0.17272727 0.09027778 0.63716814 0.29059829]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0C.algorithm, crf0C.c1, crf0C.c2, crf0C.pa_type, crf0C.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 1.0 None None\n",
      "  Weighted:\n",
      "  - F1: 0.5811224023583894\n",
      "  - Prec: 0.6272431558647711\n",
      "  - Rec 0.5817575083426029\n",
      "  Unweighted:\n",
      "  - F1: [0.88389058 0.         0.         0.         0.62406816 0.34899329]\n",
      "  - Prec: [0.80066079 0.         0.         0.         0.78342246 0.8125    ]\n",
      "  - Rec [0.98643148 0.         0.         0.         0.51858407 0.22222222]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1A.algorithm, crf1A.c1, crf1A.c2, crf1A.pa_type, crf1A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 0.2 None None\n",
      "  Weighted:\n",
      "  - F1: 0.517290080102963\n",
      "  - Prec: 0.7148552332736035\n",
      "  - Rec 0.514460511679644\n",
      "  Unweighted:\n",
      "  - F1: [0.88242424 0.         0.00904977 0.         0.41344956 0.37735849]\n",
      "  - Prec: [0.7973713  0.         1.         0.         0.69747899 0.71428571]\n",
      "  - Rec [0.98778833 0.         0.00454545 0.         0.29380531 0.25641026]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1B.algorithm, crf1B.c1, crf1B.c2, crf1B.pa_type, crf1B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap None None None None\n",
      "  Weighted:\n",
      "  - F1: 0.6014970716276341\n",
      "  - Prec: 0.8224996619695852\n",
      "  - Rec 0.5912124582869855\n",
      "  Unweighted:\n",
      "  - F1: [0.87876923 0.64       0.07017544 0.10457516 0.63731656 0.28767123]\n",
      "  - Prec: [0.80405405 0.8        1.         0.88888889 0.781491   0.72413793]\n",
      "  - Rec [0.9687924  0.53333333 0.03636364 0.05555556 0.5380531  0.17948718]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf2.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf2.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf2.algorithm, crf2.c1, crf2.c2, crf2.pa_type, crf2.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 0 None\n",
      "  Weighted:\n",
      "  - F1: 0.6608095292949409\n",
      "  - Prec: 0.7676344251172861\n",
      "  - Rec 0.6551724137931034\n",
      "  Unweighted:\n",
      "  - F1: [0.88456865 0.69230769 0.29104478 0.23255814 0.67378641 0.40697674]\n",
      "  - Prec: [0.80088009 0.81818182 0.8125     0.71428571 0.74623656 0.63636364]\n",
      "  - Rec [0.98778833 0.6        0.17727273 0.13888889 0.61415929 0.2991453 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3A.algorithm, crf3A.c1, crf3A.c2, crf3A.pa_type, crf3A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 1 None\n",
      "  Weighted:\n",
      "  - F1: 0.6599815730795738\n",
      "  - Prec: 0.762389078290318\n",
      "  - Rec 0.6490545050055617\n",
      "  Unweighted:\n",
      "  - F1: [0.87945879 0.69230769 0.29927007 0.24277457 0.67249757 0.40462428]\n",
      "  - Prec: [0.80427447 0.81818182 0.75925926 0.72413793 0.74568966 0.625     ]\n",
      "  - Rec [0.97014925 0.6        0.18636364 0.14583333 0.61238938 0.2991453 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3B.algorithm, crf3B.c1, crf3B.c2, crf3B.pa_type, crf3B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 2 None\n",
      "  Weighted:\n",
      "  - F1: 0.6597046279568559\n",
      "  - Prec: 0.7595230166063811\n",
      "  - Rec 0.6490545050055617\n",
      "  Unweighted:\n",
      "  - F1: [0.87730061 0.69230769 0.30434783 0.25142857 0.67120623 0.4       ]\n",
      "  - Prec: [0.80067189 0.81818182 0.75       0.70967742 0.74514039 0.64150943]\n",
      "  - Rec [0.97014925 0.6        0.19090909 0.15277778 0.61061947 0.29059829]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3C.algorithm, crf3C.c1, crf3C.c2, crf3C.pa_type, crf3C.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Weighted:\n",
      "  - F1: 0.6586210838588668\n",
      "  - Prec: 0.6726122299605511\n",
      "  - Rec 0.664071190211346\n",
      "  Unweighted:\n",
      "  - F1: [0.87015385 0.54545455 0.28490028 0.27237354 0.66475645 0.48913043]\n",
      "  - Prec: [0.79617117 0.5        0.38167939 0.30973451 0.7219917  0.67164179]\n",
      "  - Rec [0.95929444 0.6        0.22727273 0.24305556 0.6159292  0.38461538]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4A.algorithm, crf4A.c1, crf4A.c2, crf4A.pa_type, crf4A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 0.5\n",
      "  Weighted:\n",
      "  - F1: 0.6488288150410274\n",
      "  - Prec: 0.6222010099532319\n",
      "  - Rec 0.6846496106785317\n",
      "  Unweighted:\n",
      "  - F1: [0.86294416 0.69230769 0.29045643 0.21761658 0.67236955 0.38541667]\n",
      "  - Prec: [0.81048868 0.81818182 0.26717557 0.17355372 0.65066225 0.49333333]\n",
      "  - Rec [0.92265943 0.6        0.31818182 0.29166667 0.69557522 0.31623932]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4B.algorithm, crf4B.c1, crf4B.c2, crf4B.pa_type, crf4B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model:** pa with pa_type=0; arow with variance=0.5 also has strong performance, and is strongest with other categories, Person Name and Contextual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"C\"></a>\n",
    "## Appendix C: Contextual Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "\n",
    "Look for the highest-performing (based on F1 score) models by trying different algorithms and parameters.  Algorithms vailable with sklearn_crfsuite are:\n",
    " * 'lbfgs' - Gradient descent using the L-BFGS method\n",
    " * 'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
    " * 'ap' - Averaged Perceptron\n",
    " * 'pa' - Passive Aggressive (PA)\n",
    " * 'arow' - Adaptive Regularization Of Weight Vector (AROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "max_iters=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"tag_contextual\"].unique()\n",
    "targets = [\n",
    "        'B-Occupation', 'I-Occupation', 'B-Stereotype',\n",
    "        'I-Stereotype', 'B-Omission', 'I-Omission'\n",
    "]\n",
    "f1_scorer = make_scorer(\n",
    "    metrics.flat_f1_score, average='None', \n",
    "    labels=targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf0A = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0, max_iterations=max_iters, all_possible_transitions=True) # unlimited iterations\n",
    "crf0B = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf0C = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf1A = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=1.0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 1000\n",
    "crf1B = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf2 = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "\n",
    "crf3A = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf3B = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf3C = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf4A = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=1, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf4B = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=0.5, max_iterations=max_iters, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0 None None None\n",
      "  Weighted:\n",
      "  - F1: 0.07526574269976748\n",
      "  - Prec: 0.3419825203723303\n",
      "  - Rec 0.04234527687296417\n",
      "  Unweighted:\n",
      "  - F1: [0.         0.         0.         0.         0.18710263 0.11749681]\n",
      "  - Prec: [0.         0.         0.         0.         0.76865672 0.58974359]\n",
      "  - Rec [0.         0.         0.         0.         0.10651499 0.06524823]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0A.algorithm, crf0A.c1, crf0A.c2, crf0A.pa_type, crf0A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 None None None\n",
      "  Weighted:\n",
      "  - F1: 0.27203523227916193\n",
      "  - Prec: 0.6341356146479743\n",
      "  - Rec 0.1780673181324647\n",
      "  Unweighted:\n",
      "  - F1: [0.27612903 0.25559105 0.11299435 0.16603774 0.48888889 0.1993205 ]\n",
      "  - Prec: [0.75352113 0.65934066 0.58823529 0.56410256 0.79672897 0.49438202]\n",
      "  - Rec [0.16903633 0.15852048 0.0625     0.09734513 0.35263702 0.1248227 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0B.algorithm, crf0B.c1, crf0B.c2, crf0B.pa_type, crf0B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 0.2 None None\n",
      "  Weighted:\n",
      "  - F1: 0.36974453222807907\n",
      "  - Prec: 0.6650245193879263\n",
      "  - Rec 0.2625407166123778\n",
      "  Unweighted:\n",
      "  - F1: [0.47764449 0.42293907 0.16304348 0.22738386 0.53013699 0.27465536]\n",
      "  - Prec: [0.77112676 0.65738162 0.625      0.66428571 0.78498986 0.54411765]\n",
      "  - Rec [0.34597156 0.31175694 0.09375    0.13716814 0.40020683 0.18368794]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0C.algorithm, crf0C.c1, crf0C.c2, crf0C.pa_type, crf0C.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 1.0 None None\n",
      "  Weighted:\n",
      "  - F1: 0.14238250038533273\n",
      "  - Prec: 0.6949935082632666\n",
      "  - Rec 0.08534201954397394\n",
      "  Unweighted:\n",
      "  - F1: [0.01253918 0.01308901 0.02325581 0.05890603 0.33637117 0.1907061 ]\n",
      "  - Prec: [0.8        0.71428571 0.16666667 0.6        0.84583333 0.63967611]\n",
      "  - Rec [0.00631912 0.00660502 0.0125     0.03097345 0.20992761 0.11205674]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1A.algorithm, crf1A.c1, crf1A.c2, crf1A.pa_type, crf1A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 0.2 None None\n",
      "  Weighted:\n",
      "  - F1: 0.23290156335890247\n",
      "  - Prec: 0.587957004746522\n",
      "  - Rec 0.16547231270358306\n",
      "  Unweighted:\n",
      "  - F1: [0.03703704 0.06532663 0.17894737 0.16252822 0.51733333 0.25569358]\n",
      "  - Prec: [0.8        0.66666667 0.56666667 0.34615385 0.72795497 0.47318008]\n",
      "  - Rec [0.01895735 0.0343461  0.10625    0.10619469 0.40124095 0.1751773 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1B.algorithm, crf1B.c1, crf1B.c2, crf1B.pa_type, crf1B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap None None None None\n",
      "  Weighted:\n",
      "  - F1: 0.22686387330210564\n",
      "  - Prec: 0.8443018920394695\n",
      "  - Rec 0.14505971769815418\n",
      "  Unweighted:\n",
      "  - F1: [0.26168224 0.20303384 0.02453988 0.03478261 0.49893086 0.15275995]\n",
      "  - Prec: [0.84482759 0.87       0.66666667 1.         0.80275229 0.80405405]\n",
      "  - Rec [0.15481833 0.11492734 0.0125     0.01769912 0.36194416 0.08439716]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf2.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf2.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf2.algorithm, crf2.c1, crf2.c2, crf2.pa_type, crf2.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 0 None\n",
      "  Weighted:\n",
      "  - F1: 0.306310049934223\n",
      "  - Prec: 0.80194162836387\n",
      "  - Rec 0.20781758957654722\n",
      "  Unweighted:\n",
      "  - F1: [0.45810056 0.32640333 0.08284024 0.04329004 0.5375603  0.22061483]\n",
      "  - Prec: [0.78244275 0.76585366 0.77777778 1.         0.80578512 0.73493976]\n",
      "  - Rec [0.32385466 0.20739762 0.04375    0.02212389 0.4033092  0.12978723]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3A.algorithm, crf3A.c1, crf3A.c2, crf3A.pa_type, crf3A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 1 None\n",
      "  Weighted:\n",
      "  - F1: 0.30799201369715534\n",
      "  - Prec: 0.8058167663636654\n",
      "  - Rec 0.20868621064060802\n",
      "  Unweighted:\n",
      "  - F1: [0.45240761 0.32432432 0.08284024 0.04892086 0.5399449  0.22543701]\n",
      "  - Prec: [0.77692308 0.76097561 0.77777778 1.         0.80824742 0.75100402]\n",
      "  - Rec [0.31911532 0.20607662 0.04375    0.02507375 0.40537746 0.13262411]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3B.algorithm, crf3B.c1, crf3B.c2, crf3B.pa_type, crf3B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 2 None\n",
      "  Weighted:\n",
      "  - F1: 0.30804522569488546\n",
      "  - Prec: 0.809491042440604\n",
      "  - Rec 0.20912052117263843\n",
      "  Unweighted:\n",
      "  - F1: [0.46784922 0.32398754 0.08333333 0.04610951 0.53830228 0.22128174]\n",
      "  - Prec: [0.78438662 0.75728155 0.875      1.         0.80912863 0.75      ]\n",
      "  - Rec [0.33333333 0.20607662 0.04375    0.02359882 0.4033092  0.12978723]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3C.algorithm, crf3C.c1, crf3C.c2, crf3C.pa_type, crf3C.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Weighted:\n",
      "  - F1: 0.36669929570944\n",
      "  - Prec: 0.40929601777426833\n",
      "  - Rec 0.3355048859934853\n",
      "  Unweighted:\n",
      "  - F1: [0.6036036  0.5095057  0.24512535 0.24287653 0.37733645 0.24971537]\n",
      "  - Prec: [0.70230608 0.60035842 0.22110553 0.22487437 0.43355705 0.26857143]\n",
      "  - Rec [0.52922591 0.44253633 0.275      0.2640118  0.33402275 0.23333333]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4A.algorithm, crf4A.c1, crf4A.c2, crf4A.pa_type, crf4A.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 0.5\n",
      "  Weighted:\n",
      "  - F1: 0.3925447072732632\n",
      "  - Prec: 0.43471962523819374\n",
      "  - Rec 0.36503800217155263\n",
      "  Unweighted:\n",
      "  - F1: [0.57769653 0.50433526 0.21782178 0.22643746 0.42546064 0.32653061]\n",
      "  - Prec: [0.68546638 0.55661882 0.18032787 0.18929633 0.46237864 0.38461538]\n",
      "  - Rec [0.49921011 0.46103038 0.275      0.28171091 0.39400207 0.28368794]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4B.algorithm, crf4B.c1, crf4B.c2, crf4B.pa_type, crf4B.variance)\n",
    "print(\"  Weighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  Unweighted:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model:** arow with variance=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A\"></a>\n",
    "## Appendix D: Person Name + Occupation Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "\n",
    "Look for the highest-performing (based on F1 score) models by trying different algorithms and parameters.  Algorithms vailable with sklearn_crfsuite are:\n",
    " * 'lbfgs' - Gradient descent using the L-BFGS method\n",
    " * 'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
    " * 'ap' - Averaged Perceptron\n",
    " * 'pa' - Passive Aggressive (PA)\n",
    " * 'arow' - Adaptive Regularization Of Weight Vector (AROW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_perso\n",
    "df_dev = df_dev_perso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by token, so the all the tags for one token are recorded in a list for that token's row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by sentence, where each sentence is a list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O               144035\n",
       "I-Unknown         3062\n",
       "B-Unknown         1886\n",
       "I-Masculine       1240\n",
       "B-Masculine        968\n",
       "I-Occupation       781\n",
       "I-Feminine         675\n",
       "B-Occupation       654\n",
       "B-Feminine         281\n",
       "Name: tag_personname, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_perso.tag_personname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Title', 'NN', ['O']), (':', ':', ['O']), ('Papers', 'NNS', ['O'])]\n",
      "[('After', 'IN', ['O']), ('his', 'PRP$', ['O']), ('ordination', 'NN', ['O'])]\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_personname\")\n",
    "print(train_sentences_ling[0][:3])\n",
    "dev_sentences = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_personname\")\n",
    "print(dev_sentences[0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "max_iters=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine', 'B-Masculine', 'B-Occupation', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Occupation', 'I-Unknown']\n"
     ]
    }
   ],
   "source": [
    "targets = perso_cat_tags\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the individual tag scores are reported in alphabetical order as they are listed above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf0A = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0, max_iterations=max_iters, all_possible_transitions=True) # unlimited iterations\n",
    "crf0B = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf0C = sklearn_crfsuite.CRF(algorithm=algorithms[0], c1=0.1, c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf1A = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=1.0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 1000\n",
    "crf1B = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf2 = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "\n",
    "crf3A = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=0, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf3B = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=1, max_iterations=max_iters, all_possible_transitions=True)\n",
    "crf3C = sklearn_crfsuite.CRF(algorithm=algorithms[3], pa_type=2, max_iterations=max_iters, all_possible_transitions=True)\n",
    "\n",
    "crf4A = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=1, max_iterations=max_iters, all_possible_transitions=True) # max iters: 100\n",
    "crf4B = sklearn_crfsuite.CRF(algorithm=algorithms[4], variance=0.5, max_iterations=max_iters, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0 None None None\n",
      "  Macro:\n",
      "  - F1: 0.11806056283047392\n",
      "  - Prec: 0.4043996591038267\n",
      "  - Rec 0.07129545254147415\n",
      "  Micro:\n",
      "  - F1: 0.1202252944188428\n",
      "  - Prec: 0.43643122676579926\n",
      "  - Rec 0.06971496437054632\n",
      "  Per Label:\n",
      "  - F1: [0.19259259 0.20689655 0.00304878 0.09503916 0.11994003 0.19811321\n",
      " 0.00251256 0.12634161]\n",
      "  - Prec: [0.74285714 0.46601942 0.125      0.38396624 0.60606061 0.42567568\n",
      " 0.05555556 0.43006263]\n",
      "  - Rec [0.1106383  0.13296399 0.00154321 0.05423123 0.06655574 0.12909836\n",
      " 0.00128535 0.07404745]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0A.algorithm, crf0A.c1, crf0A.c2, crf0A.pa_type, crf0A.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 None None None\n",
      "  Macro:\n",
      "  - F1: 0.4019058883799401\n",
      "  - Prec: 0.647656187601269\n",
      "  - Rec 0.30500624658036857\n",
      "  Micro:\n",
      "  - F1: 0.3995488964072821\n",
      "  - Prec: 0.6209313970956435\n",
      "  - Rec 0.29453681710213775\n",
      "  Per Label:\n",
      "  - F1: [0.57356608 0.40512821 0.28498728 0.38471023 0.49947313 0.35170604\n",
      " 0.28218332 0.43349282]\n",
      "  - Prec: [0.69277108 0.52901786 0.8115942  0.61986755 0.68103448 0.48905109\n",
      " 0.70984456 0.64806867]\n",
      "  - Rec [0.4893617  0.32825485 0.17283951 0.27890346 0.39434276 0.27459016\n",
      " 0.17609254 0.32566499]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0B.algorithm, crf0B.c1, crf0B.c2, crf0B.pa_type, crf0B.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs 0.1 0.2 None None\n",
      "  Macro:\n",
      "  - F1: 0.4966810338805706\n",
      "  - Prec: 0.6569351509464121\n",
      "  - Rec 0.40417134541234684\n",
      "  Micro:\n",
      "  - F1: 0.47962591850367403\n",
      "  - Prec: 0.6394221254700179\n",
      "  - Rec 0.383729216152019\n",
      "  Per Label:\n",
      "  - F1: [0.65550239 0.41196013 0.4978903  0.45596645 0.62535748 0.34590377\n",
      " 0.47733105 0.50353669]\n",
      "  - Prec: [0.74863388 0.51452282 0.78666667 0.63280423 0.73214286 0.47330961\n",
      " 0.71355499 0.65384615]\n",
      "  - Rec [0.58297872 0.3434903  0.36419753 0.35637664 0.54575707 0.27254098\n",
      " 0.35861183 0.40941769]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf0C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf0C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf0C.algorithm, crf0C.c1, crf0C.c2, crf0C.pa_type, crf0C.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 1.0 None None\n",
      "  Macro:\n",
      "  - F1: 0.349324614839451\n",
      "  - Prec: 0.6810710834972303\n",
      "  - Rec 0.2613987831635396\n",
      "  Micro:\n",
      "  - F1: 0.3216942329570316\n",
      "  - Prec: 0.6112404389757233\n",
      "  - Rec 0.2182897862232779\n",
      "  Per Label:\n",
      "  - F1: [0.58221024 0.45285935 0.19099591 0.246139   0.4950495  0.37765634\n",
      " 0.16397229 0.28571429]\n",
      "  - Prec: [0.79411765 0.51223776 0.82352941 0.64720812 0.73051948 0.46348733\n",
      " 0.80681818 0.67065073]\n",
      "  - Rec [0.45957447 0.40581717 0.10802469 0.15196663 0.37437604 0.31864754\n",
      " 0.09125964 0.18152408]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1A.algorithm, crf1A.c1, crf1A.c2, crf1A.pa_type, crf1A.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2sgd None 0.2 None None\n",
      "  Macro:\n",
      "  - F1: 0.34286973415639593\n",
      "  - Prec: 0.662314589957276\n",
      "  - Rec 0.24484063837773637\n",
      "  Micro:\n",
      "  - F1: 0.3241336742791641\n",
      "  - Prec: 0.6292365628209518\n",
      "  - Rec 0.2182897862232779\n",
      "  Per Label:\n",
      "  - F1: [0.57526882 0.38923767 0.1972973  0.33727551 0.46614872 0.29356471\n",
      " 0.17508418 0.30908096]\n",
      "  - Prec: [0.7810219  0.55216285 0.79347826 0.63636364 0.7        0.4987715\n",
      " 0.69026549 0.64645309]\n",
      "  - Rec [0.45531915 0.30055402 0.11265432 0.22943981 0.34941764 0.2079918\n",
      " 0.10025707 0.2030913 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf1B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf1B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf1B.algorithm, crf1B.c1, crf1B.c2, crf1B.pa_type, crf1B.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap None None None None\n",
      "  Macro:\n",
      "  - F1: 0.42742563294382585\n",
      "  - Prec: 0.6790362476324592\n",
      "  - Rec 0.33416246546919387\n",
      "  Micro:\n",
      "  - F1: 0.41287817505258045\n",
      "  - Prec: 0.6473871131405378\n",
      "  - Rec 0.3030878859857482\n",
      "  Per Label:\n",
      "  - F1: [0.63636364 0.46992783 0.36682243 0.43791103 0.57471264 0.31905465\n",
      " 0.21252796 0.40208488]\n",
      "  - Prec: [0.68292683 0.55809524 0.75480769 0.62403528 0.77247191 0.57142857\n",
      " 0.81896552 0.64955894]\n",
      "  - Rec [0.59574468 0.40581717 0.24228395 0.33730632 0.45757072 0.22131148\n",
      " 0.12210797 0.29115744]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf2.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf2.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf2.algorithm, crf2.c1, crf2.c2, crf2.pa_type, crf2.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 0 None\n",
      "  Macro:\n",
      "  - F1: 0.4784699483902634\n",
      "  - Prec: 0.6952382695543528\n",
      "  - Rec 0.37839935128012814\n",
      "  Micro:\n",
      "  - F1: 0.4751027866605756\n",
      "  - Prec: 0.6618582944420874\n",
      "  - Rec 0.37054631828978624\n",
      "  Per Label:\n",
      "  - F1: [0.65566038 0.46666667 0.47739222 0.48789435 0.58016878 0.31363636\n",
      " 0.3401222  0.50621863]\n",
      "  - Prec: [0.73544974 0.58577406 0.74917492 0.63454198 0.7925072  0.60174419\n",
      " 0.81862745 0.64408662]\n",
      "  - Rec [0.59148936 0.38781163 0.35030864 0.39630513 0.45757072 0.21209016\n",
      " 0.21465296 0.41696621]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3A.algorithm, crf3A.c1, crf3A.c2, crf3A.pa_type, crf3A.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 1 None\n",
      "  Macro:\n",
      "  - F1: 0.4830839994843489\n",
      "  - Prec: 0.6936733090977836\n",
      "  - Rec 0.38455668657324876\n",
      "  Micro:\n",
      "  - F1: 0.47600913937547606\n",
      "  - Prec: 0.6634819532908705\n",
      "  - Rec 0.37114014251781474\n",
      "  Per Label:\n",
      "  - F1: [0.67132867 0.46422629 0.48856549 0.48803828 0.60474716 0.30335366\n",
      " 0.34210526 0.50230719]\n",
      "  - Prec: [0.74226804 0.58125    0.74840764 0.63811357 0.79619565 0.5922619\n",
      " 0.8047619  0.64612776]\n",
      "  - Rec [0.61276596 0.38642659 0.36265432 0.39511323 0.4875208  0.20389344\n",
      " 0.21722365 0.4108555 ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3B.algorithm, crf3B.c1, crf3B.c2, crf3B.pa_type, crf3B.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa None None 2 None\n",
      "  Macro:\n",
      "  - F1: 0.4773530017269165\n",
      "  - Prec: 0.696614533193446\n",
      "  - Rec 0.3761656310189457\n",
      "  Micro:\n",
      "  - F1: 0.4739488117001828\n",
      "  - Prec: 0.6607901444350043\n",
      "  - Rec 0.3694774346793349\n",
      "  Per Label:\n",
      "  - F1: [0.65393795 0.45923461 0.48580442 0.49176729 0.57142857 0.31268882\n",
      " 0.34046891 0.50349345]\n",
      "  - Prec: [0.74456522 0.575      0.76237624 0.63696682 0.79525223 0.59482759\n",
      " 0.8226601  0.64126808]\n",
      "  - Rec [0.58297872 0.38227147 0.35648148 0.40047676 0.44592346 0.21209016\n",
      " 0.21465296 0.41445004]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf3C.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf3C.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf3C.algorithm, crf3C.c1, crf3C.c2, crf3C.pa_type, crf3C.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Macro:\n",
      "  - F1: 0.5133300275449454\n",
      "  - Prec: 0.5378413835501588\n",
      "  - Rec 0.5040420010135154\n",
      "  Micro:\n",
      "  - F1: 0.49219892735251103\n",
      "  - Prec: 0.5055082623935904\n",
      "  - Rec 0.4795724465558195\n",
      "  Per Label:\n",
      "  - F1: [0.61075269 0.49718222 0.60491803 0.50335121 0.58477157 0.38247012\n",
      " 0.42766631 0.49552807]\n",
      "  - Prec: [0.6173913  0.45371429 0.6451049  0.57503828 0.75       0.37209302\n",
      " 0.36290323 0.52648605]\n",
      "  - Rec [0.60425532 0.5498615  0.56944444 0.44755662 0.47920133 0.39344262\n",
      " 0.52056555 0.46800863]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4A.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4A.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4A.algorithm, crf4A.c1, crf4A.c2, crf4A.pa_type, crf4A.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 0.5\n",
      "  Macro:\n",
      "  - F1: 0.48948765405359684\n",
      "  - Prec: 0.5048488465375063\n",
      "  - Rec 0.4791669431025771\n",
      "  Micro:\n",
      "  - F1: 0.4660059339688151\n",
      "  - Prec: 0.49737232178951624\n",
      "  - Rec 0.43836104513064134\n",
      "  Per Label:\n",
      "  - F1: [0.62985685 0.37897469 0.6215781  0.47994697 0.49915966 0.36127637\n",
      " 0.49381188 0.45129671]\n",
      "  - Prec: [0.60629921 0.35653236 0.64983165 0.54070202 0.50424448 0.38258877\n",
      " 0.47613365 0.52245863]\n",
      "  - Rec [0.65531915 0.40443213 0.59567901 0.43146603 0.49417637 0.34221311\n",
      " 0.51285347 0.39719626]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf4B.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict\n",
    "y_pred = crf4B.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "print(crf4B.algorithm, crf4B.c1, crf4B.c2, crf4B.pa_type, crf4B.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model:** AROW with variance=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

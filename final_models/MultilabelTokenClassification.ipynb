{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f4a1b9-3ca3-4bc1-8550-86d4a1ecea7f",
   "metadata": {},
   "source": [
    "# Multilabel Token Classification\n",
    "## Experiments 1 and 2, Model 1\n",
    "## Classification of Linguistic labels: *Gendered Pronoun*, *Gendered Role*, *Generalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32487bc-2de3-4c9d-9214-7c45b3e73981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For word embeddings\n",
    "from gensim.models import FastText #, Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "from gensim import utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# For multilabel token classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For saving model\n",
    "import joblib\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c511793-443c-4269-a5be-d8d786d06e51",
   "metadata": {},
   "source": [
    "### 1. Create Word Embeddings\n",
    "\n",
    "Train custom word embeddings on metadata descriptions from the University of Edinburgh Heritage Collections' Archives catalog.\n",
    "\n",
    "* Data file: `descriptions_by_fonds`\n",
    "* Date of harvesting: October 2020\n",
    "* Harvesting and transformation code: [annot-prep/PreparationForAnnotation.ipynb](https://github.com/thegoose20/annot-prep/blob/main/PreparationForAnnotation.ipynb)\n",
    "\n",
    "References:\n",
    "* https://radimrehurek.com/gensim/models/fasttext.html\n",
    "* https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd03ebe8-49d1-43ad-94ff-3da0dcc527d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n"
     ]
    }
   ],
   "source": [
    "dir_path = config.inf_data_path+\"descriptions_by_fonds/\"\n",
    "file_list = os.listdir(dir_path)\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b67881f6-9439-40ec-b6b8-19df4fdddf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusIterator:\n",
    "    def __iter__(self):\n",
    "        file_list = os.listdir(dir_path)\n",
    "        for fonds_f in file_list:\n",
    "            assert \".txt\" in fonds_f, \"All files should be Plaintext.\" \n",
    "            file_path = dir_path+fonds_f\n",
    "            with utils.open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    # Lowercase the tokens\n",
    "                    yield list(tokenize(line.lower()))   #list(tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c3002-fb91-4e87-8617-2935cdd9dafb",
   "metadata": {},
   "source": [
    "Define the hyperparameters for the unsupervised training of the fastText model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b1fde27-8585-4b04-b780-1048b8cfd5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training architecture (default = \"cbow\" for Continuous Bag of Words)\n",
    "training_arch = \"cbow\"  #\"skipgram\n",
    "# Specify the learning rate (default = 0.025)\n",
    "alpha = 0.025\n",
    "# Specify the training objective (default = \"ns\")\n",
    "# losses = [\"ns\", \"hs\", \"softmax\"]\n",
    "# loss = losses[0]\n",
    "# Specify the number of negative words to sample for 'ns' training objective (default = 5)\n",
    "negative = 5\n",
    "# Specify the threshold for downsampling higher-frequency words (default = 0.001)\n",
    "sample = 0.001\n",
    "# Specify the word embeddings' dimensions\n",
    "vector_dimensions = 100 #50 #300\n",
    "# Specify the context window (default is 5) \n",
    "context_window = 5\n",
    "# Specify the number of epochs (default is 5)\n",
    "epochs = 5\n",
    "# Specify the threshold of word occurrences (ignore words that occur less than specified number of times; default = 5)\n",
    "min_count = 5\n",
    "# Specify the minimum and maximum length of character ngrams (defaults are 3 and 6)\n",
    "min_n = 2\n",
    "max_n = 6  # if 0, no character n-grams (subword vectors) will be used\n",
    "# Specify the number of buckets for hashing ngrams (default = 2000000) \n",
    "bucket = 2000000\n",
    "# Sort vocabulary by descending frequency (default = 1)\n",
    "sorted_vocab = 1\n",
    "# Specify the number of threads to use (default = 12)\n",
    "# threads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b9da24c-445d-4f65-ae8d-e568cfa0cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = FastText(\n",
    "    alpha=alpha, negative=negative, sample=sample,\n",
    "    vector_size=vector_dimensions, window=context_window, \n",
    "    epochs=epochs, min_count=min_count, min_n=min_n, \n",
    "    max_n=max_n, bucket=bucket, sorted_vocab=sorted_vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8128ca7-da29-48aa-835d-135693ac967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.build_vocab(corpus_iterable=CorpusIterator())\n",
    "total_examples = embedding_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29711eff-e772-4695-8b23-fbda6a0de3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7322568, 10119275)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.train(corpus_iterable=CorpusIterator(), total_examples=total_examples, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d241752-ace9-4414-a6f4-5c4091e78e0f",
   "metadata": {},
   "source": [
    "Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "700be198-0cd4-4989-828d-1f98de91ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext_cbow_100d.model\n"
     ]
    }
   ],
   "source": [
    "file_name = \"fasttext_{a}_{d}d.model\".format(a=training_arch, d=vector_dimensions)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59085d52-4a82-43ca-9f02-b707c6909c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.save(\"models/\"+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba6b31-317d-4afc-8e12-fb2d344703fe",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfb613e-cffa-47e5-bb98-6e38f02ac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data = config.exp_data_path+\"token_5fold.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffa0a75-008c-4ead-8667-7e8b7a294b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id       token token_offsets  \\\n",
       "0               0            0   99999         0  Identifier       (0, 10)   \n",
       "1               0            0   99999         1           :      (10, 11)   \n",
       "2               0            0   99999         2         AA5      (12, 15)   \n",
       "3               1            1   99999         3       Title      (17, 22)   \n",
       "4               1            1   99999         4           :      (22, 23)   \n",
       "\n",
       "  pos tag       field    fold  \n",
       "0  NN   O  Identifier  split4  \n",
       "1   :   O  Identifier  split4  \n",
       "2  NN   O  Identifier  split4  \n",
       "3  NN   O       Title  split2  \n",
       "4   :   O       Title  split2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(token_data, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74999926-cad3-4589-9273-3b0987d5ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_tags = [\"B-Generalization\", \"I-Generalization\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f33439a-f2ab-47b2-a5e4-af28d61cdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_consider = ling_tags\n",
    "col = \"tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4793b2d0-57ca-47b8-a58e-100129fcb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implodeDataFrame(df, cols_to_groupby):\n",
    "    cols_to_agg = list(df.columns)\n",
    "    for col in cols_to_groupby:\n",
    "        cols_to_agg.remove(col)\n",
    "    agg_dict = dict.fromkeys(cols_to_agg, lambda x: x.tolist())\n",
    "    return df.groupby(cols_to_groupby).agg(agg_dict).reset_index().set_index(cols_to_groupby)\n",
    "\n",
    "def preprocessTokenData(df, col, label_list):\n",
    "    initial_shape = df.shape\n",
    "    # Change any tags not in label_list to \"O\"\n",
    "    df_l = df.loc[df[col].isin(label_list)]\n",
    "    df_o = df.loc[~df[col].isin(label_list)]\n",
    "    df_o = df_o.drop(columns=[col])\n",
    "    df_o.insert(len(df_o.columns), col, ([\"O\"]*(df_o.shape[0])))\n",
    "    df = pd.concat([df_l, df_o])\n",
    "    df = df.sort_values(by=\"token_id\")\n",
    "    assert initial_shape == df.shape, \"The DataFrame should have the same number of rows and columns after changing select column values.\"\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Replace tags with labels, removing \"B-\" and \"I-\" from the start of the tags\n",
    "    old_col = df[col]\n",
    "    new_col = [tag[2:] if tag != \"O\" else tag for tag in old_col]\n",
    "    df = df.drop(columns=[col])\n",
    "    df.insert((len(df.columns)-2), col, new_col)\n",
    "    \n",
    "    # Group by token, so there's one row per token and lists of tags for each token\n",
    "    df = implodeDataFrame(df, [\n",
    "        \"description_id\", \"sentence_id\", \"token_id\", \"token\", \"pos\", \"field\", \"token_offsets\", \"fold\"\n",
    "    ])\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Deduplicate tag lists and remove any \"O\" tags from lists with other values\n",
    "    old_col = list(df[col])\n",
    "    dedup_col = [list(set(value_list)) for value_list in old_col]\n",
    "    assert len(old_col) == len(dedup_col), \"The column should have the same number of rows.\"\n",
    "    new_col = []\n",
    "    for col_list in dedup_col:\n",
    "        if (\"O\" in col_list) and (len(col_list) > 1):\n",
    "            col_list.remove(\"O\")\n",
    "        col_list.sort()\n",
    "        new_col += [col_list]\n",
    "    assert len(new_col) == len(old_col), \"The column should have the same number of rows.\"\n",
    "    df = df.drop(columns=[col])\n",
    "    df.insert((len(df.columns)-2), col, new_col)\n",
    "    \n",
    "    return df  #.explode([col])  # one tag-token pair per row, tokens can repeat across rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360c5223-6ca5-4821-a92a-82e9524702c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token pos       field  \\\n",
       "0               0            0         0  Identifier  NN  Identifier   \n",
       "1               0            0         1           :   :  Identifier   \n",
       "2               0            0         2         AA5  NN  Identifier   \n",
       "3               1            1         3       Title  NN       Title   \n",
       "4               1            1         4           :   :       Title   \n",
       "\n",
       "  token_offsets  tag    fold   ann_id  \n",
       "0       (0, 10)  [O]  split4  [99999]  \n",
       "1      (10, 11)  [O]  split4  [99999]  \n",
       "2      (12, 15)  [O]  split4  [99999]  \n",
       "3      (17, 22)  [O]  split2  [99999]  \n",
       "4      (22, 23)  [O]  split2  [99999]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocessTokenData(df, col, labels_to_consider)\n",
    "df = df.sort_values(by=\"token_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddfbc71a-2f83-48cc-bac5-7cf21befd845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                                   744728\n",
       "[Gendered-Pronoun]                      3624\n",
       "[Gendered-Role]                         3151\n",
       "[Generalization]                        1808\n",
       "[Gendered-Pronoun, Generalization]       107\n",
       "[Gendered-Role, Generalization]          103\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03315648-56ad-47fc-b0ee-b011b17a4987",
   "metadata": {},
   "source": [
    "### 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3025def-a99c-4470-a376-4278ce441db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText.load(config.fasttext_path+\"fasttext_cbow_100d.model\")\n",
    "def getFeatures(df, embedding_model=ft_model, feature_cols=[\"token_id\", \"token\"]):\n",
    "    # Zip the features\n",
    "    feature_data = list(zip(df[feature_cols[0]], df[feature_cols[1]]))\n",
    "    \n",
    "    # Make FastText feature matrix\n",
    "    feature_list = [embedding_model.wv[token.lower()] for token_id,token in feature_data]\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190ee20-a1fd-4678-b16c-594013de6230",
   "metadata": {},
   "source": [
    "Define the five splits of the data to combine iteratively into training and test sets using five-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a04589-e7cd-48b3-883b-b18199f7cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['split0' 'split1' 'split2' 'split3' 'split4']\n"
     ]
    }
   ],
   "source": [
    "split_col = \"fold\"\n",
    "splits = df[split_col].unique()\n",
    "splits.sort()\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14bd54df-1ae3-4ff9-8685-621fbb726c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train0, test0 = list(splits[:4]), splits[4]\n",
    "train1, test1 = list(splits[1:]), splits[0]\n",
    "train2, test2 = list(splits[2:])+[splits[0]], splits[1]\n",
    "train3, test3 = list(splits[3:])+list(splits[:2]), splits[2]\n",
    "train4, test4 = [splits[4]]+list(splits[:3]), splits[3]\n",
    "runs = [(train0, test0), (train1, test1), (train2, test2), (train3, test3), (train4, test4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4844299a-8de9-4e2c-a473-de4c750a4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits, test_split = runs[-1][0], runs[-1][1]\n",
    "df_train = df.loc[df[split_col].isin(train_splits)]\n",
    "df_test = df.loc[df[split_col] == test_split]\n",
    "assert df.shape[0] == df_train.shape[0] + df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "370a0f33-02b7-4b89-839d-e7c65407912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = getFeatures(df_train)\n",
    "X_test = getFeatures(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af8bc054-7eb3-425e-b352-5b619b690599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun' 'Gendered-Role' 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([[\"Gendered-Pronoun\", \"Gendered-Role\", \"Generalization\"]])\n",
    "y_train = mlb.transform(df_train[col])\n",
    "y_test = mlb.transform(df_test[col])\n",
    "print(mlb.classes_)\n",
    "# print((df_test[col])[:10])\n",
    "# print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41938255-1247-4c8a-bfdc-4a67d2248dcd",
   "metadata": {},
   "source": [
    "### 4. Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dc19a7c-78c5-4061-8d07-2d74ec39a80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ClassifierChain(\n",
    "    classifier = RandomForestClassifier(random_state=22),\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af9367-eabc-4c09-acb3-4b3cf91f5a92",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b217bf9d-6e9a-489d-9427-5ad4c005bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85082481-6b66-4d1e-a0ff-0fbfe8b3a3a7",
   "metadata": {},
   "source": [
    "Export the data with the predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447bfae8-b7d7-475a-aef9-72dd60147ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['Gendered-Pronoun'], ['O'], ['Gendered-Pronoun'], ['O']]\n"
     ]
    }
   ],
   "source": [
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "print(new_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bedba21-db12-4bc6-89f5-59f6358600cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(907, 912)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split3</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(913, 916)</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>split3</td>\n",
       "      <td>[14379]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(917, 927)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split3</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(928, 930)</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>split3</td>\n",
       "      <td>[14380]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(931, 936)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split3</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id  sentence_id  token_id       token   pos  \\\n",
       "154               3            5       154       After    IN   \n",
       "155               3            5       155         his  PRP$   \n",
       "156               3            5       156  ordination    NN   \n",
       "157               3            5       157          he   PRP   \n",
       "158               3            5       158       spent   VBD   \n",
       "\n",
       "                         field token_offsets                 tag    fold  \\\n",
       "154  Biographical / Historical    (907, 912)                 [O]  split3   \n",
       "155  Biographical / Historical    (913, 916)  [Gendered-Pronoun]  split3   \n",
       "156  Biographical / Historical    (917, 927)                 [O]  split3   \n",
       "157  Biographical / Historical    (928, 930)  [Gendered-Pronoun]  split3   \n",
       "158  Biographical / Historical    (931, 936)                 [O]  split3   \n",
       "\n",
       "      ann_id           predicted  \n",
       "154  [99999]                 [O]  \n",
       "155  [14379]  [Gendered-Pronoun]  \n",
       "156  [99999]                 [O]  \n",
       "157  [14380]  [Gendered-Pronoun]  \n",
       "158  [99999]                 [O]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.insert(len(df.columns), \"predicted\", new_preds)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22f3135d-b8fb-4051-897f-096a5ed482cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                   150820\n",
       "[Gendered-Pronoun]       913\n",
       "[Gendered-Role]          620\n",
       "[Generalization]         102\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b89ba10-c521-4a06-b835-6e4ceed59ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_test.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_test.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0edc63ba-0d97-42fd-b835-d2931c3a6563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(907, 912)</td>\n",
       "      <td>O</td>\n",
       "      <td>split3</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(913, 916)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>split3</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(917, 927)</td>\n",
       "      <td>O</td>\n",
       "      <td>split3</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(928, 930)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>split3</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(931, 936)</td>\n",
       "      <td>O</td>\n",
       "      <td>split3</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token   pos  \\\n",
       "0               3            5       154       After    IN   \n",
       "1               3            5       155         his  PRP$   \n",
       "2               3            5       156  ordination    NN   \n",
       "3               3            5       157          he   PRP   \n",
       "4               3            5       158       spent   VBD   \n",
       "\n",
       "                       field token_offsets               tag    fold  \\\n",
       "0  Biographical / Historical    (907, 912)                 O  split3   \n",
       "1  Biographical / Historical    (913, 916)  Gendered-Pronoun  split3   \n",
       "2  Biographical / Historical    (917, 927)                 O  split3   \n",
       "3  Biographical / Historical    (928, 930)  Gendered-Pronoun  split3   \n",
       "4  Biographical / Historical    (931, 936)                 O  split3   \n",
       "\n",
       "          predicted         _merge  \n",
       "0                 O  true negative  \n",
       "1  Gendered-Pronoun  true positive  \n",
       "2                 O  true negative  \n",
       "3  Gendered-Pronoun  true positive  \n",
       "4                 O  true negative  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "# Add the predicted tags to the DataFrame with expected tags\n",
    "exp_pred_df = pd.merge(\n",
    "    left=exp_df, \n",
    "    right=pred_df, \n",
    "    how=\"outer\",\n",
    "    left_on=left_on_cols,\n",
    "    right_on=right_on_cols,\n",
    "    suffixes=[\"\", \"_pred\"],\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Replace any NaN values with \"O\" to indicate no predicted tag\n",
    "exp_pred_df[exp_col] = exp_pred_df[exp_col].fillna(no_tag_value)\n",
    "exp_pred_df[pred_col] = exp_pred_df[pred_col].fillna(no_tag_value)\n",
    "\n",
    "# Find true negatives based on the expected and predicted tags\n",
    "sub_exp_pred_df = exp_pred_df.loc[exp_pred_df[exp_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.loc[sub_exp_pred_df[pred_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.drop(columns=[\"_merge\"])\n",
    "sub_exp_pred_df.insert( len(sub_exp_pred_df.columns), \"_merge\", ( [\"true negative\"]*(sub_exp_pred_df.shape[0]) ) )\n",
    "# Record false negatives, false positives, and true positives based on the merge values\n",
    "sub_exp_pred_df2 = exp_pred_df.loc[~exp_pred_df.index.isin(sub_exp_pred_df.index)]\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"left_only\", value=\"false negative\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"right_only\", value=\"false positive\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"both\", value=\"true positive\")\n",
    "# Combine the DataFrames to include all agreement types and sort the DataFrame\n",
    "eval_df = pd.concat([sub_exp_pred_df,sub_exp_pred_df2])\n",
    "eval_df = eval_df.sort_index()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b71b39ad-0a40-4a2a-ba12-0fedfe13b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     151194\n",
       "true positive       1253\n",
       "false negative       584\n",
       "false positive       382\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b93f1003-ad7e-4c58-be26-c6fc38303dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)\n",
    "\n",
    "def precisionRecallF1(tp_count, fp_count, fn_count):\n",
    "    # Precision Score: ability of classifier not to label a sample that should be negative as positive; best possible = 1, worst possible = 0\n",
    "    if tp_count+fp_count == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = (tp_count/(tp_count+fp_count))\n",
    "    # Recall Score: ability of classifier to find all positive samples; best possible = 1, worst possible = 0\n",
    "    if tp_count+fn_count == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = (tp_count/(tp_count+fn_count))\n",
    "    # F1 Score: harmonic mean of precision and recall; best possible = 1, worst possible = 0\n",
    "    if (precision+recall == 0):\n",
    "        f_1 = 0\n",
    "    else:\n",
    "        f_1 = (2*precision*recall)/(precision+recall)\n",
    "    return precision, recall, f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12383f15-46c2-4110-836c-85bda955272a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>24.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0.805038</td>\n",
       "      <td>0.968379</td>\n",
       "      <td>0.879187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>242.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.727419</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.686976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>318.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.174026</td>\n",
       "      <td>0.275154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            24.0           178.0          735.0   0.805038   \n",
       "0     Gendered-Role           242.0           169.0          451.0   0.727419   \n",
       "0    Generalization           318.0            35.0           67.0   0.656863   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.968379  0.879187  \n",
       "0  0.650794  0.686976  \n",
       "0  0.174026  0.275154  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e1d5b-6b89-4aeb-841e-77a30ee598d7",
   "metadata": {},
   "source": [
    "Export the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd7c7a86-ee61-4eab-bedd-eb1145d2d97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/multilabel_linguistic/mlb_linglabels.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"models/multilabel_token/\"\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save classifier\n",
    "filename = model_dir+\"cc-{a}_F-fasttext{d}_T-linglabels.joblib\".format(a=\"rf\", d=\"100\")  # include features (F) and targets (T) in model's file name\n",
    "dump(clf, filename)\n",
    "\n",
    "# Save multilabel binarizer\n",
    "filename = model_dir+\"mlb_linglabels.joblib\"\n",
    "dump(mlb, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd118d8-c8b6-4774-82f5-c7651c06fb94",
   "metadata": {},
   "source": [
    "### 5. Classification of External Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0ff07e-bc28-45e7-9e5b-b567f65b3632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordType</th>\n",
       "      <th>AltRefNo</th>\n",
       "      <th>RefNo</th>\n",
       "      <th>Title</th>\n",
       "      <th>Original Date Field</th>\n",
       "      <th>Description</th>\n",
       "      <th>RelatedNameCode</th>\n",
       "      <th>Authority Type</th>\n",
       "      <th>Authority Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photograph</td>\n",
       "      <td>TCD 263/MUS 1079</td>\n",
       "      <td>BTA/5 PH/7/MUS 1079</td>\n",
       "      <td>Wedding Greetings (General)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image of telegram.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Photograph</td>\n",
       "      <td>TCD 263/MUS 1142</td>\n",
       "      <td>BTA/5 PH/7/MUS 1142</td>\n",
       "      <td>Baby (Blanket and tag design)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image of telegram.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Photograph</td>\n",
       "      <td>TCD 263/MUS 1075</td>\n",
       "      <td>BTA/5 PH/7/MUS 1075</td>\n",
       "      <td>Wedding (General Greeting)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image of telegram.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photograph</td>\n",
       "      <td>TCD 263/MUS 977</td>\n",
       "      <td>BTA/5 PH/7/MUS 977</td>\n",
       "      <td>Ordinary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Designer/manufacturer: Perry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Photograph</td>\n",
       "      <td>TCD 263/MUS 637</td>\n",
       "      <td>BTA/5 PH/7/MUS 637</td>\n",
       "      <td>Two girls sending telegraph message</td>\n",
       "      <td>c1910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordType          AltRefNo                RefNo  \\\n",
       "0  Photograph  TCD 263/MUS 1079  BTA/5 PH/7/MUS 1079   \n",
       "1  Photograph  TCD 263/MUS 1142  BTA/5 PH/7/MUS 1142   \n",
       "2  Photograph  TCD 263/MUS 1075  BTA/5 PH/7/MUS 1075   \n",
       "3  Photograph   TCD 263/MUS 977   BTA/5 PH/7/MUS 977   \n",
       "4  Photograph   TCD 263/MUS 637   BTA/5 PH/7/MUS 637   \n",
       "\n",
       "                                 Title Original Date Field  \\\n",
       "0          Wedding Greetings (General)                 NaN   \n",
       "1        Baby (Blanket and tag design)                 NaN   \n",
       "2           Wedding (General Greeting)                 NaN   \n",
       "3                             Ordinary                 NaN   \n",
       "4  Two girls sending telegraph message               c1910   \n",
       "\n",
       "                    Description RelatedNameCode Authority Type Authority Name  \n",
       "0            Image of telegram.             NaN            NaN            NaN  \n",
       "1            Image of telegram.             NaN            NaN            NaN  \n",
       "2            Image of telegram.             NaN            NaN            NaN  \n",
       "3  Designer/manufacturer: Perry             NaN            NaN            NaN  \n",
       "4                           NaN             NaN            NaN            NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt = pd.read_csv(\"../data/congruence_engine/BT_sample.csv\", low_memory=False)\n",
    "bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18d1793-173b-43d5-bf9f-6888844f659e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two', 'girls', 'sending', 'telegraph', 'message']\n"
     ]
    }
   ],
   "source": [
    "bt_title = list(bt[\"Title\"])\n",
    "tokens = word_tokenize(bt_title[4])\n",
    "token_ids = [0, 1, 2, 3, 4]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae09678-00e9-41af-ac6e-8da6dc121d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText.load(\"models/fasttext_cbow_100d.model\")\n",
    "# Zip the features\n",
    "feature_data = list(zip(token_ids, tokens))\n",
    "# Make FastText feature matrix\n",
    "feature_list = [ft_model.wv[token.lower()] for token_id,token in feature_data]\n",
    "X = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdb8eb39-fc30-4f77-926f-40523c14bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = joblib.load(\"models/for_reuse/multilabel_linguistic/mlb_linglabels.joblib\")\n",
    "trained_clf = joblib.load(\"models/for_reuse/multilabel_linguistic/cc-rf_F-fasttext100_T-linglabels.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9fb3e3-1f78-436e-8fa1-bc15f9a45247",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db78e1d-16f0-4305-be54-8cd6a1439f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O',), ('Generalization',), ('O',), ('O',), ('O',)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = mlb.inverse_transform(y_pred)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76660c-fd84-49f2-acf2-21f21eaf921b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias-env",
   "language": "python",
   "name": "gender-bias-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

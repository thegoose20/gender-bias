{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f4a1b9-3ca3-4bc1-8550-86d4a1ecea7f",
   "metadata": {},
   "source": [
    "# Multilabel Token Classification\n",
    "## Experiments 1 and 2, Model 1\n",
    "## Classification of Linguistic labels: *Gendered Pronoun*, *Gendered Role*, *Generalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32487bc-2de3-4c9d-9214-7c45b3e73981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For word embeddings\n",
    "from gensim.models import FastText #, Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "from gensim import utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# For multilabel token classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For saving model\n",
    "import joblib\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c511793-443c-4269-a5be-d8d786d06e51",
   "metadata": {},
   "source": [
    "### 1. Create Word Embeddings\n",
    "\n",
    "Train custom word embeddings on metadata descriptions from the University of Edinburgh Heritage Collections' Archives catalog.\n",
    "\n",
    "* Data file: `descriptions_by_fonds`\n",
    "* Date of harvesting: October 2020\n",
    "* Harvesting and transformation code: [annot-prep/PreparationForAnnotation.ipynb](https://github.com/thegoose20/annot-prep/blob/main/PreparationForAnnotation.ipynb)\n",
    "\n",
    "References:\n",
    "* https://radimrehurek.com/gensim/models/fasttext.html\n",
    "* https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd03ebe8-49d1-43ad-94ff-3da0dcc527d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"../data/descriptions_by_fonds/\"\n",
    "file_list = os.listdir(dir_path)\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67881f6-9439-40ec-b6b8-19df4fdddf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusIterator:\n",
    "    def __iter__(self):\n",
    "        file_list = os.listdir(dir_path)\n",
    "        for fonds_f in file_list:\n",
    "            assert \".txt\" in fonds_f, \"All files should be Plaintext.\" \n",
    "            file_path = dir_path+fonds_f\n",
    "            with utils.open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    # Lowercase the tokens\n",
    "                    yield list(tokenize(line.lower()))   #list(tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c3002-fb91-4e87-8617-2935cdd9dafb",
   "metadata": {},
   "source": [
    "Define the hyperparameters for the unsupervised training of the fastText model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1fde27-8585-4b04-b780-1048b8cfd5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training architecture (default = \"cbow\" for Continuous Bag of Words)\n",
    "training_arch = \"cbow\"  #\"skipgram\n",
    "# Specify the learning rate (default = 0.025)\n",
    "alpha = 0.025\n",
    "# Specify the training objective (default = \"ns\")\n",
    "# losses = [\"ns\", \"hs\", \"softmax\"]\n",
    "# loss = losses[0]\n",
    "# Specify the number of negative words to sample for 'ns' training objective (default = 5)\n",
    "negative = 5\n",
    "# Specify the threshold for downsampling higher-frequency words (default = 0.001)\n",
    "sample = 0.001\n",
    "# Specify the word embeddings' dimensions\n",
    "vector_dimensions = 100 #50 #300\n",
    "# Specify the context window (default is 5) \n",
    "context_window = 5\n",
    "# Specify the number of epochs (default is 5)\n",
    "epochs = 5\n",
    "# Specify the threshold of word occurrences (ignore words that occur less than specified number of times; default = 5)\n",
    "min_count = 5\n",
    "# Specify the minimum and maximum length of character ngrams (defaults are 3 and 6)\n",
    "min_n = 2\n",
    "max_n = 6  # if 0, no character n-grams (subword vectors) will be used\n",
    "# Specify the number of buckets for hashing ngrams (default = 2000000) \n",
    "bucket = 2000000\n",
    "# Sort vocabulary by descending frequency (default = 1)\n",
    "sorted_vocab = 1\n",
    "# Specify the number of threads to use (default = 12)\n",
    "# threads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9da24c-445d-4f65-ae8d-e568cfa0cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = FastText(\n",
    "    alpha=alpha, negative=negative, sample=sample,\n",
    "    vector_size=vector_dimensions, window=context_window, \n",
    "    epochs=epochs, min_count=min_count, min_n=min_n, \n",
    "    max_n=max_n, bucket=bucket, sorted_vocab=sorted_vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8128ca7-da29-48aa-835d-135693ac967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.build_vocab(corpus_iterable=CorpusIterator())\n",
    "total_examples = embedding_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29711eff-e772-4695-8b23-fbda6a0de3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7320895, 10119275)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.train(corpus_iterable=CorpusIterator(), total_examples=total_examples, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d241752-ace9-4414-a6f4-5c4091e78e0f",
   "metadata": {},
   "source": [
    "Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700be198-0cd4-4989-828d-1f98de91ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext_cbow_100d.model\n"
     ]
    }
   ],
   "source": [
    "file_name = \"fasttext_{a}_{d}d.model\".format(a=training_arch, d=vector_dimensions)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59085d52-4a82-43ca-9f02-b707c6909c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.save(\"models/embeddings/custom_fasttext/\"+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba6b31-317d-4afc-8e12-fb2d344703fe",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfb613e-cffa-47e5-bb98-6e38f02ac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data = config.exp_data_path+\"token_5fold.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bffa0a75-008c-4ead-8667-7e8b7a294b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id       token token_offsets  \\\n",
       "0               0            0   99999         0  Identifier       (0, 10)   \n",
       "1               0            0   99999         1           :      (10, 11)   \n",
       "2               0            0   99999         2         AA5      (12, 15)   \n",
       "3               1            1   99999         3       Title      (17, 22)   \n",
       "4               1            1   99999         4           :      (22, 23)   \n",
       "\n",
       "  pos tag       field    fold  \n",
       "0  NN   O  Identifier  split4  \n",
       "1   :   O  Identifier  split4  \n",
       "2  NN   O  Identifier  split4  \n",
       "3  NN   O       Title  split2  \n",
       "4   :   O       Title  split2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(token_data, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74999926-cad3-4589-9273-3b0987d5ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_tags = [\"B-Generalization\", \"I-Generalization\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f33439a-f2ab-47b2-a5e4-af28d61cdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_consider = ling_tags\n",
    "col = \"tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4793b2d0-57ca-47b8-a58e-100129fcb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implodeDataFrame(df, cols_to_groupby):\n",
    "    cols_to_agg = list(df.columns)\n",
    "    for col in cols_to_groupby:\n",
    "        cols_to_agg.remove(col)\n",
    "    agg_dict = dict.fromkeys(cols_to_agg, lambda x: x.tolist())\n",
    "    return df.groupby(cols_to_groupby).agg(agg_dict).reset_index().set_index(cols_to_groupby)\n",
    "\n",
    "def preprocessTokenData(df, col, label_list):\n",
    "    initial_shape = df.shape\n",
    "    # Change any tags not in label_list to \"O\"\n",
    "    df_l = df.loc[df[col].isin(label_list)]\n",
    "    df_o = df.loc[~df[col].isin(label_list)]\n",
    "    df_o = df_o.drop(columns=[col])\n",
    "    df_o.insert(len(df_o.columns), col, ([\"O\"]*(df_o.shape[0])))\n",
    "    df = pd.concat([df_l, df_o])\n",
    "    df = df.sort_values(by=\"token_id\")\n",
    "    assert initial_shape == df.shape, \"The DataFrame should have the same number of rows and columns after changing select column values.\"\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Replace tags with labels, removing \"B-\" and \"I-\" from the start of the tags\n",
    "    old_col = df[col]\n",
    "    new_col = [tag[2:] if tag != \"O\" else tag for tag in old_col]\n",
    "    df = df.drop(columns=[col])\n",
    "    df.insert((len(df.columns)-2), col, new_col)\n",
    "    \n",
    "    # Group by token, so there's one row per token and lists of tags for each token\n",
    "    df = implodeDataFrame(df, [\n",
    "        \"description_id\", \"sentence_id\", \"token_id\", \"token\", \"pos\", \"field\", \"token_offsets\", \"fold\"\n",
    "    ])\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Deduplicate tag lists and remove any \"O\" tags from lists with other values\n",
    "    old_col = list(df[col])\n",
    "    dedup_col = [list(set(value_list)) for value_list in old_col]\n",
    "    assert len(old_col) == len(dedup_col), \"The column should have the same number of rows.\"\n",
    "    new_col = []\n",
    "    for col_list in dedup_col:\n",
    "        if (\"O\" in col_list) and (len(col_list) > 1):\n",
    "            col_list.remove(\"O\")\n",
    "        col_list.sort()\n",
    "        new_col += [col_list]\n",
    "    assert len(new_col) == len(old_col), \"The column should have the same number of rows.\"\n",
    "    df = df.drop(columns=[col])\n",
    "    df.insert((len(df.columns)-2), col, new_col)\n",
    "    \n",
    "    return df  #.explode([col])  # one tag-token pair per row, tokens can repeat across rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "360c5223-6ca5-4821-a92a-82e9524702c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token pos       field  \\\n",
       "0               0            0         0  Identifier  NN  Identifier   \n",
       "1               0            0         1           :   :  Identifier   \n",
       "2               0            0         2         AA5  NN  Identifier   \n",
       "3               1            1         3       Title  NN       Title   \n",
       "4               1            1         4           :   :       Title   \n",
       "\n",
       "  token_offsets  tag    fold   ann_id  \n",
       "0       (0, 10)  [O]  split4  [99999]  \n",
       "1      (10, 11)  [O]  split4  [99999]  \n",
       "2      (12, 15)  [O]  split4  [99999]  \n",
       "3      (17, 22)  [O]  split2  [99999]  \n",
       "4      (22, 23)  [O]  split2  [99999]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocessTokenData(df, col, labels_to_consider)\n",
    "df = df.sort_values(by=\"token_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfbc71a-2f83-48cc-bac5-7cf21befd845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                                   744728\n",
       "[Gendered-Pronoun]                      3624\n",
       "[Gendered-Role]                         3151\n",
       "[Generalization]                        1808\n",
       "[Gendered-Pronoun, Generalization]       107\n",
       "[Gendered-Role, Generalization]          103\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03315648-56ad-47fc-b0ee-b011b17a4987",
   "metadata": {},
   "source": [
    "### 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3025def-a99c-4470-a376-4278ce441db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText.load(config.fasttext_path+\"fasttext_cbow_100d.model\")\n",
    "def getFeatures(df, embedding_model=ft_model, feature_cols=[\"token_id\", \"token\"]):\n",
    "    # Zip the features\n",
    "    feature_data = list(zip(df[feature_cols[0]], df[feature_cols[1]]))\n",
    "    \n",
    "    # Make FastText feature matrix\n",
    "    feature_list = [embedding_model.wv[token.lower()] for token_id,token in feature_data]\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190ee20-a1fd-4678-b16c-594013de6230",
   "metadata": {},
   "source": [
    "Define the five splits of the data to combine iteratively into training and test sets using five-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a04589-e7cd-48b3-883b-b18199f7cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['split0' 'split1' 'split2' 'split3' 'split4']\n"
     ]
    }
   ],
   "source": [
    "split_col = \"fold\"\n",
    "splits = df[split_col].unique()\n",
    "splits.sort()\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14bd54df-1ae3-4ff9-8685-621fbb726c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['split0', 'split1', 'split2'], 'split3'), (['split1', 'split2', 'split3'], 'split0'), (['split2', 'split3', 'split0'], 'split1'), (['split3', 'split0', 'split1'], 'split2')]\n",
      "split4\n"
     ]
    }
   ],
   "source": [
    "train0, devtest0 = list(splits[:3]), splits[3]\n",
    "train1, devtest1 = list(splits[1:4]), splits[0]\n",
    "train2, devtest2 = list(splits[2:4])+[splits[0]], splits[1]\n",
    "train3, devtest3 = [splits[3]]+list(splits[:2]), splits[2]\n",
    "runs = [(train0, devtest0), (train1, devtest1), (train2, devtest2), (train3, devtest3)]\n",
    "test = splits[4]\n",
    "print(runs)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4844299a-8de9-4e2c-a473-de4c750a4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits, devtest_split = runs[-1][0], runs[-1][1]\n",
    "df_train = df.loc[df[split_col].isin(train_splits)]\n",
    "df_devtest = df.loc[df[split_col] == devtest_split]\n",
    "df_test = df.loc[df[split_col] == test]\n",
    "assert df.shape[0] == df_train.shape[0] + df_devtest.shape[0] + df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "370a0f33-02b7-4b89-839d-e7c65407912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = getFeatures(df_train)\n",
    "X_devtest = getFeatures(df_devtest)\n",
    "X_test = getFeatures(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af8bc054-7eb3-425e-b352-5b619b690599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun' 'Gendered-Role' 'Generalization']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([[\"Gendered-Pronoun\", \"Gendered-Role\", \"Generalization\"]])\n",
    "y_train = mlb.transform(df_train[col])\n",
    "y_devtest = mlb.transform(df_devtest[col])\n",
    "y_test = mlb.transform(df_test[col])\n",
    "print(mlb.classes_)\n",
    "# print((df_test[col])[:10])\n",
    "# print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41938255-1247-4c8a-bfdc-4a67d2248dcd",
   "metadata": {},
   "source": [
    "### 4. Classifier Training\n",
    "#### 4.1 100-Dimension Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dc19a7c-78c5-4061-8d07-2d74ec39a80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ClassifierChain(\n",
    "    classifier = RandomForestClassifier(random_state=22),\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af9367-eabc-4c09-acb3-4b3cf91f5a92",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b217bf9d-6e9a-489d-9427-5ad4c005bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_devtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85082481-6b66-4d1e-a0ff-0fbfe8b3a3a7",
   "metadata": {},
   "source": [
    "Export the data with the predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "447bfae8-b7d7-475a-aef9-72dd60147ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['O'], ['O'], ['O'], ['O']]\n"
     ]
    }
   ],
   "source": [
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "print(new_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bedba21-db12-4bc6-89f5-59f6358600cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Title</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>Title</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[14384, 24275, 52952]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id   token  pos  field token_offsets  \\\n",
       "3               1            1         3   Title   NN  Title      (17, 22)   \n",
       "4               1            1         4       :    :  Title      (22, 23)   \n",
       "5               1            1         5  Papers  NNS  Title      (24, 30)   \n",
       "6               1            1         6      of   IN  Title      (31, 33)   \n",
       "7               1            1         7     The   DT  Title      (34, 37)   \n",
       "\n",
       "   tag    fold                 ann_id predicted  \n",
       "3  [O]  split2                [99999]       [O]  \n",
       "4  [O]  split2                [99999]       [O]  \n",
       "5  [O]  split2                [99999]       [O]  \n",
       "6  [O]  split2                [99999]       [O]  \n",
       "7  [O]  split2  [14384, 24275, 52952]       [O]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devtest.insert(len(df.columns), \"predicted\", new_preds)\n",
    "df_devtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22f3135d-b8fb-4051-897f-096a5ed482cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                                151743\n",
       "[Gendered-Pronoun]                    980\n",
       "[Gendered-Role]                       660\n",
       "[Generalization]                       84\n",
       "[Gendered-Role, Generalization]         2\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devtest.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b89ba10-c521-4a06-b835-6e4ceed59ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_devtest.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_devtest.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0edc63ba-0d97-42fd-b835-d2931c3a6563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Title</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>Title</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id   token  pos  field token_offsets  \\\n",
       "0               1            1         3   Title   NN  Title      (17, 22)   \n",
       "1               1            1         4       :    :  Title      (22, 23)   \n",
       "2               1            1         5  Papers  NNS  Title      (24, 30)   \n",
       "3               1            1         6      of   IN  Title      (31, 33)   \n",
       "4               1            1         7     The   DT  Title      (34, 37)   \n",
       "\n",
       "  tag    fold predicted         _merge  \n",
       "0   O  split2         O  true negative  \n",
       "1   O  split2         O  true negative  \n",
       "2   O  split2         O  true negative  \n",
       "3   O  split2         O  true negative  \n",
       "4   O  split2         O  true negative  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "# Add the predicted tags to the DataFrame with expected tags\n",
    "exp_pred_df = pd.merge(\n",
    "    left=exp_df, \n",
    "    right=pred_df, \n",
    "    how=\"outer\",\n",
    "    left_on=left_on_cols,\n",
    "    right_on=right_on_cols,\n",
    "    suffixes=[\"\", \"_pred\"],\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Replace any NaN values with \"O\" to indicate no predicted tag\n",
    "exp_pred_df[exp_col] = exp_pred_df[exp_col].fillna(no_tag_value)\n",
    "exp_pred_df[pred_col] = exp_pred_df[pred_col].fillna(no_tag_value)\n",
    "\n",
    "# Find true negatives based on the expected and predicted tags\n",
    "sub_exp_pred_df = exp_pred_df.loc[exp_pred_df[exp_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.loc[sub_exp_pred_df[pred_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.drop(columns=[\"_merge\"])\n",
    "sub_exp_pred_df.insert( len(sub_exp_pred_df.columns), \"_merge\", ( [\"true negative\"]*(sub_exp_pred_df.shape[0]) ) )\n",
    "# Record false negatives, false positives, and true positives based on the merge values\n",
    "sub_exp_pred_df2 = exp_pred_df.loc[~exp_pred_df.index.isin(sub_exp_pred_df.index)]\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"left_only\", value=\"false negative\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"right_only\", value=\"false positive\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"both\", value=\"true positive\")\n",
    "# Combine the DataFrames to include all agreement types and sort the DataFrame\n",
    "eval_df = pd.concat([sub_exp_pred_df,sub_exp_pred_df2])\n",
    "eval_df = eval_df.sort_index()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b71b39ad-0a40-4a2a-ba12-0fedfe13b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     152139\n",
       "true positive       1322\n",
       "false negative       623\n",
       "false positive       406\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b93f1003-ad7e-4c58-be26-c6fc38303dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)\n",
    "\n",
    "def precisionRecallF1(tp_count, fp_count, fn_count):\n",
    "    # Precision Score: ability of classifier not to label a sample that should be negative as positive; best possible = 1, worst possible = 0\n",
    "    if tp_count+fp_count == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = (tp_count/(tp_count+fp_count))\n",
    "    # Recall Score: ability of classifier to find all positive samples; best possible = 1, worst possible = 0\n",
    "    if tp_count+fn_count == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = (tp_count/(tp_count+fn_count))\n",
    "    # F1 Score: harmonic mean of precision and recall; best possible = 1, worst possible = 0\n",
    "    if (precision+recall == 0):\n",
    "        f_1 = 0\n",
    "    else:\n",
    "        f_1 = (2*precision*recall)/(precision+recall)\n",
    "    return precision, recall, f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12383f15-46c2-4110-836c-85bda955272a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>14.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.982346</td>\n",
       "      <td>0.878737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>241.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.735650</td>\n",
       "      <td>0.668956</td>\n",
       "      <td>0.700719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>368.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.219608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            14.0           201.0          779.0   0.794898   \n",
       "0     Gendered-Role           241.0           175.0          487.0   0.735650   \n",
       "0    Generalization           368.0            30.0           56.0   0.651163   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.982346  0.878737  \n",
       "0  0.668956  0.700719  \n",
       "0  0.132075  0.219608  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb29652",
   "metadata": {},
   "source": [
    "#### 4.2 300-Dimension Word Embeddings\n",
    "Try training the model using higher-dimension word embeddings and evaluate its performance on the devtest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf3e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext_cbow_300d.model\n"
     ]
    }
   ],
   "source": [
    "vector_dimensions = 300\n",
    "\n",
    "embedding_model = FastText(\n",
    "    alpha=alpha, negative=negative, sample=sample,\n",
    "    vector_size=vector_dimensions, window=context_window, \n",
    "    epochs=epochs, min_count=min_count, min_n=min_n, \n",
    "    max_n=max_n, bucket=bucket, sorted_vocab=sorted_vocab\n",
    ")\n",
    "\n",
    "embedding_model.build_vocab(corpus_iterable=CorpusIterator())\n",
    "total_examples = embedding_model.corpus_count\n",
    "\n",
    "embedding_model.train(corpus_iterable=CorpusIterator(), total_examples=total_examples, epochs=epochs)\n",
    "\n",
    "file_name = \"fasttext_{a}_{d}d.model\".format(a=training_arch, d=vector_dimensions)\n",
    "print(file_name)\n",
    "\n",
    "embedding_model.save(\"models/embeddings/custom_fasttext/\"+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a5955",
   "metadata": {},
   "source": [
    "Feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d909109",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText.load(config.fasttext_path+f\"fasttext_cbow_{vector_dimensions}d.model\")\n",
    "def getFeatures(df, embedding_model=ft_model, feature_cols=[\"token_id\", \"token\"]):\n",
    "    # Zip the features\n",
    "    feature_data = list(zip(df[feature_cols[0]], df[feature_cols[1]]))\n",
    "    \n",
    "    # Make FastText feature matrix\n",
    "    feature_list = [embedding_model.wv[token.lower()] for token_id,token in feature_data]\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9200a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits, devtest_split = runs[-1][0], runs[-1][1]\n",
    "df_train = df.loc[df[split_col].isin(train_splits)]\n",
    "df_devtest = df.loc[df[split_col] == devtest_split]\n",
    "# df_test = df.loc[df[split_col] == test]\n",
    "assert df.shape[0] == df_train.shape[0] + df_devtest.shape[0] + df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dea3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = getFeatures(df_train)\n",
    "X_devtest = getFeatures(df_devtest)\n",
    "# X_test = getFeatures(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a237423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun' 'Gendered-Role' 'Generalization']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([[\"Gendered-Pronoun\", \"Gendered-Role\", \"Generalization\"]])\n",
    "y_train = mlb.transform(df_train[col])\n",
    "y_devtest = mlb.transform(df_devtest[col])\n",
    "print(mlb.classes_)\n",
    "# print((df_test[col])[:10])\n",
    "# print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4fb4ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_300 = ClassifierChain(\n",
    "    classifier = RandomForestClassifier(random_state=22),\n",
    ")\n",
    "clf_300.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "408e92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_300.predict(X_devtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e061bf63",
   "metadata": {},
   "source": [
    "Export the data with the predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a4d0125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['O'], ['O'], ['O'], ['O']]\n"
     ]
    }
   ],
   "source": [
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "print(new_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c79242e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>predicted_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Title</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>Title</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[14384, 24275, 52952]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id   token  pos  field token_offsets  \\\n",
       "3               1            1         3   Title   NN  Title      (17, 22)   \n",
       "4               1            1         4       :    :  Title      (22, 23)   \n",
       "5               1            1         5  Papers  NNS  Title      (24, 30)   \n",
       "6               1            1         6      of   IN  Title      (31, 33)   \n",
       "7               1            1         7     The   DT  Title      (34, 37)   \n",
       "\n",
       "   tag    fold                 ann_id predicted_300  \n",
       "3  [O]  split2                [99999]           [O]  \n",
       "4  [O]  split2                [99999]           [O]  \n",
       "5  [O]  split2                [99999]           [O]  \n",
       "6  [O]  split2                [99999]           [O]  \n",
       "7  [O]  split2  [14384, 24275, 52952]           [O]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devtest.insert(len(df.columns), \"predicted_300\", new_preds)\n",
    "df_devtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31101647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                                151743\n",
       "[Gendered-Pronoun]                    980\n",
       "[Gendered-Role]                       660\n",
       "[Generalization]                       84\n",
       "[Gendered-Role, Generalization]         2\n",
       "Name: predicted_300, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devtest.predicted_300.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3df7157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_devtest.drop(columns=[\"predicted_300\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_devtest.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5850ee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted_300</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Title</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>Title</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id   token  pos  field token_offsets  \\\n",
       "0               1            1         3   Title   NN  Title      (17, 22)   \n",
       "1               1            1         4       :    :  Title      (22, 23)   \n",
       "2               1            1         5  Papers  NNS  Title      (24, 30)   \n",
       "3               1            1         6      of   IN  Title      (31, 33)   \n",
       "4               1            1         7     The   DT  Title      (34, 37)   \n",
       "\n",
       "  tag    fold predicted_300         _merge  \n",
       "0   O  split2             O  true negative  \n",
       "1   O  split2             O  true negative  \n",
       "2   O  split2             O  true negative  \n",
       "3   O  split2             O  true negative  \n",
       "4   O  split2             O  true negative  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted_300\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "# Add the predicted tags to the DataFrame with expected tags\n",
    "exp_pred_df = pd.merge(\n",
    "    left=exp_df, \n",
    "    right=pred_df, \n",
    "    how=\"outer\",\n",
    "    left_on=left_on_cols,\n",
    "    right_on=right_on_cols,\n",
    "    suffixes=[\"\", \"_pred300\"],\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Replace any NaN values with \"O\" to indicate no predicted tag\n",
    "exp_pred_df[exp_col] = exp_pred_df[exp_col].fillna(no_tag_value)\n",
    "exp_pred_df[pred_col] = exp_pred_df[pred_col].fillna(no_tag_value)\n",
    "\n",
    "# Find true negatives based on the expected and predicted tags\n",
    "sub_exp_pred_df = exp_pred_df.loc[exp_pred_df[exp_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.loc[sub_exp_pred_df[pred_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.drop(columns=[\"_merge\"])\n",
    "sub_exp_pred_df.insert( len(sub_exp_pred_df.columns), \"_merge\", ( [\"true negative\"]*(sub_exp_pred_df.shape[0]) ) )\n",
    "# Record false negatives, false positives, and true positives based on the merge values\n",
    "sub_exp_pred_df2 = exp_pred_df.loc[~exp_pred_df.index.isin(sub_exp_pred_df.index)]\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"left_only\", value=\"false negative\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"right_only\", value=\"false positive\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"both\", value=\"true positive\")\n",
    "# Combine the DataFrames to include all agreement types and sort the DataFrame\n",
    "eval_df = pd.concat([sub_exp_pred_df,sub_exp_pred_df2])\n",
    "eval_df = eval_df.sort_index()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cff27d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     152139\n",
       "true positive       1322\n",
       "false negative       623\n",
       "false positive       406\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1202ad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)\n",
    "\n",
    "def precisionRecallF1(tp_count, fp_count, fn_count):\n",
    "    # Precision Score: ability of classifier not to label a sample that should be negative as positive; best possible = 1, worst possible = 0\n",
    "    if tp_count+fp_count == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = (tp_count/(tp_count+fp_count))\n",
    "    # Recall Score: ability of classifier to find all positive samples; best possible = 1, worst possible = 0\n",
    "    if tp_count+fn_count == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = (tp_count/(tp_count+fn_count))\n",
    "    # F1 Score: harmonic mean of precision and recall; best possible = 1, worst possible = 0\n",
    "    if (precision+recall == 0):\n",
    "        f_1 = 0\n",
    "    else:\n",
    "        f_1 = (2*precision*recall)/(precision+recall)\n",
    "    return precision, recall, f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "210f1ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>14.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.982346</td>\n",
       "      <td>0.878737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>241.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.735650</td>\n",
       "      <td>0.668956</td>\n",
       "      <td>0.700719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>368.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.219608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            14.0           201.0          779.0   0.794898   \n",
       "0     Gendered-Role           241.0           175.0          487.0   0.735650   \n",
       "0    Generalization           368.0            30.0           56.0   0.651163   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.982346  0.878737  \n",
       "0  0.668956  0.700719  \n",
       "0  0.132075  0.219608  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores_300 = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df_300 = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df_300 = agmt_df_300.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df_300.loc[agmt_df_300._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df_300.loc[agmt_df_300._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df_300.loc[agmt_df_300._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores_300 = pd.concat([agmt_scores_300, label_agmt])\n",
    "agmt_scores_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6139ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with 100 Dimensions, 3 Labels\n",
    "#             label\tfalse negative\tfalse positive\ttrue positive\tprecision\trecall\t    f1\n",
    "# 0\t    Gendered-Pronoun\t24.0\t       178.0\t   735.0\t    0.805038\t0.968379\t0.879187\n",
    "# 0\t    Gendered-Role\t    242.0\t       169.0\t   451.0\t    0.727419\t0.650794\t0.686976\n",
    "# 0    \tGeneralization\t    318.0\t        35.0\t    67.0\t    0.656863\t0.174026\t0.275154"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1436d",
   "metadata": {},
   "source": [
    "#### 4.3 Compare Models\n",
    "Run the two models classifying with 3 labels on the blind test data to see which performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590959fb",
   "metadata": {},
   "source": [
    "4.3.1 100-Dimension Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4aabd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ft_model = FastText.load(\"models/embeddings/custom_fasttext/fasttext_cbow_100d.model\")\n",
    "X_test = getFeatures(df_test, ft_model)\n",
    "y_test = mlb.transform(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f6f92f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca3fa6",
   "metadata": {},
   "source": [
    "Export the data with the predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "340476ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['O'], ['O'], ['Gendered-Pronoun'], ['O']]\n"
     ]
    }
   ],
   "source": [
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "print(new_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f9f7a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=[\"predicted\", \"predicted_300\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33c01d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[14377]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id  sentence_id  token_id       token  pos  \\\n",
       "0                 0            0         0  Identifier   NN   \n",
       "1                 0            0         1           :    :   \n",
       "2                 0            0         2         AA5   NN   \n",
       "134               3            4       134          He  PRP   \n",
       "135               3            4       135         was  VBD   \n",
       "\n",
       "                         field token_offsets                 tag    fold  \\\n",
       "0                   Identifier       (0, 10)                 [O]  split4   \n",
       "1                   Identifier      (10, 11)                 [O]  split4   \n",
       "2                   Identifier      (12, 15)                 [O]  split4   \n",
       "134  Biographical / Historical    (789, 791)  [Gendered-Pronoun]  split4   \n",
       "135  Biographical / Historical    (792, 795)                 [O]  split4   \n",
       "\n",
       "      ann_id           predicted  \n",
       "0    [99999]                 [O]  \n",
       "1    [99999]                 [O]  \n",
       "2    [99999]                 [O]  \n",
       "134  [14377]  [Gendered-Pronoun]  \n",
       "135  [99999]                 [O]  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.insert(len(df.columns), \"predicted\", new_preds)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c29acef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                   147310\n",
       "[Gendered-Pronoun]       965\n",
       "[Gendered-Role]          604\n",
       "[Generalization]         101\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a59e254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_test.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_test.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96b52c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>split4</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos  \\\n",
       "0               0            0         0  Identifier   NN   \n",
       "1               0            0         1           :    :   \n",
       "2               0            0         2         AA5   NN   \n",
       "3               3            4       134          He  PRP   \n",
       "4               3            4       135         was  VBD   \n",
       "\n",
       "                       field token_offsets               tag    fold  \\\n",
       "0                 Identifier       (0, 10)                 O  split4   \n",
       "1                 Identifier      (10, 11)                 O  split4   \n",
       "2                 Identifier      (12, 15)                 O  split4   \n",
       "3  Biographical / Historical    (789, 791)  Gendered-Pronoun  split4   \n",
       "4  Biographical / Historical    (792, 795)                 O  split4   \n",
       "\n",
       "          predicted         _merge  \n",
       "0                 O  true negative  \n",
       "1                 O  true negative  \n",
       "2                 O  true negative  \n",
       "3  Gendered-Pronoun  true positive  \n",
       "4                 O  true negative  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "# Add the predicted tags to the DataFrame with expected tags\n",
    "exp_pred_df = pd.merge(\n",
    "    left=exp_df, \n",
    "    right=pred_df, \n",
    "    how=\"outer\",\n",
    "    left_on=left_on_cols,\n",
    "    right_on=right_on_cols,\n",
    "    suffixes=[\"\", \"_pred\"],\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Replace any NaN values with \"O\" to indicate no predicted tag\n",
    "exp_pred_df[exp_col] = exp_pred_df[exp_col].fillna(no_tag_value)\n",
    "exp_pred_df[pred_col] = exp_pred_df[pred_col].fillna(no_tag_value)\n",
    "\n",
    "# Find true negatives based on the expected and predicted tags\n",
    "sub_exp_pred_df = exp_pred_df.loc[exp_pred_df[exp_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.loc[sub_exp_pred_df[pred_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.drop(columns=[\"_merge\"])\n",
    "sub_exp_pred_df.insert( len(sub_exp_pred_df.columns), \"_merge\", ( [\"true negative\"]*(sub_exp_pred_df.shape[0]) ) )\n",
    "# Record false negatives, false positives, and true positives based on the merge values\n",
    "sub_exp_pred_df2 = exp_pred_df.loc[~exp_pred_df.index.isin(sub_exp_pred_df.index)]\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"left_only\", value=\"false negative\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"right_only\", value=\"false positive\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"both\", value=\"true positive\")\n",
    "# Combine the DataFrames to include all agreement types and sort the DataFrame\n",
    "eval_df = pd.concat([sub_exp_pred_df,sub_exp_pred_df2])\n",
    "eval_df = eval_df.sort_index()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e45542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     147756\n",
       "true positive       1214\n",
       "false negative       585\n",
       "false positive       456\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de01c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)\n",
    "\n",
    "def precisionRecallF1(tp_count, fp_count, fn_count):\n",
    "    # Precision Score: ability of classifier not to label a sample that should be negative as positive; best possible = 1, worst possible = 0\n",
    "    if tp_count+fp_count == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = (tp_count/(tp_count+fp_count))\n",
    "    # Recall Score: ability of classifier to find all positive samples; best possible = 1, worst possible = 0\n",
    "    if tp_count+fn_count == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = (tp_count/(tp_count+fn_count))\n",
    "    # F1 Score: harmonic mean of precision and recall; best possible = 1, worst possible = 0\n",
    "    if (precision+recall == 0):\n",
    "        f_1 = 0\n",
    "    else:\n",
    "        f_1 = (2*precision*recall)/(precision+recall)\n",
    "    return precision, recall, f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5088d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>17.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.977690</td>\n",
       "      <td>0.862768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>202.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>0.670530</td>\n",
       "      <td>0.667216</td>\n",
       "      <td>0.668869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>366.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.148837</td>\n",
       "      <td>0.241055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            17.0           220.0          745.0   0.772021   \n",
       "0     Gendered-Role           202.0           199.0          405.0   0.670530   \n",
       "0    Generalization           366.0            37.0           64.0   0.633663   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.977690  0.862768  \n",
       "0  0.667216  0.668869  \n",
       "0  0.148837  0.241055  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7fad0",
   "metadata": {},
   "source": [
    "4.3.2 300-Dimension Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "281c4a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ft_model = FastText.load(\"models/embeddings/custom_fasttext/fasttext_cbow_300d.model\")\n",
    "X_test = getFeatures(df_test, ft_model)\n",
    "y_test = mlb.transform(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c759901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_300.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bae070",
   "metadata": {},
   "source": [
    "Export the data with the predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f85c75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['O'], ['O'], ['Gendered-Pronoun'], ['O']]\n"
     ]
    }
   ],
   "source": [
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "print(new_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a79e803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>predicted_300</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[14377]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id  sentence_id  token_id       token  pos  \\\n",
       "0                 0            0         0  Identifier   NN   \n",
       "1                 0            0         1           :    :   \n",
       "2                 0            0         2         AA5   NN   \n",
       "134               3            4       134          He  PRP   \n",
       "135               3            4       135         was  VBD   \n",
       "\n",
       "                         field token_offsets                 tag    fold  \\\n",
       "0                   Identifier       (0, 10)                 [O]  split4   \n",
       "1                   Identifier      (10, 11)                 [O]  split4   \n",
       "2                   Identifier      (12, 15)                 [O]  split4   \n",
       "134  Biographical / Historical    (789, 791)  [Gendered-Pronoun]  split4   \n",
       "135  Biographical / Historical    (792, 795)                 [O]  split4   \n",
       "\n",
       "      ann_id       predicted_300           predicted  \n",
       "0    [99999]                 [O]                 [O]  \n",
       "1    [99999]                 [O]                 [O]  \n",
       "2    [99999]                 [O]                 [O]  \n",
       "134  [14377]  [Gendered-Pronoun]  [Gendered-Pronoun]  \n",
       "135  [99999]                 [O]                 [O]  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.insert(len(df.columns), \"predicted_300\", new_preds)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d02112b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                   147310\n",
       "[Gendered-Pronoun]       965\n",
       "[Gendered-Role]          603\n",
       "[Generalization]         102\n",
       "Name: predicted_300, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.predicted_300.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eebc4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_test.drop(columns=[\"predicted\", \"predicted_300\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_test.drop(columns=[\"predicted\", \"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0303ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted_300</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>split4</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos  \\\n",
       "0               0            0         0  Identifier   NN   \n",
       "1               0            0         1           :    :   \n",
       "2               0            0         2         AA5   NN   \n",
       "3               3            4       134          He  PRP   \n",
       "4               3            4       135         was  VBD   \n",
       "\n",
       "                       field token_offsets               tag    fold  \\\n",
       "0                 Identifier       (0, 10)                 O  split4   \n",
       "1                 Identifier      (10, 11)                 O  split4   \n",
       "2                 Identifier      (12, 15)                 O  split4   \n",
       "3  Biographical / Historical    (789, 791)  Gendered-Pronoun  split4   \n",
       "4  Biographical / Historical    (792, 795)                 O  split4   \n",
       "\n",
       "      predicted_300         _merge  \n",
       "0                 O  true negative  \n",
       "1                 O  true negative  \n",
       "2                 O  true negative  \n",
       "3  Gendered-Pronoun  true positive  \n",
       "4                 O  true negative  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted_300\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "# Add the predicted tags to the DataFrame with expected tags\n",
    "exp_pred_df = pd.merge(\n",
    "    left=exp_df, \n",
    "    right=pred_df, \n",
    "    how=\"outer\",\n",
    "    left_on=left_on_cols,\n",
    "    right_on=right_on_cols,\n",
    "    suffixes=[\"\", \"_pred300\"],\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Replace any NaN values with \"O\" to indicate no predicted tag\n",
    "exp_pred_df[exp_col] = exp_pred_df[exp_col].fillna(no_tag_value)\n",
    "exp_pred_df[pred_col] = exp_pred_df[pred_col].fillna(no_tag_value)\n",
    "\n",
    "# Find true negatives based on the expected and predicted tags\n",
    "sub_exp_pred_df = exp_pred_df.loc[exp_pred_df[exp_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.loc[sub_exp_pred_df[pred_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.drop(columns=[\"_merge\"])\n",
    "sub_exp_pred_df.insert( len(sub_exp_pred_df.columns), \"_merge\", ( [\"true negative\"]*(sub_exp_pred_df.shape[0]) ) )\n",
    "# Record false negatives, false positives, and true positives based on the merge values\n",
    "sub_exp_pred_df2 = exp_pred_df.loc[~exp_pred_df.index.isin(sub_exp_pred_df.index)]\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"left_only\", value=\"false negative\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"right_only\", value=\"false positive\")\n",
    "sub_exp_pred_df2 = sub_exp_pred_df2.replace(to_replace=\"both\", value=\"true positive\")\n",
    "# Combine the DataFrames to include all agreement types and sort the DataFrame\n",
    "eval_df = pd.concat([sub_exp_pred_df,sub_exp_pred_df2])\n",
    "eval_df = eval_df.sort_index()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f12a930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     147756\n",
       "true positive       1214\n",
       "false negative       585\n",
       "false positive       456\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a52c0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)\n",
    "\n",
    "def precisionRecallF1(tp_count, fp_count, fn_count):\n",
    "    # Precision Score: ability of classifier not to label a sample that should be negative as positive; best possible = 1, worst possible = 0\n",
    "    if tp_count+fp_count == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = (tp_count/(tp_count+fp_count))\n",
    "    # Recall Score: ability of classifier to find all positive samples; best possible = 1, worst possible = 0\n",
    "    if tp_count+fn_count == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = (tp_count/(tp_count+fn_count))\n",
    "    # F1 Score: harmonic mean of precision and recall; best possible = 1, worst possible = 0\n",
    "    if (precision+recall == 0):\n",
    "        f_1 = 0\n",
    "    else:\n",
    "        f_1 = (2*precision*recall)/(precision+recall)\n",
    "    return precision, recall, f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c093485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>17.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.977690</td>\n",
       "      <td>0.862768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>202.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.667216</td>\n",
       "      <td>0.669421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>366.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.148837</td>\n",
       "      <td>0.240602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            17.0           220.0          745.0   0.772021   \n",
       "0     Gendered-Role           202.0           198.0          405.0   0.671642   \n",
       "0    Generalization           366.0            38.0           64.0   0.627451   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.977690  0.862768  \n",
       "0  0.667216  0.669421  \n",
       "0  0.148837  0.240602  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores_300 = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores_300 = pd.concat([agmt_scores_300, label_agmt])\n",
    "agmt_scores_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2f602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90607af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c72159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "410e1d5b-6b89-4aeb-841e-77a30ee598d7",
   "metadata": {},
   "source": [
    "Export the highest-performing models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c7a86-ee61-4eab-bedd-eb1145d2d97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/multilabel_linguistic/mlb_linglabels.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_dir = \"models/multilabel_token/\"\n",
    "# Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Save classifier\n",
    "# filename = model_dir+\"cc-{a}_F-fasttext{d}_T-linglabels.joblib\".format(a=\"rf\", d=\"100\")  # include features (F) and targets (T) in model's file name\n",
    "# dump(clf, filename)\n",
    "\n",
    "# # Save multilabel binarizer\n",
    "# filename = model_dir+\"mlb_linglabels.joblib\"\n",
    "# dump(mlb, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76660c-fd84-49f2-acf2-21f21eaf921b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

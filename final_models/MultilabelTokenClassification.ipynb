{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f4a1b9-3ca3-4bc1-8550-86d4a1ecea7f",
   "metadata": {},
   "source": [
    "# Multilabel Token Classification\n",
    "## Experiments 1 and 2, Model 1\n",
    "## Classification of Linguistic labels: *Gendered Pronoun*, *Gendered Role*, *Generalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32487bc-2de3-4c9d-9214-7c45b3e73981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import my_utils\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For word embeddings\n",
    "from gensim.models import FastText #, Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "from gensim import utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# For multilabel token classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For saving model\n",
    "import joblib\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c511793-443c-4269-a5be-d8d786d06e51",
   "metadata": {},
   "source": [
    "### 1. Create Word Embeddings\n",
    "\n",
    "Train custom word embeddings on metadata descriptions from the University of Edinburgh Heritage Collections' Archives catalog.\n",
    "\n",
    "* Data file: `descriptions_by_fonds`\n",
    "* Date of harvesting: October 2020\n",
    "* Harvesting and transformation code: [annot-prep/PreparationForAnnotation.ipynb](https://github.com/thegoose20/annot-prep/blob/main/PreparationForAnnotation.ipynb)\n",
    "\n",
    "References:\n",
    "* https://radimrehurek.com/gensim/models/fasttext.html\n",
    "* https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd03ebe8-49d1-43ad-94ff-3da0dcc527d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"../data/descriptions_by_fonds/\"\n",
    "file_list = os.listdir(dir_path)\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67881f6-9439-40ec-b6b8-19df4fdddf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusIterator:\n",
    "    def __iter__(self):\n",
    "        file_list = os.listdir(dir_path)\n",
    "        for fonds_f in file_list:\n",
    "            assert \".txt\" in fonds_f, \"All files should be Plaintext.\" \n",
    "            file_path = dir_path+fonds_f\n",
    "            with utils.open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    # Lowercase the tokens\n",
    "                    yield list(tokenize(line.lower()))   #list(tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c3002-fb91-4e87-8617-2935cdd9dafb",
   "metadata": {},
   "source": [
    "Define the hyperparameters for the unsupervised training of the fastText model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1fde27-8585-4b04-b780-1048b8cfd5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training architecture (default = \"cbow\" for Continuous Bag of Words)\n",
    "training_arch = \"cbow\"  #\"skipgram\"  \n",
    "if training_arch == \"skipgram\":\n",
    "    sg = 1\n",
    "else:\n",
    "    sg = 0\n",
    "# Specify the learning rate (default = 0.025)\n",
    "alpha = 0.025\n",
    "# Specify the training objective (default = \"ns\")\n",
    "# losses = [\"ns\", \"hs\", \"softmax\"]\n",
    "# loss = losses[0]\n",
    "# Specify the number of negative words to sample for 'ns' training objective (default = 5)\n",
    "negative = 5\n",
    "# Specify the threshold for downsampling higher-frequency words (default = 0.001)\n",
    "sample = 0.001\n",
    "# Specify the word embeddings' dimensions\n",
    "vector_dimensions = 100 #50 #300\n",
    "# Specify the context window (default is 5) \n",
    "context_window = 5\n",
    "# Specify the number of epochs (default is 5)\n",
    "epochs = 5\n",
    "# Specify the threshold of word occurrences (ignore words that occur less than specified number of times; default = 5)\n",
    "min_count = 5\n",
    "# Specify the minimum and maximum length of character ngrams (defaults are 3 and 6)\n",
    "min_n = 2\n",
    "max_n = 6  # if 0, no character n-grams (subword vectors) will be used\n",
    "# Specify the number of buckets for hashing ngrams (default = 2000000) \n",
    "bucket = 2000000\n",
    "# Sort vocabulary by descending frequency (default = 1)\n",
    "sorted_vocab = 1\n",
    "# Specify the number of threads to use (default = 12)\n",
    "# threads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9da24c-445d-4f65-ae8d-e568cfa0cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = FastText(\n",
    "    alpha=alpha, sg=sg, negative=negative, sample=sample,\n",
    "    vector_size=vector_dimensions, window=context_window, \n",
    "    epochs=epochs, min_count=min_count, min_n=min_n, \n",
    "    max_n=max_n, bucket=bucket, sorted_vocab=sorted_vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8128ca7-da29-48aa-835d-135693ac967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.build_vocab(corpus_iterable=CorpusIterator())\n",
    "total_examples = embedding_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29711eff-e772-4695-8b23-fbda6a0de3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7321026, 10119275)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.train(corpus_iterable=CorpusIterator(), total_examples=total_examples, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d241752-ace9-4414-a6f4-5c4091e78e0f",
   "metadata": {},
   "source": [
    "Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700be198-0cd4-4989-828d-1f98de91ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext_cbow_100d.model\n"
     ]
    }
   ],
   "source": [
    "file_name = \"fasttext_{a}_{d}d.model\".format(a=training_arch, d=vector_dimensions)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59085d52-4a82-43ca-9f02-b707c6909c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.save(\"models/embeddings/custom_fasttext/\"+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba6b31-317d-4afc-8e12-fb2d344703fe",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfb613e-cffa-47e5-bb98-6e38f02ac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data = config.exp_data_path+\"token_5fold.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffa0a75-008c-4ead-8667-7e8b7a294b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id       token token_offsets  \\\n",
       "0               0            0   99999         0  Identifier       (0, 10)   \n",
       "1               0            0   99999         1           :      (10, 11)   \n",
       "2               0            0   99999         2         AA5      (12, 15)   \n",
       "3               1            1   99999         3       Title      (17, 22)   \n",
       "4               1            1   99999         4           :      (22, 23)   \n",
       "\n",
       "  pos tag       field    fold  \n",
       "0  NN   O  Identifier  split4  \n",
       "1   :   O  Identifier  split4  \n",
       "2  NN   O  Identifier  split4  \n",
       "3  NN   O       Title  split2  \n",
       "4   :   O       Title  split2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(token_data, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74999926-cad3-4589-9273-3b0987d5ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_tags = [\"B-Generalization\", \"I-Generalization\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f33439a-f2ab-47b2-a5e4-af28d61cdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_consider = ling_tags\n",
    "col = \"tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360c5223-6ca5-4821-a92a-82e9524702c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token pos       field  \\\n",
       "0               0            0         0  Identifier  NN  Identifier   \n",
       "1               0            0         1           :   :  Identifier   \n",
       "2               0            0         2         AA5  NN  Identifier   \n",
       "3               1            1         3       Title  NN       Title   \n",
       "4               1            1         4           :   :       Title   \n",
       "\n",
       "  token_offsets  tag    fold   ann_id  \n",
       "0       (0, 10)  [O]  split4  [99999]  \n",
       "1      (10, 11)  [O]  split4  [99999]  \n",
       "2      (12, 15)  [O]  split4  [99999]  \n",
       "3      (17, 22)  [O]  split2  [99999]  \n",
       "4      (22, 23)  [O]  split2  [99999]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = my_utils.preprocessTokenData(df, col, labels_to_consider)\n",
    "df = df.sort_values(by=\"token_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddfbc71a-2f83-48cc-bac5-7cf21befd845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                                   744728\n",
       "[Gendered-Pronoun]                      3624\n",
       "[Gendered-Role]                         3151\n",
       "[Generalization]                        1808\n",
       "[Gendered-Pronoun, Generalization]       107\n",
       "[Gendered-Role, Generalization]          103\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03315648-56ad-47fc-b0ee-b011b17a4987",
   "metadata": {},
   "source": [
    "### 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3025def-a99c-4470-a376-4278ce441db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText model with cbow architecture and 100 dimensions.\n"
     ]
    }
   ],
   "source": [
    "ft_model = FastText.load(config.fasttext_path+\"fasttext_{a}_{d}d.model\".format(a=training_arch, d=vector_dimensions))\n",
    "print(\"Loading FastText model with\", training_arch, \"architecture and\", vector_dimensions, \"dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190ee20-a1fd-4678-b16c-594013de6230",
   "metadata": {},
   "source": [
    "Define the five splits of the data to combine iteratively into training and test sets using five-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47a04589-e7cd-48b3-883b-b18199f7cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['split0' 'split1' 'split2' 'split3' 'split4']\n"
     ]
    }
   ],
   "source": [
    "split_col = \"fold\"\n",
    "splits = df[split_col].unique()\n",
    "splits.sort()\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14bd54df-1ae3-4ff9-8685-621fbb726c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['split0', 'split1', 'split2'], 'split3'), (['split1', 'split2', 'split3'], 'split0'), (['split2', 'split3', 'split0'], 'split1'), (['split3', 'split0', 'split1'], 'split2')]\n",
      "split4\n"
     ]
    }
   ],
   "source": [
    "train0, devtest0 = list(splits[:3]), splits[3]\n",
    "train1, devtest1 = list(splits[1:4]), splits[0]\n",
    "train2, devtest2 = list(splits[2:4])+[splits[0]], splits[1]\n",
    "train3, devtest3 = [splits[3]]+list(splits[:2]), splits[2]\n",
    "runs = [(train0, devtest0), (train1, devtest1), (train2, devtest2), (train3, devtest3)]\n",
    "test = splits[4]\n",
    "print(runs)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f736edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([[\"Gendered-Pronoun\", \"Gendered-Role\", \"Generalization\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41938255-1247-4c8a-bfdc-4a67d2248dcd",
   "metadata": {},
   "source": [
    "### 4. 4-Fold Cross-Validation: Classifier Training and Development\n",
    "#### 4.1 100-Dimension Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dc19a7c-78c5-4061-8d07-2d74ec39a80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[O]                                598082\n",
       "[Gendered-Pronoun]                   3677\n",
       "[Gendered-Role]                      2425\n",
       "[Generalization]                      353\n",
       "[Gendered-Role, Generalization]         4\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_devtest = pd.DataFrame()\n",
    "for run in runs:\n",
    "    # Select 3 subsets of data as the training set and 1 subset of data as the devtest set\n",
    "    train_splits, devtest_split = run[0], run[1]\n",
    "    df_train = df.loc[df[split_col].isin(train_splits)]\n",
    "    df_devtest = df.loc[df[split_col] == devtest_split]\n",
    "    # df_test = df.loc[df[split_col] == test]\n",
    "    # assert df.shape[0] == df_train.shape[0] + df_devtest.shape[0] + df_test.shape[0]\n",
    "\n",
    "    # Extract features\n",
    "    X_train = my_utils.getFeatures(df_train, ft_model)\n",
    "    X_devtest = my_utils.getFeatures(df_devtest, ft_model)\n",
    "\n",
    "    # Binarize the targets (a.k.a. the values in the DataFrame's 'tag' column)\n",
    "    y_train = mlb.transform(df_train[col])\n",
    "    y_devtest = mlb.transform(df_devtest[col])\n",
    "    \n",
    "    # Train a classifier\n",
    "    clf = ClassifierChain(\n",
    "        classifier = RandomForestClassifier(random_state=22),\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Classify the devtest data with the trained classifier\n",
    "    y_pred = clf.predict(X_devtest)\n",
    "\n",
    "    # Format the predicted tags as lists to match the format of the expected tags\n",
    "    pred_labels = mlb.inverse_transform(y_pred)\n",
    "    new_preds = []\n",
    "    for labels in pred_labels:\n",
    "        if len(labels) == 0:\n",
    "            new_preds += [[\"O\"]]\n",
    "        else:\n",
    "            new_preds += [list(labels)]\n",
    "    \n",
    "    # Add the predictions to the devtest DataFrame\n",
    "    df_devtest.insert(len(df.columns), \"predicted\", new_preds)\n",
    "\n",
    "    # Merge any previous devtest DataFrames with the latest devtest DataFrame\n",
    "    final_df_devtest = pd.concat([final_df_devtest, df_devtest])\n",
    "\n",
    "assert final_df_devtest.shape[0] < df.shape[0]\n",
    "final_df_devtest.predicted.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85082481-6b66-4d1e-a0ff-0fbfe8b3a3a7",
   "metadata": {},
   "source": [
    "Determine the classifier's performance on the devtest sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b89ba10-c521-4a06-b835-6e4ceed59ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = final_df_devtest.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = final_df_devtest.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0edc63ba-0d97-42fd-b835-d2931c3a6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "eval_df = my_utils.getTpTnFpFn(exp_df, pred_df, pred_col, exp_col, no_tag_value, left_on_cols, right_on_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b71b39ad-0a40-4a2a-ba12-0fedfe13b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     599617\n",
       "true positive       4889\n",
       "false negative      2315\n",
       "false positive      1574\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b93f1003-ad7e-4c58-be26-c6fc38303dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12383f15-46c2-4110-836c-85bda955272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores = my_utils.getPerformanceScores(eval_df, exp_col, pred_col, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a655499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>61.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>2908.0</td>\n",
       "      <td>0.790862</td>\n",
       "      <td>0.979454</td>\n",
       "      <td>0.875113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>888.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>0.724166</td>\n",
       "      <td>0.664526</td>\n",
       "      <td>0.693065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.139798</td>\n",
       "      <td>0.228278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            61.0           769.0         2908.0   0.790862   \n",
       "0     Gendered-Role           888.0           670.0         1759.0   0.724166   \n",
       "0    Generalization          1366.0           135.0          222.0   0.621849   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.979454  0.875113  \n",
       "0  0.664526  0.693065  \n",
       "0  0.139798  0.228278  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d506d",
   "metadata": {},
   "source": [
    "Save the devtest predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81388726",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = \"data/multilabel_token_predictions/ccrf_ftcbow100lower/\"\n",
    "Path(pred_dir).mkdir(parents=True, exist_ok=True)\n",
    "eval_df.to_csv(pred_dir+\"ccrf_ftcbow100_devtest_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6d8fe",
   "metadata": {},
   "source": [
    "Evaluate the classifier on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dc5f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_test = df.loc[df[split_col] == test]\n",
    "X_test = my_utils.getFeatures(df_test, ft_model)\n",
    "y_test = mlb.transform(df_test[col])\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "\n",
    "# Add the predictions to the test DataFrame\n",
    "df_test.insert(len(df.columns), \"predicted\", new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8449295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_test.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_test.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9ad03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>split4</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos  \\\n",
       "0               0            0         0  Identifier   NN   \n",
       "1               0            0         1           :    :   \n",
       "2               0            0         2         AA5   NN   \n",
       "3               3            4       134          He  PRP   \n",
       "4               3            4       135         was  VBD   \n",
       "\n",
       "                       field token_offsets               tag    fold  \\\n",
       "0                 Identifier       (0, 10)                 O  split4   \n",
       "1                 Identifier      (10, 11)                 O  split4   \n",
       "2                 Identifier      (12, 15)                 O  split4   \n",
       "3  Biographical / Historical    (789, 791)  Gendered-Pronoun  split4   \n",
       "4  Biographical / Historical    (792, 795)                 O  split4   \n",
       "\n",
       "          predicted         _merge  \n",
       "0                 O  true negative  \n",
       "1                 O  true negative  \n",
       "2                 O  true negative  \n",
       "3  Gendered-Pronoun  true positive  \n",
       "4                 O  true negative  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "test_eval_df = my_utils.getTpTnFpFn(exp_df, pred_df, pred_col, exp_col, no_tag_value, left_on_cols, right_on_cols)\n",
    "test_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac58bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3479432f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>17.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.977690</td>\n",
       "      <td>0.862768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>202.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.667216</td>\n",
       "      <td>0.669421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>366.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.148837</td>\n",
       "      <td>0.240602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            17.0           220.0          745.0   0.772021   \n",
       "0     Gendered-Role           202.0           198.0          405.0   0.671642   \n",
       "0    Generalization           366.0            38.0           64.0   0.627451   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.977690  0.862768  \n",
       "0  0.667216  0.669421  \n",
       "0  0.148837  0.240602  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_agmt_scores = my_utils.getPerformanceScores(test_eval_df, exp_col, pred_col, labels)\n",
    "test_agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bad357",
   "metadata": {},
   "source": [
    "#### Error analysis\n",
    "A review of the *Gendered Pronoun* and *Gendered Role* false positives shows that the model's predictions are actually correct; the human coders mistakenly missed the tokens that the models classified with these labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10752e2e",
   "metadata": {},
   "source": [
    "Save the test set predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f76ef33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_df.to_csv(pred_dir+\"ccrf_ftcbow100_test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb29652",
   "metadata": {},
   "source": [
    "#### 4.2 300-Dimension Word Embeddings\n",
    "Try training the model using higher-dimension word embeddings and evaluate its performance on the devtest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cf3e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained more embeddings and saved as: fasttext_skipgram_300d.model\n"
     ]
    }
   ],
   "source": [
    "vector_dimensions = 300\n",
    "\n",
    "embedding_model = FastText(\n",
    "    alpha=alpha, sg=sg, negative=negative, sample=sample,\n",
    "    vector_size=vector_dimensions, window=context_window, \n",
    "    epochs=epochs, min_count=min_count, min_n=min_n, \n",
    "    max_n=max_n, bucket=bucket, sorted_vocab=sorted_vocab\n",
    ")\n",
    "\n",
    "embedding_model.build_vocab(corpus_iterable=CorpusIterator())\n",
    "total_examples = embedding_model.corpus_count\n",
    "\n",
    "embedding_model.train(corpus_iterable=CorpusIterator(), total_examples=total_examples, epochs=epochs)\n",
    "\n",
    "file_name = \"fasttext_{a}_{d}d.model\".format(a=training_arch, d=vector_dimensions)\n",
    "print(\"Trained more embeddings and saved as:\", file_name)\n",
    "\n",
    "embedding_model.save(\"models/embeddings/custom_fasttext/\"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d909109",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = embedding_model #FastText.load(config.fasttext_path+f\"fasttext_{training_arch}_{vector_dimensions}d.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9200a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[O]                                598080\n",
       "[Gendered-Pronoun]                   3677\n",
       "[Gendered-Role]                      2427\n",
       "[Generalization]                      353\n",
       "[Gendered-Role, Generalization]         4\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_devtest = pd.DataFrame()\n",
    "for run in runs:\n",
    "    # Select 3 subsets of data as the training set and 1 subset of data as the devtest set\n",
    "    train_splits, devtest_split = run[0], run[1]\n",
    "    df_train = df.loc[df[split_col].isin(train_splits)]\n",
    "    df_devtest = df.loc[df[split_col] == devtest_split]\n",
    "    df_test = df.loc[df[split_col] == test]\n",
    "    assert df.shape[0] == df_train.shape[0] + df_devtest.shape[0] + df_test.shape[0]\n",
    "\n",
    "    # Extract features\n",
    "    X_train = my_utils.getFeatures(df_train, ft_model)\n",
    "    X_devtest = my_utils.getFeatures(df_devtest, ft_model)\n",
    "\n",
    "    # Binarize the targets (a.k.a. the values in the DataFrame's 'tag' column)\n",
    "    y_train = mlb.transform(df_train[col])\n",
    "    y_devtest = mlb.transform(df_devtest[col])\n",
    "    \n",
    "    # Train a classifier\n",
    "    clf_300 = ClassifierChain(\n",
    "        classifier = RandomForestClassifier(random_state=22),\n",
    "    )\n",
    "    clf_300.fit(X_train, y_train)\n",
    "\n",
    "    # Classify the devtest data with the trained classifier\n",
    "    y_pred = clf_300.predict(X_devtest)\n",
    "\n",
    "    # Format the predicted tags as lists to match the format of the expected tags\n",
    "    pred_labels = mlb.inverse_transform(y_pred)\n",
    "    new_preds = []\n",
    "    for labels in pred_labels:\n",
    "        if len(labels) == 0:\n",
    "            new_preds += [[\"O\"]]\n",
    "        else:\n",
    "            new_preds += [list(labels)]\n",
    "    \n",
    "    # Add the predictions to the devtest DataFrame\n",
    "    df_devtest.insert(len(df.columns), \"predicted\", new_preds)\n",
    "\n",
    "    # Merge any previous devtest DataFrames with the latest devtest DataFrame\n",
    "    final_df_devtest = pd.concat([final_df_devtest, df_devtest])\n",
    "\n",
    "assert final_df_devtest.shape[0] < df.shape[0]\n",
    "final_df_devtest.predicted.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e061bf63",
   "metadata": {},
   "source": [
    "Determine the classifier performance on the devtest subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = final_df_devtest.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = final_df_devtest.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850ee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Title</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>Title</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>Title</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>O</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id   token  pos  field token_offsets  \\\n",
       "0               1            1         3   Title   NN  Title      (17, 22)   \n",
       "1               1            1         4       :    :  Title      (22, 23)   \n",
       "2               1            1         5  Papers  NNS  Title      (24, 30)   \n",
       "3               1            1         6      of   IN  Title      (31, 33)   \n",
       "4               1            1         7     The   DT  Title      (34, 37)   \n",
       "\n",
       "  tag    fold predicted         _merge  \n",
       "0   O  split2         O  true negative  \n",
       "1   O  split2         O  true negative  \n",
       "2   O  split2         O  true negative  \n",
       "3   O  split2         O  true negative  \n",
       "4   O  split2         O  true negative  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "eval_df = my_utils.getTpTnFpFn(exp_df, pred_df, pred_col, exp_col, no_tag_value, left_on_cols, right_on_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cff27d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     152138\n",
       "true positive       1323\n",
       "false negative       622\n",
       "false positive       406\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1202ad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f1ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>14.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.982346</td>\n",
       "      <td>0.878737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>240.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.736048</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.701653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>368.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.219608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            14.0           201.0          779.0   0.794898   \n",
       "0     Gendered-Role           240.0           175.0          488.0   0.736048   \n",
       "0    Generalization           368.0            30.0           56.0   0.651163   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.982346  0.878737  \n",
       "0  0.670330  0.701653  \n",
       "0  0.132075  0.219608  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores_300 = my_utils.getPerformanceScores(eval_df, exp_col, pred_col, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1436d",
   "metadata": {},
   "source": [
    "#### 4.3 Compare Models\n",
    "Run the two models classifying with 3 labels on the blind test data to see which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "464c59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_test = df.loc[df[split_col] == test]\n",
    "y_test = mlb.transform(df_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590959fb",
   "metadata": {},
   "source": [
    "4.3.1 100-Dimension Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4aabd1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arch, dimensions = \"skipgram\", 100\n",
    "ft_model = FastText.load(\"models/embeddings/custom_fasttext/fasttext_{a}_{d}d.model\".format(a=training_arch, d=dimensions))\n",
    "X_test = my_utils.getFeatures(df_test, ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6f92f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca3fa6",
   "metadata": {},
   "source": [
    "Export the data with the predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "340476ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['O'], ['O'], ['Gendered-Pronoun'], ['O']]\n"
     ]
    }
   ],
   "source": [
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "print(new_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33c01d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[14377]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id  sentence_id  token_id       token  pos  \\\n",
       "0                 0            0         0  Identifier   NN   \n",
       "1                 0            0         1           :    :   \n",
       "2                 0            0         2         AA5   NN   \n",
       "134               3            4       134          He  PRP   \n",
       "135               3            4       135         was  VBD   \n",
       "\n",
       "                         field token_offsets                 tag    fold  \\\n",
       "0                   Identifier       (0, 10)                 [O]  split4   \n",
       "1                   Identifier      (10, 11)                 [O]  split4   \n",
       "2                   Identifier      (12, 15)                 [O]  split4   \n",
       "134  Biographical / Historical    (789, 791)  [Gendered-Pronoun]  split4   \n",
       "135  Biographical / Historical    (792, 795)                 [O]  split4   \n",
       "\n",
       "      ann_id           predicted  \n",
       "0    [99999]                 [O]  \n",
       "1    [99999]                 [O]  \n",
       "2    [99999]                 [O]  \n",
       "134  [14377]  [Gendered-Pronoun]  \n",
       "135  [99999]                 [O]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.insert(len(df.columns), \"predicted\", new_preds)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c29acef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                   147311\n",
       "[Gendered-Pronoun]       965\n",
       "[Gendered-Role]          603\n",
       "[Generalization]         101\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a59e254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_test.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_test.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b52c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>split4</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos  \\\n",
       "0               0            0         0  Identifier   NN   \n",
       "1               0            0         1           :    :   \n",
       "2               0            0         2         AA5   NN   \n",
       "3               3            4       134          He  PRP   \n",
       "4               3            4       135         was  VBD   \n",
       "\n",
       "                       field token_offsets               tag    fold  \\\n",
       "0                 Identifier       (0, 10)                 O  split4   \n",
       "1                 Identifier      (10, 11)                 O  split4   \n",
       "2                 Identifier      (12, 15)                 O  split4   \n",
       "3  Biographical / Historical    (789, 791)  Gendered-Pronoun  split4   \n",
       "4  Biographical / Historical    (792, 795)                 O  split4   \n",
       "\n",
       "          predicted         _merge  \n",
       "0                 O  true negative  \n",
       "1                 O  true negative  \n",
       "2                 O  true negative  \n",
       "3  Gendered-Pronoun  true positive  \n",
       "4                 O  true negative  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "eval_df = my_utils.getTpTnFpFn(exp_df, pred_df, pred_col, exp_col, no_tag_value, left_on_cols, right_on_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e45542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     147756\n",
       "true positive       1214\n",
       "false negative       585\n",
       "false positive       455\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de01c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5088d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>17.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.977690</td>\n",
       "      <td>0.862768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>202.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.667216</td>\n",
       "      <td>0.669421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>366.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.148837</td>\n",
       "      <td>0.241055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            17.0           220.0          745.0   0.772021   \n",
       "0     Gendered-Role           202.0           198.0          405.0   0.671642   \n",
       "0    Generalization           366.0            37.0           64.0   0.633663   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.977690  0.862768  \n",
       "0  0.667216  0.669421  \n",
       "0  0.148837  0.241055  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = my_utils.getPerformanceScores(eval_df, exp_col, pred_col, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7fad0",
   "metadata": {},
   "source": [
    "4.3.2 300-Dimension Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "281c4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arch, dimensions = \"skipgram\", 300\n",
    "ft_model = FastText.load(\"models/embeddings/custom_fasttext/fasttext_{a}_{d}d.model\".format(a=training_arch, d=dimensions))\n",
    "X_test = my_utils.getFeatures(df_test, ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c759901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_300.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bae070",
   "metadata": {},
   "source": [
    "Export the data with the predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f85c75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O'], ['O'], ['O'], ['Gendered-Pronoun'], ['O']]\n"
     ]
    }
   ],
   "source": [
    "# Format the predicted tags as lists to match the format of the expected tags\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "new_preds = []\n",
    "for labels in pred_labels:\n",
    "    if len(labels) == 0:\n",
    "        new_preds += [[\"O\"]]\n",
    "    else:\n",
    "        new_preds += [list(labels)]\n",
    "print(new_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79e803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[14377]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>[O]</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id  sentence_id  token_id       token  pos  \\\n",
       "0                 0            0         0  Identifier   NN   \n",
       "1                 0            0         1           :    :   \n",
       "2                 0            0         2         AA5   NN   \n",
       "134               3            4       134          He  PRP   \n",
       "135               3            4       135         was  VBD   \n",
       "\n",
       "                         field token_offsets                 tag    fold  \\\n",
       "0                   Identifier       (0, 10)                 [O]  split4   \n",
       "1                   Identifier      (10, 11)                 [O]  split4   \n",
       "2                   Identifier      (12, 15)                 [O]  split4   \n",
       "134  Biographical / Historical    (789, 791)  [Gendered-Pronoun]  split4   \n",
       "135  Biographical / Historical    (792, 795)                 [O]  split4   \n",
       "\n",
       "      ann_id           predicted  \n",
       "0    [99999]                 [O]  \n",
       "1    [99999]                 [O]  \n",
       "2    [99999]                 [O]  \n",
       "134  [14377]  [Gendered-Pronoun]  \n",
       "135  [99999]                 [O]  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.drop(columns=[\"predicted\"])\n",
    "df_test.insert(len(df.columns), \"predicted\", new_preds)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d02112b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]                   147310\n",
       "[Gendered-Pronoun]       965\n",
       "[Gendered-Role]          604\n",
       "[Generalization]         101\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eebc4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_test.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = df_test.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0303ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>tag</th>\n",
       "      <th>fold</th>\n",
       "      <th>predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(789, 791)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>split4</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>(792, 795)</td>\n",
       "      <td>O</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos  \\\n",
       "0               0            0         0  Identifier   NN   \n",
       "1               0            0         1           :    :   \n",
       "2               0            0         2         AA5   NN   \n",
       "3               3            4       134          He  PRP   \n",
       "4               3            4       135         was  VBD   \n",
       "\n",
       "                       field token_offsets               tag    fold  \\\n",
       "0                 Identifier       (0, 10)                 O  split4   \n",
       "1                 Identifier      (10, 11)                 O  split4   \n",
       "2                 Identifier      (12, 15)                 O  split4   \n",
       "3  Biographical / Historical    (789, 791)  Gendered-Pronoun  split4   \n",
       "4  Biographical / Historical    (792, 795)                 O  split4   \n",
       "\n",
       "          predicted         _merge  \n",
       "0                 O  true negative  \n",
       "1                 O  true negative  \n",
       "2                 O  true negative  \n",
       "3  Gendered-Pronoun  true positive  \n",
       "4                 O  true negative  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "\n",
    "eval_df = my_utils.getTpTnFpFn(exp_df, pred_df, pred_col, exp_col, no_tag_value, left_on_cols, right_on_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12a930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     147755\n",
       "true positive       1215\n",
       "false negative       584\n",
       "false positive       455\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a52c0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c093485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>17.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.977690</td>\n",
       "      <td>0.862768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>201.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.672185</td>\n",
       "      <td>0.668863</td>\n",
       "      <td>0.670520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>366.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.148837</td>\n",
       "      <td>0.241055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            17.0           220.0          745.0   0.772021   \n",
       "0     Gendered-Role           201.0           198.0          406.0   0.672185   \n",
       "0    Generalization           366.0            37.0           64.0   0.633663   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.977690  0.862768  \n",
       "0  0.668863  0.670520  \n",
       "0  0.148837  0.241055  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores_300 = my_utils.getPerformanceScores(eval_df, exp_col, pred_col, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ee6fe",
   "metadata": {},
   "source": [
    "The classifiers perform very similarly, with the 100-dimension skip-gram and CBOW embedding models slightly better than the 300-dimension skip-gram and CBOW models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e1d5b-6b89-4aeb-841e-77a30ee598d7",
   "metadata": {},
   "source": [
    "### 5. Export Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd7c7a86-ee61-4eab-bedd-eb1145d2d97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/multilabel_token/mlb_targets_ling.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"models/multilabel_token/\"\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save classifier\n",
    "filename = model_dir+\"cc-{alg}_F-fasttext{a}{d}_T-linglabels.joblib\".format(alg=\"rf\", a=training_arch, d=vector_dimensions)  # include features (F) and targets (T) in model's file name\n",
    "dump(clf, filename)\n",
    "\n",
    "# Save multilabel binarizer\n",
    "filename = model_dir+\"mlb_targets_ling.joblib\" #\"mlb_linglabels.joblib\"\n",
    "dump(mlb, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942ddbd",
   "metadata": {},
   "source": [
    "### 6. Classify All Data\n",
    "With the highest-performing model setup, train and test a classifier using a modified form of cross-validation to get predicted classifications for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e25574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['split0', 'split1', 'split2', 'split3'], 'split4')\n",
      "(['split1', 'split2', 'split3', 'split4'], 'split0')\n",
      "(['split2', 'split3', 'split4', 'split0'], 'split1')\n",
      "(['split3', 'split4', 'split0', 'split1'], 'split2')\n",
      "(['split4', 'split0', 'split1', 'split2'], 'split3')\n"
     ]
    }
   ],
   "source": [
    "train0, test0 = list(splits[:4]), splits[4]\n",
    "train1, test1 = list(splits[1:]), splits[0]\n",
    "train2, test2 = list(splits[2:])+[splits[0]], splits[1]\n",
    "train3, test3 = list(splits[3:])+list(splits[:2]), splits[2]\n",
    "train4, test4 = [splits[4]]+list(splits[:3]), splits[3]\n",
    "runs = [(train0, test0), (train1, test1), (train2, test2), (train3, test3), (train4, test4)]\n",
    "for run in runs:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0681d971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gendered-Pronoun', 'Gendered-Role', 'Generalization'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = joblib.load('models/multilabel_token/mlb_targets_ling.joblib')\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6c6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model =  FastText.load(\"models/embeddings/custom_fasttext/fasttext_{a}_{d}d.model\".format(a=\"cbow\", d=\"100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ce8229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[O]                                745356\n",
       "[Gendered-Pronoun]                   4645\n",
       "[Gendered-Role]                      3057\n",
       "[Generalization]                      461\n",
       "[Gendered-Role, Generalization]         2\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_test = pd.DataFrame()\n",
    "for run in runs:\n",
    "    # Select 3 subsets of data as the training set and 1 subset of data as the devtest set\n",
    "    train_splits, test_split = run[0], run[1]\n",
    "    df_train = df.loc[df[split_col].isin(train_splits)]\n",
    "    df_test = df.loc[df[split_col] == test_split]\n",
    "    assert df.shape[0] == df_train.shape[0] + df_test.shape[0]\n",
    "\n",
    "    # Extract features\n",
    "    X_train = my_utils.getFeatures(df_train, ft_model)\n",
    "    X_test = my_utils.getFeatures(df_test, ft_model)\n",
    "\n",
    "    # Binarize the targets (a.k.a. the values in the DataFrame's 'tag' column)\n",
    "    y_train = mlb.transform(df_train[col])\n",
    "    y_test = mlb.transform(df_test[col])\n",
    "    \n",
    "    # Train a classifier\n",
    "    clf = ClassifierChain(\n",
    "        classifier = RandomForestClassifier(random_state=22),\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Classify the test data with the trained classifier\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Format the predicted tags as lists to match the format of the expected tags\n",
    "    pred_labels = mlb.inverse_transform(y_pred)\n",
    "    new_preds = []\n",
    "    for labels in pred_labels:\n",
    "        if len(labels) == 0:\n",
    "            new_preds += [[\"O\"]]\n",
    "        else:\n",
    "            new_preds += [list(labels)]\n",
    "    \n",
    "    # Add the predictions to the test DataFrame\n",
    "    df_test.insert(len(df.columns), \"predicted\", new_preds)\n",
    "\n",
    "    # Merge any previous test DataFrames with the latest test DataFrame\n",
    "    final_df_test = pd.concat([final_df_test, df_test])\n",
    "\n",
    "final_df_test.predicted.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcfc848",
   "metadata": {},
   "source": [
    "Determine the classifier's performance on the devtest sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d4bc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = final_df_test.drop(columns=[\"predicted\", \"ann_id\"])\n",
    "exp_df = exp_df.explode(col)\n",
    "pred_df = final_df_test.drop(columns=[\"tag\", \"ann_id\"])\n",
    "pred_df = pred_df.explode(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aea1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col = \"predicted\"\n",
    "exp_col = col\n",
    "no_tag_value = \"O\"\n",
    "left_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", exp_col]\n",
    "right_on_cols = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"field\", \"fold\", pred_col]\n",
    "\n",
    "eval_df = my_utils.getTpTnFpFn(exp_df, pred_df, pred_col, exp_col, no_tag_value, left_on_cols, right_on_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29655f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     747328\n",
       "true positive       6147\n",
       "false negative      2856\n",
       "false positive      2020\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b65554ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(eval_df.tag.unique())\n",
    "labels.sort()\n",
    "labels.remove(\"O\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad99e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores = my_utils.getPerformanceScores(eval_df, exp_col, pred_col, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9798821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>77.0</td>\n",
       "      <td>991.0</td>\n",
       "      <td>3654.0</td>\n",
       "      <td>0.786652</td>\n",
       "      <td>0.979362</td>\n",
       "      <td>0.872493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>2197.0</td>\n",
       "      <td>0.718209</td>\n",
       "      <td>0.675169</td>\n",
       "      <td>0.696024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0.639309</td>\n",
       "      <td>0.146680</td>\n",
       "      <td>0.238613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            77.0           991.0         3654.0   0.786652   \n",
       "0     Gendered-Role          1057.0           862.0         2197.0   0.718209   \n",
       "0    Generalization          1722.0           167.0          296.0   0.639309   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.979362  0.872493  \n",
       "0  0.675169  0.696024  \n",
       "0  0.146680  0.238613  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9a9df",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e991049",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = \"data/multilabel_token_predictions/ccrf_ftcbow100lower/\"\n",
    "eval_df.to_csv(pred_dir+\"ccrf_ftcbow100_alldata_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f9a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

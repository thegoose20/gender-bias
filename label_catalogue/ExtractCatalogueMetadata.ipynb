{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Latest Catalogue Data for Classification\n",
    "Harvesting, transforming, and exporting metadata descriptions for classifying gendered and gender biased language.\n",
    "\n",
    "This project is focused on the English language and archival institutions in the United Kingdom.\n",
    "\n",
    "* Creator: Lucy Havens\n",
    "* Date: April 2023 (harvesting latest catalogue data for automated annotation with classifiers)\n",
    "* Project: PhD research at the School of Informatics, University of Edinburgh\n",
    "* Data Source: Heritage Collections' [online archival catalog](https://archives.collections.ed.ac.uk/)\n",
    "\n",
    "***\n",
    "**Table of Contents**\n",
    "\n",
    "  [I. Harvesting](#harvesting)\n",
    "\n",
    "  [II. Transforming](#transforming)\n",
    "\n",
    "  [III. Preparing](#preparing)\n",
    "  \n",
    "  ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"harvesting\"></a>\n",
    "## I. Harvesting\n",
    "Obtain metadata from the Heritage Collections' online archival catalog using the Open Archives Initiative - Protocol for Metadata Harvesting (OAI-PMH).  Heritage Collections provides its metadata in Encoded Archival Description (EAD) format as XML data.  Harvest metadata descriptions from the following metadata fields in the Archives online catalog:\n",
    "  * Scope and Contents\n",
    "  * Biographical Historical\n",
    "  * Processing Information\n",
    "  * Title\n",
    "  * Language of Material\n",
    "  * Geography Name\n",
    "  * Unit ID\n",
    "  * Encoded Archival Description Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for harvesting\n",
    "import xml.dom.minidom\n",
    "import urllib.request\n",
    "import urllib\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import config\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element {http://www.openarchives.org/OAI/2.0/}OAI-PMH at 0x7f713f545840>\n"
     ]
    }
   ],
   "source": [
    "archiveMetadataUrl = \"https://aspaceoai.collections.ed.ac.uk/?verb=ListRecords&metadataPrefix=oai_ead\"  #Outdated URL: \"http://lac-archives-live.is.ed.ac.uk:8082/?verb=ListRecords&metadataPrefix=oai_ead\"\n",
    "\n",
    "def getRootFromUrl(url):\n",
    "    content = urllib.request.urlopen(url)\n",
    "\n",
    "    #tree = ET.parse(content)\n",
    "    parser = etree.XMLParser(recover=True)  # Use recover to try to fix broken XML\n",
    "    tree = etree.parse(content, parser)\n",
    "    \n",
    "    root = tree.getroot()\n",
    "    return root\n",
    "\n",
    "root = getRootFromUrl(archiveMetadataUrl)\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: part of or the entirety of a tag name below which you want to get text \n",
    "# Output: a list of text between tags contained within the inputted tagName, \n",
    "#         with one list element per tagName instance\n",
    "def getTextBeneathTag(root, tagName):\n",
    "    text_list = []\n",
    "    for child in root.iter():\n",
    "        tag = child.tag\n",
    "        if tagName in tag:\n",
    "            text_elem = \"\"\n",
    "            for subchild_text in child.itertext():\n",
    "                text_elem = text_elem + subchild_text\n",
    "            text_list.append(text_elem)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: binary value, url for harvesting metadata, starting prefix for the end of the url, and lists of metadata fields to gather\n",
    "# Output: lists of strings of the gathered metadata fields' descriptions, with one string per fonds, series, subseries, file, and item in the catalog\n",
    "def getDescriptiveMetadata(more, archiveMetadataUrlShort, startingPrefix, eadid, ut, ui, ud, gn, lm, sc, bh, pi):    \n",
    "   \n",
    "    archiveMetadataUrlWithPrefix = archiveMetadataUrlShort + startingPrefix\n",
    "    root = getRootFromUrl(archiveMetadataUrlWithPrefix)\n",
    "    eadid.append(getTextBeneathTag(root, \"eadid\"))\n",
    "    ut.append(getTextBeneathTag(root, \"unittitle\"))\n",
    "    ui.append(getTextBeneathTag(root, \"unitid\"))\n",
    "    ud.append(getTextBeneathTag(root, \"unitdate\"))\n",
    "    gn.append(getTextBeneathTag(root, \"geogname\"))\n",
    "    lm.append(getTextBeneathTag(root, \"langmaterial\"))\n",
    "    sc.append(getTextBeneathTag(root, \"scopecontent\"))\n",
    "    bh.append(getTextBeneathTag(root, \"bioghist\"))\n",
    "    pi.append(getTextBeneathTag(root, \"processinfo\"))\n",
    "    resumptionToken = getTextBeneathTag(root, \"resumptionToken\")\n",
    "    \n",
    "    if len(resumptionToken) == 0:\n",
    "        more = False\n",
    "    i = 1\n",
    "    \n",
    "    while more:\n",
    "        archiveMetadataUrlWithToken = archiveMetadataUrlShort + \"resumptionToken=\" + resumptionToken[0]\n",
    "        root = getRootFromUrl(archiveMetadataUrlWithToken)\n",
    "        eadid.append(getTextBeneathTag(root, \"eadid\"))\n",
    "        ut.append(getTextBeneathTag(root, \"unittitle\"))\n",
    "        ui.append(getTextBeneathTag(root, \"unitid\"))\n",
    "        ud.append(getTextBeneathTag(root, \"unitdate\"))\n",
    "        gn.append(getTextBeneathTag(root, \"geogname\"))\n",
    "        lm.append(getTextBeneathTag(root, \"langmaterial\"))\n",
    "        sc.append(getTextBeneathTag(root, \"scopecontent\"))\n",
    "        bh.append(getTextBeneathTag(root, \"bioghist\"))\n",
    "        pi.append(getTextBeneathTag(root, \"processinfo\"))\n",
    "        resumptionToken = getTextBeneathTag(root, \"resumptionToken\")\n",
    "        if len(resumptionToken) == 0:\n",
    "            more = False\n",
    "        i += 1\n",
    "    \n",
    "    print(str(i) + \" resumption tokens\")\n",
    "    return eadid, ut, ui, ud, gn, lm, sc, bh, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663 resumption tokens\n"
     ]
    }
   ],
   "source": [
    "url = \"https://aspaceoai.collections.ed.ac.uk/?verb=ListRecords&\"   #Outdated URL: \"http://lac-archives-live.is.ed.ac.uk:8082/?verb=ListRecords&\"\n",
    "startPrefix = \"metadataPrefix=oai_ead\"\n",
    "eadid = [] # List of fonds-level identifiers\n",
    "ut = [] # List of fonds, series, subseries, file, and item titles\n",
    "ui = [] # List of fonds, series, subseries, file, and item identifiers\n",
    "ud = [] # List of fonds, series, subseries, file, and item dates\n",
    "gn = [] # List of fonds, series, subseries, file, and item associated geographic locations \n",
    "lm = [] # List of fonds, series, subseries, file, and item material languages\n",
    "sc = [] # List of fonds, series, subseries, file, and item \"Scope and Contents\" descriptions\n",
    "bh = [] # List of fonds, series, subseries, file, and item \"Biographical / Historical\" descriptions\n",
    "pi = []  # List of fonds, series, subseries, file, and item \"Processing Information\" descriptions\n",
    "\n",
    "eadid, ut, ui, ud, gn, lm, sc, bh, pi = getDescriptiveMetadata(True, url, startPrefix, eadid, ut, ui, ud, gn, lm, sc, bh, pi)  # initial number of resumption tokens: 1081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(eadid) == len(ut)\n",
    "assert len(ut) == len(ui)\n",
    "assert len(ui) == len(ud)\n",
    "assert len(gn) == len(ui)\n",
    "assert len(lm) == len(sc)\n",
    "assert len(eadid) == len(sc)\n",
    "assert len(bh) == len(pi)\n",
    "assert len(pi) == len(eadid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sublists however have different lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "124\n",
      "124\n",
      "124\n",
      "116\n",
      "0\n",
      "119\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(len(eadid[i]))  # 1\n",
    "print(len(ut[i]))     # 124\n",
    "print(len(ui[i]))     # 124\n",
    "print(len(ud[i]))     # 124\n",
    "print(len(gn[i]))     # 116\n",
    "print(len(lm[i]))     # 125\n",
    "print(len(sc[i]))     # 119\n",
    "print(len(bh[i]))     # 2\n",
    "print(len(pi[i]))     # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"transforming\"></a>\n",
    "## II. Transforming\n",
    "Create a table (pandas DataFrame) of the metadata without multi-sentence descriptions and plain text files of the descriptive metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Metadata Fields\n",
    "\n",
    "Create a CSV file of the EADIDs and unit titles, identifiers, dates, geographies, and languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Coll-1064'], ['Coll-31'], ['Coll-51'], ['Coll-204'], ['Coll-206'], ['Coll 205'], ['Coll-1443'], ['Coll-1444'], ['Coll-1391'], ['Coll-1371']]\n"
     ]
    }
   ],
   "source": [
    "print(eadid[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = []\n",
    "for sublist in eadid:\n",
    "    for item in sublist:\n",
    "        flatten += [item]\n",
    "assert type(flatten[0]) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(eadid) == len(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>unit_title</th>\n",
       "      <th>unit_identifier</th>\n",
       "      <th>unit_date</th>\n",
       "      <th>geography</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coll-1064</td>\n",
       "      <td>[Papers of Professor Walter Ledermann, 1 (37),...</td>\n",
       "      <td>[Coll-1064, Coll-1064/1, Coll-1064/2, Coll-106...</td>\n",
       "      <td>[1937-1954, 2 Feb 1937, 10 Feb 1937, 16 Feb 19...</td>\n",
       "      <td>[Edinburgh -- Scotland, Edinburgh -- Scotland,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coll-31</td>\n",
       "      <td>[Drawings from the Office of Sir Rowand Anders...</td>\n",
       "      <td>[Coll-31, Coll-31/1, Coll-31/1/1, Coll-31/1/1/...</td>\n",
       "      <td>[1814-1924, 1874-1905, 1874-1879, 1874-1875, 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coll-51</td>\n",
       "      <td>[Papers of Sir Roderick Impey Murchison and hi...</td>\n",
       "      <td>[Coll-51, Coll-51/1, Coll-51/2, Coll-51/2/1, C...</td>\n",
       "      <td>[1771-1935, 1723-1935, 1770-1938, 1770-1938, 1...</td>\n",
       "      <td>[Calcutta (India), Europe, Scotland, Tarradale...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coll-204</td>\n",
       "      <td>[Lecture Notes of John Robison, Introductions,...</td>\n",
       "      <td>[Coll-204, Coll-204/1, Coll-204/2, Coll-204/3,...</td>\n",
       "      <td>[c1779-c1801, c1779-c1801, c1804, c1802, c1780...</td>\n",
       "      <td>[Edinburgh -- Scotland, Glasgow Lanarkshire Sc...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coll-206</td>\n",
       "      <td>[Records of the Wernerian Natural History Soci...</td>\n",
       "      <td>[Coll-206, Coll-206/1, Coll-206/1/1, Coll-206/...</td>\n",
       "      <td>[1808-1858, 12 January 1808-16 April 1858, 12 ...</td>\n",
       "      <td>[Edinburgh -- Scotland, Freiburg im Breisgau (...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eadid                                         unit_title  \\\n",
       "0  Coll-1064  [Papers of Professor Walter Ledermann, 1 (37),...   \n",
       "1    Coll-31  [Drawings from the Office of Sir Rowand Anders...   \n",
       "2    Coll-51  [Papers of Sir Roderick Impey Murchison and hi...   \n",
       "3   Coll-204  [Lecture Notes of John Robison, Introductions,...   \n",
       "4   Coll-206  [Records of the Wernerian Natural History Soci...   \n",
       "\n",
       "                                     unit_identifier  \\\n",
       "0  [Coll-1064, Coll-1064/1, Coll-1064/2, Coll-106...   \n",
       "1  [Coll-31, Coll-31/1, Coll-31/1/1, Coll-31/1/1/...   \n",
       "2  [Coll-51, Coll-51/1, Coll-51/2, Coll-51/2/1, C...   \n",
       "3  [Coll-204, Coll-204/1, Coll-204/2, Coll-204/3,...   \n",
       "4  [Coll-206, Coll-206/1, Coll-206/1/1, Coll-206/...   \n",
       "\n",
       "                                           unit_date  \\\n",
       "0  [1937-1954, 2 Feb 1937, 10 Feb 1937, 16 Feb 19...   \n",
       "1  [1814-1924, 1874-1905, 1874-1879, 1874-1875, 1...   \n",
       "2  [1771-1935, 1723-1935, 1770-1938, 1770-1938, 1...   \n",
       "3  [c1779-c1801, c1779-c1801, c1804, c1802, c1780...   \n",
       "4  [1808-1858, 12 January 1808-16 April 1858, 12 ...   \n",
       "\n",
       "                                           geography language  \n",
       "0  [Edinburgh -- Scotland, Edinburgh -- Scotland,...       []  \n",
       "1                                                 []       []  \n",
       "2  [Calcutta (India), Europe, Scotland, Tarradale...       []  \n",
       "3  [Edinburgh -- Scotland, Glasgow Lanarkshire Sc...       []  \n",
       "4  [Edinburgh -- Scotland, Freiburg im Breisgau (...       []  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.DataFrame.from_dict({\"eadid\":flatten,\"unit_title\":ut, \"unit_identifier\":ui, \"unit_date\":ud, \"geography\":gn, \"language\":lm})\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', 'BAI', 'Coll 205', 'Coll-100', 'Coll-1000']\n"
     ]
    }
   ],
   "source": [
    "ids = list(df_meta[\"eadid\"])\n",
    "ids.sort()\n",
    "print(ids[:10])  # 6 of these are empty strings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give EADIDs that are empty strings a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n",
      "['Coll-1064', 'Coll-31', 'Coll-51', 'Coll-204', 'Coll-206', 'Coll 205', 'Coll-1443', 'Coll-1444', 'Coll-1391', 'Coll-1371']\n"
     ]
    }
   ],
   "source": [
    "new_eadids = []\n",
    "no_ids = 0\n",
    "for ui in flatten:\n",
    "    if ui == \"\":\n",
    "        new_eadids += [\"no_id\"+str(no_ids)]\n",
    "        no_ids += 1\n",
    "    else:\n",
    "        new_eadids += [ui]\n",
    "print(len(new_eadids))\n",
    "print(new_eadids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(new_eadids) == len(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta[\"eadid\"] = new_eadids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(663, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_meta.shape)\n",
    "df_meta.to_csv(config.latest_cat_path+\"CRC_units-grouped-by-fonds_April2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Descriptive Metadata Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the metadata field names from the description strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFieldName(descs, field_name):\n",
    "    new_descs = []\n",
    "    for desc_list in descs:\n",
    "        new_list = []\n",
    "        for d in desc_list:\n",
    "            # Remove the metadata field name from the start of the description\n",
    "            new_d = d.replace(field_name, \"\")\n",
    "            # Remove any leading and trailing whitespace from the description\n",
    "            new_d = new_d.strip()\n",
    "            new_list += [new_d]\n",
    "        new_descs += [new_list]\n",
    "    assert len(new_descs) == len(descs)\n",
    "    return new_descs\n",
    "\n",
    "new_ut = removeFieldName(ut, \"Title\")\n",
    "new_sc = removeFieldName(sc, \"Scope and Contents\")\n",
    "new_bh = removeFieldName(bh, \"Biographical / Historical\")\n",
    "new_pi = removeFieldName(pi, \"Processing Information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a CSV file of the descriptions associated with their EADID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coll-1064</td>\n",
       "      <td>[Papers of Professor Walter Ledermann, 1 (37),...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coll-31</td>\n",
       "      <td>[Drawings from the Office of Sir Rowand Anders...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coll-51</td>\n",
       "      <td>[Papers of Sir Roderick Impey Murchison and hi...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coll-204</td>\n",
       "      <td>[Lecture Notes of John Robison, Introductions,...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coll-206</td>\n",
       "      <td>[Records of the Wernerian Natural History Soci...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eadid                                        description  field\n",
       "0  Coll-1064  [Papers of Professor Walter Ledermann, 1 (37),...  Title\n",
       "1    Coll-31  [Drawings from the Office of Sir Rowand Anders...  Title\n",
       "2    Coll-51  [Papers of Sir Roderick Impey Murchison and hi...  Title\n",
       "3   Coll-204  [Lecture Notes of John Robison, Introductions,...  Title\n",
       "4   Coll-206  [Records of the Wernerian Natural History Soci...  Title"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = len(new_eadids)\n",
    "df_ut = pd.DataFrame({\"eadid\":new_eadids, \"description\":new_ut, \"field\":[\"Title\"]*n_rows})\n",
    "df_sc = pd.DataFrame({\"eadid\":new_eadids, \"description\":new_sc, \"field\":[\"Scope and Contents\"]*n_rows})\n",
    "df_bh = pd.DataFrame({\"eadid\":new_eadids, \"description\":new_bh, \"field\":[\"Biographical / Historical\"]*n_rows})\n",
    "df_pi = pd.DataFrame({\"eadid\":new_eadids, \"description\":new_pi, \"field\":[\"Processing Information\"]*n_rows})\n",
    "df_desc = pd.concat([df_ut, df_sc, df_bh, df_pi], axis=0)\n",
    "df_desc.head() # df_desc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_exploded = df_desc.explode(\"description\")\n",
    "df_desc_exploded = df_desc_exploded.sort_values(by=\"eadid\")\n",
    "# df_desc_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199608, 3)\n"
     ]
    }
   ],
   "source": [
    "df_desc_exploded = df_desc_exploded.loc[~df_desc_exploded.description.isna()]\n",
    "df_desc_exploded = df_desc_exploded.drop_duplicates()\n",
    "print(df_desc_exploded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199608, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BAI</td>\n",
       "      <td>Review by John Baillie of the fifth chapter of...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BAI</td>\n",
       "      <td>Letters of condolence received primarily by Fl...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BAI</td>\n",
       "      <td>Cutting describing the opening of the Baillie ...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BAI</td>\n",
       "      <td>A selection of memorabilia gathered together b...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BAI</td>\n",
       "      <td>Correspondence and related items relating to t...</td>\n",
       "      <td>Scope and Contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id eadid                                        description  \\\n",
       "0               0   BAI  Review by John Baillie of the fifth chapter of...   \n",
       "1               1   BAI  Letters of condolence received primarily by Fl...   \n",
       "2               2   BAI  Cutting describing the opening of the Baillie ...   \n",
       "3               3   BAI  A selection of memorabilia gathered together b...   \n",
       "4               4   BAI  Correspondence and related items relating to t...   \n",
       "\n",
       "                field  \n",
       "0  Scope and Contents  \n",
       "1  Scope and Contents  \n",
       "2  Scope and Contents  \n",
       "3  Scope and Contents  \n",
       "4  Scope and Contents  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc_exploded = df_desc_exploded.reset_index()\n",
    "df_desc_exploded = df_desc_exploded.drop(columns=[\"index\"])\n",
    "df_desc_exploded = df_desc_exploded.reset_index()\n",
    "df_desc_exploded = df_desc_exploded.rename(columns={\"index\":\"description_id\"})\n",
    "print(df_desc_exploded.shape)\n",
    "df_desc_exploded.head()  #tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>eadid</th>\n",
       "      <th>description</th>\n",
       "      <th>field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199606</th>\n",
       "      <td>199606</td>\n",
       "      <td>no_id5</td>\n",
       "      <td>Box 8: Various</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199607</th>\n",
       "      <td>199607</td>\n",
       "      <td>no_id5</td>\n",
       "      <td>1.\\tFolded Chest X-ray Adolf Heller2.\\tPartial...</td>\n",
       "      <td>Title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        description_id   eadid  \\\n",
       "199606          199606  no_id5   \n",
       "199607          199607  no_id5   \n",
       "\n",
       "                                              description  \\\n",
       "199606                                     Box 8: Various   \n",
       "199607  1.\\tFolded Chest X-ray Adolf Heller2.\\tPartial...   \n",
       "\n",
       "                            field  \n",
       "199606  Biographical / Historical  \n",
       "199607                      Title  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc_exploded.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the DataFrame as a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_exploded.to_csv(config.latest_cat_path+\"descriptions_April2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preparing\"></a>\n",
    "## III. Preparing\n",
    "Prepare the files for classification, splitting descriptions into sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import csv\n",
    "import config\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for Natural Language Processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_exploded = pd.read_csv(config.latest_cat_path+\"descriptions_April2023.csv\", index_col=0)\n",
    "# df_desc_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert df_desc_exploded.loc[df_desc_exploded.description.isna()].shape[0] == 0  # 8?\n",
    "df_desc_exploded = df_desc_exploded.loc[~df_desc_exploded.description.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = list(df_desc_exploded.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "199607",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-73e5547386c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwords_by_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(sents[199607])              # Looks good\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_by_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m199607\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Looks good\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 199607"
     ]
    }
   ],
   "source": [
    "# # sents = dict()\n",
    "# words_by_sent = dict()\n",
    "# for i,desc in enumerate(descs):\n",
    "#     sentences = sent_tokenize(desc)\n",
    "#     sents[i] = sentences\n",
    "#     sentence_words = []\n",
    "#     for s in sentences:\n",
    "#         words = word_tokenize(s)\n",
    "#         sentence_words += [words]\n",
    "#     words_by_sent[i] = sentence_words\n",
    "# print(sents[199607])              # Looks good\n",
    "desc_ids = list(df_desc_exploded.description_id)\n",
    "print(words_by_sent[(desc_ids[-1])][1])   # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199599\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199607\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 297. GiB for an array with shape (39840160000,) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a1d2f27bd078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"description_id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# df_sents1 = df_sents1.reset_index().drop(columns=[\"index\"]).reset_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# df_sents1 = df_sents1.rename(columns={\"index\":\"sentence_id\"})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# df_sents1.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mexplode\u001b[0;34m(self, column)\u001b[0m\n\u001b[1;32m   6322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"columns must be unique\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6324\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6325\u001b[0m         return (\n\u001b[1;32m   6326\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mexplode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3698\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3700\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reshape.pyx\u001b[0m in \u001b[0;36mpandas._libs.reshape.explode\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 297. GiB for an array with shape (39840160000,) and data type object"
     ]
    }
   ],
   "source": [
    "df_sents = pd.DataFrame({\"description_id\":sents.keys(), \"sentence\":sents.values()})\n",
    "df_sents = df_sents.explode(\"sentence\")\n",
    "# df_sents1 = df_sents1.reset_index().drop(columns=[\"index\"]).reset_index()\n",
    "# df_sents1 = df_sents1.rename(columns={\"index\":\"sentence_id\"})\n",
    "# df_sents1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

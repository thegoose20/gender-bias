{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Bias Sequence Classifiers\n",
    "\n",
    "### Target: Labels\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/crf_l2sgd/`\n",
    "* Sequence classification\n",
    "    * 9 lables (2 from original annotation taxonomy weren't applied during manual annotation):\n",
    "        1. Person Name: Unknown, Feminine, Masculine (Non-binary not annotated with)\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Occupation, Omission, Stereotype (Empowering not annotated with enough)\n",
    "    * 1 model per category\n",
    "* Word embeddings\n",
    "    * GloVe (trained on Common Crawl + English Wikipedia dump)\n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[0.](#0) Preprocessing\n",
    "\n",
    "  * [Hypotheses](#h)\n",
    "\n",
    "[1.](#1) Models\n",
    "\n",
    "  * [Linguistic](#ling)\n",
    "  * [Person Name](#pers)\n",
    "  * [Contextual](#cont)\n",
    "\n",
    "[2.](#2) Performance Evaluation\n",
    "\n",
    "[3.](#3) Transitions\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.stats\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay#, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate rows with all but the same annotation ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that won't be used as features for the classifiers and remove any duplicate rows that remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"pos\", \"token\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[cols_to_keep]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev[cols_to_keep]\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate subsets of data for each category so they can be used with three separate models, replacing `NaN` tag values with `'O'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine' 'B-Gendered-Pronoun' 'B-Gendered-Role' 'B-Generalization'\n",
      " 'B-Masculine' 'B-Occupation' 'B-Omission' 'B-Stereotype' 'B-Unknown'\n",
      " 'I-Feminine' 'I-Gendered-Pronoun' 'I-Gendered-Role' 'I-Generalization'\n",
      " 'I-Masculine' 'I-Occupation' 'I-Omission' 'I-Stereotype' 'I-Unknown' 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = (df_train.tag.unique())\n",
    "tags.sort()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_cat_tags = ['B-Gendered-Pronoun', 'B-Gendered-Role', 'B-Generalization', 'I-Gendered-Pronoun', 'I-Gendered-Role', 'I-Generalization']\n",
    "df_train_ling = df_train.loc[df_train.tag.isin(ling_cat_tags)]\n",
    "df_dev_ling = df_dev.loc[df_dev.tag.isin(ling_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Unknown']\n",
    "df_train_pers = df_train.loc[df_train.tag.isin(pers_cat_tags)]\n",
    "df_dev_pers = df_dev.loc[df_dev.tag.isin(pers_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cat_tags = ['B-Occupation', 'B-Omission', 'B-Stereotype', 'I-Occupation', 'I-Omission', 'I-Stereotype']\n",
    "df_train_cont = df_train.loc[df_train.tag.isin(cont_cat_tags)]\n",
    "df_dev_cont = df_dev.loc[df_dev.tag.isin(cont_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.drop(columns=[\"tag\"])).drop_duplicates()\n",
    "df_dev = (df_dev.drop(columns=[\"tag\"])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"sentence_id\", \"token_id\", \"pos\", \"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train.join(df_train_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_ling = df_train_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_train_ling = df_train_ling.fillna('O')\n",
    "# df_train_ling.head()\n",
    "df_dev_ling = df_dev.join(df_dev_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_ling = df_dev_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_dev_ling = df_dev_ling.fillna('O')\n",
    "# df_dev_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pers = df_train.join(df_train_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_pers = df_train_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_train_pers = df_train_pers.fillna('O')\n",
    "df_dev_pers = df_dev.join(df_dev_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_pers = df_dev_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_dev_pers = df_dev_pers.fillna('O')\n",
    "# df_dev_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Papers</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>DT</td>\n",
       "      <td>The</td>\n",
       "      <td>B-Stereotype</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  pos   token tag_contextual\n",
       "3            1         3   NN   Title              O\n",
       "4            1         4    :       :              O\n",
       "5            1         5  NNS  Papers              O\n",
       "6            1         6   IN      of              O\n",
       "7            1         7   DT     The   B-Stereotype"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cont = df_train.join(df_train_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_cont = df_train_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_train_cont = df_train_cont.fillna('O')\n",
    "df_dev_cont = df_dev.join(df_dev_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_cont = df_dev_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_dev_cont = df_dev_cont.fillna('O')\n",
    "df_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train_ling.drop_duplicates()\n",
    "df_dev_ling = df_dev_ling.drop_duplicates()\n",
    "df_train_pers = df_train_pers.drop_duplicates()\n",
    "df_dev_pers = df_dev_pers.drop_duplicates()\n",
    "df_train_cont = df_train_cont.drop_duplicates()\n",
    "df_dev_cont = df_dev_cont.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452222 452086\n",
      "455327 452086\n",
      "453119 452086\n",
      "\n",
      "152494 152455\n",
      "153568 152455\n",
      "152768 152455\n"
     ]
    }
   ],
   "source": [
    "train_dfs = [df_train_ling, df_train_pers, df_train_cont]\n",
    "dev_dfs = [df_dev_ling, df_dev_pers, df_dev_cont]\n",
    "for df in train_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))\n",
    "print()\n",
    "for df in dev_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens can have multiple tags, so there are more rows than unique token IDs.  In order to pass the data into a CRF model, we need to have one tag per token, so we'll simply **take the first tag** when we extract features for each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings\n",
    "\n",
    "Get GloVe word embeddings (which were trained on English Wikipedia entries) for the vocabulary of the dataset (the unique tokens in the training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\"50\", \"100\", \"200\", \"300\"]\n",
    "d = dimensions[1]  \n",
    "# dimensonality of custom fastText embeddings = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = utils.getGloveEmbeddings(d)\n",
    "# print(glove[\"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35968\n",
      "Lowercased vocabulary size: 31335\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(df_train.token.unique())\n",
    "vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = utils.getEmbeddingsForTokens(glove, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(word_embeddings[0], glove[vocabulary[0].lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = dict(zip(vocabulary, word_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict_keys = list(embedding_dict.keys())\n",
    "for token in vocabulary:\n",
    "    assert token in embedding_dict_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "# Get a vector representation of a token from a GloVe word embedding\n",
    "def extractEmbedding(token, embedding_dict=glove, dimensions=int(d)):\n",
    "    if token.isalpha():\n",
    "        token = token.lower()\n",
    "    try:\n",
    "        embedding = embedding_dict[token]\n",
    "    except KeyError:\n",
    "        embedding = np.zeros((dimensions,))\n",
    "    return embedding.reshape(-1,1)\n",
    "\n",
    "def extractTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token,\n",
    "    }\n",
    "    \n",
    "    # Add each value in a token's word embedding as a separate feature\n",
    "    # Reference: https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training\n",
    "    embedding = extractEmbedding(token)\n",
    "    for i,n in enumerate(embedding):\n",
    "        features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractSentenceFeatures(sentence):\n",
    "    return [extractTokenFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def extractSentenceTargets(sentence):\n",
    "    return [tag_list[0] for token, pos, tag_list in sentence]\n",
    "\n",
    "def extractSentenceTokens(sentence):\n",
    "    return [token for token, pos, tag_list in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"h\"></a>\n",
    "#### Hypothesis:\n",
    "The three multiclass baseline sequence classifiers with GloVe word embeddings as features will have higher F1 scores than the same models with custom fastText embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Models\n",
    "<a id=\"ling\"></a>\n",
    "### Linguistic\n",
    "\n",
    "* **Features:** custom fastText embeddings, token suffixes\n",
    "* **Target:** Linguistic label category IOB tags\n",
    "* **Algorithm:** L2SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_ling\n",
    "df_dev = df_dev_ling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by token, so the all the tags for one token are recorded in a list for that token's row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by sentence, where each sentence is a list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_ling = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_linguistic\")\n",
    "# print(train_sentences_ling[0][:3])\n",
    "dev_sentences_ling = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_linguistic\")\n",
    "# print(dev_sentences_ling[0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_ling\n",
    "dev_sentences = dev_sentences_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m [extractSentenceFeatures(sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_sentences\u001b[49m]\n\u001b[1;32m      3\u001b[0m X_dev \u001b[38;5;241m=\u001b[39m [extractSentenceFeatures(sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m dev_sentences]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Target\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** pa with pa_type=0 was best, however, arow with variance=0.5 also had strong performance, and is strongest with other categories, Person Name and Contextual, so we'll use arow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Linguistic** category of tags.  We'll increase the max_iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ling = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_ling.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(clf_ling.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_ling.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's scores with GloVe embeddings of 100 dimensions were:\n",
    "\n",
    "The baseline model's scores with GloVe embeddings of 50 dimensions were:\n",
    "  - F1: 0.6682632094564904\n",
    "  - Prec: 0.6397609767051633\n",
    "  - Rec 0.7057842046718577\n",
    "  \n",
    "Which is a slightly lower performance than the baseline model with custom fastText embeddings:\n",
    "  - F1: 0.6697698893667122\n",
    "  - Prec: 0.696012355375722\n",
    "  - Rec 0.6718576195773082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pers\"></a>\n",
    "### Person Name\n",
    "\n",
    "* **Features:** custom fastText embeddings\n",
    "* **Target:** Person-Name label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_pers\n",
    "df_dev = df_dev_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_pers = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_personname\")\n",
    "# print(train_sentences_pers[0][:3])\n",
    "dev_sentences_pers = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_personname\")\n",
    "# print(dev_sentences_pers[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_pers\n",
    "dev_sentences = dev_sentences_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=0.5 was best-performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pers = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_pers.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'I-Masculine', 'B-Masculine', 'B-Feminine', 'I-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_pers.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pers.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.45688362747838485\n",
      "  - Prec: 0.44852949944619963\n",
      "  - Rec 0.4783540505786541\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's performance scores were:\n",
    "  - F1: 0.45688362747838485\n",
    "  - Prec: 0.44852949944619963\n",
    "  - Rec 0.4783540505786541\n",
    "\n",
    "Compared to the baseline model with custom fastText embeddings:\n",
    "  - F1: 0.4789287297354048\n",
    "  - Prec: 0.5381704595959792\n",
    "  - Rec 0.43620517216745247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "### Contextual\n",
    "\n",
    "* **Features:** custom fastText embeddings, token suffixes\n",
    "* **Target:** Contextual label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_cont\n",
    "df_dev = df_dev_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_cont = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_contextual\")\n",
    "# print(train_sentences_cont[0][:3])\n",
    "dev_sentences_cont = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_contextual\")\n",
    "# print(dev_sentences_cont[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_cont\n",
    "dev_sentences = dev_sentences_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=0.5 was the best performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Contextual** category of tags.  We'll increase the maximum iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cont = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_cont.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Stereotype', 'I-Stereotype', 'B-Occupation', 'I-Occupation', 'B-Omission', 'I-Omission']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_cont.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_cont.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.3896210891326545\n",
      "  - Prec: 0.40701772348045956\n",
      "  - Rec 0.3752442996742671\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's performance scores were:\n",
    "  - F1: 0.3896210891326545\n",
    "  - Prec: 0.40701772348045956\n",
    "  - Rec 0.3752442996742671\n",
    "  \n",
    "Compared to the baseline model with custom fastText embeddings:\n",
    "  - F1: 0.40803990799640844\n",
    "  - Prec: 0.4124968743940007\n",
    "  - Rec 0.4091205211726384"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

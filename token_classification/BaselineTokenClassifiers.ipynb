{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Biased Token Classifiers\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory ../data/token_clf_data/model_input/\n",
    "* Multilabel classification\n",
    "    * 3 categories of labels:\n",
    "        1. Person Name: Unknown, Non-binary, Feminine, Masculine\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Empowering, Occupation, Omission, Stereotype\n",
    "* Also try a [classifier chain](https://scikit-learn.org/stable/modules/multiclass.html#classifierchain)!!!\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[0.](#0) Preprocessing\n",
    "\n",
    "[1.](#1) Logistic Regression (LR)\n",
    "\n",
    "[2.](#2) Decision Tree\n",
    "\n",
    "[3.](#3) Random Forest\n",
    "\n",
    "[4.](#4) Support Vector Machines (SVM) (a.k.a. support vector classification (SVC))\n",
    "\n",
    "[5.](#4) Error Analysis\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "* https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets \n",
    "* https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2\n",
    "* Text Analysis with Python for Social Scienctists (Hovy, 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# For classifcation\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer  # does binary one-hot encoding if features are strings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470712, 8) (158836, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token        tag  field  \\\n",
       "3               1            1   99999         3   Title          O  Title   \n",
       "4               1            1   99999         4       :          O  Title   \n",
       "5               1            1   99999         5  Papers          O  Title   \n",
       "6               1            1   99999         6      of          O  Title   \n",
       "7               1            1   14384         7     The  B-Unknown  Title   \n",
       "\n",
       "  subset  \n",
       "3  train  \n",
       "4  train  \n",
       "5  train  \n",
       "6  train  \n",
       "7  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = list(df_train.token)\n",
    "lemmas_train = [lmtzr.lemmatize(token) for token in tokens_train]\n",
    "tokens_dev = list(df_dev.token)\n",
    "lemmas_dev = [lmtzr.lemmatize(token) for token in tokens_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.insert((list(df_train.columns).index(\"token\")+1), \"lemma\", lemmas_train)\n",
    "df_dev.insert((list(df_dev.columns).index(\"token\")+1), \"lemma\", lemmas_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>784526</th>\n",
       "      <td>27907</td>\n",
       "      <td>42028</td>\n",
       "      <td>99999</td>\n",
       "      <td>753916</td>\n",
       "      <td>medical</td>\n",
       "      <td>medical</td>\n",
       "      <td>O</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784527</th>\n",
       "      <td>27907</td>\n",
       "      <td>42028</td>\n",
       "      <td>99999</td>\n",
       "      <td>753917</td>\n",
       "      <td>treatment</td>\n",
       "      <td>treatment</td>\n",
       "      <td>O</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784528</th>\n",
       "      <td>27907</td>\n",
       "      <td>42028</td>\n",
       "      <td>99999</td>\n",
       "      <td>753918</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784529</th>\n",
       "      <td>27907</td>\n",
       "      <td>42028</td>\n",
       "      <td>99999</td>\n",
       "      <td>753919</td>\n",
       "      <td>homosexuality</td>\n",
       "      <td>homosexuality</td>\n",
       "      <td>O</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784530</th>\n",
       "      <td>27907</td>\n",
       "      <td>42028</td>\n",
       "      <td>99999</td>\n",
       "      <td>753920</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        description_id  sentence_id  ann_id  token_id          token  \\\n",
       "784526           27907        42028   99999    753916        medical   \n",
       "784527           27907        42028   99999    753917      treatment   \n",
       "784528           27907        42028   99999    753918             of   \n",
       "784529           27907        42028   99999    753919  homosexuality   \n",
       "784530           27907        42028   99999    753920              .   \n",
       "\n",
       "                lemma tag               field subset  \n",
       "784526        medical   O  Scope and Contents  train  \n",
       "784527      treatment   O  Scope and Contents  train  \n",
       "784528             of   O  Scope and Contents  train  \n",
       "784529  homosexuality   O  Scope and Contents  train  \n",
       "784530              .   O  Scope and Contents  train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>99999</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14379</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>his</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>99999</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14380</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>99999</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id  sentence_id  ann_id  token_id       token       lemma  \\\n",
       "172               3            5   99999       154       After       After   \n",
       "173               3            5   14379       155         his         his   \n",
       "174               3            5   99999       156  ordination  ordination   \n",
       "175               3            5   14380       157          he          he   \n",
       "176               3            5   99999       158       spent       spent   \n",
       "\n",
       "                    tag                      field subset  \n",
       "172                   O  Biographical / Historical    dev  \n",
       "173  B-Gendered-Pronoun  Biographical / Historical    dev  \n",
       "174                   O  Biographical / Historical    dev  \n",
       "175  B-Gendered-Pronoun  Biographical / Historical    dev  \n",
       "176                   O  Biographical / Historical    dev  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize and encode the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.drop(columns=[\"description_id\",\"ann_id\", \"token_id\", \"field\", \"subset\"])\n",
    "# df_dev = df_dev.drop(columns=[\"description_id\",\"ann_id\", \"token_id\", \"field\", \"subset\"])\n",
    "v = DictVectorizer(sparse=False)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels2numbers = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-Feminine': 0, 'B-Gendered-Pronoun': 1, 'B-Gendered-Role': 2, 'B-Generalization': 3, 'B-Masculine': 4, 'B-Nonbinary': 5, 'B-Occupation': 6, 'B-Omission': 7, 'B-Stereotype': 8, 'B-Unknown': 9, 'I-Feminine': 10, 'I-Gendered-Pronoun': 11, 'I-Gendered-Role': 12, 'I-Generalization': 13, 'I-Masculine': 14, 'I-Nonbinary': 15, 'I-Occupation': 16, 'I-Omission': 17, 'I-Stereotype': 18, 'I-Unknown': 19, 'O': 20}\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"sentence_id\", \"lemma\"]\n",
    "target_col = \"tag\"\n",
    "labels = np.unique(y_train)\n",
    "labels2numbers = LabelEncoder()\n",
    "y = labels2numbers.fit_transform(labels)\n",
    "label_to_no = dict(zip(labels,list(y)))\n",
    "print(label_to_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117686, 12897)\n",
      "(117686, 19)\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(4,)\n",
      "B-Masculine\n"
     ]
    }
   ],
   "source": [
    "# TAKE A SAMPLE OF 25% FOR NOW\n",
    "sent_ids = list(df_train.sentence_id)\n",
    "quarter = int(len(sent_ids)/4)\n",
    "sent_ids_sample = list(set(sent_ids[:quarter]))\n",
    "df_train_sample = df_train.loc[df_train.sentence_id.isin(sent_ids_sample)]\n",
    "\n",
    "X_train = df_train_sample[feature_cols]\n",
    "# X_train = df_train[[\"sentence_id\", \"lemma\"]]\n",
    "X_train = v.fit_transform(X_train.to_dict('records'))\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = df_train_sample[target_col].values\n",
    "# Convert the string labels to numeric labels\n",
    "y_train_numeric = utils.getNumericLabels(y_train, label_to_no)\n",
    "# Convert each iterable of iterables above to a multilabel format\n",
    "y_train_binarized = mlb.fit_transform(y_train_numeric)\n",
    "print(y_train_binarized.shape)\n",
    "print(y_train_binarized[5])\n",
    "print(y_train_numeric[5])\n",
    "print(y_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39741, 7021)\n",
      "(39741, 19)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "(20,)\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "# TAKE A SAMPLE OF 25% FOR NOW\n",
    "sent_ids = list(df_dev.sentence_id)\n",
    "quarter = int(len(sent_ids)/4)\n",
    "sent_ids_sample = list(set(sent_ids[:quarter]))\n",
    "df_dev_sample = df_dev.loc[df_dev.sentence_id.isin(sent_ids_sample)]\n",
    "\n",
    "X_dev = df_dev_sample[feature_cols]\n",
    "# X_dev = df_dev.drop(\"tag\", axis=1)\n",
    "X_dev = v.fit_transform(X_dev.to_dict('records'))\n",
    "print(X_dev.shape)\n",
    "\n",
    "y_dev = df_dev_sample[target_col].values\n",
    "# Convert the string labels to numeric labels\n",
    "y_dev_numeric = utils.getNumericLabels(y_dev, label_to_no)\n",
    "# Convert each iterable of iterables above to a multilabel format\n",
    "y_dev_binarized = mlb.fit_transform(y_dev_numeric)\n",
    "print(y_dev_binarized.shape)\n",
    "print(y_dev_binarized[5])\n",
    "print(y_dev_numeric[5])\n",
    "print(y_dev[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_pipeline = Pipeline([\n",
    "#     (\"vect\", CountVectorizer()),\n",
    "#     (\"tfidf\", TfidfTransformer()),\n",
    "#     (\"clf\", OneVsRestClassifier(LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")))\n",
    "# ])\n",
    "clf = OneVsRestClassifier(LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 7021 features per sample; expecting 12897",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-91d61a081f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# clf_pipeline.fit(X_train, y_train_binarized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_binarized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicted_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_predict_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m                 \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# probabilities of the positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    273\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 7021 features per sample; expecting 12897"
     ]
    }
   ],
   "source": [
    "# clf_pipeline.fit(X_train, y_train_binarized)\n",
    "clf.fit(X_train, y_train_binarized)\n",
    "predicted_dev = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dev Accuracy:\", np.mean(predicted_dev == y_dev_binarized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_matrix = multilabel_confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

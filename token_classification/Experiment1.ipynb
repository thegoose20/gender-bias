{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "#### Model Setup\n",
    "\n",
    "Run models in the following order, using their output labels as features for the next model:\n",
    "\n",
    "[1.](#1) Multilabel Linguistic Classifier\n",
    "\n",
    "[2.](#2) Multiclass Person Name + Occupation Sequence Classifier\n",
    "\n",
    "[3.](#3) Multilabel Document Classifier\n",
    "\n",
    "***\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/experiment_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/experiment1/`\n",
    "* Word Embeddings\n",
    "    * Custom fastText (word2vec with subwords) embeddings of 100 dimensions trained on the CRC Archives catalog's descriptive metadata (harvested October 2020)\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load programming resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, utils1, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For preprocessing\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "\n",
    "# For multilabel token classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# For multiclass sequence classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resources for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.experiment_input_path).mkdir(parents=True, exist_ok=True)    # For train, devtest, and blind test data\n",
    "Path(config.experiment1_output_path).mkdir(parents=True, exist_ok=True)  # For predictions\n",
    "Path(config.experiment1_agmt_path).mkdir(parents=True, exist_ok=True)    # For agreement metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1:\n",
    "ling_label_subset = [\"B-Generalization\", \"I-Generalization\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"]\n",
    "# Model 2:\n",
    "pers_o_label_subset = [\"B-Unknown\", \"I-Unknown\", \"B-Feminine\", \"I-Feminine\", \"B-Masculine\", \"I-Masculine\", \"B-Occupation\", \"I-Occupation\"]\n",
    "# Model 3:\n",
    "so_label_subset = [\"B-Stereotype\", \"I-Stereotype\", \"B-Omission\", \"I-Omission\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_label_tags = {\n",
    "    \"Gendered-Pronoun\": [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"], \"Gendered-Role\": [\"B-Gendered-Role\", \"I-Gendered-Role\"],\"Generalization\": [\"B-Generalization\", \"I-Generalization\"]\n",
    "    }\n",
    "pers_o_label_tags = {\n",
    "    \"Unknown\": [\"B-Unknown\", \"I-Unknown\"], \"Feminine\": [\"B-Feminine\", \"I-Feminine\"], \"Masculine\": [\"B-Masculine\", \"I-Masculine\"],\n",
    "     \"Occupation\": [\"B-Occupation\", \"I-Occupation\"]\n",
    "    }\n",
    "so_label_tags = {\n",
    "    \"Stereotype\": [\"B-Stereotype\", \"I-Stereotype\"], \"Omission\": [\"B-Omission\", \"I-Omission\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100  # dimensions of word embeddings (should match utils1.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Linguistic Classifier\n",
    "\n",
    "Run a multilabel classifier on the train set of the data, focusing only on applying the Linguistic category of labels: Gendered Pronoun, Gendered Role, and Generalization.\n",
    "\n",
    "Use a Classifier Chain with Random Forest, as this was the highest-performing multilabel model setup from previous algorithm experiments for the Linguistic labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we'll train the model on 40% of the data, rather than 60%.  We'll use fastText embeddings of 100 dimensions, as was used in the model that achieved the above scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(config.tokc_path+\"experiment_input/token_train.csv\", index_col=0)\n",
    "dev_df = pd.read_csv(config.tokc_path+\"experiment_input/token_validate.csv\", index_col=0)\n",
    "ling_train, ling_dev = utils.selectDataForLabels(train_df, dev_df, \"tag\", ling_label_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298617, 5) (305924, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>NN</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>NNS</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>NNS</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id     token  pos  tag\n",
       "0            2        16     Scope   NN  [O]\n",
       "1            2        17       and   CC  [O]\n",
       "2            2        18  Contents  NNS  [O]\n",
       "3            2        19         :    :  [O]\n",
       "4            2        20   Sermons  NNS  [O]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = utils1.loadData(ling_train)\n",
    "dev_data = utils1.loadData(ling_dev)\n",
    "print(train_data.shape, dev_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_data.shape[0] == len(train_data.token_id.unique())\n",
    "assert dev_data.shape[0] == len(dev_data.token_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = utils1.zipTokensFeatures(train_data)\n",
    "dev_tokens = utils1.zipTokensFeatures(dev_data)\n",
    "X_train = utils1.makeFastTextFeatureMatrix(train_tokens)\n",
    "X_dev = utils1.makeFastTextFeatureMatrix(dev_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb, y_train = utils1.binarizeTrainTargets(train_data)\n",
    "y_dev = utils1.binarizeDevTargets(mlb, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"rf\"\n",
    "clf = ClassifierChain(\n",
    "    classifier = RandomForestClassifier(random_state=22),\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Strict, All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - macro: 0.46238272522632073\n",
      "Recall - macro: 0.42298863525280694\n",
      "F1 Score - macro: 0.42251820432443793\n",
      "Accuracy - normalized: 0.9925798564349315\n",
      "Accuracy - unnormalized: 303654\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - macro:\", sklearn.metrics.precision_score(y_dev, predictions, average=\"macro\", zero_division=0))  # macro = mean of all labels' score\n",
    "print(\"Recall - macro:\", sklearn.metrics.recall_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print(\"F1 Score - macro:\", sklearn.metrics.f1_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print(\"Accuracy - normalized:\", sklearn.metrics.accuracy_score(y_dev, predictions, normalize=True))  # fraction of correctly classified samples\n",
    "print(\"Accuracy - unnormalized:\", sklearn.metrics.accuracy_score(y_dev, predictions, normalize=False))  # number of correctly classified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 305924\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", X_dev.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Each Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id   token  pos predicted_tag\n",
       "0            1         3   Title   NN             O\n",
       "1            1         4       :    :             O\n",
       "2            1         5  Papers  NNS             O\n",
       "3            1         6      of   IN             O\n",
       "4            1         7     The   DT             O"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = utils.makePredictionDF(predictions, dev_data, \"tag\", \"predicted_tag\", \"O\", mlb)\n",
    "assert pred_df.loc[pred_df.predicted_tag.isna()].shape[0] == 0, \"Any NaN values should be replaced with 'O'\"\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306940 305924\n"
     ]
    }
   ],
   "source": [
    "print(pred_df.shape[0], len(pred_df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(config.experiment1_output_path+\"cc-{a}_ling_baseline_fastText{d}_predictions.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more predictions than unique tokens, because with multilabel classification, one token can have multiple predicted tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id   token  pos expected_tag\n",
       "0            1         3   Title   NN            O\n",
       "1            1         4       :    :            O\n",
       "2            1         5  Papers  NNS            O\n",
       "3            1         6      of   IN            O\n",
       "4            1         7     The   DT            O"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = dev_data.explode([\"tag\"])\n",
    "exp_df = exp_df.rename(columns={\"tag\":\"expected_tag\"})\n",
    "exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307597 305924\n"
     ]
    }
   ],
   "source": [
    "print(exp_df.shape[0], len(exp_df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308371, 7)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_pred_df = pd.merge(\n",
    "    left=exp_df, \n",
    "    right=pred_df.loc[pred_df.predicted_tag != \"O\"], # only include the predictions of Linguistic labels\n",
    "    how=\"outer\",\n",
    "    left_on=[\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\"],\n",
    "    right_on=[\"sentence_id\", \"token_id\", \"token\", \"pos\", \"predicted_tag\"],\n",
    "    suffixes=[\"\", \"_pred\"],\n",
    "    indicator=True\n",
    ")\n",
    "exp_pred_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the agreement type for each row, ignoring rows with `'O'` and `NaN` value pairs (the `true negative` agreement type, which doesn't go into the precision, recall, or F1 score calculations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>His</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7</td>\n",
       "      <td>226</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>16</td>\n",
       "      <td>435</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  token_id token   pos        expected_tag  \\\n",
       "39             5       155   his  PRP$  B-Gendered-Pronoun   \n",
       "41             5       157    he   PRP  B-Gendered-Pronoun   \n",
       "62             7       216   His  PRP$  B-Gendered-Pronoun   \n",
       "72             7       226    he   PRP  B-Gendered-Pronoun   \n",
       "218           16       435    He   PRP  B-Gendered-Pronoun   \n",
       "\n",
       "          predicted_tag         _merge  \n",
       "39   B-Gendered-Pronoun  true positive  \n",
       "41   B-Gendered-Pronoun  true positive  \n",
       "62   B-Gendered-Pronoun  true positive  \n",
       "72   B-Gendered-Pronoun  true positive  \n",
       "218  B-Gendered-Pronoun  true positive  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_col = \"expected_tag\"\n",
    "pred_col = \"predicted_tag\"\n",
    "no_tag_value = \"O\"\n",
    "# Find true negatives based on the expected and predicted tags\n",
    "sub_exp_pred_df = exp_pred_df.loc[exp_pred_df[exp_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.loc[sub_exp_pred_df[pred_col].isna()]\n",
    "# sub_exp_pred_df.replace(to_replace=\"left_only\", value=\"true negative\", inplace=True)\n",
    "tn_tokens = list(sub_exp_pred_df[\"token_id\"])\n",
    "\n",
    "# Record false negatives, false positives, and true positives based on the merge values\n",
    "eval_df = exp_pred_df.loc[~exp_pred_df[\"token_id\"].isin(tn_tokens)]\n",
    "eval_df = eval_df.replace(to_replace=\"left_only\", value=\"false negative\")\n",
    "eval_df = eval_df.replace(to_replace=\"right_only\", value=\"false positive\")\n",
    "eval_df = eval_df.replace(to_replace=\"both\", value=\"true positive\")\n",
    "eval_df = eval_df.sort_index()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2177, 7)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(config.experiment1_agmt_path+\"cc-{a}_ling_baseline_fastText{d}_evaluation.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the true positives, false positives, false negatives, precision, recall, and F1 metrics for all tags and each tag individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>476</td>\n",
       "      <td>7</td>\n",
       "      <td>1694</td>\n",
       "      <td>0.462383</td>\n",
       "      <td>0.422989</td>\n",
       "      <td>0.422518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Generalization</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.699764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Generalization</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "      <td>0.997722</td>\n",
       "      <td>0.818692</td>\n",
       "      <td>0.899384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2802</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.994675</td>\n",
       "      <td>0.996976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Pronoun</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag(s)  false negative  false positive  true positive  \\\n",
       "0                 all             476               7           1694   \n",
       "0    B-Generalization             124               3            148   \n",
       "0    I-Generalization              85               1              0   \n",
       "0     B-Gendered-Role              97               1            438   \n",
       "0     I-Gendered-Role             132               0              0   \n",
       "0  B-Gendered-Pronoun              15               2           2802   \n",
       "0  I-Gendered-Pronoun              23               0              0   \n",
       "\n",
       "   precision    recall        f1  \n",
       "0   0.462383  0.422989  0.422518  \n",
       "0   0.980132  0.544118  0.699764  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "0   0.997722  0.818692  0.899384  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "0   0.999287  0.994675  0.996976  \n",
       "0   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_stats = utils.getAgreementStatsForAllTags(eval_df, \"_merge\", \"token_id\", \"tag(s)\", y_dev, predictions)\n",
    "for label_tag in ling_label_subset:\n",
    "    label_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [label_tag])\n",
    "    agmt_stats = pd.concat([agmt_stats, label_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_stats.to_csv(config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_strict_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Annotation-level Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the manual annotations' offsets to the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df = pd.read_csv(config.agg_path+\"aggregated_final.csv\")#, usecols=[\"description_id\",\"agg_ann_id\", \"ann_offsets\"])\n",
    "# Get only the Linguistic annotations\n",
    "annot_df = annot_df.loc[annot_df.category == \"Linguistic\"]\n",
    "annot_df = annot_df[[\"agg_ann_id\", \"ann_offsets\", \"label\"]]\n",
    "annot_df = annot_df.rename(columns={\"agg_ann_id\":\"ann_id\"})\n",
    "# annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_token_ids = list(dev_data.token_id.unique())\n",
    "ling_dev_subset = ling_dev.loc[ling_dev.token_id.isin(dev_token_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3996, 9)\n",
      "(3996, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "      <td>14379</td>\n",
       "      <td>(913, 916)</td>\n",
       "      <td>(913, 916)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "      <td>14380</td>\n",
       "      <td>(928, 930)</td>\n",
       "      <td>(928, 930)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>216</td>\n",
       "      <td>His</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "      <td>14382</td>\n",
       "      <td>(1241, 1244)</td>\n",
       "      <td>(1241, 1244)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>226</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1315, 1317)</td>\n",
       "      <td>(1315, 1317)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218.0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>435</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "      <td>9516</td>\n",
       "      <td>(677, 679)</td>\n",
       "      <td>(677, 679)</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id token   pos        expected_tag  \\\n",
       "39.0           5.0       155   his  PRP$  B-Gendered-Pronoun   \n",
       "41.0           5.0       157    he   PRP  B-Gendered-Pronoun   \n",
       "62.0           7.0       216   His  PRP$  B-Gendered-Pronoun   \n",
       "72.0           7.0       226    he   PRP  B-Gendered-Pronoun   \n",
       "218.0         16.0       435    He   PRP  B-Gendered-Pronoun   \n",
       "\n",
       "            predicted_tag         _merge  ann_id token_offsets   ann_offsets  \\\n",
       "39.0   B-Gendered-Pronoun  true positive   14379    (913, 916)    (913, 916)   \n",
       "41.0   B-Gendered-Pronoun  true positive   14380    (928, 930)    (928, 930)   \n",
       "62.0   B-Gendered-Pronoun  true positive   14382  (1241, 1244)  (1241, 1244)   \n",
       "72.0   B-Gendered-Pronoun  true positive   14383  (1315, 1317)  (1315, 1317)   \n",
       "218.0  B-Gendered-Pronoun  true positive    9516    (677, 679)    (677, 679)   \n",
       "\n",
       "         expected_label  \n",
       "39.0   Gendered-Pronoun  \n",
       "41.0   Gendered-Pronoun  \n",
       "62.0   Gendered-Pronoun  \n",
       "72.0   Gendered-Pronoun  \n",
       "218.0  Gendered-Pronoun  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_add = ling_dev_subset[[\"ann_id\", \"token_id\", \"token_offsets\"]]\n",
    "# Only include annotations with Linguistic labels\n",
    "to_add = to_add.loc[to_add.ann_id.isin(list(annot_df.ann_id))]\n",
    "eval_df_joined = eval_df.join(to_add.set_index(\"token_id\"), on=\"token_id\", how=\"outer\")\n",
    "# Join on the left, as there will be annotations from outside the devtest set in annot_df\n",
    "print(eval_df_joined.shape)\n",
    "eval_df_joined = eval_df_joined.join(annot_df.set_index(\"ann_id\"), on=\"ann_id\", how=\"left\")\n",
    "print(eval_df_joined.shape)  # Looks good!  Same as before join.\n",
    "eval_df_joined = eval_df_joined.rename(columns={\"label\":\"expected_label\"})\n",
    "eval_df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the predicted tags with their corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_label              2234\n",
       "B-Gendered-Pronoun    1447\n",
       "B-Gendered-Role        232\n",
       "B-Generalization        82\n",
       "I-Generalization         1\n",
       "Name: predicted_tag, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_joined.expected_label = eval_df_joined.expected_label.fillna(\"no_label\")\n",
    "eval_df_joined.expected_tag = eval_df_joined.expected_tag.fillna(\"no_label\")\n",
    "eval_df_joined.predicted_tag = eval_df_joined.predicted_tag.fillna(\"no_label\")\n",
    "eval_df_joined.predicted_tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = list(eval_df_joined.predicted_tag)\n",
    "predicted_labels = [tag[2:] if tag != \"no_label\" else tag for tag in predicted_labels]\n",
    "eval_df_joined.insert(len(eval_df_joined.columns), \"predicted_label\", predicted_labels)\n",
    "# eval_df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"token\", \"expected_label\", \"predicted_label\", \"_merge\", \"token_offsets\", \"ann_offsets\", \"ann_id\"]\n",
    "eval_by_ann = utils.implodeDataFrame(eval_df_joined[cols_to_keep], [\"ann_id\", \"ann_offsets\"]).reset_index()\n",
    "exp_labels = list(eval_by_ann[\"expected_label\"])\n",
    "exp_labels = [labels[0] for labels in exp_labels]\n",
    "eval_by_ann[\"expected_label\"] = exp_labels\n",
    "# eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert eval_by_ann.loc[eval_by_ann.expected_label == \"no_label\"].shape[0] == 0\n",
    "assert eval_by_ann.loc[eval_by_ann.expected_label.isna()].shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row should have an annotation label (a Linguistic label in `expected_label`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>ann_offsets</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>annotation_agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>[5760.0, 5760.0]</td>\n",
       "      <td>[133674, 133674]</td>\n",
       "      <td>[knighted, knighted]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>[no_label, Generalization]</td>\n",
       "      <td>[false negative, false positive]</td>\n",
       "      <td>[(1407, 1415), (1407, 1415)]</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[228678, 228679]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[(9625, 9635), (9635, 9636)]</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(2426, 2439)</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[196525, 196526, 196527]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>[no_label, no_label, no_label]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[(2426, 2432), (2433, 2439), (2439, 2440)]</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>(4141, 4148)</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[4714, 4715]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>[no_label, no_label]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[(4141, 4148), (4148, 4149)]</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1063</td>\n",
       "      <td>(1532, 1535)</td>\n",
       "      <td>[12112.0]</td>\n",
       "      <td>[272117]</td>\n",
       "      <td>[his]</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "      <td>[true positive]</td>\n",
       "      <td>[(1532, 1535)]</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ann_id   ann_offsets       sentence_id                  token_id  \\\n",
       "0       0  (1407, 1415)  [5760.0, 5760.0]          [133674, 133674]   \n",
       "1       1  (9625, 9635)        [nan, nan]          [228678, 228679]   \n",
       "2       2  (2426, 2439)   [nan, nan, nan]  [196525, 196526, 196527]   \n",
       "3      93  (4141, 4148)        [nan, nan]              [4714, 4715]   \n",
       "4    1063  (1532, 1535)         [12112.0]                  [272117]   \n",
       "\n",
       "                  token    expected_label                 predicted_label  \\\n",
       "0  [knighted, knighted]     Gendered-Role      [no_label, Generalization]   \n",
       "1            [nan, nan]     Gendered-Role            [no_label, no_label]   \n",
       "2       [nan, nan, nan]     Gendered-Role  [no_label, no_label, no_label]   \n",
       "3            [nan, nan]     Gendered-Role            [no_label, no_label]   \n",
       "4                 [his]  Gendered-Pronoun              [Gendered-Pronoun]   \n",
       "\n",
       "                             _merge  \\\n",
       "0  [false negative, false positive]   \n",
       "1                        [nan, nan]   \n",
       "2                   [nan, nan, nan]   \n",
       "3                        [nan, nan]   \n",
       "4                   [true positive]   \n",
       "\n",
       "                                token_offsets annotation_agreement  \n",
       "0                [(1407, 1415), (1407, 1415)]       false positive  \n",
       "1                [(9625, 9635), (9635, 9636)]       false negative  \n",
       "2  [(2426, 2432), (2433, 2439), (2439, 2440)]       false negative  \n",
       "3                [(4141, 4148), (4148, 4149)]       false negative  \n",
       "4                              [(1532, 1535)]        true positive  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_agmts = []\n",
    "token_agmts = (eval_by_ann[\"_merge\"])\n",
    "for agmts in token_agmts:\n",
    "    if \"true positive\" in agmts:\n",
    "        ann_agmt = \"true positive\"\n",
    "    elif \"false positive\" in agmts:\n",
    "        ann_agmt = \"false positive\"\n",
    "    else:\n",
    "        ann_agmt = \"false negative\"\n",
    "    ann_agmts += [ann_agmt]\n",
    "assert len(ann_agmts) == eval_by_ann.shape[0]\n",
    "eval_by_ann.insert(len(eval_by_ann.columns), \"annotation_agreement\", ann_agmts)\n",
    "eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_by_ann[[\"ann_id\", \"ann_offsets\", \"token_id\", \"expected_label\", \"predicted_label\", \"annotation_agreement\"]].to_csv(\n",
    "    config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_annot_evaluation.csv\".format(a=a,d=d)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate annotation agreement metrics for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_agmt = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914491</td>\n",
       "      <td>0.955336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>976.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.190713</td>\n",
       "      <td>0.319444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>408.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.376328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun           131.0             0.0         1401.0   1.000000   \n",
       "0     Gendered-Role           976.0             4.0          230.0   0.982906   \n",
       "0    Generalization           408.0             3.0          124.0   0.976378   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.914491  0.955336  \n",
       "0  0.190713  0.319444  \n",
       "0  0.233083  0.376328  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ling_label_tags.keys()\n",
    "for label in labels:\n",
    "    agmt_df = eval_by_ann.loc[eval_by_ann.expected_label == label]\n",
    "    tp = agmt_df.loc[agmt_df.annotation_agreement == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df.annotation_agreement == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df.annotation_agreement == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    annot_agmt = pd.concat([annot_agmt, label_agmt])\n",
    "annot_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_by_ann.loc[eval_by_ann.expected_label == \"Gendered-Role\"][\"annotation_agreement\"].value_counts()     # Looks good\n",
    "# eval_by_ann.loc[eval_by_ann.expected_label == \"Gendered-Pronoun\"][\"annotation_agreement\"].value_counts()  # Looks good\n",
    "# eval_by_ann.loc[eval_by_ann.expected_label == \"Generalization\"][\"annotation_agreement\"].value_counts()    # Looks good\n",
    "annot_agmt.to_csv(config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_annot_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loose Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each label, where a correct prediction is a prediction with the correct annotation label (not necessarily the correct IOB tag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the evaluation DataFrame where tags are replaced by label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"rf\"\n",
    "eval_df = pd.read_csv(config.experiment1_agmt_path+\"cc-{a}_ling_baseline_fastText{d}_evaluation.csv\".format(a=a,d=d), index_col=0)\n",
    "loose_eval_df = eval_df.copy()\n",
    "for label,tags in ling_label_tags.items():\n",
    "    for tag in tags:\n",
    "        loose_eval_df[\"expected_tag\"] = loose_eval_df[\"expected_tag\"].replace(to_replace=tag, value=label)\n",
    "        loose_eval_df[\"predicted_tag\"] = loose_eval_df[\"predicted_tag\"].replace(to_replace=tag, value=label)\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose_eval_df.loc[loose_eval_df.predicted_tag.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>His</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7</td>\n",
       "      <td>226</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>16</td>\n",
       "      <td>435</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  token_id token   pos      expected_tag     predicted_tag  \\\n",
       "39             5       155   his  PRP$  Gendered-Pronoun  Gendered-Pronoun   \n",
       "41             5       157    he   PRP  Gendered-Pronoun  Gendered-Pronoun   \n",
       "62             7       216   His  PRP$  Gendered-Pronoun  Gendered-Pronoun   \n",
       "72             7       226    he   PRP  Gendered-Pronoun  Gendered-Pronoun   \n",
       "218           16       435    He   PRP  Gendered-Pronoun  Gendered-Pronoun   \n",
       "\n",
       "            _merge  \n",
       "39   true positive  \n",
       "41   true positive  \n",
       "62   true positive  \n",
       "72   true positive  \n",
       "218  true positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose_eval_df = loose_eval_df.fillna(\"O\")\n",
    "loose_eval_df = loose_eval_df.drop(columns=[\"_merge\"])\n",
    "loose_eval_df = utils.compareExpectedPredicted(loose_eval_df, \"_merge\", \"O\")\n",
    "loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df.to_csv(config.experiment1_agmt_path+\"cc-{a}_ling_baseline_fastText{d}_evaluation_loose.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt = pd.DataFrame.from_dict({\n",
    "        \"tag(s)\":[], \"false negative\":[], \"false positive\":[], \"true negative\":[], \n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2802.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986620</td>\n",
       "      <td>0.993265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>438.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.656672</td>\n",
       "      <td>0.792760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.414566</td>\n",
       "      <td>0.586139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tag(s)  false negative  false positive  true negative  \\\n",
       "0  Gendered-Pronoun            38.0             0.0            NaN   \n",
       "0     Gendered-Role           229.0             0.0            NaN   \n",
       "0    Generalization           209.0             0.0            NaN   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0         2802.0        1.0  0.986620  0.993265  \n",
       "0          438.0        1.0  0.656672  0.792760  \n",
       "0          148.0        1.0  0.414566  0.586139  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label,tags in ling_label_tags.items():\n",
    "    labels_agmt_stats = utils.getScoresByTags(loose_eval_df, \"_merge\", [label])\n",
    "    loose_agmt = pd.concat([loose_agmt, labels_agmt_stats])\n",
    "loose_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  The performance of this model looks comparable to the model trained on 60% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt.to_csv(config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_loose_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"2\"></a>\n",
    "## 2. Person Name + Occupation Labels\n",
    "\n",
    "Train a multiclass sequence classifier, using Conditional Random Field with Adaptive Regularization of Weight Vectors (AROW), on the Person Name and Occupation labels, **passing in the Linguistic labels (not specific BIO label-tag pair) from the previous model's predictions as features to this model.**\n",
    "\n",
    "Multiclass is a suitable setup for these labels because they are mutually exclusive (no one token should have more than one of these labels).  The sequence classifier with AROW was the highest performing for past algorithm experiments with sequence classifiers for Person Name and Occupation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pred_ling_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>155</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>157</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>216</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>226</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>435</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id     pred_ling_tag\n",
       "39        155  Gendered-Pronoun\n",
       "41        157  Gendered-Pronoun\n",
       "62        216  Gendered-Pronoun\n",
       "72        226  Gendered-Pronoun\n",
       "218       435  Gendered-Pronoun"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loose_eval_df = pd.read_csv(config.experiment1_agmt_path+\"cc-{a}_ling_baseline_fastText{d}_evaluation_loose.csv\".format(a=a,d=d), index_col=0)\n",
    "train_ling_features = loose_eval_df[[\"token_id\", \"predicted_tag\"]]\n",
    "train_ling_features = train_ling_features.rename(columns={\"predicted_tag\":\"pred_ling_tag\"})\n",
    "train_ling_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The devtest data subset from the model in step 1 will be the train data subset in this step, with the predicted Linguistic labels as features passed into this second model.  The train data subset from the first model will be the devtest data subset for this second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316721, 10) (308583, 10)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(config.tokc_path+\"experiment_input/token_validate.csv\", index_col=0)\n",
    "dev_df =  pd.read_csv(config.tokc_path+\"experiment_input/token_train.csv\", index_col=0)\n",
    "perso_train, perso_dev = utils.selectDataForLabels(train_df, dev_df, \"tag\", pers_o_label_subset)\n",
    "print(perso_train.shape, perso_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the linguistic labels (features) to the train and devtest data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "      <th>pred_ling_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52952</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>dev</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "9               1            1   52952         7     The      (34, 37)   DT   \n",
       "\n",
       "  tag  field subset pred_ling_tag  \n",
       "3   O  Title    dev           NaN  \n",
       "4   O  Title    dev           NaN  \n",
       "5   O  Title    dev           NaN  \n",
       "6   O  Title    dev           NaN  \n",
       "9   O  Title    dev           NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perso_train = perso_train.join(train_ling_features.set_index(\"token_id\"), on=\"token_id\", how=\"outer\")\n",
    "perso_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                   315090\n",
       "Gendered-Pronoun      1447\n",
       "Gendered-Role          232\n",
       "Generalization          83\n",
       "Name: pred_ling_tag, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perso_train.pred_ling_tag = perso_train.pred_ling_tag.fillna(\"O\")\n",
    "perso_train.pred_ling_tag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = perso_train.drop(columns=[\"description_id\", \"ann_id\", \"token_offsets\", \"field\", \"subset\", \"pos\"])\n",
    "dev_df = perso_dev.drop(columns=[\"description_id\", \"ann_id\", \"token_offsets\", \"field\", \"subset\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(train_df, ['token_id', 'sentence_id', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "# df_train_token_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_token_groups = utils.implodeDataFrame(dev_df, ['token_id', 'sentence_id', 'token'])\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()\n",
    "# df_dev_token_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "      <th>pred_ling_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, The, Very, Rev, Prof, J...</td>\n",
       "      <td>[[O], [O], [O], [O], [O, B-Unknown, B-Masculin...</td>\n",
       "      <td>[[O], [O], [O], [O], [O, O, O], [O, O, O], [O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[109, 110, 111, 112, 113, 114, 115, 116, 117, ...</td>\n",
       "      <td>[Biographical, /, Historical, :, Professor, Ja...</td>\n",
       "      <td>[[O], [O], [O], [O], [B-Masculine], [I-Masculi...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[[O], [Gendered-Pronoun], [O], [Gendered-Prono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[216, 217, 218, 219, 220, 221, 222, 223, 224, ...</td>\n",
       "      <td>[His, primary, interests, were, in, liturgy, a...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[[Gendered-Pronoun], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[256, 257, 258, 259, 260, 261, 262, 263, 264, ...</td>\n",
       "      <td>[The, service, was, relayed, around, the, worl...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "1                [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]   \n",
       "3            [109, 110, 111, 112, 113, 114, 115, 116, 117, ...   \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "7            [216, 217, 218, 219, 220, 221, 222, 223, 224, ...   \n",
       "9            [256, 257, 258, 259, 260, 261, 262, 263, 264, ...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "1            [Title, :, Papers, of, The, Very, Rev, Prof, J...   \n",
       "3            [Biographical, /, Historical, :, Professor, Ja...   \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "7            [His, primary, interests, were, in, liturgy, a...   \n",
       "9            [The, service, was, relayed, around, the, worl...   \n",
       "\n",
       "                                                           tag  \\\n",
       "sentence_id                                                      \n",
       "1            [[O], [O], [O], [O], [O, B-Unknown, B-Masculin...   \n",
       "3            [[O], [O], [O], [O], [B-Masculine], [I-Masculi...   \n",
       "5            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "7            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "9            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "\n",
       "                                                 pred_ling_tag  \n",
       "sentence_id                                                     \n",
       "1            [[O], [O], [O], [O], [O, O, O], [O, O, O], [O,...  \n",
       "3            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "5            [[O], [Gendered-Pronoun], [O], [Gendered-Prono...  \n",
       "7            [[Gendered-Pronoun], [O], [O], [O], [O], [O], ...  \n",
       "9            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_train_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the linguistic label and BIO tags together with the tokens so each sentence item is a tuple: `(TOKEN, LING_LABEL, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('After', ['O'], ['O']), ('his', ['Gendered-Pronoun'], ['O']), ('ordination', ['O'], ['O'])]\n",
      "[('Scope', ['O']), ('and', ['O']), ('Contents', ['O'])]\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_pers = utils1.zipTrainFeaturesAndTarget(df_train_grouped, \"tag\")\n",
    "print(train_sentences_pers[2][:3])\n",
    "dev_sentences_pers = utils1.zipDevFeaturesAndTarget(df_dev_grouped, \"tag\")\n",
    "print(dev_sentences_pers[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_pers\n",
    "dev_sentences = dev_sentences_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [utils1.extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [utils1.extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [utils1.extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [utils1.extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"arow\"\n",
    "clf_pers = sklearn_crfsuite.CRF(algorithm=a, variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_pers.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Unknown', 'B-Masculine', 'I-Masculine', 'B-Occupation', 'I-Occupation', 'B-Unknown', 'I-Feminine', 'B-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_pers.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pers.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.40267473104429147\n",
      "  - Prec: 0.4517275156285195\n",
      "  - Rec 0.3767280305661688\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[233, 234, 235, 236, 237, 238, 239, 240, 241, ...</td>\n",
       "      <td>[James, Whyte, was, called, upon, to, preach, ...</td>\n",
       "      <td>[[B-Masculine], [I-Masculine], [O], [O], [O], ...</td>\n",
       "      <td>[B-Masculine, I-Unknown, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>[520, 521, 522, 523, 524, 525, 526, 527, 528, ...</td>\n",
       "      <td>[Rev, Tom, Allan, 's, first, charge, was, Nort...</td>\n",
       "      <td>[[B-Masculine], [I-Masculine], [I-Masculine], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>[579, 580, 581, 582, 583, 584, 585, 586, 587, ...</td>\n",
       "      <td>[In, 1953, the, \", Tell, Scotland, \", committe...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>[768, 769, 770, 771, 772, 773, 774, 775, 776, ...</td>\n",
       "      <td>[Title, :, Papers, of, Rev, Prof, Alec, Campbe...</td>\n",
       "      <td>[[O], [O], [O], [O], [B-Masculine, B-Unknown],...</td>\n",
       "      <td>[O, O, O, O, O, O, B-Unknown, I-Unknown, I-Mas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                           token_id  \\\n",
       "0            2  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "1            8  [233, 234, 235, 236, 237, 238, 239, 240, 241, ...   \n",
       "2           19  [520, 521, 522, 523, 524, 525, 526, 527, 528, ...   \n",
       "3           21  [579, 580, 581, 582, 583, 584, 585, 586, 587, ...   \n",
       "4           30  [768, 769, 770, 771, 772, 773, 774, 775, 776, ...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "1  [James, Whyte, was, called, upon, to, preach, ...   \n",
       "2  [Rev, Tom, Allan, 's, first, charge, was, Nort...   \n",
       "3  [In, 1953, the, \", Tell, Scotland, \", committe...   \n",
       "4  [Title, :, Papers, of, Rev, Prof, Alec, Campbe...   \n",
       "\n",
       "                                 tag_pers_o_expected  \\\n",
       "0  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "1  [[B-Masculine], [I-Masculine], [O], [O], [O], ...   \n",
       "2  [[B-Masculine], [I-Masculine], [I-Masculine], ...   \n",
       "3  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "4  [[O], [O], [O], [O], [B-Masculine, B-Unknown],...   \n",
       "\n",
       "                                tag_pers_o_predicted  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [B-Masculine, I-Unknown, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, B-Unknown, I-Unknown, I-Mas...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag\":\"tag_pers_o_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_pers_o_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id  sentence tag_pers_o_expected tag_pers_o_predicted\n",
       "sentence_id                                                            \n",
       "2                 16     Scope                 [O]                    O\n",
       "2                 17       and                 [O]                    O\n",
       "2                 18  Contents                 [O]                    O\n",
       "2                 19         :                 [O]                    O\n",
       "2                 20   Sermons                 [O]                    O"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.set_index(\"sentence_id\")\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_{a}_pers_o_baseline_fastText{d}_predictions.csv\".format(a=a, d=d)\n",
    "df_dev_exploded.to_csv(config.experiment1_output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the development data's test, the predicted labels will be deemed incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"arow\"\n",
    "category = \"pers_o\"\n",
    "filename = \"crf_{a}_{c}_baseline_fastText{d}_predictions.csv\".format(a=a, c=category, d=d)\n",
    "pred_perso = pd.read_csv(config.experiment1_output_path+filename)\n",
    "pred_perso = utils.getColumnValuesAsLists(pred_perso, \"tag_{}_expected\".format(category))\n",
    "# pred_pers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics for each category of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  sentence tag_pers_o_expected tag_pers_o_predicted  \\\n",
       "0            2        16     Scope                 [O]                    O   \n",
       "1            2        17       and                 [O]                    O   \n",
       "2            2        18  Contents                 [O]                    O   \n",
       "3            2        19         :                 [O]                    O   \n",
       "4            2        20   Sermons                 [O]                    O   \n",
       "\n",
       "          _merge  \n",
       "0  true negative  \n",
       "1  true negative  \n",
       "2  true negative  \n",
       "3  true negative  \n",
       "4  true negative  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso = utils.isPredictedInExpected(pred_perso, \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), '_merge', 'O')\n",
    "pred_perso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>1086</td>\n",
       "      <td>1003</td>\n",
       "      <td>1314</td>\n",
       "      <td>0.567113</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.557134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>2117</td>\n",
       "      <td>2002</td>\n",
       "      <td>2639</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.554878</td>\n",
       "      <td>0.561669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>45</td>\n",
       "      <td>215</td>\n",
       "      <td>309</td>\n",
       "      <td>0.589695</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.703872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>249</td>\n",
       "      <td>128</td>\n",
       "      <td>311</td>\n",
       "      <td>0.708428</td>\n",
       "      <td>0.555357</td>\n",
       "      <td>0.622623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>303</td>\n",
       "      <td>315</td>\n",
       "      <td>404</td>\n",
       "      <td>0.561892</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.566620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>697</td>\n",
       "      <td>433</td>\n",
       "      <td>314</td>\n",
       "      <td>0.420348</td>\n",
       "      <td>0.310584</td>\n",
       "      <td>0.357224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>373</td>\n",
       "      <td>712</td>\n",
       "      <td>655</td>\n",
       "      <td>0.479151</td>\n",
       "      <td>0.637160</td>\n",
       "      <td>0.546973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>662</td>\n",
       "      <td>477</td>\n",
       "      <td>553</td>\n",
       "      <td>0.536893</td>\n",
       "      <td>0.455144</td>\n",
       "      <td>0.492650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0     B-Unknown            1086            1003           1314   0.567113   \n",
       "0     I-Unknown            2117            2002           2639   0.568627   \n",
       "0    B-Feminine              45             215            309   0.589695   \n",
       "0    I-Feminine             249             128            311   0.708428   \n",
       "0   B-Masculine             303             315            404   0.561892   \n",
       "0   I-Masculine             697             433            314   0.420348   \n",
       "0  B-Occupation             373             712            655   0.479151   \n",
       "0  I-Occupation             662             477            553   0.536893   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.547500  0.557134  \n",
       "0  0.554878  0.561669  \n",
       "0  0.872881  0.703872  \n",
       "0  0.555357  0.622623  \n",
       "0  0.571429  0.566620  \n",
       "0  0.310584  0.357224  \n",
       "0  0.637160  0.546973  \n",
       "0  0.455144  0.492650  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso_stats = utils.getScoresByCatTags(\n",
    "    pred_perso, \"_merge\", pers_o_label_subset[0], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(pers_o_label_subset)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_perso, \"_merge\", pers_o_label_subset[i], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_perso_stats = pd.concat([pred_perso_stats, tag_stats])\n",
    "pred_perso_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_stats.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_strict_agmt.csv\".format(a=a, c=category, d=d)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotation Agreement\n",
    "\n",
    "Calculate agreement at the annotation level, so if the model labels any word correctly from a manually annotated text span, that annotation is recorded as being correctly labeled (`true positive`).  Note whether the models' labels are an `exact_match`, `label_match`, `category_match` or `mismatch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the annotation data:\n",
    "\n",
    "*Note: `ann_id` of `9999` indicates no annotation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df =  pd.read_csv(config.tokc_path+\"experiment_input/token_train.csv\", usecols=[\"sentence_id\", \"ann_id\", \"token_id\", \"tag\"])\n",
    "# dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the annotation data by token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ann = utils.implodeDataFrame(dev_df, [\"sentence_id\", \"ann_id\", \"token_id\"])\n",
    "df_ann = df_ann.reset_index()\n",
    "# print(df_ann.shape)\n",
    "# df_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align the columns of the dev and prediction DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename `sentence` column `token`\n",
    "pred_perso = pred_perso.rename(columns={\"sentence\":\"token\"})\n",
    "# pred_perso.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the data, adding the annotation IDs (`ann_id` column) to the prediction DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [\"sentence_id\", \"token_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_ann = pred_perso.join(df_ann.set_index(index_list), on=index_list, how=\"left\")\n",
    "pred_perso_ann = pred_perso_ann.drop(columns=[\"tag\"])  # duplicate of tag_expected\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"token_id\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"ann_id\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"tag_pers_o_predicted\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"tag_pers_o_expected\"].isna()].shape[0] == 0\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explode the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_ann = pred_perso_ann.explode([\"tag_pers_o_expected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalize the BIO tags to label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted labels\n",
    "pred_labels = list(pred_perso_ann[\"tag_{}_predicted\".format(category)])\n",
    "pred_labels = [label if label == \"O\" else label[2:] for label in pred_labels]\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"label_{}_predicted\".format(category), pred_labels)\n",
    "# Get the lists of expected labels\n",
    "exp_labels = list(pred_perso_ann[\"tag_{}_expected\".format(category)])\n",
    "exp_labels = [label if label == \"O\" else label[2:] for label in exp_labels]\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"label_{}_expected\".format(category), exp_labels)\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>_merge</th>\n",
       "      <th>label_pers_o_predicted</th>\n",
       "      <th>label_pers_o_expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>14387</td>\n",
       "      <td>[233, 234]</td>\n",
       "      <td>[James, Whyte]</td>\n",
       "      <td>[true positive, false positive]</td>\n",
       "      <td>[Masculine, Unknown]</td>\n",
       "      <td>[Masculine, Masculine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>99999</td>\n",
       "      <td>[235, 236, 237, 238, 239, 240, 241, 242, 243, ...</td>\n",
       "      <td>[was, called, upon, to, preach, at, the, memor...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>9518</td>\n",
       "      <td>[533]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>9519</td>\n",
       "      <td>[539]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  ann_id                                           token_id  \\\n",
       "0            2   99999  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "1            8   14387                                         [233, 234]   \n",
       "2            8   99999  [235, 236, 237, 238, 239, 240, 241, 242, 243, ...   \n",
       "3           19    9518                                              [533]   \n",
       "4           19    9519                                              [539]   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "1                                     [James, Whyte]   \n",
       "2  [was, called, upon, to, preach, at, the, memor...   \n",
       "3                                               [he]   \n",
       "4                                               [he]   \n",
       "\n",
       "                                              _merge  \\\n",
       "0  [true negative, true negative, true negative, ...   \n",
       "1                    [true positive, false positive]   \n",
       "2  [true negative, true negative, true negative, ...   \n",
       "3                                    [true negative]   \n",
       "4                                    [true negative]   \n",
       "\n",
       "                              label_pers_o_predicted  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1                               [Masculine, Unknown]   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3                                                [O]   \n",
       "4                                                [O]   \n",
       "\n",
       "                               label_pers_o_expected  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1                             [Masculine, Masculine]  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3                                                [O]  \n",
       "4                                                [O]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso_ann = pred_perso_ann.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_perso_ann = utils.implodeDataFrame(pred_perso_ann, [\"sentence_id\", \"ann_id\"])\n",
    "pred_perso_ann = pred_perso_ann.reset_index()\n",
    "pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the agreements and disagreements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_types_perso, agmt_labels_perso = utils1.getAnnotationAgreement(pred_perso_ann, \"label_pers_o_predicted\", \"label_pers_o_expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>_merge</th>\n",
       "      <th>label_pers_o_predicted</th>\n",
       "      <th>label_pers_o_expected</th>\n",
       "      <th>annotation_agreement</th>\n",
       "      <th>agreement_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>false positive</td>\n",
       "      <td>Occupation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>14387</td>\n",
       "      <td>[233, 234]</td>\n",
       "      <td>[James, Whyte]</td>\n",
       "      <td>[true positive, false positive]</td>\n",
       "      <td>[Masculine, Unknown]</td>\n",
       "      <td>[Masculine, Masculine]</td>\n",
       "      <td>true positive</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>99999</td>\n",
       "      <td>[235, 236, 237, 238, 239, 240, 241, 242, 243, ...</td>\n",
       "      <td>[was, called, upon, to, preach, at, the, memor...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>true negative</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>9518</td>\n",
       "      <td>[533]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>true negative</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>9519</td>\n",
       "      <td>[539]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>true negative</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  ann_id                                           token_id  \\\n",
       "0            2   99999  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "1            8   14387                                         [233, 234]   \n",
       "2            8   99999  [235, 236, 237, 238, 239, 240, 241, 242, 243, ...   \n",
       "3           19    9518                                              [533]   \n",
       "4           19    9519                                              [539]   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "1                                     [James, Whyte]   \n",
       "2  [was, called, upon, to, preach, at, the, memor...   \n",
       "3                                               [he]   \n",
       "4                                               [he]   \n",
       "\n",
       "                                              _merge  \\\n",
       "0  [true negative, true negative, true negative, ...   \n",
       "1                    [true positive, false positive]   \n",
       "2  [true negative, true negative, true negative, ...   \n",
       "3                                    [true negative]   \n",
       "4                                    [true negative]   \n",
       "\n",
       "                              label_pers_o_predicted  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1                               [Masculine, Unknown]   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3                                                [O]   \n",
       "4                                                [O]   \n",
       "\n",
       "                               label_pers_o_expected annotation_agreement  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       false positive   \n",
       "1                             [Masculine, Masculine]        true positive   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...        true negative   \n",
       "3                                                [O]        true negative   \n",
       "4                                                [O]        true negative   \n",
       "\n",
       "  agreement_label  \n",
       "0      Occupation  \n",
       "1       Masculine  \n",
       "2               O  \n",
       "3               O  \n",
       "4               O  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"annotation_agreement\", agmt_types_perso)\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"agreement_label\", agmt_labels_perso)\n",
    "pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>false negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>false positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>4850</td>\n",
       "      <td>5243</td>\n",
       "      <td>2235</td>\n",
       "      <td>0.701123</td>\n",
       "      <td>0.519469</td>\n",
       "      <td>0.596779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person Name</td>\n",
       "      <td>4307</td>\n",
       "      <td>4376</td>\n",
       "      <td>1684</td>\n",
       "      <td>0.722112</td>\n",
       "      <td>0.503973</td>\n",
       "      <td>0.593638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>3037</td>\n",
       "      <td>2744</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.705398</td>\n",
       "      <td>0.474658</td>\n",
       "      <td>0.567470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>231</td>\n",
       "      <td>641</td>\n",
       "      <td>166</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.735092</td>\n",
       "      <td>0.763550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>1039</td>\n",
       "      <td>991</td>\n",
       "      <td>372</td>\n",
       "      <td>0.727073</td>\n",
       "      <td>0.488177</td>\n",
       "      <td>0.584144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>543</td>\n",
       "      <td>867</td>\n",
       "      <td>551</td>\n",
       "      <td>0.611425</td>\n",
       "      <td>0.614894</td>\n",
       "      <td>0.613154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels  false negative  true positive  false positive  precision  \\\n",
       "0          all            4850           5243            2235   0.701123   \n",
       "0  Person Name            4307           4376            1684   0.722112   \n",
       "0      Unknown            3037           2744            1146   0.705398   \n",
       "0     Feminine             231            641             166   0.794300   \n",
       "0    Masculine            1039            991             372   0.727073   \n",
       "0   Occupation             543            867             551   0.611425   \n",
       "\n",
       "     recall       f_1  \n",
       "0  0.519469  0.596779  \n",
       "0  0.503973  0.593638  \n",
       "0  0.474658  0.567470  \n",
       "0  0.735092  0.763550  \n",
       "0  0.488177  0.584144  \n",
       "0  0.614894  0.613154  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_perso_all = utils1.getAnnotationAgreementMetrics(pred_perso_ann, \"all\")\n",
    "metrics_perso_pn = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[~(pred_perso_ann.agreement_label.isin([\"Occupation\",\"O\"]))], \"Person Name\")\n",
    "metrics_perso_unk = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Unknown\"], \"Unknown\")\n",
    "metrics_perso_fem = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Feminine\"], \"Feminine\")\n",
    "metrics_perso_mas = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Masculine\"], \"Masculine\")\n",
    "metrics_perso_occ = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Occupation\"], \"Occupation\")\n",
    "metrics_perso = pd.concat([metrics_perso_all, metrics_perso_pn, metrics_perso_unk, metrics_perso_fem, metrics_perso_mas, metrics_perso_occ])\n",
    "metrics_perso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_perso.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_annot_agmt.csv\".format(a=a, d=d, c=category)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loose Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the manual annotation evaluation, we want to evaluate the predictions more loosely, considering overlapping text spans in addition to exactly matching text spans.\n",
    "\n",
    "#### Token Agreement\n",
    "\n",
    "First, generalize the tokens' IOB tags to the label, and calculate agreement scores for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_labels = pred_perso.drop(columns=[\"_merge\"])\n",
    "tag_exp = list(pred_perso_labels[\"tag_{}_expected\".format(category)])\n",
    "tag_pred = list(pred_perso_labels[\"tag_{}_predicted\".format(category)])\n",
    "label_exp = [[tag if tag == \"O\" else tag[2:] for tag in tag_exp_list] for tag_exp_list in tag_exp]\n",
    "label_pred = [tag if tag == \"O\" else tag[2:] for tag in tag_pred]\n",
    "pred_perso_labels = pred_perso_labels.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_perso_labels.insert(len(pred_perso_labels.columns), \"label_{}_expected\".format(category), label_exp)\n",
    "pred_perso_labels.insert(len(pred_perso_labels.columns), \"label_{}_predicted\".format(category), label_pred)\n",
    "# pred_pers_labels.loc[pred_pers_labels.label_personname_predicted == \"Feminine\"].head()  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the agreement metrics at the label level for each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>3198</td>\n",
       "      <td>2653</td>\n",
       "      <td>4305</td>\n",
       "      <td>0.618712</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.595395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>669</td>\n",
       "      <td>0.694704</td>\n",
       "      <td>0.695426</td>\n",
       "      <td>0.695065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>998</td>\n",
       "      <td>655</td>\n",
       "      <td>811</td>\n",
       "      <td>0.553206</td>\n",
       "      <td>0.448314</td>\n",
       "      <td>0.495267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>1035</td>\n",
       "      <td>1087</td>\n",
       "      <td>1310</td>\n",
       "      <td>0.546516</td>\n",
       "      <td>0.558635</td>\n",
       "      <td>0.552509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0     Unknown            3198            2653           4305   0.618712   \n",
       "0    Feminine             293             294            669   0.694704   \n",
       "0   Masculine             998             655            811   0.553206   \n",
       "0  Occupation            1035            1087           1310   0.546516   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.573770  0.595395  \n",
       "0  0.695426  0.695065  \n",
       "0  0.448314  0.495267  \n",
       "0  0.558635  0.552509  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['Unknown', 'Feminine', 'Masculine', 'Occupation']\n",
    "pred_perso_labels = utils.isPredictedInExpected(pred_perso_labels, \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), '_merge', 'O')\n",
    "\n",
    "pred_perso_stats = utils.getScoresByCatTags(\n",
    "    pred_perso_labels, \"_merge\", tags[0], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_perso_labels, \"_merge\", tags[i], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_perso_stats = pd.concat([pred_perso_stats, tag_stats])\n",
    "pred_perso_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine and save the performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_stats.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_loose_agmt.csv\".format(a=a, d=d, c=category)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

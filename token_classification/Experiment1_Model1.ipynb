{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1, Model 1\n",
    "\n",
    "#### Model Setup\n",
    "\n",
    "Run models in the following order, using their output labels as features for the next model:\n",
    "\n",
    "1. Multilabel Linguistic Classifier\n",
    "2. Multiclass Person Name + Occupation Sequence Classifier\n",
    "3. Multilabel Stereotype and Omission Document Classifier\n",
    "\n",
    "Train the first model and then run it over the entire dataset.\n",
    "\n",
    "***\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/experiment_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/experiment1/`\n",
    "* Word Embeddings\n",
    "    * Custom fastText (word2vec with subwords) embeddings of 100 dimensions trained on the CRC Archives catalog's descriptive metadata (harvested October 2020)\n",
    "    \n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[I.](#i) Linguistic Classifier\n",
    "* [Preprocessing](#prep)\n",
    "* [Training & Prediction](#tp)\n",
    "* [Evaluation](#eval)\n",
    "\n",
    "[II.](#ii) Predict Over All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load programming resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, utils1, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For preprocessing\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "\n",
    "# For multilabel token classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For saving model\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resources for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path(config.experiment_input_path).mkdir(parents=True, exist_ok=True)    # For train, devtest, and blind test data\n",
    "predictions_dir = config.experiment1_path+\"5fold/output/\"\n",
    "Path(predictions_dir).mkdir(parents=True, exist_ok=True)  # For predictions\n",
    "agreement_dir = config.experiment1_path+\"5fold/agreement/\"\n",
    "Path(agreement_dir).mkdir(parents=True, exist_ok=True)    # For agreement metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1:\n",
    "ling_label_subset = [\"B-Generalization\", \"I-Generalization\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_label_tags = {\n",
    "    \"Gendered-Pronoun\": [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"], \"Gendered-Role\": [\"B-Gendered-Role\", \"I-Gendered-Role\"],\"Generalization\": [\"B-Generalization\", \"I-Generalization\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100  # dimensions of word embeddings (should match utils1.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"i\"></a>\n",
    "## I. Train the Linguistic Classifier\n",
    "\n",
    "Run a multilabel classifier on the train set of the data, focusing only on applying the Linguistic category of labels: Gendered Pronoun, Gendered Role, and Generalization.\n",
    "\n",
    "Use a Classifier Chain with Random Forest, as this was the highest-performing multilabel model setup from previous algorithm experiments for the Linguistic labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For this experiment, we'll train the model on 40% of the data, rather than 60%.\n",
    "### We'll use fastText embeddings of 100 dimensions, as was used in the model that achieved the above scores.\n",
    "###\n",
    "# train_df = pd.read_csv(config.tokc_path+\"experiment_input/token_train.csv\", index_col=0)\n",
    "# dev_df = pd.read_csv(config.tokc_path+\"experiment_input/token_validate.csv\", index_col=0)\n",
    "# test_df = pd.read_csv(config.tokc_path+\"experiment_input/token_test.csv\", index_col=0)\n",
    "# ling_train = utils1.selectDataForLabels(train_df, \"tag\", ling_label_subset)\n",
    "# ling_dev = utils1.selectDataForLabels(dev_df, \"tag\", ling_label_subset)\n",
    "# ling_test = utils1.selectDataForLabels(test_df, \"tag\", ling_label_subset)\n",
    "# train_data = utils1.loadData(ling_train)\n",
    "# dev_data = utils1.loadData(ling_dev)\n",
    "# test_data = utils1.loadData(ling_test)\n",
    "# assert train_data.shape[0] == len(train_data.token_id.unique())\n",
    "# assert dev_data.shape[0] == len(dev_data.token_id.unique())\n",
    "# assert test_data.shape[0] == len(test_data.token_id.unique())\n",
    "# print(train_data.shape, dev_data.shape, test_data.shape)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we'll repeatedly train models on different 80% selections of data and predict on the remaining 20% split, for a modified 5-fold cross-validation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id       token token_offsets  \\\n",
       "0               0            0   99999         0  Identifier       (0, 10)   \n",
       "1               0            0   99999         1           :      (10, 11)   \n",
       "2               0            0   99999         2         AA5      (12, 15)   \n",
       "3               1            1   99999         3       Title      (17, 22)   \n",
       "4               1            1   99999         4           :      (22, 23)   \n",
       "\n",
       "  pos tag       field    fold  \n",
       "0  NN   O  Identifier  split4  \n",
       "1   :   O  Identifier  split4  \n",
       "2  NN   O  Identifier  split4  \n",
       "3  NN   O       Title  split2  \n",
       "4   :   O       Title  split2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(config.tokc_path+\"experiment_input/token_5fold.csv\", index_col=0)\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove mistaken labels that were thought to have been removed already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.tag != \"B-Nonbinary\"]\n",
    "df = df.loc[df.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778801, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure only Linguistic tags are considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils1.selectDataForLabels(df, \"tag\", ling_label_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the tags with label names (remove ``B-`` and ``I-``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_col = utils1.getLabelColFromTagCol(df, \"tag\")\n",
    "df.insert(len(df.columns), \"label\", labels_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                   769616\n",
       "Gendered-Pronoun      3732\n",
       "Gendered-Role         3392\n",
       "Generalization        2061\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the label associated with each annotation for future evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2364]</td>\n",
       "      <td>[5760]</td>\n",
       "      <td>[133674]</td>\n",
       "      <td>[knighted]</td>\n",
       "      <td>[(1407, 1415)]</td>\n",
       "      <td>[VBN]</td>\n",
       "      <td>[B-Gendered-Role]</td>\n",
       "      <td>[Biographical / Historical]</td>\n",
       "      <td>[split3]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4542, 4542]</td>\n",
       "      <td>[10365, 10365]</td>\n",
       "      <td>[228678, 228679]</td>\n",
       "      <td>[knighthood, .]</td>\n",
       "      <td>[(9625, 9635), (9635, 9636)]</td>\n",
       "      <td>[NN, .]</td>\n",
       "      <td>[B-Gendered-Role, I-Gendered-Role]</td>\n",
       "      <td>[Scope and Contents, Scope and Contents]</td>\n",
       "      <td>[split2, split2]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3660, 3660, 3660]</td>\n",
       "      <td>[8733, 8733, 8733]</td>\n",
       "      <td>[196525, 196526, 196527]</td>\n",
       "      <td>[Prince, Regent, .]</td>\n",
       "      <td>[(2426, 2432), (2433, 2439), (2439, 2440)]</td>\n",
       "      <td>[NNP, NNP, .]</td>\n",
       "      <td>[B-Gendered-Role, I-Gendered-Role, I-Gendered-...</td>\n",
       "      <td>[Biographical / Historical, Biographical / His...</td>\n",
       "      <td>[split3, split3, split3]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4678, 4678]</td>\n",
       "      <td>[10637, 10637]</td>\n",
       "      <td>[236354, 236355]</td>\n",
       "      <td>[knighthood, .]</td>\n",
       "      <td>[(9993, 10003), (10003, 10004)]</td>\n",
       "      <td>[NN, .]</td>\n",
       "      <td>[B-Gendered-Role, I-Gendered-Role]</td>\n",
       "      <td>[Scope and Contents, Scope and Contents]</td>\n",
       "      <td>[split0, split0]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4732]</td>\n",
       "      <td>[10763]</td>\n",
       "      <td>[239212]</td>\n",
       "      <td>[Sir]</td>\n",
       "      <td>[(7192, 7195)]</td>\n",
       "      <td>[NNP]</td>\n",
       "      <td>[B-Gendered-Role]</td>\n",
       "      <td>[Biographical / Historical]</td>\n",
       "      <td>[split1]</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            description_id         sentence_id                  token_id  \\\n",
       "ann_id                                                                     \n",
       "0                   [2364]              [5760]                  [133674]   \n",
       "1             [4542, 4542]      [10365, 10365]          [228678, 228679]   \n",
       "2       [3660, 3660, 3660]  [8733, 8733, 8733]  [196525, 196526, 196527]   \n",
       "3             [4678, 4678]      [10637, 10637]          [236354, 236355]   \n",
       "4                   [4732]             [10763]                  [239212]   \n",
       "\n",
       "                      token                               token_offsets  \\\n",
       "ann_id                                                                    \n",
       "0                [knighted]                              [(1407, 1415)]   \n",
       "1           [knighthood, .]                [(9625, 9635), (9635, 9636)]   \n",
       "2       [Prince, Regent, .]  [(2426, 2432), (2433, 2439), (2439, 2440)]   \n",
       "3           [knighthood, .]             [(9993, 10003), (10003, 10004)]   \n",
       "4                     [Sir]                              [(7192, 7195)]   \n",
       "\n",
       "                  pos                                                tag  \\\n",
       "ann_id                                                                     \n",
       "0               [VBN]                                  [B-Gendered-Role]   \n",
       "1             [NN, .]                 [B-Gendered-Role, I-Gendered-Role]   \n",
       "2       [NNP, NNP, .]  [B-Gendered-Role, I-Gendered-Role, I-Gendered-...   \n",
       "3             [NN, .]                 [B-Gendered-Role, I-Gendered-Role]   \n",
       "4               [NNP]                                  [B-Gendered-Role]   \n",
       "\n",
       "                                                    field  \\\n",
       "ann_id                                                      \n",
       "0                             [Biographical / Historical]   \n",
       "1                [Scope and Contents, Scope and Contents]   \n",
       "2       [Biographical / Historical, Biographical / His...   \n",
       "3                [Scope and Contents, Scope and Contents]   \n",
       "4                             [Biographical / Historical]   \n",
       "\n",
       "                            fold          label  \n",
       "ann_id                                           \n",
       "0                       [split3]  Gendered-Role  \n",
       "1               [split2, split2]  Gendered-Role  \n",
       "2       [split3, split3, split3]  Gendered-Role  \n",
       "3               [split0, split0]  Gendered-Role  \n",
       "4                       [split1]  Gendered-Role  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_ann = pd.read_csv(config.tokc_path+\"experiment_input/token_5fold.csv\", index_col=0)\n",
    "df_by_ann = df_by_ann.drop_duplicates()\n",
    "df_by_ann = utils.implodeDataFrame(df_by_ann, [\"ann_id\"])\n",
    "tags_col = list(df_by_ann.tag)\n",
    "labels = [[tag[2:] if tag != \"O\" else tag for tag in tags] for tags in tags_col]\n",
    "labels = [label_list[0] for label_list in labels]\n",
    "df_by_ann.insert(len(df_by_ann.columns), \"label\", labels)\n",
    "ling_labels = list(ling_label_tags.keys())\n",
    "df_by_ann = df_by_ann.loc[df_by_ann.label.isin(ling_labels)]\n",
    "df_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure any tokens with a label don't also have an `O` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token       field  \\\n",
       "0               0            0         0  Identifier  Identifier   \n",
       "1               0            0         1           :  Identifier   \n",
       "2               0            0         2         AA5  Identifier   \n",
       "3               1            1         3       Title       Title   \n",
       "4               1            1         4           :       Title   \n",
       "\n",
       "  token_offsets pos    fold   ann_id  tag label  \n",
       "0       (0, 10)  NN  split4  [99999]  [O]   [O]  \n",
       "1      (10, 11)   :  split4  [99999]  [O]   [O]  \n",
       "2      (12, 15)  NN  split4  [99999]  [O]   [O]  \n",
       "3      (17, 22)  NN  split2  [99999]  [O]   [O]  \n",
       "4      (22, 23)   :  split2  [99999]  [O]   [O]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imploded = utils.implodeDataFrame(\n",
    "    df[[\"description_id\", \"sentence_id\", \"ann_id\", \"token_id\", \"token\", \"field\", \"token_offsets\", \"pos\", \"tag\", \"label\", \"fold\"]], \n",
    "    [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"field\", \"token_offsets\", \"pos\", \"fold\"]\n",
    ").reset_index()\n",
    "df_imploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"label\"  #\"tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(df_imploded[target_col])\n",
    "ann_ids = list(df_imploded[\"ann_id\"])\n",
    "new_tags, new_ann_ids = [], []\n",
    "for i,tag_list in enumerate(tags):\n",
    "    unique_tags = list(set(tag_list))\n",
    "    ann_list = ann_ids[i]\n",
    "    if (len(unique_tags) > 1) and (\"O\" in unique_tags):\n",
    "        o_index = unique_tags.index(\"O\")\n",
    "        unique_tags.remove(\"O\")\n",
    "        \n",
    "        ann_to_remove = ann_list[o_index]\n",
    "        ann_list.remove(ann_to_remove)\n",
    "    \n",
    "    new_tags += [unique_tags]\n",
    "    new_ann_ids += [ann_list]\n",
    "    \n",
    "df_imploded[target_col] = new_tags\n",
    "df_imploded[\"ann_id\"] = new_ann_ids\n",
    "# # df_imploded.head(20)\n",
    "# df_imploded.tag.value_counts()  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                   744728\n",
       "Gendered-Pronoun      3731\n",
       "Gendered-Role         3254\n",
       "Generalization        2018\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded = df_imploded.explode([target_col])\n",
    "df_exploded[target_col].value_counts()  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753731, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>field</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>fold</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>split4</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>Title</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>split2</td>\n",
       "      <td>[99999]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token       field  \\\n",
       "0               0            0         0  Identifier  Identifier   \n",
       "1               0            0         1           :  Identifier   \n",
       "2               0            0         2         AA5  Identifier   \n",
       "3               1            1         3       Title       Title   \n",
       "4               1            1         4           :       Title   \n",
       "\n",
       "  token_offsets pos    fold   ann_id  tag label  \n",
       "0       (0, 10)  NN  split4  [99999]  [O]     O  \n",
       "1      (10, 11)   :  split4  [99999]  [O]     O  \n",
       "2      (12, 15)  NN  split4  [99999]  [O]     O  \n",
       "3      (17, 22)  NN  split2  [99999]  [O]     O  \n",
       "4      (22, 23)   :  split2  [99999]  [O]     O  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_exploded.shape)\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_exploded.loc[df_exploded.ann_id.isna()].shape[0] == 0\n",
    "assert df_exploded.loc[df_exploded.token_id.isna()].shape[0] == 0\n",
    "assert df_exploded.loc[df_exploded[target_col].isna()].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df.token_id == 326190]  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imploded.loc[df_imploded.token_id == 326190]  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the Annotation ID column for training and testing the classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_exploded.drop(columns=[\"ann_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the five splits of the data to combine iteratively into training and test sets using five-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['split0' 'split1' 'split2' 'split3' 'split4']\n"
     ]
    }
   ],
   "source": [
    "split_col = \"fold\"\n",
    "splits = df[split_col].unique()\n",
    "splits.sort()\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0, test0 = list(splits[:4]), splits[4]\n",
    "train1, test1 = list(splits[1:]), splits[0]\n",
    "train2, test2 = list(splits[2:])+[splits[0]], splits[1]\n",
    "train3, test3 = list(splits[3:])+list(splits[:2]), splits[2]\n",
    "train4, test4 = [splits[4]]+list(splits[:3]), splits[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['split0', 'split1', 'split2', 'split3'], 'split4')\n",
      "(['split1', 'split2', 'split3', 'split4'], 'split0')\n",
      "(['split2', 'split3', 'split4', 'split0'], 'split1')\n",
      "(['split3', 'split4', 'split0', 'split1'], 'split2')\n",
      "(['split4', 'split0', 'split1', 'split2'], 'split3')\n"
     ]
    }
   ],
   "source": [
    "runs = [(train0, test0), (train1, test1), (train2, test2), (train3, test3), (train4, test4)]\n",
    "for run in runs:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokens = utils1.zipTokensFeatures(train_data)\n",
    "# dev_tokens = utils1.zipTokensFeatures(dev_data)\n",
    "# all_tokens = utils1.zipTokensFeatures(all_data)\n",
    "# X_train = utils1.makeFastTextFeatureMatrix(train_tokens)\n",
    "# X_dev = utils1.makeFastTextFeatureMatrix(dev_tokens)\n",
    "# X_all = utils1.makeFastTextFeatureMatrix(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb, y_train = utils1.binarizeTrainTargets(train_data)\n",
    "# y_dev = utils1.binarizeDevTargets(mlb, dev_data)\n",
    "# y_all = utils1.binarizeDevTargets(mlb, all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tp\"></a>\n",
    "### Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified 5-fold cross-validation complete!\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "a = \"rf\"\n",
    "\n",
    "# Drop tag column if using labels as targets:\n",
    "df = df.drop(columns=[\"tag\"])\n",
    "\n",
    "for run in runs:\n",
    "    # Get the train (80%) and test (20%) subsets of data\n",
    "    train_splits, test_split = run[0], run[1]\n",
    "    print(\"Training on:\", train_splits)\n",
    "    train_df = df.loc[df[split_col].isin(train_splits)]\n",
    "    dev_df = df.loc[df[split_col] == test_split]\n",
    "    \n",
    "    ling_train = train_df.rename(columns={\"fold\":\"subset\"})  # Change column name to next function's expected column name\n",
    "    ling_dev = dev_df.rename(columns={\"fold\":\"subset\"})      # Change column name to next function's expected column name\n",
    "    train_data = utils1.loadData(ling_train)\n",
    "    dev_data = utils1.loadData(ling_dev)\n",
    "    \n",
    "    # Create feature matrices\n",
    "    train_tokens = utils1.zipTokensFeatures(train_data)\n",
    "    dev_tokens = utils1.zipTokensFeatures(dev_data)\n",
    "    X_train = utils1.makeFastTextFeatureMatrix(train_tokens)\n",
    "    X_dev = utils1.makeFastTextFeatureMatrix(dev_tokens)\n",
    "    \n",
    "    # Binarize targets\n",
    "    mlb, y_train = utils1.binarizeTrainTargets(train_data, target_col=target_col)\n",
    "    y_dev = utils1.binarizeDevTargets(mlb, dev_data, target_col=target_col)\n",
    "\n",
    "    # Train a classification model\n",
    "    clf = ClassifierChain(\n",
    "        classifier = RandomForestClassifier(random_state=22),\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict with the trained model\n",
    "    print(\"Predicting on:\", test_split)\n",
    "    predictions = clf.predict(X_dev)\n",
    "    if pred_df.shape[0] > 0:\n",
    "        next_pred_df = utils.makePredictionDF(predictions, dev_data, target_col, \"predicted_{}\".format(target_col), \"O\", mlb)\n",
    "        pred_df = pd.concat([pred_df, next_pred_df])\n",
    "    else:\n",
    "        pred_df = utils.makePredictionDF(predictions, dev_data, target_col, \"predicted_{}\".format(target_col), \"O\", mlb)\n",
    "\n",
    "assert pred_df.loc[pred_df[\"predicted_{}\".format(target_col)].isna()].shape[0] == 0, \"Any NaN values should be replaced with 'O'\"\n",
    "print(\"Modified 5-fold cross-validation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753522 753521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos   predicted_label\n",
       "0               0            0         0  Identifier   NN                 O\n",
       "1               0            0         1           :    :                 O\n",
       "2               0            0         2         AA5   NN                 O\n",
       "3               3            4       134          He  PRP  Gendered-Pronoun\n",
       "4               3            4       135         was  VBD                 O"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred_df.shape[0], len(pred_df.token_id.unique()))\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(predictions_dir+\"cc-{a}_linglabels_baseline_fastText{d}_predictions.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model (the last model run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/experiment1/cc-{a}_linglabels_F-fastText{d}_T-ling.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"models/experiment1/\"\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "filename = model_dir+\"cc-{a}_linglabels_F-fastText{d}_T-ling.joblib\".format(a=a, d=d)  # include features (F) and targets (T) in model's file name\n",
    "dump(clf, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "### Evaluation\n",
    "#### Evaluate: Strict, Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more predictions than unique tokens, because with multilabel classification, one token can have multiple predicted tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"rf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753522, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos   predicted_label\n",
       "0               0            0         0  Identifier   NN                 O\n",
       "1               0            0         1           :    :                 O\n",
       "2               0            0         2         AA5   NN                 O\n",
       "3               3            4       134          He  PRP  Gendered-Pronoun\n",
       "4               3            4       135         was  VBD                 O"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.read_csv(predictions_dir+\"cc-{a}_linglabels_baseline_fastText{d}_predictions.csv\".format(a=a,d=d), index_col=0)\n",
    "print(pred_df.shape)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778801, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token token_offsets pos tag  \\\n",
       "0               0            0         0  Identifier       (0, 10)  NN   O   \n",
       "1               0            0         1           :      (10, 11)   :   O   \n",
       "2               0            0         2         AA5      (12, 15)  NN   O   \n",
       "3               1            1         3       Title      (17, 22)  NN   O   \n",
       "4               1            1         4           :      (22, 23)   :   O   \n",
       "\n",
       "        field    fold expected_label  \n",
       "0  Identifier  split4              O  \n",
       "1  Identifier  split4              O  \n",
       "2  Identifier  split4              O  \n",
       "3       Title  split2              O  \n",
       "4       Title  split2              O  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = \"label\"\n",
    "exp_df = df.drop(columns=[\"ann_id\"])\n",
    "exp_df = exp_df.rename(columns={target_col:\"expected_{}\".format(target_col)})\n",
    "print(exp_df.shape)\n",
    "exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred_df.token_id.unique()) == len(exp_df.token_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_col = \"expected_{}\".format(target_col)\n",
    "pred_col = \"predicted_{}\".format(target_col)\n",
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    exp_df, \n",
    "    pred_df, \n",
    "    [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"pos\", exp_col],\n",
    "    [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"pos\", pred_col],\n",
    "    [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"tag\", \"field\", \"fold\", exp_col, pred_col, \"_merge\"], \n",
    "    pred_col,\n",
    "    exp_col,\n",
    "    \"O\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert eval_df.loc[eval_df.token_id == \"\"].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token token_offsets pos tag  \\\n",
       "0               0            0         0  Identifier       (0, 10)  NN   O   \n",
       "1               0            0         1           :      (10, 11)   :   O   \n",
       "2               0            0         2         AA5      (12, 15)  NN   O   \n",
       "3               1            1         3       Title      (17, 22)  NN   O   \n",
       "4               1            1         4           :      (22, 23)   :   O   \n",
       "\n",
       "        field    fold expected_label predicted_label         _merge  \n",
       "0  Identifier  split4              O               O  true negative  \n",
       "1  Identifier  split4              O               O  true negative  \n",
       "2  Identifier  split4              O               O  true negative  \n",
       "3       Title  split2              O               O  true negative  \n",
       "4       Title  split2              O               O  true negative  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     770519\n",
       "true positive       6214\n",
       "false negative      2971\n",
       "false positive      2020\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df._merge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(predictions_dir+\"cc-{a}_linglabels_baseline_fastText{d}_strict_evaluation.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the true positives, false positives, false negatives, precision, recall, and F1 metrics for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(ling_label_tags.keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>77.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>3654.0</td>\n",
       "      <td>0.786822</td>\n",
       "      <td>0.979362</td>\n",
       "      <td>0.872597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>0.717747</td>\n",
       "      <td>0.673219</td>\n",
       "      <td>0.694770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.236715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            77.0           990.0         3654.0   0.786822   \n",
       "0     Gendered-Role          1064.0           862.0         2192.0   0.717747   \n",
       "0    Generalization          1728.0           168.0          294.0   0.636364   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.979362  0.872597  \n",
       "0  0.673219  0.694770  \n",
       "0  0.145401  0.236715  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores.to_csv(agreement_dir+\"cc-{a}_linglabels_baseline_fastText{d}_strict_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Each Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the manual annotations IDs to the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2364</td>\n",
       "      <td>5760</td>\n",
       "      <td>133674</td>\n",
       "      <td>[knighted]</td>\n",
       "      <td>(1407, 1415)</td>\n",
       "      <td>VBN</td>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>split3</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4542</td>\n",
       "      <td>10365</td>\n",
       "      <td>228678</td>\n",
       "      <td>[knighthood, .]</td>\n",
       "      <td>(9625, 9635)</td>\n",
       "      <td>NN</td>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>split2</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4542</td>\n",
       "      <td>10365</td>\n",
       "      <td>228679</td>\n",
       "      <td>[knighthood, .]</td>\n",
       "      <td>(9635, 9636)</td>\n",
       "      <td>.</td>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>split2</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3660</td>\n",
       "      <td>8733</td>\n",
       "      <td>196525</td>\n",
       "      <td>[Prince, Regent, .]</td>\n",
       "      <td>(2426, 2432)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>split3</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3660</td>\n",
       "      <td>8733</td>\n",
       "      <td>196526</td>\n",
       "      <td>[Prince, Regent, .]</td>\n",
       "      <td>(2433, 2439)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>split3</td>\n",
       "      <td>Gendered-Role</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ann_id description_id sentence_id token_id                token  \\\n",
       "0       0           2364        5760   133674           [knighted]   \n",
       "1       1           4542       10365   228678      [knighthood, .]   \n",
       "2       1           4542       10365   228679      [knighthood, .]   \n",
       "3       2           3660        8733   196525  [Prince, Regent, .]   \n",
       "4       2           3660        8733   196526  [Prince, Regent, .]   \n",
       "\n",
       "  token_offsets  pos              tag                      field    fold  \\\n",
       "0  (1407, 1415)  VBN  B-Gendered-Role  Biographical / Historical  split3   \n",
       "1  (9625, 9635)   NN  B-Gendered-Role         Scope and Contents  split2   \n",
       "2  (9635, 9636)    .  I-Gendered-Role         Scope and Contents  split2   \n",
       "3  (2426, 2432)  NNP  B-Gendered-Role  Biographical / Historical  split3   \n",
       "4  (2433, 2439)  NNP  I-Gendered-Role  Biographical / Historical  split3   \n",
       "\n",
       "           label  \n",
       "0  Gendered-Role  \n",
       "1  Gendered-Role  \n",
       "2  Gendered-Role  \n",
       "3  Gendered-Role  \n",
       "4  Gendered-Role  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_ann = df_by_ann.explode([\"description_id\", \"sentence_id\", \"token_id\", \"token_offsets\", \"pos\", \"tag\", \"field\", \"fold\"])\n",
    "df_by_ann = df_by_ann.reset_index()\n",
    "df_by_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos   predicted_label\n",
       "0               0            0         0  Identifier   NN                 O\n",
       "1               0            0         1           :    :                 O\n",
       "2               0            0         2         AA5   NN                 O\n",
       "3               3            4       134          He  PRP  Gendered-Pronoun\n",
       "4               3            4       135         was  VBD                 O"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753914, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>14377.0</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id       token  pos   predicted_label  \\\n",
       "0               0            0         0  Identifier   NN                 O   \n",
       "1               0            0         1           :    :                 O   \n",
       "2               0            0         2         AA5   NN                 O   \n",
       "3               3            4       134          He  PRP  Gendered-Pronoun   \n",
       "4               3            4       135         was  VBD                 O   \n",
       "\n",
       "    ann_id    expected_label  \n",
       "0  99999.0                    \n",
       "1  99999.0                    \n",
       "2  99999.0                    \n",
       "3  14377.0  Gendered-Pronoun  \n",
       "4  99999.0                    "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_add = df_by_ann[[\"ann_id\", \"token_id\", \"label\"]]\n",
    "eval_df_joined = pred_df.join(to_add.set_index(\"token_id\"), on=\"token_id\", how=\"outer\")\n",
    "print(eval_df_joined.shape)\n",
    "eval_df_joined = eval_df_joined.rename(columns={\"label\":exp_col})\n",
    "eval_df_joined[\"ann_id\"] = eval_df_joined[\"ann_id\"].fillna(99999)\n",
    "eval_df_joined[exp_col] = eval_df_joined[exp_col].fillna(\"\")\n",
    "eval_df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49808, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, The, Very, Rev, Prof, J...</td>\n",
       "      <td>[NN, :, NNS, IN, DT, NNP, NNP, NNP, NNP, NNP, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[109, 110, 111, 112, 113, 114, 115, 116, 117, ...</td>\n",
       "      <td>[Biographical, /, Historical, :, Professor, Ja...</td>\n",
       "      <td>[NNP, /, NNP, :, NNP, NNP, NNP, NNP, VBD, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14377.0</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[He]</td>\n",
       "      <td>[PRP]</td>\n",
       "      <td>[Gendered-Pronoun]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id   ann_id    expected_label  \\\n",
       "0               0            0  99999.0                     \n",
       "1               1            1  99999.0                     \n",
       "2               2            2  99999.0                     \n",
       "3               3            3  99999.0                     \n",
       "4               3            4  14377.0  Gendered-Pronoun   \n",
       "\n",
       "                                            token_id  \\\n",
       "0                                          [0, 1, 2]   \n",
       "1      [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]   \n",
       "2  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "3  [109, 110, 111, 112, 113, 114, 115, 116, 117, ...   \n",
       "4                                              [134]   \n",
       "\n",
       "                                               token  \\\n",
       "0                               [Identifier, :, AA5]   \n",
       "1  [Title, :, Papers, of, The, Very, Rev, Prof, J...   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [Biographical, /, Historical, :, Professor, Ja...   \n",
       "4                                               [He]   \n",
       "\n",
       "                                                 pos  \\\n",
       "0                                        [NN, :, NN]   \n",
       "1  [NN, :, NNS, IN, DT, NNP, NNP, NNP, NNP, NNP, ...   \n",
       "2  [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "3  [NNP, /, NNP, :, NNP, NNP, NNP, NNP, VBD, DT, ...   \n",
       "4                                              [PRP]   \n",
       "\n",
       "                                     predicted_label  \n",
       "0                                          [O, O, O]  \n",
       "1            [O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4                                 [Gendered-Pronoun]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_by_ann = utils.implodeDataFrame(eval_df_joined, [\"description_id\", \"sentence_id\", \"ann_id\", \"expected_label\"]).reset_index()\n",
    "print(eval_by_ann.shape)\n",
    "eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get unique values for each predicted label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52047, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, The, Very, Rev, Prof, J...</td>\n",
       "      <td>[NN, :, NNS, IN, DT, NNP, NNP, NNP, NNP, NNP, ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "      <td>[109, 110, 111, 112, 113, 114, 115, 116, 117, ...</td>\n",
       "      <td>[Biographical, /, Historical, :, Professor, Ja...</td>\n",
       "      <td>[NNP, /, NNP, :, NNP, NNP, NNP, NNP, VBD, DT, ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14377.0</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[He]</td>\n",
       "      <td>[PRP]</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id   ann_id    expected_label  \\\n",
       "0               0            0  99999.0                     \n",
       "1               1            1  99999.0                     \n",
       "2               2            2  99999.0                     \n",
       "3               3            3  99999.0                     \n",
       "4               3            4  14377.0  Gendered-Pronoun   \n",
       "\n",
       "                                            token_id  \\\n",
       "0                                          [0, 1, 2]   \n",
       "1      [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]   \n",
       "2  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "3  [109, 110, 111, 112, 113, 114, 115, 116, 117, ...   \n",
       "4                                              [134]   \n",
       "\n",
       "                                               token  \\\n",
       "0                               [Identifier, :, AA5]   \n",
       "1  [Title, :, Papers, of, The, Very, Rev, Prof, J...   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [Biographical, /, Historical, :, Professor, Ja...   \n",
       "4                                               [He]   \n",
       "\n",
       "                                                 pos   predicted_label  \n",
       "0                                        [NN, :, NN]                 O  \n",
       "1  [NN, :, NNS, IN, DT, NNP, NNP, NNP, NNP, NNP, ...                 O  \n",
       "2  [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...                 O  \n",
       "3  [NNP, /, NNP, :, NNP, NNP, NNP, NNP, VBD, DT, ...                 O  \n",
       "4                                              [PRP]  Gendered-Pronoun  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label_col = list(eval_by_ann[pred_col])\n",
    "unique_pred_label_col = [list(set(pred_labels)) for pred_labels in pred_label_col]\n",
    "eval_by_ann = eval_by_ann.drop(columns=[pred_col])\n",
    "eval_by_ann.insert(len(eval_by_ann.columns), pred_col, unique_pred_label_col)\n",
    "eval_by_ann = eval_by_ann.explode([pred_col])\n",
    "print(eval_by_ann.shape)\n",
    "eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert eval_by_ann.loc[eval_by_ann.expected_label.isna()].shape[0] == 0\n",
    "assert eval_by_ann.loc[eval_by_ann.predicted_label.isna()].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_col = \"expected_label\"\n",
    "# pred_col = \"predicted_label\"\n",
    "df_pred = eval_by_ann.drop(columns=[exp_col, \"token_id\", \"token\", \"pos\"])\n",
    "df_exp = eval_by_ann.drop(columns=[pred_col, \"token_id\", \"token\", \"pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the agreement type for each row, either false positive, true positive, false negative, or true negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9449</th>\n",
       "      <td>2364</td>\n",
       "      <td>5760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58683</th>\n",
       "      <td>2364</td>\n",
       "      <td>5760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Generalization</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16313</th>\n",
       "      <td>4542</td>\n",
       "      <td>10365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16314</th>\n",
       "      <td>4542</td>\n",
       "      <td>10365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63847</th>\n",
       "      <td>4542</td>\n",
       "      <td>10365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       description_id  sentence_id  ann_id expected_label predicted_label  \\\n",
       "9449             2364         5760     0.0  Gendered-Role               O   \n",
       "58683            2364         5760     0.0              O  Generalization   \n",
       "16313            4542        10365     1.0  Gendered-Role   Gendered-Role   \n",
       "16314            4542        10365     1.0  Gendered-Role   Gendered-Role   \n",
       "63847            4542        10365     1.0              O               O   \n",
       "\n",
       "               _merge  \n",
       "9449   false negative  \n",
       "58683  false positive  \n",
       "16313   true positive  \n",
       "16314   true positive  \n",
       "63847   true negative  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_on =  [\"description_id\", \"sentence_id\", \"ann_id\"]\n",
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    df_exp, \n",
    "    df_pred, \n",
    "    join_on+[exp_col], \n",
    "    join_on+[pred_col], \n",
    "    [\"description_id\", \"sentence_id\", \"ann_id\", \"expected_label\", \"predicted_label\", \"_merge\"], \n",
    "    exp_col, \n",
    "    pred_col, \n",
    "    \"O\"\n",
    ")\n",
    "eval_df = eval_df.sort_values(by=[id_col, exp_col, pred_col])\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95641, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = eval_df.drop_duplicates()\n",
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(predictions_dir+\"cc-{a}_linglabels_baseline_fastText{d}_annot_evaluation.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate annotation agreement metrics for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gendered-Pronoun', 'Gendered-Role', 'Generalization']\n"
     ]
    }
   ],
   "source": [
    "labels = list(ling_label_tags.keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>29.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>3654.0</td>\n",
       "      <td>0.811099</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.892526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>535.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>0.740315</td>\n",
       "      <td>0.808244</td>\n",
       "      <td>0.772790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.231939</td>\n",
       "      <td>0.341354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            29.0           851.0         3654.0   0.811099   \n",
       "0     Gendered-Role           535.0           791.0         2255.0   0.740315   \n",
       "0    Generalization          1010.0           167.0          305.0   0.646186   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.992126  0.892526  \n",
       "0  0.808244  0.772790  \n",
       "0  0.231939  0.341354  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores.to_csv(agreement_dir+\"cc-{a}_linglabels_baseline_fastText{d}_annot_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Loose, Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each label, where a correct prediction is a prediction with the correct annotation label (not necessarily the correct IOB tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a copy of the evaluation DataFrame where tags are replaced by label names:\n",
    "# a = \"rf\"\n",
    "# eval_df = pd.read_csv(predictions_dir+\"cc-{a}_ling_baseline_fastText{d}_strict_evaluation.csv\".format(a=a,d=d), index_col=0)\n",
    "# loose_eval_df = eval_df.copy()\n",
    "# for label,tags in ling_label_tags.items():\n",
    "#     for tag in tags:\n",
    "#         loose_eval_df[exp_col] = loose_eval_df[exp_col].replace(to_replace=tag, value=label)\n",
    "#         loose_eval_df[pred_col] = loose_eval_df[pred_col].replace(to_replace=tag, value=label)\n",
    "# # loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loose_eval_df.loc[loose_eval_df.predicted_tag.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>668</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>674</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>756</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     description_id  sentence_id  token_id token   pos      expected_tag  \\\n",
       "1                 3            5       155   his  PRP$  Gendered-Pronoun   \n",
       "3                 3            5       157    he   PRP  Gendered-Pronoun   \n",
       "152               7           24       668    he   PRP  Gendered-Pronoun   \n",
       "158               7           24       674    he   PRP  Gendered-Pronoun   \n",
       "220               7           28       756    He   PRP  Gendered-Pronoun   \n",
       "\n",
       "        predicted_tag         _merge  \n",
       "1    Gendered-Pronoun  true positive  \n",
       "3    Gendered-Pronoun  true positive  \n",
       "152  Gendered-Pronoun  true positive  \n",
       "158  Gendered-Pronoun  true positive  \n",
       "220  Gendered-Pronoun  true positive  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loose_eval_df = loose_eval_df.fillna(\"O\")\n",
    "# loose_eval_df = loose_eval_df.drop(columns=[\"_merge\"])\n",
    "# loose_eval_df = utils.compareExpectedPredicted(loose_eval_df, \"_merge\", \"O\")\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loose_eval_df.to_csv(predictions_dir+\"cc-{a}_ling_baseline_fastText{d}_evaluation_loose.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loose_agmt = pd.DataFrame.from_dict({\n",
    "#         \"tag(s)\":[], \"false negative\":[], \"false positive\":[],\n",
    "#          \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.991903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.881057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285078</td>\n",
       "      <td>0.443674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun            24.0             0.0         1470.0        1.0   \n",
       "0     Gendered-Role           243.0             0.0          900.0        1.0   \n",
       "0    Generalization           321.0             0.0          128.0        1.0   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.983936  0.991903  \n",
       "0  0.787402  0.881057  \n",
       "0  0.285078  0.443674  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for label,tags in ling_label_tags.items():\n",
    "#     labels_agmt_stats = utils.getScoresByTags(loose_eval_df, \"_merge\", [label])\n",
    "#     loose_agmt = pd.concat([loose_agmt, labels_agmt_stats])\n",
    "# loose_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loose_agmt.to_csv(agreement_dir+\"cc-{a}_ling_baseline_fastText{d}_loose_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<a id=\"ii\"></a>\n",
    "\n",
    "#### *For train-dev-test (i.e., 40-40-20) approach*\n",
    "\n",
    "## II. Predict Over All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = clf.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id     token  pos predicted_tag\n",
       "0            2        16     Scope   NN             O\n",
       "1            2        17       and   CC             O\n",
       "2            2        18  Contents  NNS             O\n",
       "3            2        19         :    :             O\n",
       "4            2        20   Sermons  NNS             O"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = utils.makePredictionDF(all_predictions, all_data, \"tag\", \"predicted_tag\", \"O\", mlb)\n",
    "assert pred_df.loc[pred_df.predicted_tag.isna()].shape[0] == 0, \"Any NaN values should be replaced with 'O'\"\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755963 753521\n"
     ]
    }
   ],
   "source": [
    "print(pred_df.shape[0], len(pred_df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(config.experiment1_output_path+\"cc-{a}_ling_baseline_fastText{d}_predictions_ALLDATA.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Strict, All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - macro: 0.5920109983470005\n",
      "Recall - macro: 0.44067573805476495\n",
      "F1 Score - macro: 0.44051951753599433\n",
      "Accuracy - normalized: 0.9929769707811726\n",
      "Accuracy - unnormalized: 748229\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - macro:\", sklearn.metrics.precision_score(y_all, all_predictions, average=\"macro\", zero_division=0))  # macro = mean of all labels' score\n",
    "print(\"Recall - macro:\", sklearn.metrics.recall_score(y_all, all_predictions, average=\"macro\", zero_division=0))\n",
    "print(\"F1 Score - macro:\", sklearn.metrics.f1_score(y_all, all_predictions, average=\"macro\", zero_division=0))\n",
    "print(\"Accuracy - normalized:\", sklearn.metrics.accuracy_score(y_all, all_predictions, normalize=True))  # fraction of correctly classified samples\n",
    "print(\"Accuracy - unnormalized:\", sklearn.metrics.accuracy_score(y_all, all_predictions, normalize=False))  # number of correctly classified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 753521\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", X_all.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more predictions than unique tokens, because with multilabel classification, one token can have multiple predicted tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id     token  pos expected_tag\n",
       "0            2        16     Scope   NN            O\n",
       "1            2        17       and   CC            O\n",
       "2            2        18  Contents  NNS            O\n",
       "3            2        19         :    :            O\n",
       "4            2        20   Sermons  NNS            O"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = all_data.explode([\"tag\"])\n",
    "exp_df = exp_df.rename(columns={\"tag\":\"expected_tag\"})\n",
    "exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757416 753521\n"
     ]
    }
   ],
   "source": [
    "print(exp_df.shape[0], len(exp_df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759346, 7)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_pred_df = pd.merge(\n",
    "    left=exp_df, \n",
    "    right=pred_df.loc[pred_df.predicted_tag != \"O\"], # only include the predictions of Linguistic labels\n",
    "    how=\"outer\",\n",
    "    left_on=[\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\"],\n",
    "    right_on=[\"sentence_id\", \"token_id\", \"token\", \"pos\", \"predicted_tag\"],\n",
    "    suffixes=[\"\", \"_pred\"],\n",
    "    indicator=True\n",
    ")\n",
    "exp_pred_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the agreement type for each row, ignoring rows with `'O'` and `NaN` value pairs (the `true negative` agreement type, which doesn't go into the precision, recall, or F1 score calculations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>19</td>\n",
       "      <td>533</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>19</td>\n",
       "      <td>539</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>37</td>\n",
       "      <td>960</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>37</td>\n",
       "      <td>973</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>39</td>\n",
       "      <td>1002</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  token_id token   pos        expected_tag  \\\n",
       "129           19       533    he   PRP  B-Gendered-Pronoun   \n",
       "135           19       539    he   PRP  B-Gendered-Pronoun   \n",
       "261           37       960    he   PRP  B-Gendered-Pronoun   \n",
       "274           37       973    he   PRP  B-Gendered-Pronoun   \n",
       "292           39      1002   his  PRP$  B-Gendered-Pronoun   \n",
       "\n",
       "          predicted_tag         _merge  \n",
       "129  B-Gendered-Pronoun  true positive  \n",
       "135  B-Gendered-Pronoun  true positive  \n",
       "261  B-Gendered-Pronoun  true positive  \n",
       "274  B-Gendered-Pronoun  true positive  \n",
       "292  B-Gendered-Pronoun  true positive  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_col = \"expected_tag\"\n",
    "pred_col = \"predicted_tag\"\n",
    "no_tag_value = \"O\"\n",
    "# Find true negatives based on the expected and predicted tags\n",
    "sub_exp_pred_df = exp_pred_df.loc[exp_pred_df[exp_col] == no_tag_value]\n",
    "sub_exp_pred_df = sub_exp_pred_df.loc[sub_exp_pred_df[pred_col].isna()]\n",
    "# sub_exp_pred_df.replace(to_replace=\"left_only\", value=\"true negative\", inplace=True)\n",
    "tn_tokens = list(sub_exp_pred_df[\"token_id\"])\n",
    "\n",
    "# Record false negatives, false positives, and true positives based on the merge values\n",
    "eval_df = exp_pred_df.loc[~exp_pred_df[\"token_id\"].isin(tn_tokens)]\n",
    "eval_df = eval_df.replace(to_replace=\"left_only\", value=\"false negative\")\n",
    "eval_df = eval_df.replace(to_replace=\"right_only\", value=\"false positive\")\n",
    "eval_df = eval_df.replace(to_replace=\"both\", value=\"true positive\")\n",
    "eval_df = eval_df.sort_index()\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5264, 7)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(config.experiment1_agmt_path+\"cc-{a}_ling_baseline_fastText{d}_evaluation_ALLDATA.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the true positives, false positives, false negatives, precision, recall, and F1 metrics for all tags and each tag individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>1045</td>\n",
       "      <td>16</td>\n",
       "      <td>4203</td>\n",
       "      <td>0.462383</td>\n",
       "      <td>0.422989</td>\n",
       "      <td>0.422518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Generalization</td>\n",
       "      <td>261</td>\n",
       "      <td>10</td>\n",
       "      <td>444</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.629787</td>\n",
       "      <td>0.766178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Generalization</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>0.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>1178</td>\n",
       "      <td>0.999152</td>\n",
       "      <td>0.869373</td>\n",
       "      <td>0.929755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>6782</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.998528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Pronoun</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag(s)  false negative  false positive  true positive  \\\n",
       "0                 all            1045              16           4203   \n",
       "0    B-Generalization             261              10            444   \n",
       "0    I-Generalization             221               2              2   \n",
       "0     B-Gendered-Role             177               1           1178   \n",
       "0     I-Gendered-Role             319               0              0   \n",
       "0  B-Gendered-Pronoun              17               3           6782   \n",
       "0  I-Gendered-Pronoun              50               0              0   \n",
       "\n",
       "   precision    recall        f1  \n",
       "0   0.462383  0.422989  0.422518  \n",
       "0   0.977974  0.629787  0.766178  \n",
       "0   0.500000  0.008969  0.017621  \n",
       "0   0.999152  0.869373  0.929755  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "0   0.999558  0.997500  0.998528  \n",
       "0   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_stats = utils.getAgreementStatsForAllTags(eval_df, \"_merge\", \"token_id\", \"tag(s)\", y_dev, predictions)\n",
    "for label_tag in ling_label_subset:\n",
    "    label_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [label_tag])\n",
    "    agmt_stats = pd.concat([agmt_stats, label_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_stats.to_csv(config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_strict_agmt_ALLDATA.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Annotation-level Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the manual annotations' offsets to the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df = pd.read_csv(config.agg_path+\"aggregated_final.csv\")#, usecols=[\"description_id\",\"agg_ann_id\", \"ann_offsets\"])\n",
    "# Get only the Linguistic annotations\n",
    "annot_df = annot_df.loc[annot_df.category == \"Linguistic\"]\n",
    "annot_df = annot_df[[\"agg_ann_id\", \"ann_offsets\", \"label\"]]\n",
    "annot_df = annot_df.rename(columns={\"agg_ann_id\":\"ann_id\"})\n",
    "# annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_token_ids = list(dev_data.token_id.unique())\n",
    "ling_dev_subset = ling_dev.loc[ling_dev.token_id.isin(dev_token_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7083, 9)\n",
      "(7083, 11)\n"
     ]
    }
   ],
   "source": [
    "to_add = ling_dev_subset[[\"ann_id\", \"token_id\", \"token_offsets\"]]\n",
    "# Only include annotations with Linguistic labels\n",
    "to_add = to_add.loc[to_add.ann_id.isin(list(annot_df.ann_id))]\n",
    "eval_df_joined = eval_df.join(to_add.set_index(\"token_id\"), on=\"token_id\", how=\"outer\")\n",
    "# Join on the left, as there will be annotations from outside the devtest set in annot_df\n",
    "print(eval_df_joined.shape)\n",
    "eval_df_joined = eval_df_joined.join(annot_df.set_index(\"ann_id\"), on=\"ann_id\", how=\"left\")\n",
    "print(eval_df_joined.shape)  # Looks good!  Same as before join.\n",
    "eval_df_joined = eval_df_joined.rename(columns={\"label\":\"expected_label\"})\n",
    "# eval_df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the predicted tags with their corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_joined.expected_label = eval_df_joined.expected_label.fillna(\"no_label\")\n",
    "eval_df_joined.expected_tag = eval_df_joined.expected_tag.fillna(\"no_label\")\n",
    "eval_df_joined.predicted_tag = eval_df_joined.predicted_tag.fillna(\"no_label\")\n",
    "# eval_df_joined.predicted_tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = list(eval_df_joined.predicted_tag)\n",
    "predicted_labels = [tag[2:] if tag != \"no_label\" else tag for tag in predicted_labels]\n",
    "eval_df_joined.insert(len(eval_df_joined.columns), \"predicted_label\", predicted_labels)\n",
    "# eval_df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"token\", \"expected_label\", \"predicted_label\", \"_merge\", \"token_offsets\", \"ann_offsets\", \"ann_id\"]\n",
    "eval_by_ann = utils.implodeDataFrame(eval_df_joined[cols_to_keep], [\"ann_id\", \"ann_offsets\"]).reset_index()\n",
    "exp_labels = list(eval_by_ann[\"expected_label\"])\n",
    "exp_labels = [labels[0] for labels in exp_labels]\n",
    "eval_by_ann[\"expected_label\"] = exp_labels\n",
    "# eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert eval_by_ann.loc[eval_by_ann.expected_label == \"no_label\"].shape[0] == 0\n",
    "assert eval_by_ann.loc[eval_by_ann.expected_label.isna()].shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row should have an annotation label (a Linguistic label in `expected_label`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_agmts = []\n",
    "token_agmts = (eval_by_ann[\"_merge\"])\n",
    "for agmts in token_agmts:\n",
    "    if \"true positive\" in agmts:\n",
    "        ann_agmt = \"true positive\"\n",
    "    elif \"false positive\" in agmts:\n",
    "        ann_agmt = \"false positive\"\n",
    "    else:\n",
    "        ann_agmt = \"false negative\"\n",
    "    ann_agmts += [ann_agmt]\n",
    "assert len(ann_agmts) == eval_by_ann.shape[0]\n",
    "eval_by_ann.insert(len(eval_by_ann.columns), \"annotation_agreement\", ann_agmts)\n",
    "# eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_by_ann[[\"ann_id\", \"ann_offsets\", \"token_id\", \"expected_label\", \"predicted_label\", \"annotation_agreement\"]].to_csv(\n",
    "    config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_annot_evaluation_ALLDATA.csv\".format(a=a,d=d)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate annotation agreement metrics for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_agmt = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914491</td>\n",
       "      <td>0.955336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>976.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.190713</td>\n",
       "      <td>0.319444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>408.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.376328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun           131.0             0.0         1401.0   1.000000   \n",
       "0     Gendered-Role           976.0             4.0          230.0   0.982906   \n",
       "0    Generalization           408.0             3.0          124.0   0.976378   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.914491  0.955336  \n",
       "0  0.190713  0.319444  \n",
       "0  0.233083  0.376328  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ling_label_tags.keys()\n",
    "for label in labels:\n",
    "    agmt_df = eval_by_ann.loc[eval_by_ann.expected_label == label]\n",
    "    tp = agmt_df.loc[agmt_df.annotation_agreement == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df.annotation_agreement == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df.annotation_agreement == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    annot_agmt = pd.concat([annot_agmt, label_agmt])\n",
    "annot_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_by_ann.loc[eval_by_ann.expected_label == \"Gendered-Role\"][\"annotation_agreement\"].value_counts()     # Looks good\n",
    "# eval_by_ann.loc[eval_by_ann.expected_label == \"Gendered-Pronoun\"][\"annotation_agreement\"].value_counts()  # Looks good\n",
    "# eval_by_ann.loc[eval_by_ann.expected_label == \"Generalization\"][\"annotation_agreement\"].value_counts()    # Looks good\n",
    "annot_agmt.to_csv(config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_annot_agmt_ALLDATA.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loose Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each label, where a correct prediction is a prediction with the correct annotation label (not necessarily the correct IOB tag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the evaluation DataFrame where tags are replaced by label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"rf\"\n",
    "eval_df = pd.read_csv(config.experiment1_agmt_path+\"cc-{a}_ling_baseline_fastText{d}_evaluation_ALLDATA.csv\".format(a=a,d=d), index_col=0)\n",
    "loose_eval_df = eval_df.copy()\n",
    "for label,tags in ling_label_tags.items():\n",
    "    for tag in tags:\n",
    "        loose_eval_df[\"expected_tag\"] = loose_eval_df[\"expected_tag\"].replace(to_replace=tag, value=label)\n",
    "        loose_eval_df[\"predicted_tag\"] = loose_eval_df[\"predicted_tag\"].replace(to_replace=tag, value=label)\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 7)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose_eval_df.loc[loose_eval_df.predicted_tag.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df = loose_eval_df.fillna(\"O\")\n",
    "loose_eval_df = loose_eval_df.drop(columns=[\"_merge\"])\n",
    "loose_eval_df = utils.compareExpectedPredicted(loose_eval_df, \"_merge\", \"O\")\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df.to_csv(config.experiment1_agmt_path+\"cc-{a}_ling_baseline_fastText{d}_evaluation_loose_ALLDATA.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt = pd.DataFrame.from_dict({\n",
    "        \"tag(s)\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990218</td>\n",
       "      <td>0.995085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.480603</td>\n",
       "      <td>0.649199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tag(s)  false negative  false positive  true negative  \\\n",
       "0  Gendered-Pronoun            67.0             0.0            NaN   \n",
       "0     Gendered-Role           496.0             0.0            NaN   \n",
       "0    Generalization           482.0             0.0            NaN   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0         6782.0        1.0  0.990218  0.995085  \n",
       "0         1178.0        1.0  0.703704  0.826087  \n",
       "0          446.0        1.0  0.480603  0.649199  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label,tags in ling_label_tags.items():\n",
    "    labels_agmt_stats = utils.getScoresByTags(loose_eval_df, \"_merge\", [label])\n",
    "    loose_agmt = pd.concat([loose_agmt, labels_agmt_stats])\n",
    "loose_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt.to_csv(config.experiment1_agmt_path+\"cc-{a}_baseline_fastText{d}_ling_loose_agmt_ALLDATA.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1, Model 2\n",
    "\n",
    "#### Model Setup\n",
    "\n",
    "Run models in the following order, using their output labels as features for the next model:\n",
    "\n",
    "1. Multilabel Linguistic Classifier\n",
    "2. Multiclass Person Name + Occupation Sequence Classifier\n",
    "3. Multilabel Stereotype + Omission Document Classifier\n",
    "\n",
    "***\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/experiment_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/experiment1/`\n",
    "* Word Embeddings\n",
    "    * Custom fastText (word2vec with subwords) embeddings of 100 dimensions trained on the CRC Archives catalog's descriptive metadata (harvested October 2020)\n",
    "    \n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[I.](#i) Person Name + Occupation Classifier\n",
    "* [Preprocessing](#prep)\n",
    "* [Training & Prediction](#tp)\n",
    "* [Evaluation](#eval)\n",
    "\n",
    "[II.](#ii) Predict Over All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load programming resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, utils1, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For preprocessing\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "\n",
    "# For classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For saving model\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resources for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path(config.experiment_input_path).mkdir(parents=True, exist_ok=True)    # For train, devtest, and blind test data\n",
    "predictions_dir = config.experiment1_path+\"5fold/output/\"\n",
    "Path(predictions_dir).mkdir(parents=True, exist_ok=True)  # For predictions\n",
    "agreement_dir = config.experiment1_path+\"5fold/agreement/\"\n",
    "Path(agreement_dir).mkdir(parents=True, exist_ok=True)    # For agreement metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_o_label_subset = [\n",
    "    \"B-Unknown\", \"I-Unknown\", \"B-Feminine\", \"I-Feminine\", \n",
    "    \"B-Masculine\", \"I-Masculine\", \"B-Occupation\", \"I-Occupation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_label_tags = {\n",
    "    \"Gendered-Pronoun\": [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"], \"Gendered-Role\": [\"B-Gendered-Role\", \"I-Gendered-Role\"],\"Generalization\": [\"B-Generalization\", \"I-Generalization\"]\n",
    "    }\n",
    "pers_o_label_tags = {\n",
    "    \"Unknown\": [\"B-Unknown\", \"I-Unknown\"], \"Feminine\": [\"B-Feminine\", \"I-Feminine\"], \"Masculine\": [\"B-Masculine\", \"I-Masculine\"],\n",
    "     \"Occupation\": [\"B-Occupation\", \"I-Occupation\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100                   # dimensions of word embeddings (should match utils1.py) for file names\n",
    "target_labels = \"pers_o\"  # for file names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"i\"></a>\n",
    "## I. Person Name + Occupation Labels\n",
    "\n",
    "Train a multiclass sequence classifier, using Conditional Random Field with Adaptive Regularization of Weight Vectors (AROW), on the Person Name and Occupation labels, **passing in the Linguistic labels (not specific BIO label-tag pair) from the previous model's predictions as features to this model.** The Person Name labels were assigned based on the presence or absence of gendered terminology referring to named people within a description, so the Linguistic labels passed as features will be rolled up to the description level. \n",
    "\n",
    "Multiclass is a suitable setup for these labels because they are mutually exclusive (no one token should have more than one of these labels).  The sequence classifier with AROW was the highest performing for past algorithm experiments with sequence classifiers for Person Name and Occupation labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Linguistic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"rf\"\n",
    "ling_filename = predictions_dir+\"cc-{a}_linglabels_baseline_fastText{d}_strict_evaluation.csv\".format(a=a, d=d)\n",
    "ling_eval_df = pd.read_csv(ling_filename, usecols=[\"description_id\", \"token_id\", \"predicted_label\"])\n",
    "ling_features = ling_eval_df.rename(columns={\"predicted_label\":\"pred_ling_label\"})\n",
    "ling_features = ling_features.fillna(\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Linguistic predictions by description, removing duplicates from the list of Linguistic predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred_ling_label  description_id\n",
       "0             [O]               0\n",
       "1             [O]               1\n",
       "2             [O]               2\n",
       "3             [O]               3\n",
       "4             [O]               4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ling_features = utils.implodeDataFrame(ling_features, [\"description_id\"]).reset_index()\n",
    "col = \"pred_ling_label\"\n",
    "pred_col = list(ling_features[col])\n",
    "# Remove duplicates\n",
    "unique_pred_col = [list(set(preds)) for preds in pred_col]\n",
    "# Remove \"O\" values\n",
    "unique_pred_col = [preds.remove(\"O\") if \"O\" in preds else preds for preds in unique_pred_col]\n",
    "# Sort the lists\n",
    "new_pred_col = []\n",
    "for preds in unique_pred_col:\n",
    "    if preds == None:\n",
    "        preds = [\"O\"]\n",
    "    else:\n",
    "        preds.sort()\n",
    "    new_pred_col += [preds]\n",
    "assert len(pred_col) == len(new_pred_col)\n",
    "ling_features = ling_features.drop(columns=[col, \"token_id\"])\n",
    "ling_features.insert((len(ling_features.columns)-1), col, new_pred_col)\n",
    "ling_features.head() # Want to keep desc ids in previous model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[O]    27908\n",
       "Name: pred_ling_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ling_features[col].value_counts()  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779270, 10) (779270, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(config.tokc_path+\"experiment_input/token_5fold.csv\", index_col=0)\n",
    "perso_df = utils1.selectDataForLabels(df, \"tag\", pers_o_label_subset)\n",
    "print(df.shape, perso_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the label associated with each annotation for future evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1082, 1082, 1082, 1082]</td>\n",
       "      <td>[2590, 2590, 2590, 2590]</td>\n",
       "      <td>[58341, 58342, 58343, 58344]</td>\n",
       "      <td>[Mrs, Norman, Macleod, ,]</td>\n",
       "      <td>[(36375, 36378), (36379, 36385), (36386, 36393...</td>\n",
       "      <td>[NNP, NNP, NNP, ,]</td>\n",
       "      <td>[B-Feminine, I-Feminine, I-Feminine, I-Feminine]</td>\n",
       "      <td>[Scope and Contents, Scope and Contents, Scope...</td>\n",
       "      <td>[split2, split2, split2, split2]</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[855, 855, 855, 855]</td>\n",
       "      <td>[1097, 1097, 1097, 1097]</td>\n",
       "      <td>[19836, 19837, 19838, 19839]</td>\n",
       "      <td>[Dr., Nelly, Renee, Deme]</td>\n",
       "      <td>[(40, 43), (44, 49), (50, 55), (56, 60)]</td>\n",
       "      <td>[NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[Title, Title, Title, Title]</td>\n",
       "      <td>[split4, split4, split4, split4]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1038, 1038]</td>\n",
       "      <td>[1485, 1485]</td>\n",
       "      <td>[28713, 28714]</td>\n",
       "      <td>[Marjory, Kennedy-Fraser]</td>\n",
       "      <td>[(14570, 14577), (14578, 14592)]</td>\n",
       "      <td>[NNP, NNP]</td>\n",
       "      <td>[B-Unknown, I-Unknown]</td>\n",
       "      <td>[Scope and Contents, Scope and Contents]</td>\n",
       "      <td>[split4, split4]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1038, 1038, 1038, 1038]</td>\n",
       "      <td>[1486, 1486, 1486, 1486]</td>\n",
       "      <td>[28738, 28739, 28740, 28741]</td>\n",
       "      <td>[Marjory, Kennedy, Fraser, ,]</td>\n",
       "      <td>[(14698, 14705), (14706, 14713), (14714, 14720...</td>\n",
       "      <td>[NNP, NNP, NNP, ,]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[Scope and Contents, Scope and Contents, Scope...</td>\n",
       "      <td>[split3, split3, split3, split3]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1038, 1038, 1038]</td>\n",
       "      <td>[1487, 1487, 1487]</td>\n",
       "      <td>[28790, 28791, 28792]</td>\n",
       "      <td>[Marjory, Kennedy-Fraser, ,]</td>\n",
       "      <td>[(14924, 14931), (14932, 14946), (14946, 14947)]</td>\n",
       "      <td>[NNP, NNP, ,]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[Scope and Contents, Scope and Contents, Scope...</td>\n",
       "      <td>[split0, split0, split0]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  description_id               sentence_id  \\\n",
       "ann_id                                                       \n",
       "7       [1082, 1082, 1082, 1082]  [2590, 2590, 2590, 2590]   \n",
       "14          [855, 855, 855, 855]  [1097, 1097, 1097, 1097]   \n",
       "15                  [1038, 1038]              [1485, 1485]   \n",
       "16      [1038, 1038, 1038, 1038]  [1486, 1486, 1486, 1486]   \n",
       "17            [1038, 1038, 1038]        [1487, 1487, 1487]   \n",
       "\n",
       "                            token_id                          token  \\\n",
       "ann_id                                                                \n",
       "7       [58341, 58342, 58343, 58344]      [Mrs, Norman, Macleod, ,]   \n",
       "14      [19836, 19837, 19838, 19839]      [Dr., Nelly, Renee, Deme]   \n",
       "15                    [28713, 28714]      [Marjory, Kennedy-Fraser]   \n",
       "16      [28738, 28739, 28740, 28741]  [Marjory, Kennedy, Fraser, ,]   \n",
       "17             [28790, 28791, 28792]   [Marjory, Kennedy-Fraser, ,]   \n",
       "\n",
       "                                            token_offsets  \\\n",
       "ann_id                                                      \n",
       "7       [(36375, 36378), (36379, 36385), (36386, 36393...   \n",
       "14               [(40, 43), (44, 49), (50, 55), (56, 60)]   \n",
       "15                       [(14570, 14577), (14578, 14592)]   \n",
       "16      [(14698, 14705), (14706, 14713), (14714, 14720...   \n",
       "17       [(14924, 14931), (14932, 14946), (14946, 14947)]   \n",
       "\n",
       "                         pos  \\\n",
       "ann_id                         \n",
       "7         [NNP, NNP, NNP, ,]   \n",
       "14      [NNP, NNP, NNP, NNP]   \n",
       "15                [NNP, NNP]   \n",
       "16        [NNP, NNP, NNP, ,]   \n",
       "17             [NNP, NNP, ,]   \n",
       "\n",
       "                                                     tag  \\\n",
       "ann_id                                                     \n",
       "7       [B-Feminine, I-Feminine, I-Feminine, I-Feminine]   \n",
       "14          [B-Unknown, I-Unknown, I-Unknown, I-Unknown]   \n",
       "15                                [B-Unknown, I-Unknown]   \n",
       "16          [B-Unknown, I-Unknown, I-Unknown, I-Unknown]   \n",
       "17                     [B-Unknown, I-Unknown, I-Unknown]   \n",
       "\n",
       "                                                    field  \\\n",
       "ann_id                                                      \n",
       "7       [Scope and Contents, Scope and Contents, Scope...   \n",
       "14                           [Title, Title, Title, Title]   \n",
       "15               [Scope and Contents, Scope and Contents]   \n",
       "16      [Scope and Contents, Scope and Contents, Scope...   \n",
       "17      [Scope and Contents, Scope and Contents, Scope...   \n",
       "\n",
       "                                    fold expected_label  \n",
       "ann_id                                                   \n",
       "7       [split2, split2, split2, split2]       Feminine  \n",
       "14      [split4, split4, split4, split4]        Unknown  \n",
       "15                      [split4, split4]        Unknown  \n",
       "16      [split3, split3, split3, split3]        Unknown  \n",
       "17              [split0, split0, split0]        Unknown  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_ann = pd.read_csv(config.tokc_path+\"experiment_input/token_5fold.csv\", index_col=0)\n",
    "df_by_ann = df_by_ann.drop_duplicates()\n",
    "df_by_ann = utils.implodeDataFrame(df_by_ann, [\"ann_id\"])\n",
    "tags_col = list(df_by_ann.tag)\n",
    "labels = [[tag[2:] if tag != \"O\" else tag for tag in tags] for tags in tags_col]\n",
    "labels = [label_list[0] for label_list in labels]\n",
    "df_by_ann.insert(len(df_by_ann.columns), \"expected_label\", labels)\n",
    "perso_labels = list(pers_o_label_tags.keys())\n",
    "df_by_ann = df_by_ann.loc[df_by_ann.expected_label.isin(perso_labels)]\n",
    "df_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the linguistic labels of descriptions (which will be passed to the model as features) to the model input and evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O    779270\n",
       "Name: pred_ling_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perso_df = perso_df.join(ling_features.set_index(\"description_id\"), on=\"description_id\", how=\"left\")\n",
    "assert perso_df.loc[perso_df.tag.isna()].shape[0] == 0\n",
    "perso_df = perso_df.fillna(\"O\")\n",
    "feature_col = list(perso_df[col])\n",
    "new_feature_col = []\n",
    "for preds in feature_col:\n",
    "    if preds != \"O\":\n",
    "        preds.sort()\n",
    "        preds = \",\".join(preds)\n",
    "    new_feature_col += [preds]\n",
    "perso_df = perso_df.drop(columns=[col])\n",
    "perso_df.insert(2, col, new_feature_col)\n",
    "perso_df[col].value_counts() # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "### Preprocessing\n",
    "\n",
    "Group data by token and then by sentence, so each sentence is a list of tokens and each token has a list of tags associated with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perso_data = perso_df.drop(columns=[\"ann_id\", \"token_offsets\", \"field\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "perso_token_groups = utils.implodeDataFrame(perso_data, [\"description_id\", \"token_id\", \"sentence_id\", \"token\", \"fold\", col]).reset_index()\n",
    "# perso_token_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42030, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, The, Very, Rev, Prof, J...</td>\n",
       "      <td>[[O], [O], [O], [O], [O, B-Unknown, B-Masculin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>split1</td>\n",
       "      <td>O</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>[109, 110, 111, 112, 113, 114, 115, 116, 117, ...</td>\n",
       "      <td>[Biographical, /, Historical, :, Professor, Ja...</td>\n",
       "      <td>[[O], [O], [O], [O], [B-Masculine], [I-Masculi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>[134, 135, 136, 137, 138, 139, 140, 141, 142, ...</td>\n",
       "      <td>[He, was, educated, at, Daniel, Stewart, 's, C...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id    fold pred_ling_label  \\\n",
       "0               0            0  split4               O   \n",
       "1               1            1  split2               O   \n",
       "2               2            2  split1               O   \n",
       "3               3            3  split2               O   \n",
       "4               3            4  split4               O   \n",
       "\n",
       "                                            token_id  \\\n",
       "0                                          [0, 1, 2]   \n",
       "1      [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]   \n",
       "2  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "3  [109, 110, 111, 112, 113, 114, 115, 116, 117, ...   \n",
       "4  [134, 135, 136, 137, 138, 139, 140, 141, 142, ...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0                               [Identifier, :, AA5]   \n",
       "1  [Title, :, Papers, of, The, Very, Rev, Prof, J...   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [Biographical, /, Historical, :, Professor, Ja...   \n",
       "4  [He, was, educated, at, Daniel, Stewart, 's, C...   \n",
       "\n",
       "                                                 tag  \n",
       "0                                    [[O], [O], [O]]  \n",
       "1  [[O], [O], [O], [O], [O, B-Unknown, B-Masculin...  \n",
       "2  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "3  [[O], [O], [O], [O], [B-Masculine], [I-Masculi...  \n",
       "4  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perso_grouped = utils.implodeDataFrame(perso_token_groups, [\"description_id\", \"sentence_id\", \"fold\", col]).reset_index()\n",
    "perso_grouped = perso_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "print(perso_grouped.shape)\n",
    "perso_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O    42030\n",
       "Name: pred_ling_label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perso_grouped[col].value_counts()  # Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the five groups of training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['split0' 'split1' 'split2' 'split3' 'split4']\n"
     ]
    }
   ],
   "source": [
    "split_col = \"fold\"\n",
    "splits = perso_grouped[split_col].unique()\n",
    "splits.sort()\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0, test0 = list(splits[:4]), splits[4]\n",
    "train1, test1 = list(splits[1:]), splits[0]\n",
    "train2, test2 = list(splits[2:])+[splits[0]], splits[1]\n",
    "train3, test3 = list(splits[3:])+list(splits[:2]), splits[2]\n",
    "train4, test4 = [splits[4]]+list(splits[:3]), splits[3]\n",
    "runs = [(train0, test0), (train1, test1), (train2, test2), (train3, test3), (train4, test4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tp\"></a>\n",
    "### Training & Prediction\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll set the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: ['split0', 'split1', 'split2', 'split3']\n",
      "Predicting on: split4\n",
      "Predictions for split4 saved!\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "\n",
    "# Specify the run one at a time (with for loop, model remembers what it learned in previous runs)\n",
    "run = runs[0]  # 1, 2, 3, 4\n",
    "\n",
    "# Get the train (80%) and test (20%) subsets of data\n",
    "# with Person Name tags as targets and Linguistic labels as features\n",
    "train_splits, test_split = run[0], run[1]\n",
    "print(\"Training on:\", train_splits)\n",
    "train_df = perso_grouped.loc[perso_grouped[split_col].isin(train_splits)]\n",
    "dev_df = perso_grouped.loc[perso_grouped[split_col] == test_split]\n",
    "\n",
    "# Zip the linguistic label and BIO tags together with the tokens so each \n",
    "# sentence item is a tuple: `(TOKEN, LING_LABEL(S), TAG_LIST)`\n",
    "train_sentences = utils1.zip2FeaturesAndTarget(train_df, \"tag\", feature_col2=col)\n",
    "dev_sentences = utils1.zip2FeaturesAndTarget(dev_df, \"tag\", feature_col2=col)\n",
    "\n",
    "# Extract features\n",
    "X_train = [utils1.extractSentenceFeatures(s) for s in train_sentences] \n",
    "X_dev = [utils1.extractSentenceFeatures(s) for s in dev_sentences]\n",
    "\n",
    "# Extract targets\n",
    "y_train = [utils1.extractSentenceTargets(s) for s in train_sentences]\n",
    "y_dev = [utils1.extractSentenceTargets(s) for s in dev_sentences]\n",
    "\n",
    "# Train a classification model\n",
    "a = \"arow\"\n",
    "clf = sklearn_crfsuite.CRF(algorithm=a, variance=1, max_iterations=100, all_possible_transitions=True)\n",
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict with the trained model\n",
    "print(\"Predicting on:\", test_split)\n",
    "predictions = clf.predict(X_dev)\n",
    "\n",
    "dev_df = dev_df.rename(columns={\"tag\":\"tag_pers_o_expected\"})\n",
    "dev_df.insert(len(dev_df.columns), \"tag_pers_o_predicted\", predictions)\n",
    "dev_df = dev_df.set_index([\"description_id\", \"sentence_id\", \"fold\", col])\n",
    "dev_df_exploded = dev_df.explode(list(dev_df.columns))\n",
    "\n",
    "if pred_df.shape[0] > 0:\n",
    "    pred_df = pd.concat([pred_df, dev_df_exploded])\n",
    "else:\n",
    "    pred_df = dev_df_exploded\n",
    "\n",
    "assert pred_df.loc[pred_df[\"tag_pers_o_expected\"].isna()].shape[0] == 0, \"Any NaN values should be replaced with 'O'\"\n",
    "\n",
    "filename = \"crf_{a}_{t}_baseline_fastText{d}_predictions_{s}.csv\".format(a=a, t=target_labels, d=d, s=test_split)\n",
    "pred_df.to_csv(predictions_dir+filename)\n",
    "\n",
    "print(\"Predictions for {} saved!\".format(test_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model (the last model run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/experiment1/crf-arow_pn_F-fastText100Ling_T-PNOcc.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"models/experiment1/\"\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "filename = model_dir+\"crf-{a}_pn_F-fastText{d}Ling_T-PNOcc.joblib\".format(a=a, d=d)  # include features (F) and targets (T) in model's file name\n",
    "dump(clf, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753521, 7)\n"
     ]
    }
   ],
   "source": [
    "pred_df0 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_predictions_split0.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df1 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_predictions_split1.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df2 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_predictions_split2.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df3 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_predictions_split3.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df4 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_predictions_split4.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_perso = pd.concat([pred_df0, pred_df1, pred_df2, pred_df3, pred_df4])\n",
    "print(pred_perso.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>233</td>\n",
       "      <td>James</td>\n",
       "      <td>[B-Masculine]</td>\n",
       "      <td>B-Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>234</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>[I-Masculine]</td>\n",
       "      <td>I-Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>235</td>\n",
       "      <td>was</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>236</td>\n",
       "      <td>called</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>237</td>\n",
       "      <td>upon</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id    fold pred_ling_label  token_id sentence  \\\n",
       "0               3            8  split0               O       233    James   \n",
       "1               3            8  split0               O       234    Whyte   \n",
       "2               3            8  split0               O       235      was   \n",
       "3               3            8  split0               O       236   called   \n",
       "4               3            8  split0               O       237     upon   \n",
       "\n",
       "  tag_pers_o_expected tag_pers_o_predicted  \n",
       "0       [B-Masculine]          B-Masculine  \n",
       "1       [I-Masculine]            I-Unknown  \n",
       "2                 [O]                    O  \n",
       "3                 [O]                    O  \n",
       "4                 [O]                    O  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso = pred_perso.reset_index()\n",
    "pred_perso = utils.getColumnValuesAsLists(pred_perso, \"tag_pers_o_expected\")\n",
    "pred_perso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O    753521\n",
       "Name: pred_ling_label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert pred_perso.shape[0] == len(pred_perso.token_id.unique()), \"There should be one row per token.\"\n",
    "pred_perso.pred_ling_label.value_counts()  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include only the first value from the expected tags column, as that's what was used in training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_col = \"tag_pers_o_expected\"\n",
    "pred_col = \"tag_pers_o_predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pred_lists = list(pred_perso[exp_col])\n",
    "new_exp_pred_col = [exp_pred_list[0] for exp_pred_list in exp_pred_lists]\n",
    "pred_df = pred_perso.drop(columns=[exp_col])\n",
    "pred_df.insert(len(pred_df.columns)-1, exp_col, new_exp_pred_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>233</td>\n",
       "      <td>James</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>234</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>I-Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>235</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>236</td>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>237</td>\n",
       "      <td>upon</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id    fold pred_ling_label  token_id sentence  \\\n",
       "0               3            8  split0               O       233    James   \n",
       "1               3            8  split0               O       234    Whyte   \n",
       "2               3            8  split0               O       235      was   \n",
       "3               3            8  split0               O       236   called   \n",
       "4               3            8  split0               O       237     upon   \n",
       "\n",
       "  tag_pers_o_expected tag_pers_o_predicted  \n",
       "0         B-Masculine          B-Masculine  \n",
       "1         I-Masculine            I-Unknown  \n",
       "2                   O                    O  \n",
       "3                   O                    O  \n",
       "4                   O                    O  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[exp_col].fillna(\"O\")\n",
    "pred_df[pred_col].fillna(\"O\")\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the concatenated prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = target_labels\n",
    "a = \"arow\"\n",
    "pred_df.to_csv(predictions_dir+\"crf_{a}_{c}_baseline_fastText{d}_predictions.csv\".format(a=a, c=category, d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "### Evaluation\n",
    "#### Evaluate: Strict, Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the development data's test, the predicted labels will be deemed incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics for each category of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.rename(columns={\"sentence\":\"token\"})\n",
    "df_pred = pred_df.drop(columns=[exp_col])\n",
    "df_exp = pred_df.drop(columns=[pred_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>233</td>\n",
       "      <td>James</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>234</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>was</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>236</td>\n",
       "      <td>called</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>237</td>\n",
       "      <td>upon</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id   token    fold pred_ling_label  \\\n",
       "0               3            8       233   James  split0               O   \n",
       "1               3            8       234   Whyte  split0               O   \n",
       "2               3            8       235     was  split0               O   \n",
       "3               3            8       236  called  split0               O   \n",
       "4               3            8       237    upon  split0               O   \n",
       "\n",
       "  tag_pers_o_expected tag_pers_o_predicted          _merge  \n",
       "0         B-Masculine          B-Masculine   true positive  \n",
       "1         I-Masculine                    O  false negative  \n",
       "2                   O                    O   true negative  \n",
       "3                   O                    O   true negative  \n",
       "4                   O                    O   true negative  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_on =  [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"fold\", \"pred_ling_label\"]\n",
    "df_agmt = utils.makeEvaluationDataFrame(\n",
    "    df_exp, \n",
    "    df_pred, \n",
    "    join_on+[exp_col],\n",
    "    join_on+[pred_col],\n",
    "    join_on+[exp_col, pred_col, \"_merge\"], \n",
    "    pred_col,\n",
    "    exp_col,\n",
    "    \"O\"\n",
    ")\n",
    "df_agmt = eval_df.fillna(\"O\")\n",
    "df_agmt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786096, 9)\n",
      "(753521, 7)\n",
      "(753521, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_agmt.shape)\n",
    "print(df_exp.shape)\n",
    "print(df_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the agreement data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agmt.to_csv(predictions_dir+\"crf-arow_pers_o_baseline_fastText100_strict_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the true positives, false positives, false negatives, precision, recall, and F1 metrics for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['B-Feminine', 'I-Feminine', 'B-Masculine', 'I-Masculine', 'B-Unknown', 'I-Unknown', 'B-Occupation', 'I-Occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>397.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>0.436416</td>\n",
       "      <td>0.532941</td>\n",
       "      <td>0.479873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.428787</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.471514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>0.330569</td>\n",
       "      <td>0.277796</td>\n",
       "      <td>0.301894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>3812.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>0.268049</td>\n",
       "      <td>0.292970</td>\n",
       "      <td>0.279956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>4131.0</td>\n",
       "      <td>3183.0</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>0.485867</td>\n",
       "      <td>0.421348</td>\n",
       "      <td>0.451313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>7317.0</td>\n",
       "      <td>4876.0</td>\n",
       "      <td>5388.0</td>\n",
       "      <td>0.524942</td>\n",
       "      <td>0.424085</td>\n",
       "      <td>0.469154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>0.609619</td>\n",
       "      <td>0.518997</td>\n",
       "      <td>0.560669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>2054.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>0.517580</td>\n",
       "      <td>0.381325</td>\n",
       "      <td>0.439126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label  false negative  false positive  true positive  precision  \\\n",
       "0    B-Feminine           397.0           585.0          453.0   0.436416   \n",
       "0    I-Feminine          1035.0          1516.0         1138.0   0.428787   \n",
       "0   B-Masculine          2176.0          1695.0          837.0   0.330569   \n",
       "0   I-Masculine          3369.0          3812.0         1396.0   0.268049   \n",
       "0     B-Unknown          4131.0          3183.0         3008.0   0.485867   \n",
       "0     I-Unknown          7317.0          4876.0         5388.0   0.524942   \n",
       "0  B-Occupation          1304.0           901.0         1407.0   0.609619   \n",
       "0  I-Occupation          2054.0          1180.0         1266.0   0.517580   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.532941  0.479873  \n",
       "0  0.523700  0.471514  \n",
       "0  0.277796  0.301894  \n",
       "0  0.292970  0.279956  \n",
       "0  0.421348  0.451313  \n",
       "0  0.424085  0.469154  \n",
       "0  0.518997  0.560669  \n",
       "0  0.381325  0.439126  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([df_agmt.loc[df_agmt[exp_col] == label], df_agmt.loc[df_agmt[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores.to_csv(agreement_dir+\"crf-arow_pers_o_baseline_fastText100_strict_agmt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Annotation Agreement\n",
    "\n",
    "Calculate agreement at the annotation level, so if the model labels any word correctly from a manually annotated text span, that annotation is recorded as being correctly labeled (`true positive`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753521, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>233</td>\n",
       "      <td>James</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>234</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>235</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>236</td>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>237</td>\n",
       "      <td>upon</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id    fold pred_ling_label  token_id   token  \\\n",
       "0               3            8  split0               O       233   James   \n",
       "1               3            8  split0               O       234   Whyte   \n",
       "2               3            8  split0               O       235     was   \n",
       "3               3            8  split0               O       236  called   \n",
       "4               3            8  split0               O       237    upon   \n",
       "\n",
       "  tag_pers_o_expected tag_pers_o_predicted predicted_label  \n",
       "0         B-Masculine          B-Masculine       Masculine  \n",
       "1         I-Masculine            I-Unknown         Unknown  \n",
       "2                   O                    O               O  \n",
       "3                   O                    O               O  \n",
       "4                   O                    O               O  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generalize tags to labels for annotation agreement\n",
    "pred_col, exp_col = \"predicted_label\", \"expected_label\"\n",
    "category = \"pers_o\"\n",
    "pred_labels = list(pred_df[\"tag_{}_predicted\".format(category)])\n",
    "pred_labels = [label if label == \"O\" else label[2:] for label in pred_labels]\n",
    "pred_df.insert(len(pred_df.columns), pred_col, pred_labels)\n",
    "print(pred_df.shape)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>58341</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(36375, 36378)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>split2</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>58342</td>\n",
       "      <td>Norman</td>\n",
       "      <td>(36379, 36385)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>split2</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>58343</td>\n",
       "      <td>Macleod</td>\n",
       "      <td>(36386, 36393)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>split2</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>58344</td>\n",
       "      <td>,</td>\n",
       "      <td>(36393, 36394)</td>\n",
       "      <td>,</td>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>Scope and Contents</td>\n",
       "      <td>split2</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>19836</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>(40, 43)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>split4</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ann_id description_id sentence_id token_id    token   token_offsets  pos  \\\n",
       "0       7           1082        2590    58341      Mrs  (36375, 36378)  NNP   \n",
       "1       7           1082        2590    58342   Norman  (36379, 36385)  NNP   \n",
       "2       7           1082        2590    58343  Macleod  (36386, 36393)  NNP   \n",
       "3       7           1082        2590    58344        ,  (36393, 36394)    ,   \n",
       "4      14            855        1097    19836      Dr.        (40, 43)  NNP   \n",
       "\n",
       "          tag               field    fold expected_label  \n",
       "0  B-Feminine  Scope and Contents  split2       Feminine  \n",
       "1  I-Feminine  Scope and Contents  split2       Feminine  \n",
       "2  I-Feminine  Scope and Contents  split2       Feminine  \n",
       "3  I-Feminine  Scope and Contents  split2       Feminine  \n",
       "4   B-Unknown               Title  split4        Unknown  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_ann = df_by_ann.explode([\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \"tag\", \"field\", \"fold\"])\n",
    "df_by_ann = df_by_ann.reset_index()\n",
    "df_by_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763670, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>233</td>\n",
       "      <td>James</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>14387.0</td>\n",
       "      <td>(1350, 1355)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>234</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14387.0</td>\n",
       "      <td>(1356, 1361)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>Biographical / Historical</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>235</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>236</td>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>237</td>\n",
       "      <td>upon</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id    fold pred_ling_label  token_id   token  \\\n",
       "0               3            8  split0               O       233   James   \n",
       "1               3            8  split0               O       234   Whyte   \n",
       "2               3            8  split0               O       235     was   \n",
       "3               3            8  split0               O       236  called   \n",
       "4               3            8  split0               O       237    upon   \n",
       "\n",
       "  tag_pers_o_expected tag_pers_o_predicted predicted_label   ann_id  \\\n",
       "0         B-Masculine          B-Masculine       Masculine  14387.0   \n",
       "1         I-Masculine            I-Unknown         Unknown  14387.0   \n",
       "2                   O                    O               O  99999.0   \n",
       "3                   O                    O               O  99999.0   \n",
       "4                   O                    O               O  99999.0   \n",
       "\n",
       "  token_offsets  pos          tag                      field expected_label  \n",
       "0  (1350, 1355)  NNP  B-Masculine  Biographical / Historical      Masculine  \n",
       "1  (1356, 1361)  NNP  I-Masculine  Biographical / Historical      Masculine  \n",
       "2           NaN  NaN          NaN                        NaN              O  \n",
       "3           NaN  NaN          NaN                        NaN              O  \n",
       "4           NaN  NaN          NaN                        NaN              O  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_on = [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"fold\"]\n",
    "eval_df_joined = pred_df.join(df_by_ann.set_index(join_on), on=join_on, how=\"outer\")\n",
    "print(eval_df_joined.shape)\n",
    "eval_df_joined[\"ann_id\"] = eval_df_joined[\"ann_id\"].fillna(99999)\n",
    "eval_df_joined[exp_col] = eval_df_joined[exp_col].fillna(\"O\")\n",
    "eval_df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63277, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown, Unknown, ...</td>\n",
       "      <td>[(34, 37), (38, 42), (43, 46), (47, 51), (52, ...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown, I...</td>\n",
       "      <td>[Title, Title, Title, Title, Title, Title]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24275.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown, Unknown, ...</td>\n",
       "      <td>[(34, 37), (38, 42), (43, 46), (47, 51), (52, ...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[B-Masculine, I-Masculine, I-Masculine, I-Masc...</td>\n",
       "      <td>[Title, Title, Title, Title, Title, Title]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26233.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[9, 10, 11, 12]</td>\n",
       "      <td>[Rev, Prof, James, Whyte]</td>\n",
       "      <td>[I-Unknown, I-Unknown, I-Masculine, O]</td>\n",
       "      <td>[I-Unknown, B-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown]</td>\n",
       "      <td>[(43, 46), (47, 51), (52, 57), (58, 63)]</td>\n",
       "      <td>[NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[Title, Title, Title, Title]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>[3, 4, 5, 6, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, (, 1920-2005, )]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id   ann_id    fold pred_ling_label  \\\n",
       "0               0            0  99999.0  split4               O   \n",
       "1               1            1  14384.0  split2               O   \n",
       "2               1            1  24275.0  split2               O   \n",
       "3               1            1  26233.0  split2               O   \n",
       "4               1            1  99999.0  split2               O   \n",
       "\n",
       "  expected_label                  token_id  \\\n",
       "0              O                 [0, 1, 2]   \n",
       "1        Unknown     [7, 8, 9, 10, 11, 12]   \n",
       "2      Masculine     [7, 8, 9, 10, 11, 12]   \n",
       "3        Unknown           [9, 10, 11, 12]   \n",
       "4              O  [3, 4, 5, 6, 13, 14, 15]   \n",
       "\n",
       "                                     token  \\\n",
       "0                     [Identifier, :, AA5]   \n",
       "1     [The, Very, Rev, Prof, James, Whyte]   \n",
       "2     [The, Very, Rev, Prof, James, Whyte]   \n",
       "3                [Rev, Prof, James, Whyte]   \n",
       "4  [Title, :, Papers, of, (, 1920-2005, )]   \n",
       "\n",
       "                                 tag_pers_o_expected  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...   \n",
       "2  [O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...   \n",
       "3             [I-Unknown, I-Unknown, I-Masculine, O]   \n",
       "4                              [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                tag_pers_o_predicted  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...   \n",
       "2  [B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...   \n",
       "3       [I-Unknown, B-Unknown, I-Unknown, I-Unknown]   \n",
       "4                              [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [Unknown, Unknown, Unknown, Unknown, Unknown, ...   \n",
       "2  [Unknown, Unknown, Unknown, Unknown, Unknown, ...   \n",
       "3               [Unknown, Unknown, Unknown, Unknown]   \n",
       "4                              [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                       token_offsets  \\\n",
       "0                                    [nan, nan, nan]   \n",
       "1  [(34, 37), (38, 42), (43, 46), (47, 51), (52, ...   \n",
       "2  [(34, 37), (38, 42), (43, 46), (47, 51), (52, ...   \n",
       "3           [(43, 46), (47, 51), (52, 57), (58, 63)]   \n",
       "4                [nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                                   pos  \\\n",
       "0                      [nan, nan, nan]   \n",
       "1        [DT, NNP, NNP, NNP, NNP, NNP]   \n",
       "2        [DT, NNP, NNP, NNP, NNP, NNP]   \n",
       "3                 [NNP, NNP, NNP, NNP]   \n",
       "4  [nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                                                 tag  \\\n",
       "0                                    [nan, nan, nan]   \n",
       "1  [B-Unknown, I-Unknown, I-Unknown, I-Unknown, I...   \n",
       "2  [B-Masculine, I-Masculine, I-Masculine, I-Masc...   \n",
       "3       [B-Unknown, I-Unknown, I-Unknown, I-Unknown]   \n",
       "4                [nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                                        field  \n",
       "0                             [nan, nan, nan]  \n",
       "1  [Title, Title, Title, Title, Title, Title]  \n",
       "2  [Title, Title, Title, Title, Title, Title]  \n",
       "3                [Title, Title, Title, Title]  \n",
       "4         [nan, nan, nan, nan, nan, nan, nan]  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_by_ann = utils.implodeDataFrame(eval_df_joined, [\"description_id\", \"sentence_id\", \"ann_id\", \"fold\", \"pred_ling_label\", \"expected_label\"]).reset_index()\n",
    "print(eval_by_ann.shape)\n",
    "eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split4</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...</td>\n",
       "      <td>[(34, 37), (38, 42), (43, 46), (47, 51), (52, ...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown, I...</td>\n",
       "      <td>[Title, Title, Title, Title, Title, Title]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24275.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...</td>\n",
       "      <td>[(34, 37), (38, 42), (43, 46), (47, 51), (52, ...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[B-Masculine, I-Masculine, I-Masculine, I-Masc...</td>\n",
       "      <td>[Title, Title, Title, Title, Title, Title]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26233.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[9, 10, 11, 12]</td>\n",
       "      <td>[Rev, Prof, James, Whyte]</td>\n",
       "      <td>[I-Unknown, I-Unknown, I-Masculine, O]</td>\n",
       "      <td>[I-Unknown, B-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[(43, 46), (47, 51), (52, 57), (58, 63)]</td>\n",
       "      <td>[NNP, NNP, NNP, NNP]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[Title, Title, Title, Title]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>[3, 4, 5, 6, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, (, 1920-2005, )]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id   ann_id    fold pred_ling_label  \\\n",
       "0               0            0  99999.0  split4               O   \n",
       "1               1            1  14384.0  split2               O   \n",
       "2               1            1  24275.0  split2               O   \n",
       "3               1            1  26233.0  split2               O   \n",
       "4               1            1  99999.0  split2               O   \n",
       "\n",
       "  expected_label                  token_id  \\\n",
       "0              O                 [0, 1, 2]   \n",
       "1        Unknown     [7, 8, 9, 10, 11, 12]   \n",
       "2      Masculine     [7, 8, 9, 10, 11, 12]   \n",
       "3        Unknown           [9, 10, 11, 12]   \n",
       "4              O  [3, 4, 5, 6, 13, 14, 15]   \n",
       "\n",
       "                                     token  \\\n",
       "0                     [Identifier, :, AA5]   \n",
       "1     [The, Very, Rev, Prof, James, Whyte]   \n",
       "2     [The, Very, Rev, Prof, James, Whyte]   \n",
       "3                [Rev, Prof, James, Whyte]   \n",
       "4  [Title, :, Papers, of, (, 1920-2005, )]   \n",
       "\n",
       "                                 tag_pers_o_expected  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...   \n",
       "2  [O, I-Unknown, I-Unknown, I-Unknown, I-Masculi...   \n",
       "3             [I-Unknown, I-Unknown, I-Masculine, O]   \n",
       "4                              [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                tag_pers_o_predicted  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...   \n",
       "2  [B-Unknown, I-Unknown, I-Unknown, B-Unknown, I...   \n",
       "3       [I-Unknown, B-Unknown, I-Unknown, I-Unknown]   \n",
       "4                              [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                       token_offsets  \\\n",
       "0                                    [nan, nan, nan]   \n",
       "1  [(34, 37), (38, 42), (43, 46), (47, 51), (52, ...   \n",
       "2  [(34, 37), (38, 42), (43, 46), (47, 51), (52, ...   \n",
       "3           [(43, 46), (47, 51), (52, 57), (58, 63)]   \n",
       "4                [nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                                   pos  \\\n",
       "0                      [nan, nan, nan]   \n",
       "1        [DT, NNP, NNP, NNP, NNP, NNP]   \n",
       "2        [DT, NNP, NNP, NNP, NNP, NNP]   \n",
       "3                 [NNP, NNP, NNP, NNP]   \n",
       "4  [nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                                                 tag  \\\n",
       "0                                    [nan, nan, nan]   \n",
       "1  [B-Unknown, I-Unknown, I-Unknown, I-Unknown, I...   \n",
       "2  [B-Masculine, I-Masculine, I-Masculine, I-Masc...   \n",
       "3       [B-Unknown, I-Unknown, I-Unknown, I-Unknown]   \n",
       "4                [nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                                        field predicted_label  \n",
       "0                             [nan, nan, nan]             NaN  \n",
       "1  [Title, Title, Title, Title, Title, Title]         Unknown  \n",
       "2  [Title, Title, Title, Title, Title, Title]         Unknown  \n",
       "3                [Title, Title, Title, Title]         Unknown  \n",
       "4         [nan, nan, nan, nan, nan, nan, nan]             NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label_col = list(eval_by_ann[pred_col])\n",
    "unique_pred_label_col = [list(set(pred_labels)) for pred_labels in pred_label_col]\n",
    "new_pred_label_col = []\n",
    "for pred_labels in unique_pred_label_col:\n",
    "    if \"O\" in pred_labels:\n",
    "        pred_labels.remove(\"O\")\n",
    "    new_pred_label_col += [pred_labels]\n",
    "eval_by_ann = eval_by_ann.drop(columns=[pred_col])\n",
    "eval_by_ann.insert(len(eval_by_ann.columns), pred_col, new_pred_label_col)\n",
    "eval_by_ann = eval_by_ann.explode([pred_col])\n",
    "eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted labels to expected label for each annotation, where if a label was predicted when none was expected, agreement is a false positive; if a correct label was predicted (even if it's only on part of the annotation), agreement is a true positive; and if no label was predicted when a label was expected, agreement is a false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_col = \"expected_label\"\n",
    "pred_col = \"predicted_label\"\n",
    "df_pred = eval_by_ann.drop(columns=[exp_col, \"fold\", \"token_id\", \"token\", \"tag_pers_o_expected\", \"tag_pers_o_predicted\"])\n",
    "df_exp = eval_by_ann.drop(columns=[pred_col, \"fold\", \"token_id\", \"token\", \"tag_pers_o_expected\", \"tag_pers_o_predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_by_ann[exp_col] = eval_by_ann[exp_col].fillna(\"O\")\n",
    "eval_by_ann[pred_col] = eval_by_ann[pred_col].fillna(\"O\")\n",
    "assert eval_by_ann.loc[eval_by_ann.expected_label.isna()].shape[0] == 0\n",
    "assert eval_by_ann.loc[eval_by_ann.predicted_label.isna()].shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the agreement type for each row, either false positive, true positive, false negative, or true negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>pred_ling_label</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>7.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69139</th>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>7.0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66635</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       description_id  sentence_id  ann_id pred_ling_label expected_label  \\\n",
       "6999             1082         2590     7.0               O       Feminine   \n",
       "69139            1082         2590     7.0               O              O   \n",
       "66635             855         1097    14.0               O              O   \n",
       "2826              855         1097    14.0               O        Unknown   \n",
       "2827              855         1097    14.0               O        Unknown   \n",
       "\n",
       "      predicted_label          _merge  \n",
       "6999                O  false negative  \n",
       "69139         Unknown  false positive  \n",
       "66635        Feminine  false positive  \n",
       "2826          Unknown   true positive  \n",
       "2827          Unknown   true positive  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_on =  [\"description_id\", \"sentence_id\", \"ann_id\", \"pred_ling_label\"]\n",
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    df_exp, \n",
    "    df_pred, \n",
    "    join_on+[exp_col], \n",
    "    join_on+[pred_col], \n",
    "    join_on+[exp_col, pred_col, \"_merge\"], \n",
    "    exp_col, \n",
    "    pred_col, \n",
    "    \"O\"\n",
    ")\n",
    "id_col = \"ann_id\"\n",
    "eval_df = eval_df.sort_values(by=[id_col, exp_col, pred_col])\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79601, 7)\n",
      "(64652, 9)\n",
      "(64652, 9)\n"
     ]
    }
   ],
   "source": [
    "eval_df = eval_df.drop_duplicates()\n",
    "print(eval_df.shape)\n",
    "print(df_pred.shape)\n",
    "print(df_exp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(predictions_dir+\"crf-{a}_{c}_baseline_fastText{d}_annot_evaluation.csv\".format(a=a, c=category, d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate annotation agreement metrics for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>553.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>0.486831</td>\n",
       "      <td>0.674514</td>\n",
       "      <td>0.565507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>3402.0</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>0.415035</td>\n",
       "      <td>0.397770</td>\n",
       "      <td>0.406219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>5982.0</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>5170.0</td>\n",
       "      <td>0.590790</td>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.519520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0.651855</td>\n",
       "      <td>0.568971</td>\n",
       "      <td>0.607599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  false negative  false positive  true positive  precision  \\\n",
       "0    Feminine           553.0          1208.0         1146.0   0.486831   \n",
       "0   Masculine          3402.0          3167.0         2247.0   0.415035   \n",
       "0     Unknown          5982.0          3581.0         5170.0   0.590790   \n",
       "0  Occupation          1278.0           901.0         1687.0   0.651855   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.674514  0.565507  \n",
       "0  0.397770  0.406219  \n",
       "0  0.463594  0.519520  \n",
       "0  0.568971  0.607599  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Feminine', 'Masculine', 'Unknown', 'Occupation']\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores.to_csv(agreement_dir+\"crf-{a}_{c}_baseline_fastText{d}_annot_agmt.csv\".format(a=a, d=d, c=category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### *For train-dev-test (i.e., 40-40-20) approach*\n",
    "\n",
    "<a id=\"ii\"></a>\n",
    "## II. Predict Over All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = utils1.zip2FeaturesAndTarget(df_test_grouped, \"tag\")\n",
    "X_test = [utils1.extractSentenceFeatures(sentence) for sentence in test_sentences]  # Features\n",
    "y_test = [utils1.extractSentenceTargets(sentence) for sentence in test_sentences]   # Target\n",
    "# Combine all data subsets' features and targets\n",
    "X_all = X_train+X_dev+X_test\n",
    "y_all = y_train+y_dev+y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = clf_perso.predict(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.5211899648086513\n",
      "  - Prec: 0.5561442804328083\n",
      "  - Rec 0.49419097345616575\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_all, all_predictions, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_all, all_predictions, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_all, all_predictions, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.rename(columns={\"tag\":\"tag_pers_o_expected\"})\n",
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.drop(columns=\"tag_{}_predicted\".format(target_labels))\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "df_test_grouped = df_test_grouped.rename(columns={\"tag\":\"tag_pers_o_expected\"})\n",
    "df_all_grouped = pd.concat([df_train_grouped, df_dev_grouped, df_test_grouped])\n",
    "# df_all_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>pred_ling_tag</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id  sentence tag_pers_o_expected pred_ling_tag  \\\n",
       "sentence_id                                                        \n",
       "2                 16     Scope                 [O]           [O]   \n",
       "2                 17       and                 [O]           [O]   \n",
       "2                 18  Contents                 [O]           [O]   \n",
       "2                 19         :                 [O]           [O]   \n",
       "2                 20   Sermons                 [O]           [O]   \n",
       "\n",
       "            tag_pers_o_predicted  \n",
       "sentence_id                       \n",
       "2                              O  \n",
       "2                              O  \n",
       "2                              O  \n",
       "2                              O  \n",
       "2                              O  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_grouped.insert(len(df_all_grouped.columns), \"tag_pers_o_predicted\", all_predictions)\n",
    "df_all_grouped = df_all_grouped.set_index(\"sentence_id\")\n",
    "df_all_exploded = df_all_grouped.explode(list(df_all_grouped.columns))\n",
    "df_all_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_exploded = df_all_exploded.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_{a}_{t}_baseline_fastText{d}_predictions_ALLDATA.csv\".format(a=a, t=target_labels, d=d)\n",
    "df_all_exploded.to_csv(config.experiment1_output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the manual annotations, the predicted labels will be deemed incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics for each category of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso = df_all_exploded.copy()\n",
    "pred_perso = pred_perso.fillna(\"O\")\n",
    "pred_perso = utils.isPredictedInExpected(pred_perso, \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), '_merge', 'O')\n",
    "# pred_perso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>2082</td>\n",
       "      <td>2433</td>\n",
       "      <td>4549</td>\n",
       "      <td>0.651533</td>\n",
       "      <td>0.686020</td>\n",
       "      <td>0.668332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>3959</td>\n",
       "      <td>3797</td>\n",
       "      <td>7738</td>\n",
       "      <td>0.670828</td>\n",
       "      <td>0.661537</td>\n",
       "      <td>0.666150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>88</td>\n",
       "      <td>183</td>\n",
       "      <td>392</td>\n",
       "      <td>0.681739</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.743128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>337</td>\n",
       "      <td>1035</td>\n",
       "      <td>1620</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.827798</td>\n",
       "      <td>0.702515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>678</td>\n",
       "      <td>875</td>\n",
       "      <td>1356</td>\n",
       "      <td>0.607799</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.635873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>1491</td>\n",
       "      <td>1339</td>\n",
       "      <td>2103</td>\n",
       "      <td>0.610982</td>\n",
       "      <td>0.585142</td>\n",
       "      <td>0.597783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>896</td>\n",
       "      <td>623</td>\n",
       "      <td>1634</td>\n",
       "      <td>0.723970</td>\n",
       "      <td>0.645850</td>\n",
       "      <td>0.682682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>1304</td>\n",
       "      <td>892</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.673977</td>\n",
       "      <td>0.585769</td>\n",
       "      <td>0.626785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0     B-Unknown            2082            2433           4549   0.651533   \n",
       "0     I-Unknown            3959            3797           7738   0.670828   \n",
       "0    B-Feminine              88             183            392   0.681739   \n",
       "0    I-Feminine             337            1035           1620   0.610169   \n",
       "0   B-Masculine             678             875           1356   0.607799   \n",
       "0   I-Masculine            1491            1339           2103   0.610982   \n",
       "0  B-Occupation             896             623           1634   0.723970   \n",
       "0  I-Occupation            1304             892           1844   0.673977   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.686020  0.668332  \n",
       "0  0.661537  0.666150  \n",
       "0  0.816667  0.743128  \n",
       "0  0.827798  0.702515  \n",
       "0  0.666667  0.635873  \n",
       "0  0.585142  0.597783  \n",
       "0  0.645850  0.682682  \n",
       "0  0.585769  0.626785  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso_stats = utils.getScoresByCatTags(\n",
    "    pred_perso, \"_merge\", pers_o_label_subset[0], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(pers_o_label_subset)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_perso, \"_merge\", pers_o_label_subset[i], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_perso_stats = pd.concat([pred_perso_stats, tag_stats])\n",
    "pred_perso_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_stats.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_strict_agmt_ALLDATA.csv\".format(a=a, c=category, d=d)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Annotation Agreement\n",
    "\n",
    "Calculate agreement at the annotation level, so if the model labels any word correctly from a manually annotated text span, that annotation is recorded as being correctly labeled (`true positive`).  Note whether the models' labels are an `exact_match`, `label_match`, `category_match` or `mismatch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the annotation data:\n",
    "\n",
    "*Note: `ann_id` of `9999` indicates no annotation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the annotation data by token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "perso_all = pd.concat([perso_train, perso_dev, perso_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778803, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>[B-Unknown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>8</td>\n",
       "      <td>[I-Unknown]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  ann_id  token_id          tag\n",
       "0            0   99999         0          [O]\n",
       "1            0   99999         1          [O]\n",
       "2            0   99999         2          [O]\n",
       "3            1   14384         7  [B-Unknown]\n",
       "4            1   14384         8  [I-Unknown]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ann = perso_all[[\"sentence_id\", \"ann_id\", \"token_id\", \"tag\"]]\n",
    "df_ann = utils.implodeDataFrame(df_ann, [\"sentence_id\", \"ann_id\", \"token_id\"])\n",
    "df_ann = df_ann.reset_index()\n",
    "print(df_ann.shape)\n",
    "df_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align the columns of the annotation and prediction DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>pred_ling_tag</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604541</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604542</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604543</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298617</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298618</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id       token tag_pers_o_expected pred_ling_tag  \\\n",
       "604541            0         0  Identifier                 [O]           [O]   \n",
       "604542            0         1           :                 [O]           [O]   \n",
       "604543            0         2         AA5                 [O]           [O]   \n",
       "298617            1         3       Title                 [O]           [O]   \n",
       "298618            1         4           :                 [O]           [O]   \n",
       "\n",
       "       tag_pers_o_predicted         _merge  \n",
       "604541                    O  true negative  \n",
       "604542                    O  true negative  \n",
       "604543                    O  true negative  \n",
       "298617                    O  true negative  \n",
       "298618                    O  true negative  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename `sentence` column `token`\n",
    "pred_perso = pred_perso.rename(columns={\"sentence\":\"token\"}).sort_values(by=\"token_id\")\n",
    "pred_perso.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the data, adding the annotation IDs (`ann_id` column) to the prediction DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [\"sentence_id\", \"token_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_ann = pred_perso.join(df_ann.set_index(index_list), on=index_list, how=\"left\")\n",
    "pred_perso_ann = pred_perso_ann.drop(columns=[\"tag\"])  # duplicate of tag_expected\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"token_id\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"ann_id\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"tag_pers_o_predicted\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"tag_pers_o_expected\"].isna()].shape[0] == 0\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explode the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_ann = pred_perso_ann.explode([\"tag_pers_o_expected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalize the BIO tags to label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted labels\n",
    "pred_labels = list(pred_perso_ann[\"tag_{}_predicted\".format(category)])\n",
    "pred_labels = [label if label == \"O\" else label[2:] for label in pred_labels]\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"label_{}_predicted\".format(category), pred_labels)\n",
    "# Get the lists of expected labels\n",
    "exp_labels = list(pred_perso_ann[\"tag_{}_expected\".format(category)])\n",
    "exp_labels = [label if label == \"O\" else label[2:] for label in exp_labels]\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"label_{}_expected\".format(category), exp_labels)\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_ann = pred_perso_ann.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_perso_ann = utils.implodeDataFrame(pred_perso_ann, [\"sentence_id\", \"ann_id\"])\n",
    "pred_perso_ann = pred_perso_ann.reset_index()\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the agreements and disagreements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_types_perso, agmt_labels_perso = utils1.getAnnotationAgreement(pred_perso_ann, \"label_pers_o_predicted\", \"label_pers_o_expected\")\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"annotation_agreement\", agmt_types_perso)\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"agreement_label\", agmt_labels_perso)\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>false negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>false positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>10080</td>\n",
       "      <td>15546</td>\n",
       "      <td>5003</td>\n",
       "      <td>0.756533</td>\n",
       "      <td>0.606649</td>\n",
       "      <td>0.673351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person Name</td>\n",
       "      <td>8551</td>\n",
       "      <td>13603</td>\n",
       "      <td>4324</td>\n",
       "      <td>0.758800</td>\n",
       "      <td>0.614020</td>\n",
       "      <td>0.678775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>3749</td>\n",
       "      <td>8755</td>\n",
       "      <td>2649</td>\n",
       "      <td>0.767713</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.732391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>817</td>\n",
       "      <td>1636</td>\n",
       "      <td>593</td>\n",
       "      <td>0.733961</td>\n",
       "      <td>0.666938</td>\n",
       "      <td>0.698847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>3985</td>\n",
       "      <td>3212</td>\n",
       "      <td>1082</td>\n",
       "      <td>0.748020</td>\n",
       "      <td>0.446297</td>\n",
       "      <td>0.559046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>1529</td>\n",
       "      <td>1943</td>\n",
       "      <td>679</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.559620</td>\n",
       "      <td>0.637676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels  false negative  true positive  false positive  precision  \\\n",
       "0          all           10080          15546            5003   0.756533   \n",
       "0  Person Name            8551          13603            4324   0.758800   \n",
       "0      Unknown            3749           8755            2649   0.767713   \n",
       "0     Feminine             817           1636             593   0.733961   \n",
       "0    Masculine            3985           3212            1082   0.748020   \n",
       "0   Occupation            1529           1943             679   0.741037   \n",
       "\n",
       "     recall       f_1  \n",
       "0  0.606649  0.673351  \n",
       "0  0.614020  0.678775  \n",
       "0  0.700176  0.732391  \n",
       "0  0.666938  0.698847  \n",
       "0  0.446297  0.559046  \n",
       "0  0.559620  0.637676  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_perso_all = utils1.getAnnotationAgreementMetrics(pred_perso_ann, \"all\")\n",
    "metrics_perso_pn = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[~(pred_perso_ann.agreement_label.isin([\"Occupation\",\"O\"]))], \"Person Name\")\n",
    "metrics_perso_unk = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Unknown\"], \"Unknown\")\n",
    "metrics_perso_fem = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Feminine\"], \"Feminine\")\n",
    "metrics_perso_mas = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Masculine\"], \"Masculine\")\n",
    "metrics_perso_occ = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Occupation\"], \"Occupation\")\n",
    "metrics_perso = pd.concat([metrics_perso_all, metrics_perso_pn, metrics_perso_unk, metrics_perso_fem, metrics_perso_mas, metrics_perso_occ])\n",
    "metrics_perso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_perso.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_annot_agmt.csv\".format(a=a, d=d, c=category)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: Loose, Each Label\n",
    "\n",
    "Generalize the tokens' BIO tags to the labels and calculate agreement scores for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_labels = pred_perso.drop(columns=[\"_merge\"])\n",
    "tag_exp = list(pred_perso_labels[\"tag_{}_expected\".format(category)])\n",
    "tag_pred = list(pred_perso_labels[\"tag_{}_predicted\".format(category)])\n",
    "label_exp = [[tag if tag == \"O\" else tag[2:] for tag in tag_exp_list] for tag_exp_list in tag_exp]\n",
    "label_pred = [tag if tag == \"O\" else tag[2:] for tag in tag_pred]\n",
    "pred_perso_labels = pred_perso_labels.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_perso_labels.insert(len(pred_perso_labels.columns), \"label_{}_expected\".format(category), label_exp)\n",
    "pred_perso_labels.insert(len(pred_perso_labels.columns), \"label_{}_predicted\".format(category), label_pred)\n",
    "# pred_pers_labels.loc[pred_pers_labels.label_personname_predicted == \"Feminine\"].head()  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the agreement metrics at the label level for each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>6017</td>\n",
       "      <td>5487</td>\n",
       "      <td>13030</td>\n",
       "      <td>0.703678</td>\n",
       "      <td>0.684097</td>\n",
       "      <td>0.693749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>422</td>\n",
       "      <td>874</td>\n",
       "      <td>2356</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.848092</td>\n",
       "      <td>0.784288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>2159</td>\n",
       "      <td>1942</td>\n",
       "      <td>3731</td>\n",
       "      <td>0.657677</td>\n",
       "      <td>0.633447</td>\n",
       "      <td>0.645334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>2200</td>\n",
       "      <td>1381</td>\n",
       "      <td>3612</td>\n",
       "      <td>0.723413</td>\n",
       "      <td>0.621473</td>\n",
       "      <td>0.668579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0     Unknown            6017            5487          13030   0.703678   \n",
       "0    Feminine             422             874           2356   0.729412   \n",
       "0   Masculine            2159            1942           3731   0.657677   \n",
       "0  Occupation            2200            1381           3612   0.723413   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.684097  0.693749  \n",
       "0  0.848092  0.784288  \n",
       "0  0.633447  0.645334  \n",
       "0  0.621473  0.668579  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['Unknown', 'Feminine', 'Masculine', 'Occupation']\n",
    "pred_perso_labels = utils.isPredictedInExpected(pred_perso_labels, \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), '_merge', 'O')\n",
    "\n",
    "pred_perso_stats = utils.getScoresByCatTags(\n",
    "    pred_perso_labels, \"_merge\", tags[0], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_perso_labels, \"_merge\", tags[i], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_perso_stats = pd.concat([pred_perso_stats, tag_stats])\n",
    "pred_perso_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine and save the performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_stats.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_loose_agmt.csv\".format(a=a, d=d, c=category)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Past error analysis on Person Name document classifiers would suggest that there's a mix-up in the manual annotations between 'Masculine' and 'Unknown,' with many Masculine-labeled names actually needing an 'Unknown' label based on the annotation descriptions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

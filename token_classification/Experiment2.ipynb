{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "\n",
    "#### Model Setup\n",
    "\n",
    "Run models in the following order, using their output labels as features for the next model:\n",
    "\n",
    "[1.](#1) Multiclass Person Name + Occupation Sequence Classifier\n",
    "\n",
    "[2.](#2) Multilabel Linguistic Classifier\n",
    "\n",
    "[3.](#3) Multilabel Document Classifier\n",
    "\n",
    "***\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/experiment_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/experiment1/`\n",
    "* Word Embeddings\n",
    "    * Custom fastText (word2vec with subwords) embeddings of 100 dimensions trained on the CRC Archives catalog's descriptive metadata (harvested October 2020)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, utils1, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For preprocessing\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "\n",
    "# For multilabel token classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# For multiclass sequence classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resources for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.experiment_input_path).mkdir(parents=True, exist_ok=True)    # For train, devtest, and blind test data\n",
    "Path(config.experiment1_output_path).mkdir(parents=True, exist_ok=True)  # For predictions\n",
    "Path(config.experiment1_agmt_path).mkdir(parents=True, exist_ok=True)    # For agreement metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1:\n",
    "ling_label_subset = [\"B-Generalization\", \"I-Generalization\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"]\n",
    "# Model 2:\n",
    "pers_o_label_subset = [\"B-Unknown\", \"I-Unknown\", \"B-Feminine\", \"I-Feminine\", \"B-Masculine\", \"I-Masculine\", \"B-Occupation\", \"I-Occupation\"]\n",
    "# Model 3:\n",
    "so_label_subset = [\"B-Stereotype\", \"I-Stereotype\", \"B-Omission\", \"I-Omission\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_label_tags = {\n",
    "    \"Gendered-Pronoun\": [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"], \"Gendered-Role\": [\"B-Gendered-Role\", \"I-Gendered-Role\"],\"Generalization\": [\"B-Generalization\", \"I-Generalization\"]\n",
    "    }\n",
    "pers_o_label_tags = {\n",
    "    \"Unknown\": [\"B-Unknown\", \"I-Unknown\"], \"Feminine\": [\"B-Feminine\", \"I-Feminine\"], \"Masculine\": [\"B-Masculine\", \"I-Masculine\"],\n",
    "     \"Occupation\": [\"B-Occupation\", \"I-Occupation\"]\n",
    "    }\n",
    "so_label_tags = {\n",
    "    \"Stereotype\": [\"B-Stereotype\", \"I-Stereotype\"], \"Omission\": [\"B-Omission\", \"I-Omission\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100  # dimensions of word embeddings (should match utils1.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Person Name + Occupation Labels\n",
    "\n",
    "Train a multiclass sequence classifier, using Conditional Random Field with Adaptive Regularization of Weight Vectors (AROW), on the Person Name and Occupation labels.\n",
    "\n",
    "Multiclass is a suitable setup for these labels because they are mutually exclusive (no one token should have more than one of these labels).  The sequence classifier with AROW was the highest performing for past algorithm experiments with sequence classifiers for Person Name and Occupation labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The devtest data subset from the model in step 1 will be the train data subset in this step, with the predicted Linguistic labels as features passed into this second model.  The train data subset from the first model will be the devtest data subset for this second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316721, 10) (308583, 10)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(config.tokc_path+\"experiment_input/token_validate.csv\", index_col=0)\n",
    "dev_df =  pd.read_csv(config.tokc_path+\"experiment_input/token_train.csv\", index_col=0)\n",
    "perso_train, perso_dev = utils.selectDataForLabels(train_df, dev_df, \"tag\", pers_o_label_subset)\n",
    "print(perso_train.shape, perso_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = perso_train.drop(columns=[\"description_id\", \"ann_id\", \"token_offsets\", \"field\", \"subset\", \"pos\"])\n",
    "dev_df = perso_dev.drop(columns=[\"description_id\", \"ann_id\", \"token_offsets\", \"field\", \"subset\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(train_df, ['token_id', 'sentence_id', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "# df_train_token_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_token_groups = utils.implodeDataFrame(dev_df, ['token_id', 'sentence_id', 'token'])\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()\n",
    "# df_dev_token_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, The, Very, Rev, Prof, J...</td>\n",
       "      <td>[[O], [O], [O], [O], [O, B-Unknown, B-Masculin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[109, 110, 111, 112, 113, 114, 115, 116, 117, ...</td>\n",
       "      <td>[Biographical, /, Historical, :, Professor, Ja...</td>\n",
       "      <td>[[O], [O], [O], [O], [B-Masculine], [I-Masculi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[216, 217, 218, 219, 220, 221, 222, 223, 224, ...</td>\n",
       "      <td>[His, primary, interests, were, in, liturgy, a...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[256, 257, 258, 259, 260, 261, 262, 263, 264, ...</td>\n",
       "      <td>[The, service, was, relayed, around, the, worl...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "1                [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]   \n",
       "3            [109, 110, 111, 112, 113, 114, 115, 116, 117, ...   \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "7            [216, 217, 218, 219, 220, 221, 222, 223, 224, ...   \n",
       "9            [256, 257, 258, 259, 260, 261, 262, 263, 264, ...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "1            [Title, :, Papers, of, The, Very, Rev, Prof, J...   \n",
       "3            [Biographical, /, Historical, :, Professor, Ja...   \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "7            [His, primary, interests, were, in, liturgy, a...   \n",
       "9            [The, service, was, relayed, around, the, worl...   \n",
       "\n",
       "                                                           tag  \n",
       "sentence_id                                                     \n",
       "1            [[O], [O], [O], [O], [O, B-Unknown, B-Masculin...  \n",
       "3            [[O], [O], [O], [O], [B-Masculine], [I-Masculi...  \n",
       "5            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "7            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "9            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_train_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the linguistic label and BIO tags together with the tokens so each sentence item is a tuple: `(TOKEN, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('After', ['O']), ('his', ['O']), ('ordination', ['O'])]\n",
      "[('Scope', ['O']), ('and', ['O']), ('Contents', ['O'])]\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_pers = utils1.zipDevFeaturesAndTarget(df_train_grouped, \"tag\")  # Dev because not using additional feature col for linguistic labels\n",
    "print(train_sentences_pers[2][:3])\n",
    "dev_sentences_pers = utils1.zipDevFeaturesAndTarget(df_dev_grouped, \"tag\")\n",
    "print(dev_sentences_pers[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_pers\n",
    "dev_sentences = dev_sentences_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [utils1.extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [utils1.extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [utils1.extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [utils1.extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"arow\"\n",
    "clf_pers = sklearn_crfsuite.CRF(algorithm=a, variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_pers.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Unknown', 'B-Masculine', 'I-Masculine', 'B-Occupation', 'I-Occupation', 'B-Unknown', 'I-Feminine', 'B-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_pers.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pers.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.42825014312210974\n",
      "  - Prec: 0.4496106745338277\n",
      "  - Rec 0.41771448419590135\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[233, 234, 235, 236, 237, 238, 239, 240, 241, ...</td>\n",
       "      <td>[James, Whyte, was, called, upon, to, preach, ...</td>\n",
       "      <td>[[B-Masculine], [I-Masculine], [O], [O], [O], ...</td>\n",
       "      <td>[B-Masculine, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>[520, 521, 522, 523, 524, 525, 526, 527, 528, ...</td>\n",
       "      <td>[Rev, Tom, Allan, 's, first, charge, was, Nort...</td>\n",
       "      <td>[[B-Masculine], [I-Masculine], [I-Masculine], ...</td>\n",
       "      <td>[B-Masculine, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>[579, 580, 581, 582, 583, 584, 585, 586, 587, ...</td>\n",
       "      <td>[In, 1953, the, \", Tell, Scotland, \", committe...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>[768, 769, 770, 771, 772, 773, 774, 775, 776, ...</td>\n",
       "      <td>[Title, :, Papers, of, Rev, Prof, Alec, Campbe...</td>\n",
       "      <td>[[O], [O], [O], [O], [B-Masculine, B-Unknown],...</td>\n",
       "      <td>[O, O, O, O, O, O, B-Masculine, I-Masculine, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                           token_id  \\\n",
       "0            2  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "1            8  [233, 234, 235, 236, 237, 238, 239, 240, 241, ...   \n",
       "2           19  [520, 521, 522, 523, 524, 525, 526, 527, 528, ...   \n",
       "3           21  [579, 580, 581, 582, 583, 584, 585, 586, 587, ...   \n",
       "4           30  [768, 769, 770, 771, 772, 773, 774, 775, 776, ...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "1  [James, Whyte, was, called, upon, to, preach, ...   \n",
       "2  [Rev, Tom, Allan, 's, first, charge, was, Nort...   \n",
       "3  [In, 1953, the, \", Tell, Scotland, \", committe...   \n",
       "4  [Title, :, Papers, of, Rev, Prof, Alec, Campbe...   \n",
       "\n",
       "                                 tag_pers_o_expected  \\\n",
       "0  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "1  [[B-Masculine], [I-Masculine], [O], [O], [O], ...   \n",
       "2  [[B-Masculine], [I-Masculine], [I-Masculine], ...   \n",
       "3  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "4  [[O], [O], [O], [O], [B-Masculine, B-Unknown],...   \n",
       "\n",
       "                                tag_pers_o_predicted  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [B-Masculine, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "2  [B-Masculine, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, B-Masculine, I-Masculine, I...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag\":\"tag_pers_o_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_pers_o_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id  sentence tag_pers_o_expected tag_pers_o_predicted\n",
       "sentence_id                                                            \n",
       "2                 16     Scope                 [O]                    O\n",
       "2                 17       and                 [O]                    O\n",
       "2                 18  Contents                 [O]                    O\n",
       "2                 19         :                 [O]                    O\n",
       "2                 20   Sermons                 [O]                    O"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.set_index(\"sentence_id\")\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_{a}_pers_o_baseline_fastText{d}_nolingfeatures_predictions.csv\".format(a=a, d=d)\n",
    "df_dev_exploded.to_csv(config.experiment1_output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the development data's test, the predicted labels will be deemed incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"arow\"\n",
    "category = \"pers_o\"\n",
    "filename = \"crf_{a}_{c}_baseline_fastText{d}_nolingfeatures_predictions.csv\".format(a=a, c=category, d=d)\n",
    "pred_perso = pd.read_csv(config.experiment1_output_path+filename)\n",
    "pred_perso = utils.getColumnValuesAsLists(pred_perso, \"tag_{}_expected\".format(category))\n",
    "# pred_pers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics for each category of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Scope</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>and</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Contents</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Sermons</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  sentence tag_pers_o_expected tag_pers_o_predicted  \\\n",
       "0            2        16     Scope                 [O]                    O   \n",
       "1            2        17       and                 [O]                    O   \n",
       "2            2        18  Contents                 [O]                    O   \n",
       "3            2        19         :                 [O]                    O   \n",
       "4            2        20   Sermons                 [O]                    O   \n",
       "\n",
       "          _merge  \n",
       "0  true negative  \n",
       "1  true negative  \n",
       "2  true negative  \n",
       "3  true negative  \n",
       "4  true negative  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso = utils.isPredictedInExpected(pred_perso, \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), '_merge', 'O')\n",
    "pred_perso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>998</td>\n",
       "      <td>1126</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.544683</td>\n",
       "      <td>0.574414</td>\n",
       "      <td>0.559153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>1872</td>\n",
       "      <td>1826</td>\n",
       "      <td>2409</td>\n",
       "      <td>0.568831</td>\n",
       "      <td>0.562719</td>\n",
       "      <td>0.565759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>47</td>\n",
       "      <td>344</td>\n",
       "      <td>358</td>\n",
       "      <td>0.509972</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.646793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>179</td>\n",
       "      <td>591</td>\n",
       "      <td>571</td>\n",
       "      <td>0.491394</td>\n",
       "      <td>0.761333</td>\n",
       "      <td>0.597280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>240</td>\n",
       "      <td>603</td>\n",
       "      <td>905</td>\n",
       "      <td>0.600133</td>\n",
       "      <td>0.790393</td>\n",
       "      <td>0.682247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>568</td>\n",
       "      <td>662</td>\n",
       "      <td>766</td>\n",
       "      <td>0.536415</td>\n",
       "      <td>0.574213</td>\n",
       "      <td>0.554671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>420</td>\n",
       "      <td>421</td>\n",
       "      <td>582</td>\n",
       "      <td>0.580259</td>\n",
       "      <td>0.580838</td>\n",
       "      <td>0.580549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>674</td>\n",
       "      <td>561</td>\n",
       "      <td>571</td>\n",
       "      <td>0.504417</td>\n",
       "      <td>0.458635</td>\n",
       "      <td>0.480438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0     B-Unknown             998            1126           1347   0.544683   \n",
       "0     I-Unknown            1872            1826           2409   0.568831   \n",
       "0    B-Feminine              47             344            358   0.509972   \n",
       "0    I-Feminine             179             591            571   0.491394   \n",
       "0   B-Masculine             240             603            905   0.600133   \n",
       "0   I-Masculine             568             662            766   0.536415   \n",
       "0  B-Occupation             420             421            582   0.580259   \n",
       "0  I-Occupation             674             561            571   0.504417   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.574414  0.559153  \n",
       "0  0.562719  0.565759  \n",
       "0  0.883951  0.646793  \n",
       "0  0.761333  0.597280  \n",
       "0  0.790393  0.682247  \n",
       "0  0.574213  0.554671  \n",
       "0  0.580838  0.580549  \n",
       "0  0.458635  0.480438  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso_stats = utils.getScoresByCatTags(\n",
    "    pred_perso, \"_merge\", pers_o_label_subset[0], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(pers_o_label_subset)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_perso, \"_merge\", pers_o_label_subset[i], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_perso_stats = pd.concat([pred_perso_stats, tag_stats])\n",
    "pred_perso_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_stats.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_nolingfeatures_strict_agmt.csv\".format(a=a, c=category, d=d)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotation Agreement\n",
    "\n",
    "Calculate agreement at the annotation level, so if the model labels any word correctly from a manually annotated text span, that annotation is recorded as being correctly labeled (`true positive`).  Note whether the models' labels are an `exact_match`, `label_match`, `category_match` or `mismatch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the annotation data:\n",
    "\n",
    "*Note: `ann_id` of `9999` indicates no annotation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df =  pd.read_csv(config.tokc_path+\"experiment_input/token_train.csv\", usecols=[\"sentence_id\", \"ann_id\", \"token_id\", \"tag\"])\n",
    "# dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the annotation data by token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ann = utils.implodeDataFrame(dev_df, [\"sentence_id\", \"ann_id\", \"token_id\"])\n",
    "df_ann = df_ann.reset_index()\n",
    "# print(df_ann.shape)\n",
    "# df_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align the columns of the dev and prediction DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename `sentence` column `token`\n",
    "pred_perso = pred_perso.rename(columns={\"sentence\":\"token\"})\n",
    "# pred_perso.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the data, adding the annotation IDs (`ann_id` column) to the prediction DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [\"sentence_id\", \"token_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_ann = pred_perso.join(df_ann.set_index(index_list), on=index_list, how=\"left\")\n",
    "pred_perso_ann = pred_perso_ann.drop(columns=[\"tag\"])  # duplicate of tag_expected\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"token_id\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"ann_id\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"tag_pers_o_predicted\"].isna()].shape[0] == 0\n",
    "assert pred_perso_ann.loc[pred_perso_ann[\"tag_pers_o_expected\"].isna()].shape[0] == 0\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explode the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_ann = pred_perso_ann.explode([\"tag_pers_o_expected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalize the BIO tags to label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted labels\n",
    "pred_labels = list(pred_perso_ann[\"tag_{}_predicted\".format(category)])\n",
    "pred_labels = [label if label == \"O\" else label[2:] for label in pred_labels]\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"label_{}_predicted\".format(category), pred_labels)\n",
    "# Get the lists of expected labels\n",
    "exp_labels = list(pred_perso_ann[\"tag_{}_expected\".format(category)])\n",
    "exp_labels = [label if label == \"O\" else label[2:] for label in exp_labels]\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"label_{}_expected\".format(category), exp_labels)\n",
    "# pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>_merge</th>\n",
       "      <th>label_pers_o_predicted</th>\n",
       "      <th>label_pers_o_expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>14387</td>\n",
       "      <td>[233, 234]</td>\n",
       "      <td>[James, Whyte]</td>\n",
       "      <td>[true positive, false negative]</td>\n",
       "      <td>[Masculine, O]</td>\n",
       "      <td>[Masculine, Masculine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>99999</td>\n",
       "      <td>[235, 236, 237, 238, 239, 240, 241, 242, 243, ...</td>\n",
       "      <td>[was, called, upon, to, preach, at, the, memor...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>9518</td>\n",
       "      <td>[533]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>9519</td>\n",
       "      <td>[539]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  ann_id                                           token_id  \\\n",
       "0            2   99999  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "1            8   14387                                         [233, 234]   \n",
       "2            8   99999  [235, 236, 237, 238, 239, 240, 241, 242, 243, ...   \n",
       "3           19    9518                                              [533]   \n",
       "4           19    9519                                              [539]   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "1                                     [James, Whyte]   \n",
       "2  [was, called, upon, to, preach, at, the, memor...   \n",
       "3                                               [he]   \n",
       "4                                               [he]   \n",
       "\n",
       "                                              _merge  \\\n",
       "0  [true negative, true negative, true negative, ...   \n",
       "1                    [true positive, false negative]   \n",
       "2  [true negative, true negative, true negative, ...   \n",
       "3                                    [true negative]   \n",
       "4                                    [true negative]   \n",
       "\n",
       "                              label_pers_o_predicted  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1                                     [Masculine, O]   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3                                                [O]   \n",
       "4                                                [O]   \n",
       "\n",
       "                               label_pers_o_expected  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1                             [Masculine, Masculine]  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3                                                [O]  \n",
       "4                                                [O]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso_ann = pred_perso_ann.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_perso_ann = utils.implodeDataFrame(pred_perso_ann, [\"sentence_id\", \"ann_id\"])\n",
    "pred_perso_ann = pred_perso_ann.reset_index()\n",
    "pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the agreements and disagreements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_types_perso, agmt_labels_perso = utils1.getAnnotationAgreement(pred_perso_ann, \"label_pers_o_predicted\", \"label_pers_o_expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>_merge</th>\n",
       "      <th>label_pers_o_predicted</th>\n",
       "      <th>label_pers_o_expected</th>\n",
       "      <th>annotation_agreement</th>\n",
       "      <th>agreement_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>false positive</td>\n",
       "      <td>Occupation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>14387</td>\n",
       "      <td>[233, 234]</td>\n",
       "      <td>[James, Whyte]</td>\n",
       "      <td>[true positive, false negative]</td>\n",
       "      <td>[Masculine, O]</td>\n",
       "      <td>[Masculine, Masculine]</td>\n",
       "      <td>true positive</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>99999</td>\n",
       "      <td>[235, 236, 237, 238, 239, 240, 241, 242, 243, ...</td>\n",
       "      <td>[was, called, upon, to, preach, at, the, memor...</td>\n",
       "      <td>[true negative, true negative, true negative, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>true negative</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>9518</td>\n",
       "      <td>[533]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>true negative</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>9519</td>\n",
       "      <td>[539]</td>\n",
       "      <td>[he]</td>\n",
       "      <td>[true negative]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>true negative</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  ann_id                                           token_id  \\\n",
       "0            2   99999  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "1            8   14387                                         [233, 234]   \n",
       "2            8   99999  [235, 236, 237, 238, 239, 240, 241, 242, 243, ...   \n",
       "3           19    9518                                              [533]   \n",
       "4           19    9519                                              [539]   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "1                                     [James, Whyte]   \n",
       "2  [was, called, upon, to, preach, at, the, memor...   \n",
       "3                                               [he]   \n",
       "4                                               [he]   \n",
       "\n",
       "                                              _merge  \\\n",
       "0  [true negative, true negative, true negative, ...   \n",
       "1                    [true positive, false negative]   \n",
       "2  [true negative, true negative, true negative, ...   \n",
       "3                                    [true negative]   \n",
       "4                                    [true negative]   \n",
       "\n",
       "                              label_pers_o_predicted  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1                                     [Masculine, O]   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3                                                [O]   \n",
       "4                                                [O]   \n",
       "\n",
       "                               label_pers_o_expected annotation_agreement  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       false positive   \n",
       "1                             [Masculine, Masculine]        true positive   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...        true negative   \n",
       "3                                                [O]        true negative   \n",
       "4                                                [O]        true negative   \n",
       "\n",
       "  agreement_label  \n",
       "0      Occupation  \n",
       "1       Masculine  \n",
       "2               O  \n",
       "3               O  \n",
       "4               O  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"annotation_agreement\", agmt_types_perso)\n",
    "pred_perso_ann.insert(len(pred_perso_ann.columns), \"agreement_label\", agmt_labels_perso)\n",
    "pred_perso_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>false negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>false positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>3413</td>\n",
       "      <td>6556</td>\n",
       "      <td>2578</td>\n",
       "      <td>0.717758</td>\n",
       "      <td>0.657639</td>\n",
       "      <td>0.686384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person Name</td>\n",
       "      <td>2750</td>\n",
       "      <td>5799</td>\n",
       "      <td>2169</td>\n",
       "      <td>0.727786</td>\n",
       "      <td>0.678325</td>\n",
       "      <td>0.702186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1915</td>\n",
       "      <td>2752</td>\n",
       "      <td>1114</td>\n",
       "      <td>0.711847</td>\n",
       "      <td>0.589672</td>\n",
       "      <td>0.645025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>146</td>\n",
       "      <td>842</td>\n",
       "      <td>449</td>\n",
       "      <td>0.652208</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.738921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>689</td>\n",
       "      <td>2205</td>\n",
       "      <td>606</td>\n",
       "      <td>0.784418</td>\n",
       "      <td>0.761921</td>\n",
       "      <td>0.773006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>663</td>\n",
       "      <td>757</td>\n",
       "      <td>409</td>\n",
       "      <td>0.649228</td>\n",
       "      <td>0.533099</td>\n",
       "      <td>0.585460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels  false negative  true positive  false positive  precision  \\\n",
       "0          all            3413           6556            2578   0.717758   \n",
       "0  Person Name            2750           5799            2169   0.727786   \n",
       "0      Unknown            1915           2752            1114   0.711847   \n",
       "0     Feminine             146            842             449   0.652208   \n",
       "0    Masculine             689           2205             606   0.784418   \n",
       "0   Occupation             663            757             409   0.649228   \n",
       "\n",
       "     recall       f_1  \n",
       "0  0.657639  0.686384  \n",
       "0  0.678325  0.702186  \n",
       "0  0.589672  0.645025  \n",
       "0  0.852227  0.738921  \n",
       "0  0.761921  0.773006  \n",
       "0  0.533099  0.585460  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_perso_all = utils1.getAnnotationAgreementMetrics(pred_perso_ann, \"all\")\n",
    "metrics_perso_pn = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[~(pred_perso_ann.agreement_label.isin([\"Occupation\",\"O\"]))], \"Person Name\")\n",
    "metrics_perso_unk = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Unknown\"], \"Unknown\")\n",
    "metrics_perso_fem = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Feminine\"], \"Feminine\")\n",
    "metrics_perso_mas = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Masculine\"], \"Masculine\")\n",
    "metrics_perso_occ = utils1.getAnnotationAgreementMetrics(pred_perso_ann.loc[pred_perso_ann.agreement_label == \"Occupation\"], \"Occupation\")\n",
    "metrics_perso = pd.concat([metrics_perso_all, metrics_perso_pn, metrics_perso_unk, metrics_perso_fem, metrics_perso_mas, metrics_perso_occ])\n",
    "metrics_perso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_perso.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_nolingfeatures_annot_agmt.csv\".format(a=a, d=d, c=category)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loose Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the manual annotation evaluation, we want to evaluate the predictions more loosely, considering overlapping text spans in addition to exactly matching text spans.\n",
    "\n",
    "#### Token Agreement\n",
    "\n",
    "First, generalize the tokens' IOB tags to the label, and calculate agreement scores for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_labels = pred_perso.copy()\n",
    "pred_perso_labels = pred_perso_labels.drop(columns=[\"_merge\"])\n",
    "tag_exp = list(pred_perso_labels[\"tag_{}_expected\".format(category)])\n",
    "tag_pred = list(pred_perso_labels[\"tag_{}_predicted\".format(category)])\n",
    "label_exp = [[tag if tag == \"O\" else tag[2:] for tag in tag_exp_list] for tag_exp_list in tag_exp]\n",
    "label_pred = [tag if tag == \"O\" else tag[2:] for tag in tag_pred]\n",
    "pred_perso_labels = pred_perso_labels.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_perso_labels.insert(len(pred_perso_labels.columns), \"label_{}_expected\".format(category), label_exp)\n",
    "pred_perso_labels.insert(len(pred_perso_labels.columns), \"label_{}_predicted\".format(category), label_pred)\n",
    "# pred_pers_labels.loc[pred_pers_labels.label_personname_predicted == \"Feminine\"].head()  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the agreement metrics at the label level for each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>2865</td>\n",
       "      <td>2614</td>\n",
       "      <td>4094</td>\n",
       "      <td>0.610316</td>\n",
       "      <td>0.588303</td>\n",
       "      <td>0.599107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>226</td>\n",
       "      <td>849</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.544528</td>\n",
       "      <td>0.817889</td>\n",
       "      <td>0.653784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>806</td>\n",
       "      <td>1120</td>\n",
       "      <td>1816</td>\n",
       "      <td>0.618529</td>\n",
       "      <td>0.692601</td>\n",
       "      <td>0.653472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>1094</td>\n",
       "      <td>901</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.577986</td>\n",
       "      <td>0.530069</td>\n",
       "      <td>0.552991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0     Unknown            2865            2614           4094   0.610316   \n",
       "0    Feminine             226             849           1015   0.544528   \n",
       "0   Masculine             806            1120           1816   0.618529   \n",
       "0  Occupation            1094             901           1234   0.577986   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.588303  0.599107  \n",
       "0  0.817889  0.653784  \n",
       "0  0.692601  0.653472  \n",
       "0  0.530069  0.552991  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['Unknown', 'Feminine', 'Masculine', 'Occupation']\n",
    "pred_perso_labels = utils.isPredictedInExpected(pred_perso_labels, \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), '_merge', 'O')\n",
    "\n",
    "pred_perso_stats = utils.getScoresByCatTags(\n",
    "    pred_perso_labels, \"_merge\", tags[0], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_perso_labels, \"_merge\", tags[i], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_perso_stats = pd.concat([pred_perso_stats, tag_stats])\n",
    "pred_perso_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine and save the performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_perso_stats.to_csv(\n",
    "    config.experiment1_agmt_path+\"crf_{a}_baseline_fastText{d}_{c}_nolingfeatures_loose_agmt.csv\".format(a=a, d=d, c=category)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3, Model 1\n",
    "\n",
    "#### Model Setup\n",
    "\n",
    "Run models in the following order, using their output labels as features for the next model:\n",
    "\n",
    "1. Multiclass Person Name + Occupation Sequence Classifier\n",
    "\n",
    "2. Multilabel Stereotype + Omission Document Classifier\n",
    "\n",
    "***\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/experiment_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/experiment3/`\n",
    "* Word Embeddings\n",
    "    * Custom fastText (word2vec with subwords) embeddings of 100 dimensions trained on the CRC Archives catalog's descriptive metadata (harvested October 2020)\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "[I.](#i) Person Name + Occupation Sequence Classifier\n",
    "* [Preprocessing](#prep)\n",
    "* [Training & Prediction](#tp)\n",
    "* [Evaluation](#eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, utils1, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For preprocessing\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "\n",
    "# For multilabel token classification\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# For multiclass sequence classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For saving model\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resources for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.experiment_input_path).mkdir(parents=True, exist_ok=True)    # For train, devtest, and blind test data\n",
    "# Path(config.experiment1_output_path).mkdir(parents=True, exist_ok=True)  # For predictions\n",
    "# Path(config.experiment1_agmt_path).mkdir(parents=True, exist_ok=True)    # For agreement metrics\n",
    "\n",
    "predictions_dir = config.experiment3_path+\"5fold/output/\"     # For predictions\n",
    "Path(predictions_dir).mkdir(parents=True, exist_ok=True)\n",
    "agreement_dir = config.experiment3_path+\"5fold/agreement/\"    # For agreement metrics\n",
    "Path(agreement_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# predictions_dir = config.experiment3_path+\"5fold_withdescid/output/\"     # For predictions\n",
    "# Path(predictions_dir).mkdir(parents=True, exist_ok=True)\n",
    "# agreement_dir = config.experiment3_path+\"5fold_withdescid/agreement/\"    # For agreement metrics\n",
    "# Path(agreement_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2:\n",
    "pers_o_label_subset = [\"B-Unknown\", \"I-Unknown\", \"B-Feminine\", \"I-Feminine\", \"B-Masculine\", \"I-Masculine\", \"B-Occupation\", \"I-Occupation\"]\n",
    "# Model 2.1:\n",
    "# pers_label_subset = [\"B-Unknown\", \"I-Unknown\", \"B-Feminine\", \"I-Feminine\", \"B-Masculine\", \"I-Masculine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_o_label_tags = {\n",
    "    \"Unknown\": [\"B-Unknown\", \"I-Unknown\"], \"Feminine\": [\"B-Feminine\", \"I-Feminine\"], \"Masculine\": [\"B-Masculine\", \"I-Masculine\"],\n",
    "     \"Occupation\": [\"B-Occupation\", \"I-Occupation\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100  # dimensions of word embeddings (should match utils1.py)\n",
    "target_labels = \"pers_o\" #_withdescid\"  # for file names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Person Name + Occupation Labels\n",
    "\n",
    "Train a multiclass sequence classifier, using Conditional Random Field with Adaptive Regularization of Weight Vectors (AROW), on the Person Name and Occupation labels.\n",
    "\n",
    "Multiclass is a suitable setup for these labels because they are mutually exclusive (no one token should have more than one of these labels).  The sequence classifier with AROW was the highest performing for past algorithm experiments with sequence classifiers for Person Name and Occupation labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The devtest data subset from the model in step 1 will be the train data subset in this step, with the predicted Linguistic labels as features passed into this second model.  The train data subset from the first model will be the devtest data subset for this second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>(0, 10)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>(10, 11)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>AA5</td>\n",
       "      <td>(12, 15)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Identifier</td>\n",
       "      <td>split4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>split2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id       token token_offsets  \\\n",
       "0               0            0   99999         0  Identifier       (0, 10)   \n",
       "1               0            0   99999         1           :      (10, 11)   \n",
       "2               0            0   99999         2         AA5      (12, 15)   \n",
       "3               1            1   99999         3       Title      (17, 22)   \n",
       "4               1            1   99999         4           :      (22, 23)   \n",
       "\n",
       "  pos tag       field    fold  \n",
       "0  NN   O  Identifier  split4  \n",
       "1   :   O  Identifier  split4  \n",
       "2  NN   O  Identifier  split4  \n",
       "3  NN   O       Title  split2  \n",
       "4   :   O       Title  split2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For this experiment, we'll repeatedly train models on different 80% selections of \n",
    "### data and predict on the remaining 20% split, for a modified 5-fold cross-validation approach.\n",
    "perso_df = pd.read_csv(config.tokc_path+\"experiment_input/token_5fold.csv\", index_col=0)\n",
    "# Make sure only Person Name and Occupation tags are considered\n",
    "perso_df = utils1.selectDataForLabels(perso_df, \"tag\", pers_o_label_subset) #pers_label_subset)\n",
    "perso_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-Unknown' 'B-Masculine' 'I-Unknown' 'I-Masculine' 'B-Occupation'\n",
      " 'I-Occupation' 'B-Feminine' 'I-Feminine']\n"
     ]
    }
   ],
   "source": [
    "print(perso_df.tag.unique())  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the label associated with each annotation for future evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[58341, 58342, 58343, 58344]</td>\n",
       "      <td>[B-Feminine, I-Feminine, I-Feminine, I-Feminine]</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[19836, 19837, 19838, 19839]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[28713, 28714]</td>\n",
       "      <td>[B-Unknown, I-Unknown]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[28738, 28739, 28740, 28741]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[28790, 28791, 28792]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            token_id  \\\n",
       "ann_id                                 \n",
       "7       [58341, 58342, 58343, 58344]   \n",
       "14      [19836, 19837, 19838, 19839]   \n",
       "15                    [28713, 28714]   \n",
       "16      [28738, 28739, 28740, 28741]   \n",
       "17             [28790, 28791, 28792]   \n",
       "\n",
       "                                                     tag expected_label  \n",
       "ann_id                                                                   \n",
       "7       [B-Feminine, I-Feminine, I-Feminine, I-Feminine]       Feminine  \n",
       "14          [B-Unknown, I-Unknown, I-Unknown, I-Unknown]        Unknown  \n",
       "15                                [B-Unknown, I-Unknown]        Unknown  \n",
       "16          [B-Unknown, I-Unknown, I-Unknown, I-Unknown]        Unknown  \n",
       "17                     [B-Unknown, I-Unknown, I-Unknown]        Unknown  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_ann = pd.read_csv(config.tokc_path+\"experiment_input/token_5fold.csv\", usecols=[\"ann_id\", \"token_id\", \"tag\"])\n",
    "df_by_ann = df_by_ann.drop_duplicates()\n",
    "df_by_ann = utils.implodeDataFrame(df_by_ann, [\"ann_id\"])\n",
    "tags_col = list(df_by_ann.tag)\n",
    "labels = [[tag[2:] if tag != \"O\" else tag for tag in tags] for tags in tags_col]\n",
    "labels = [label_list[0] for label_list in labels]\n",
    "df_by_ann.insert(len(df_by_ann.columns), \"expected_label\", labels)\n",
    "perso_labels = list(pers_o_label_tags.keys())\n",
    "df_by_ann = df_by_ann.loc[df_by_ann.expected_label.isin(perso_labels)]\n",
    "df_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the five groups of training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = \"fold\"\n",
    "splits = perso_df[split_col].unique()\n",
    "splits.sort()\n",
    "train0, test0 = list(splits[:4]), splits[4]\n",
    "train1, test1 = list(splits[1:]), splits[0]\n",
    "train2, test2 = list(splits[2:])+[splits[0]], splits[1]\n",
    "train3, test3 = list(splits[3:])+list(splits[:2]), splits[2]\n",
    "train4, test4 = [splits[4]]+list(splits[:3]), splits[3]\n",
    "runs = [(train0, test0), (train1, test1), (train2, test2), (train3, test3), (train4, test4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = perso_df.drop(columns=[\"ann_id\", \"token_offsets\", \"field\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token_groups = utils.implodeDataFrame(df, ['token_id', 'description_id', 'sentence_id', 'token', 'fold'])\n",
    "df_token_groups = df_token_groups.reset_index()\n",
    "# df_token_groups.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that every row's tags are not duplicated, and that if a row has a `B-` or `I-` tag (or category name), it doesn't also have an `O` tag, and sort the order of the tags so that any `B` tag will be selected as the expected tag for training before an \"I\" tag.  Additionally, if multiple labels are present and one is `Unknown`, put the `Unknown` tag first so that it will be selected as the expected tag for training (as the data sample output above illustrates, and as Error Analysis of document classifiers for Person Names showed, people's names should have been annotated as `Unknown` more than they actually were)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(df_token_groups[\"tag\"])\n",
    "new_tags = []\n",
    "for tag_list in tags:\n",
    "    unique_tags = list(set(tag_list))\n",
    "    if (len(unique_tags) > 1) and (\"O\" in unique_tags):\n",
    "        unique_tags.remove(\"O\")\n",
    "    unique_tags.sort()\n",
    "    # Put any Unknown tags at the start of the list, so they'll be selected\n",
    "    # as a feature for training over Masculine or Feminine tags\n",
    "    if len(unique_tags) > 1:\n",
    "        if \"I-Unknown\" in unique_tags:\n",
    "            unique_tags.remove(\"I-Unknown\")\n",
    "            unique_tags = [\"I-Unknown\"] + unique_tags\n",
    "        if \"B-Unknown\" in unique_tags:\n",
    "            unique_tags.remove(\"B-Unknown\")\n",
    "            unique_tags = [\"B-Unknown\"] + unique_tags\n",
    "    new_tags += [unique_tags]\n",
    "df_token_groups[\"tag\"] = new_tags\n",
    "# df_token_groups.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>token_id</th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>split4</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>split2</td>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[Title, :, Papers, of, The, Very, Rev, Prof, J...</td>\n",
       "      <td>[[O], [O], [O], [O], [B-Unknown, B-Masculine],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>split1</td>\n",
       "      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>split2</td>\n",
       "      <td>[109, 110, 111, 112, 113, 114, 115, 116, 117, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[Biographical, /, Historical, :, Professor, Ja...</td>\n",
       "      <td>[[O], [O], [O], [O], [B-Masculine], [I-Masculi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>split4</td>\n",
       "      <td>[134, 135, 136, 137, 138, 139, 140, 141, 142, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[He, was, educated, at, Daniel, Stewart, 's, C...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id    fold                                           token_id  \\\n",
       "0            0  split4                                          [0, 1, 2]   \n",
       "1            1  split2      [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]   \n",
       "2            2  split1  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2...   \n",
       "3            3  split2  [109, 110, 111, 112, 113, 114, 115, 116, 117, ...   \n",
       "4            4  split4  [134, 135, 136, 137, 138, 139, 140, 141, 142, ...   \n",
       "\n",
       "                                      description_id  \\\n",
       "0                                          [0, 0, 0]   \n",
       "1            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "2  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0                               [Identifier, :, AA5]   \n",
       "1  [Title, :, Papers, of, The, Very, Rev, Prof, J...   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [Biographical, /, Historical, :, Professor, Ja...   \n",
       "4  [He, was, educated, at, Daniel, Stewart, 's, C...   \n",
       "\n",
       "                                                 tag  \n",
       "0                                    [[O], [O], [O]]  \n",
       "1  [[O], [O], [O], [O], [B-Unknown, B-Masculine],...  \n",
       "2  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "3  [[O], [O], [O], [O], [B-Masculine], [I-Masculi...  \n",
       "4  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = utils.implodeDataFrame(df_token_groups, ['sentence_id', 'fold'])\n",
    "df_grouped = df_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_grouped = df_grouped.reset_index()\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42030, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tp\"></a>\n",
    "#### Training & Prediction\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"arow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: ['split4', 'split0', 'split1', 'split2']\n",
      "Predicting on: split3\n",
      "Predictions for split3 saved!\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "\n",
    "# Specify the run one at a time (with for loop, kernel dies; also, \n",
    "# crf_suite for sklearn's models will keep learning from previous runs if not restarted)\n",
    "run = runs[4]  # 0, 1, 2, 3\n",
    "\n",
    "# Get the train (80%) and test (20%) subsets of data\n",
    "train_splits, test_split = run[0], run[1]\n",
    "print(\"Training on:\", train_splits)\n",
    "train_df = df_grouped.loc[df_grouped[split_col].isin(train_splits)]\n",
    "dev_df = df_grouped.loc[df_grouped[split_col] == test_split]\n",
    "\n",
    "# Zip feature and target columns together so each \n",
    "# sentence item is a tuple: `(TOKEN, TAG_LIST)`\n",
    "train_sentences = utils1.zip1FeatureAndTarget(train_df, \"tag\")  #utils1.zip2FeaturesAndTarget(train_df, \"tag\", \"sentence\", \"description_id\")\n",
    "dev_sentences = utils1.zip1FeatureAndTarget(dev_df, \"tag\")      #utils1.zip2FeaturesAndTarget(dev_df, \"tag\", \"sentence\", \"description_id\")  #\n",
    "# Extract features\n",
    "X_train = [utils1.extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [utils1.extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Extract targets\n",
    "y_train = [utils1.extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [utils1.extractSentenceTargets(sentence) for sentence in dev_sentences]\n",
    "\n",
    "# Train a classification model\n",
    "clf_pers = sklearn_crfsuite.CRF(algorithm=a, variance=1, max_iterations=100, all_possible_transitions=True)\n",
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_pers.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Predict with the trained model\n",
    "print(\"Predicting on:\", test_split)\n",
    "predictions = clf_pers.predict(X_dev)\n",
    "dev_df = dev_df.rename(columns={\"tag\":\"tag_{}_expected\".format(target_labels)})\n",
    "dev_df.insert(len(dev_df.columns), \"tag_{}_predicted\".format(target_labels), predictions)\n",
    "dev_df = dev_df.set_index([\"sentence_id\", \"fold\"])\n",
    "dev_df_exploded = dev_df.explode(list(dev_df.columns))\n",
    "\n",
    "if pred_df.shape[0] > 0:\n",
    "    pred_df = pd.concat([pred_df, dev_df_exploded])\n",
    "else:\n",
    "    pred_df = dev_df_exploded\n",
    "\n",
    "assert pred_df.loc[pred_df[\"tag_{}_predicted\".format(target_labels)].isna()].shape[0] == 0, \"Any NaN values should be replaced with 'O'\"\n",
    "\n",
    "filename = \"crf_{a}_{t}_baseline_fastText{d}_nolingfeatures_predictions_{s}.csv\".format(a=a, t=target_labels, d=d, s=test_split)\n",
    "pred_df.to_csv(predictions_dir+filename)\n",
    "\n",
    "print(\"Predictions for {} saved!\".format(test_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753521, 6)\n"
     ]
    }
   ],
   "source": [
    "a = \"arow\"\n",
    "pred_df0 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_nolingfeatures_predictions_split0.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df1 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_nolingfeatures_predictions_split1.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df2 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_nolingfeatures_predictions_split2.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df3 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_nolingfeatures_predictions_split3.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_df4 = pd.read_csv(predictions_dir+\"crf_{a}_{t}_baseline_fastText{d}_nolingfeatures_predictions_split4.csv\".format(a=a, t=target_labels, d=d), index_col=0)\n",
    "pred_perso = pd.concat([pred_df0, pred_df1, pred_df2, pred_df3, pred_df4])\n",
    "print(pred_perso.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>token_id</th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>James</td>\n",
       "      <td>[B-Masculine]</td>\n",
       "      <td>B-Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>[I-Masculine]</td>\n",
       "      <td>I-Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>was</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>236</td>\n",
       "      <td>3</td>\n",
       "      <td>called</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>upon</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id    fold  token_id  description_id sentence tag_pers_o_expected  \\\n",
       "0            8  split0       233               3    James       [B-Masculine]   \n",
       "1            8  split0       234               3    Whyte       [I-Masculine]   \n",
       "2            8  split0       235               3      was                 [O]   \n",
       "3            8  split0       236               3   called                 [O]   \n",
       "4            8  split0       237               3     upon                 [O]   \n",
       "\n",
       "  tag_pers_o_predicted  \n",
       "0          B-Masculine  \n",
       "1          I-Masculine  \n",
       "2                    O  \n",
       "3                    O  \n",
       "4                    O  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_perso = pred_perso.reset_index()\n",
    "pred_perso = utils.getColumnValuesAsLists(pred_perso, \"tag_{}_expected\".format(target_labels))\n",
    "pred_perso.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine', 'I-Feminine', 'B-Masculine', 'I-Masculine', 'B-Unknown', 'I-Unknown', 'B-Occupation', 'I-Occupation']\n"
     ]
    }
   ],
   "source": [
    "targets = [\"B-Feminine\", \"I-Feminine\", \"B-Masculine\", \"I-Masculine\", \"B-Unknown\", \"I-Unknown\", \"B-Occupation\", \"I-Occupation\"]\n",
    "# targets = list(clf_pers.classes_)\n",
    "# targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include only the first value from the expected tags column, as that's what was used in training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_col = \"tag_pers_o_expected\"\n",
    "pred_col = \"tag_pers_o_predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pred_lists = list(pred_perso[exp_col])\n",
    "new_exp_pred_col = [exp_pred_list[0] for exp_pred_list in exp_pred_lists]\n",
    "pred_df = pred_perso.drop(columns=[exp_col])\n",
    "pred_df.insert(len(pred_df.columns)-1, exp_col, new_exp_pred_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>token_id</th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>James</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>I-Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>236</td>\n",
       "      <td>3</td>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>upon</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id    fold  token_id  description_id sentence tag_pers_o_expected  \\\n",
       "0            8  split0       233               3    James         B-Masculine   \n",
       "1            8  split0       234               3    Whyte         I-Masculine   \n",
       "2            8  split0       235               3      was                   O   \n",
       "3            8  split0       236               3   called                   O   \n",
       "4            8  split0       237               3     upon                   O   \n",
       "\n",
       "  tag_pers_o_predicted  \n",
       "0          B-Masculine  \n",
       "1          I-Masculine  \n",
       "2                    O  \n",
       "3                    O  \n",
       "4                    O  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[exp_col].fillna(\"O\")\n",
    "pred_df[pred_col].fillna(\"O\")\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the concatenated prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = target_labels\n",
    "pred_df.to_csv(predictions_dir+\"crf_{a}_{c}_baseline_fastText{d}_predictions.csv\".format(a=a, c=category, d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models/experiment3/\"\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "filename = model_dir+\"crf_arow_F-fastText100_T-pers-o.joblib\"\n",
    "dump(clf_pers, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "### Evaluation\n",
    "#### Evaluate: Strict, Each Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the development data's test, the predicted labels will be deemed incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics for each category of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.rename(columns={\"sentence\":\"token\"})\n",
    "df_pred = pred_df.drop(columns=[exp_col])\n",
    "df_exp = pred_df.drop(columns=[pred_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>fold</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>233</td>\n",
       "      <td>James</td>\n",
       "      <td>split0</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>234</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>split0</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>was</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>236</td>\n",
       "      <td>called</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>237</td>\n",
       "      <td>upon</td>\n",
       "      <td>split0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  token_id   token    fold tag_pers_o_expected  \\\n",
       "0               3            8       233   James  split0         B-Masculine   \n",
       "1               3            8       234   Whyte  split0         I-Masculine   \n",
       "2               3            8       235     was  split0                   O   \n",
       "3               3            8       236  called  split0                   O   \n",
       "4               3            8       237    upon  split0                   O   \n",
       "\n",
       "  tag_pers_o_predicted         _merge  \n",
       "0          B-Masculine  true positive  \n",
       "1          I-Masculine  true positive  \n",
       "2                    O  true negative  \n",
       "3                    O  true negative  \n",
       "4                    O  true negative  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_on =  [\"description_id\", \"sentence_id\", \"token_id\", \"token\", \"fold\"]\n",
    "df_agmt = utils.makeEvaluationDataFrame(\n",
    "    df_exp, \n",
    "    df_pred, \n",
    "    join_on+[exp_col],\n",
    "    join_on+[pred_col],\n",
    "    join_on+[exp_col, pred_col, \"_merge\"], \n",
    "    pred_col,\n",
    "    exp_col,\n",
    "    \"O\"\n",
    ")\n",
    "df_agmt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(781922, 8)\n",
      "(753521, 6)\n",
      "(753521, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_agmt.shape)\n",
    "print(df_pred.shape)\n",
    "print(df_exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true negative     724565\n",
       "true positive      21782\n",
       "false negative     19572\n",
       "false positive     16003\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agmt._merge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the agreement data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_{a}_{t}_baseline_fastText{d}_nolingfeatures_strict_evaluation.csv\".format(a=a, t=target_labels, d=d)\n",
    "df_agmt.to_csv(predictions_dir+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the true positives, false positives, false negatives, precision, recall, and F1 metrics for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'B-Feminine', 'I-Feminine', 'B-Masculine', 'I-Masculine', 'B-Occupation', 'I-Occupation']\n"
     ]
    }
   ],
   "source": [
    "labels_grouped = list(pers_o_label_tags.values())\n",
    "labels = []\n",
    "for label_group in labels_grouped:\n",
    "    for tag in label_group:\n",
    "        labels += [tag] \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>4057.0</td>\n",
       "      <td>3360.0</td>\n",
       "      <td>5407.0</td>\n",
       "      <td>0.616745</td>\n",
       "      <td>0.571323</td>\n",
       "      <td>0.593165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>6509.0</td>\n",
       "      <td>4864.0</td>\n",
       "      <td>8434.0</td>\n",
       "      <td>0.634231</td>\n",
       "      <td>0.564411</td>\n",
       "      <td>0.597288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>372.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>0.571555</td>\n",
       "      <td>0.634936</td>\n",
       "      <td>0.601581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>874.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>0.626697</td>\n",
       "      <td>0.613103</td>\n",
       "      <td>0.619825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>0.429624</td>\n",
       "      <td>0.381919</td>\n",
       "      <td>0.404370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>2744.0</td>\n",
       "      <td>1662.0</td>\n",
       "      <td>0.377213</td>\n",
       "      <td>0.389045</td>\n",
       "      <td>0.383038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>0.625701</td>\n",
       "      <td>0.537853</td>\n",
       "      <td>0.578460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.441536</td>\n",
       "      <td>0.489835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label  false negative  false positive  true positive  precision  \\\n",
       "0     B-Unknown          4057.0          3360.0         5407.0   0.616745   \n",
       "0     I-Unknown          6509.0          4864.0         8434.0   0.634231   \n",
       "0    B-Feminine           372.0           485.0          647.0   0.571555   \n",
       "0    I-Feminine           874.0           825.0         1385.0   0.626697   \n",
       "0   B-Masculine          1887.0          1548.0         1166.0   0.429624   \n",
       "0   I-Masculine          2610.0          2744.0         1662.0   0.377213   \n",
       "0  B-Occupation          1343.0           935.0         1563.0   0.625701   \n",
       "0  I-Occupation          1920.0          1242.0         1518.0   0.550000   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.571323  0.593165  \n",
       "0  0.564411  0.597288  \n",
       "0  0.634936  0.601581  \n",
       "0  0.613103  0.619825  \n",
       "0  0.381919  0.404370  \n",
       "0  0.389045  0.383038  \n",
       "0  0.537853  0.578460  \n",
       "0  0.441536  0.489835  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([df_agmt.loc[df_agmt[exp_col] == label], df_agmt.loc[df_agmt[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores.to_csv(agreement_dir+\"crf_{a}_baseline_fastText{d}_{c}_nolingfeatures_strict_agmt.csv\".format(a=a, c=category, d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Annotation Agreement\n",
    "\n",
    "Calculate agreement at the annotation level, so if the model labels any word correctly from a manually annotated text span, that annotation is recorded as being correctly labeled (`true positive`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753521, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>token_id</th>\n",
       "      <th>description_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>James</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>236</td>\n",
       "      <td>3</td>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>upon</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id    fold  token_id  description_id   token tag_pers_o_expected  \\\n",
       "0            8  split0       233               3   James         B-Masculine   \n",
       "1            8  split0       234               3   Whyte         I-Masculine   \n",
       "2            8  split0       235               3     was                   O   \n",
       "3            8  split0       236               3  called                   O   \n",
       "4            8  split0       237               3    upon                   O   \n",
       "\n",
       "  tag_pers_o_predicted predicted_label  \n",
       "0          B-Masculine       Masculine  \n",
       "1          I-Masculine       Masculine  \n",
       "2                    O               O  \n",
       "3                    O               O  \n",
       "4                    O               O  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generalize tags to labels for annotation agreement\n",
    "pred_col, exp_col = \"predicted_label\", \"expected_label\"\n",
    "category = \"pers_o\"\n",
    "pred_labels = list(pred_df[\"tag_{}_predicted\".format(category)])\n",
    "pred_labels = [label if label == \"O\" else label[2:] for label in pred_labels]\n",
    "pred_df.insert(len(pred_df.columns), pred_col, pred_labels)\n",
    "print(pred_df.shape)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>58341</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>58342</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ann_id token_id expected_label\n",
       "0       7    58341       Feminine\n",
       "1       7    58342       Feminine"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_ann = df_by_ann.drop(columns=[\"tag\"])\n",
    "df_by_ann = df_by_ann.explode([\"token_id\"]).reset_index()\n",
    "df_by_ann.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763670, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>token_id</th>\n",
       "      <th>description_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>expected_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>James</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>14387.0</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>Whyte</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>14387.0</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>236</td>\n",
       "      <td>3</td>\n",
       "      <td>called</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>split0</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>upon</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>99999.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id    fold  token_id  description_id   token tag_pers_o_expected  \\\n",
       "0            8  split0       233               3   James         B-Masculine   \n",
       "1            8  split0       234               3   Whyte         I-Masculine   \n",
       "2            8  split0       235               3     was                   O   \n",
       "3            8  split0       236               3  called                   O   \n",
       "4            8  split0       237               3    upon                   O   \n",
       "\n",
       "  tag_pers_o_predicted predicted_label   ann_id expected_label  \n",
       "0          B-Masculine       Masculine  14387.0      Masculine  \n",
       "1          I-Masculine       Masculine  14387.0      Masculine  \n",
       "2                    O               O  99999.0                 \n",
       "3                    O               O  99999.0                 \n",
       "4                    O               O  99999.0                 "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_joined = pred_df.join(df_by_ann.set_index(\"token_id\"), on=\"token_id\", how=\"outer\")\n",
    "print(eval_df_joined.shape)\n",
    "eval_df_joined[\"ann_id\"] = eval_df_joined[\"ann_id\"].fillna(99999)\n",
    "eval_df_joined[exp_col] = eval_df_joined[exp_col].fillna(\"\")\n",
    "eval_df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63277, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split4</td>\n",
       "      <td></td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...</td>\n",
       "      <td>[O, Unknown, Unknown, Unknown, Unknown, Unknown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24275.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...</td>\n",
       "      <td>[O, Unknown, Unknown, Unknown, Unknown, Unknown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26233.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[9, 10, 11, 12]</td>\n",
       "      <td>[Rev, Prof, James, Whyte]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[I-Unknown, B-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[Unknown, Unknown, Unknown, Unknown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split2</td>\n",
       "      <td></td>\n",
       "      <td>[3, 4, 5, 6, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, (, 1920-2005, )]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, I-Unknown, I-Unknown, O]</td>\n",
       "      <td>[O, O, O, O, Unknown, Unknown, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id   ann_id    fold expected_label  \\\n",
       "0               0            0  99999.0  split4                  \n",
       "1               1            1  14384.0  split2        Unknown   \n",
       "2               1            1  24275.0  split2      Masculine   \n",
       "3               1            1  26233.0  split2        Unknown   \n",
       "4               1            1  99999.0  split2                  \n",
       "\n",
       "                   token_id                                    token  \\\n",
       "0                 [0, 1, 2]                     [Identifier, :, AA5]   \n",
       "1     [7, 8, 9, 10, 11, 12]     [The, Very, Rev, Prof, James, Whyte]   \n",
       "2     [7, 8, 9, 10, 11, 12]     [The, Very, Rev, Prof, James, Whyte]   \n",
       "3           [9, 10, 11, 12]                [Rev, Prof, James, Whyte]   \n",
       "4  [3, 4, 5, 6, 13, 14, 15]  [Title, :, Papers, of, (, 1920-2005, )]   \n",
       "\n",
       "                                 tag_pers_o_expected  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...   \n",
       "2  [B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...   \n",
       "3       [B-Unknown, I-Unknown, I-Unknown, I-Unknown]   \n",
       "4                              [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                tag_pers_o_predicted  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...   \n",
       "2  [O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...   \n",
       "3       [I-Unknown, B-Unknown, I-Unknown, I-Unknown]   \n",
       "4              [O, O, O, O, I-Unknown, I-Unknown, O]   \n",
       "\n",
       "                                    predicted_label  \n",
       "0                                         [O, O, O]  \n",
       "1  [O, Unknown, Unknown, Unknown, Unknown, Unknown]  \n",
       "2  [O, Unknown, Unknown, Unknown, Unknown, Unknown]  \n",
       "3              [Unknown, Unknown, Unknown, Unknown]  \n",
       "4                 [O, O, O, O, Unknown, Unknown, O]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_by_ann = utils.implodeDataFrame(eval_df_joined, [\"description_id\", \"sentence_id\", \"ann_id\", \"fold\", \"expected_label\"]).reset_index()\n",
    "print(eval_by_ann.shape)\n",
    "eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_pers_o_expected</th>\n",
       "      <th>tag_pers_o_predicted</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split4</td>\n",
       "      <td></td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[Identifier, :, AA5]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24275.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>Masculine</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>[The, Very, Rev, Prof, James, Whyte]</td>\n",
       "      <td>[B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...</td>\n",
       "      <td>[O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26233.0</td>\n",
       "      <td>split2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[9, 10, 11, 12]</td>\n",
       "      <td>[Rev, Prof, James, Whyte]</td>\n",
       "      <td>[B-Unknown, I-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>[I-Unknown, B-Unknown, I-Unknown, I-Unknown]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>split2</td>\n",
       "      <td></td>\n",
       "      <td>[3, 4, 5, 6, 13, 14, 15]</td>\n",
       "      <td>[Title, :, Papers, of, (, 1920-2005, )]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, I-Unknown, I-Unknown, O]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id   ann_id    fold expected_label  \\\n",
       "0               0            0  99999.0  split4                  \n",
       "1               1            1  14384.0  split2        Unknown   \n",
       "2               1            1  24275.0  split2      Masculine   \n",
       "3               1            1  26233.0  split2        Unknown   \n",
       "4               1            1  99999.0  split2                  \n",
       "\n",
       "                   token_id                                    token  \\\n",
       "0                 [0, 1, 2]                     [Identifier, :, AA5]   \n",
       "1     [7, 8, 9, 10, 11, 12]     [The, Very, Rev, Prof, James, Whyte]   \n",
       "2     [7, 8, 9, 10, 11, 12]     [The, Very, Rev, Prof, James, Whyte]   \n",
       "3           [9, 10, 11, 12]                [Rev, Prof, James, Whyte]   \n",
       "4  [3, 4, 5, 6, 13, 14, 15]  [Title, :, Papers, of, (, 1920-2005, )]   \n",
       "\n",
       "                                 tag_pers_o_expected  \\\n",
       "0                                          [O, O, O]   \n",
       "1  [B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...   \n",
       "2  [B-Unknown, I-Unknown, B-Unknown, I-Unknown, I...   \n",
       "3       [B-Unknown, I-Unknown, I-Unknown, I-Unknown]   \n",
       "4                              [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                tag_pers_o_predicted predicted_label  \n",
       "0                                          [O, O, O]             NaN  \n",
       "1  [O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...         Unknown  \n",
       "2  [O, I-Unknown, I-Unknown, B-Unknown, I-Unknown...         Unknown  \n",
       "3       [I-Unknown, B-Unknown, I-Unknown, I-Unknown]         Unknown  \n",
       "4              [O, O, O, O, I-Unknown, I-Unknown, O]         Unknown  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label_col = list(eval_by_ann[pred_col])\n",
    "unique_pred_label_col = [list(set(pred_labels)) for pred_labels in pred_label_col]\n",
    "new_pred_label_col = []\n",
    "for pred_labels in unique_pred_label_col:\n",
    "    if \"O\" in pred_labels:\n",
    "        pred_labels.remove(\"O\")\n",
    "    new_pred_label_col += [pred_labels]\n",
    "eval_by_ann = eval_by_ann.drop(columns=[pred_col])\n",
    "eval_by_ann.insert(len(eval_by_ann.columns), pred_col, new_pred_label_col)\n",
    "eval_by_ann = eval_by_ann.explode([pred_col])\n",
    "eval_by_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted labels to expected label for each annotation, where if a label was predicted when none was expected, agreement is a false positive; if a correct label was predicted (even if it's only on part of the annotation), agreement is a true positive; and if no label was predicted when a label was expected, agreement is a false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_col = \"expected_label\"\n",
    "pred_col = \"predicted_label\"\n",
    "df_pred = eval_by_ann.drop(columns=[exp_col, \"fold\", \"token_id\", \"token\", \"tag_pers_o_expected\", \"tag_pers_o_predicted\"])\n",
    "df_exp = eval_by_ann.drop(columns=[pred_col, \"fold\", \"token_id\", \"token\", \"tag_pers_o_expected\", \"tag_pers_o_predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>1082</td>\n",
       "      <td>2590</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65634</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>855</td>\n",
       "      <td>1097</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66267</th>\n",
       "      <td>1038</td>\n",
       "      <td>1485</td>\n",
       "      <td>15.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Feminine</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>1038</td>\n",
       "      <td>1485</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>O</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       description_id  sentence_id  ann_id expected_label predicted_label  \\\n",
       "6848             1082         2590     7.0       Feminine        Feminine   \n",
       "65634             855         1097    14.0              O        Feminine   \n",
       "2709              855         1097    14.0        Unknown               O   \n",
       "66267            1038         1485    15.0              O        Feminine   \n",
       "3709             1038         1485    15.0        Unknown               O   \n",
       "\n",
       "               _merge  \n",
       "6848    true positive  \n",
       "65634  false positive  \n",
       "2709   false negative  \n",
       "66267  false positive  \n",
       "3709   false negative  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_on =  [\"description_id\", \"sentence_id\", \"ann_id\"]\n",
    "join_on =  [\"description_id\", \"sentence_id\", \"ann_id\"]\n",
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    df_exp, \n",
    "    df_pred, \n",
    "    join_on+[exp_col], \n",
    "    join_on+[pred_col], \n",
    "    [\"description_id\", \"sentence_id\", \"ann_id\", \"expected_label\", \"predicted_label\", \"_merge\"], \n",
    "    exp_col, \n",
    "    pred_col, \n",
    "    \"O\"\n",
    ")\n",
    "eval_df = eval_df.fillna(\"O\")\n",
    "id_col = \"ann_id\"\n",
    "eval_df = eval_df.sort_values(by=[id_col, exp_col, pred_col])\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115201, 6)\n",
      "(63829, 4)\n",
      "(63829, 4)\n"
     ]
    }
   ],
   "source": [
    "eval_df = eval_df.drop_duplicates()\n",
    "print(eval_df.shape)\n",
    "print(df_pred.shape)\n",
    "print(df_exp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(predictions_dir+\"crf-{a}_{c}_baseline_fastText{d}_annot_evaluation.csv\".format(a=a, c=category, d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate annotation agreement metrics for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores = pd.DataFrame.from_dict({\n",
    "        \"label\":[], \"false negative\":[], \"false positive\":[],\n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>602.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>0.636311</td>\n",
       "      <td>0.645674</td>\n",
       "      <td>0.640958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>3708.0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>0.506128</td>\n",
       "      <td>0.343601</td>\n",
       "      <td>0.409321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>4952.0</td>\n",
       "      <td>7090.0</td>\n",
       "      <td>0.588773</td>\n",
       "      <td>0.635760</td>\n",
       "      <td>0.611365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>0.657418</td>\n",
       "      <td>0.599325</td>\n",
       "      <td>0.627029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  false negative  false positive  true positive  precision  \\\n",
       "0    Feminine           602.0           627.0         1097.0   0.636311   \n",
       "0   Masculine          3708.0          1894.0         1941.0   0.506128   \n",
       "0     Unknown          4062.0          4952.0         7090.0   0.588773   \n",
       "0  Occupation          1188.0           926.0         1777.0   0.657418   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.645674  0.640958  \n",
       "0  0.343601  0.409321  \n",
       "0  0.635760  0.611365  \n",
       "0  0.599325  0.627029  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Feminine', 'Masculine', 'Unknown', 'Occupation']\n",
    "for label in labels:\n",
    "    agmt_df = pd.concat([eval_df.loc[eval_df[exp_col] == label], eval_df.loc[eval_df[pred_col] == label]])\n",
    "    agmt_df = agmt_df.drop_duplicates() # True positives will have been duplicated in line above\n",
    "    tp = agmt_df.loc[agmt_df._merge == \"true positive\"].shape[0]\n",
    "    fp = agmt_df.loc[agmt_df._merge == \"false positive\"].shape[0]\n",
    "    fn = agmt_df.loc[agmt_df._merge == \"false negative\"].shape[0]\n",
    "    prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "    label_agmt = pd.DataFrame.from_dict({\n",
    "            \"label\":[label], \"false negative\":[fn], \"false positive\":[fp],\n",
    "             \"true positive\":[tp], \"precision\":[prec], \"recall\":[rec], \"f1\":[f1]\n",
    "        })\n",
    "    agmt_scores = pd.concat([agmt_scores, label_agmt])\n",
    "agmt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_scores.to_csv(agreement_dir+\"crf_{a}_baseline_fastText{d}_{c}_nolingfeatures_annot_agmt.csv\".format(a=a, d=d, c=category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

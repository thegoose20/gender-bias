{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Biased Token Classifiers\n",
    "\n",
    "### Target: Label Categories\n",
    "\n",
    "### Word Embeddings: GloVe\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: under directory `../data/token_clf_data/model_output`\n",
    "* Multilabel classification\n",
    "    * 3 categories of labels: Linguistic, Person Name, Contextual\n",
    "* Word Embeddings\n",
    "    * GloVe (trained on English Wikipedia dump)\n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "**[0.](#0) Preprocessing**\n",
    "\n",
    "**[1.](#1) Baseline Model**\n",
    "\n",
    "**[2.](#2) Hyperparameter Optimization**\n",
    "\n",
    "**[3.](#3) Error Analysis**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.stats\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay#, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate rows with all but the same annotation ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Label Categories\n",
    "\n",
    "Add the annotation label categories as a column of higher-level Inside-Outside-Beginning (IOB) tags so they can be used as targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = utils.addCategoryTagColumn(df_train)\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = utils.addCategoryTagColumn(df_dev)\n",
    "# df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that won't be used as features for the classifiers and remove any duplicate rows that remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"pos\", \"token\", \"tag_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[cols_to_keep]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev[cols_to_keep]\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns for each category so they can be used as three separate targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_cat_tags = [\"B-Linguistic\", \"I-Linguistic\"]\n",
    "df_train_ling = df_train.loc[df_train.tag_cat.isin(ling_cat_tags)]\n",
    "df_dev_ling = df_dev.loc[df_dev.tag_cat.isin(ling_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_cat_tags = [\"B-Person-Name\", \"I-Person-Name\"]\n",
    "df_train_pers = df_train.loc[df_train.tag_cat.isin(pers_cat_tags)]\n",
    "df_dev_pers = df_dev.loc[df_dev.tag_cat.isin(pers_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cat_tags = [\"B-Contextual\", \"I-Contextual\"]\n",
    "df_train_cont = df_train.loc[df_train.tag_cat.isin(cont_cat_tags)]\n",
    "df_dev_cont = df_dev.loc[df_dev.tag_cat.isin(cont_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.drop(columns=[\"tag_cat\"])).drop_duplicates()\n",
    "df_dev = (df_dev.drop(columns=[\"tag_cat\"])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"sentence_id\", \"token_id\", \"pos\", \"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.join(df_train_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train = df_train.join(df_train_pers.set_index(join_cols), on=join_cols, how=\"outer\", lsuffix=\"\", rsuffix=\"_personname\")\n",
    "df_train = df_train.join(df_train_cont.set_index(join_cols), on=join_cols, how=\"outer\", lsuffix=\"\", rsuffix=\"_contextual\")\n",
    "df_train = df_train.rename(columns={\"tag_cat\":\"tag_cat_linguistic\"})\n",
    "# df_train.head(30)  # Should have one row per token!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df_dev.join(df_dev_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev = df_dev.join(df_dev_pers.set_index(join_cols), on=join_cols, how=\"outer\", lsuffix=\"\", rsuffix=\"_personname\")\n",
    "df_dev = df_dev.join(df_dev_cont.set_index(join_cols), on=join_cols, how=\"outer\", lsuffix=\"\", rsuffix=\"_contextual\")\n",
    "df_dev = df_dev.rename(columns={\"tag_cat\":\"tag_cat_linguistic\"})\n",
    "# df_dev.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_cat_linguistic</th>\n",
       "      <th>tag_cat_personname</th>\n",
       "      <th>tag_cat_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>779229</th>\n",
       "      <td>42027</td>\n",
       "      <td>753891</td>\n",
       "      <td>NN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779230</th>\n",
       "      <td>42027</td>\n",
       "      <td>753892</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779231</th>\n",
       "      <td>42027</td>\n",
       "      <td>753893</td>\n",
       "      <td>NN</td>\n",
       "      <td>homosexuality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779232</th>\n",
       "      <td>42027</td>\n",
       "      <td>753894</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779233</th>\n",
       "      <td>42027</td>\n",
       "      <td>753895</td>\n",
       "      <td>JJ</td>\n",
       "      <td>contemporary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779234</th>\n",
       "      <td>42027</td>\n",
       "      <td>753896</td>\n",
       "      <td>JJ</td>\n",
       "      <td>medical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779235</th>\n",
       "      <td>42027</td>\n",
       "      <td>753897</td>\n",
       "      <td>NNS</td>\n",
       "      <td>journals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779236</th>\n",
       "      <td>42027</td>\n",
       "      <td>753898</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779237</th>\n",
       "      <td>42027</td>\n",
       "      <td>753899</td>\n",
       "      <td>NNS</td>\n",
       "      <td>books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779238</th>\n",
       "      <td>42027</td>\n",
       "      <td>753900</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779239</th>\n",
       "      <td>42027</td>\n",
       "      <td>753901</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779240</th>\n",
       "      <td>42027</td>\n",
       "      <td>753902</td>\n",
       "      <td>NNS</td>\n",
       "      <td>references</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779241</th>\n",
       "      <td>42027</td>\n",
       "      <td>753903</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779242</th>\n",
       "      <td>42027</td>\n",
       "      <td>753904</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Church</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779243</th>\n",
       "      <td>42027</td>\n",
       "      <td>753905</td>\n",
       "      <td>NNS</td>\n",
       "      <td>reports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779244</th>\n",
       "      <td>42027</td>\n",
       "      <td>753906</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779245</th>\n",
       "      <td>42028</td>\n",
       "      <td>753907</td>\n",
       "      <td>NN</td>\n",
       "      <td>F6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779246</th>\n",
       "      <td>42028</td>\n",
       "      <td>753908</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779247</th>\n",
       "      <td>42028</td>\n",
       "      <td>753909</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Printed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779248</th>\n",
       "      <td>42028</td>\n",
       "      <td>753910</td>\n",
       "      <td>NN</td>\n",
       "      <td>material</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779249</th>\n",
       "      <td>42028</td>\n",
       "      <td>753911</td>\n",
       "      <td>IN</td>\n",
       "      <td>on</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779250</th>\n",
       "      <td>42028</td>\n",
       "      <td>753912</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779251</th>\n",
       "      <td>42028</td>\n",
       "      <td>753913</td>\n",
       "      <td>NN</td>\n",
       "      <td>history</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779252</th>\n",
       "      <td>42028</td>\n",
       "      <td>753914</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779253</th>\n",
       "      <td>42028</td>\n",
       "      <td>753915</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779254</th>\n",
       "      <td>42028</td>\n",
       "      <td>753916</td>\n",
       "      <td>JJ</td>\n",
       "      <td>medical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779255</th>\n",
       "      <td>42028</td>\n",
       "      <td>753917</td>\n",
       "      <td>NN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779256</th>\n",
       "      <td>42028</td>\n",
       "      <td>753918</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779257</th>\n",
       "      <td>42028</td>\n",
       "      <td>753919</td>\n",
       "      <td>NN</td>\n",
       "      <td>homosexuality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779258</th>\n",
       "      <td>42028</td>\n",
       "      <td>753920</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id  pos          token tag_cat_linguistic  \\\n",
       "779229        42027    753891   NN      treatment                NaN   \n",
       "779230        42027    753892   IN             of                NaN   \n",
       "779231        42027    753893   NN  homosexuality                NaN   \n",
       "779232        42027    753894   IN             in                NaN   \n",
       "779233        42027    753895   JJ   contemporary                NaN   \n",
       "779234        42027    753896   JJ        medical                NaN   \n",
       "779235        42027    753897  NNS       journals                NaN   \n",
       "779236        42027    753898   CC            and                NaN   \n",
       "779237        42027    753899  NNS          books                NaN   \n",
       "779238        42027    753900    ,              ,                NaN   \n",
       "779239        42027    753901   CC            and                NaN   \n",
       "779240        42027    753902  NNS     references                NaN   \n",
       "779241        42027    753903   IN             in                NaN   \n",
       "779242        42027    753904  NNP         Church                NaN   \n",
       "779243        42027    753905  NNS        reports                NaN   \n",
       "779244        42027    753906    .              .                NaN   \n",
       "779245        42028    753907   NN             F6                NaN   \n",
       "779246        42028    753908    :              :                NaN   \n",
       "779247        42028    753909  VBN        Printed                NaN   \n",
       "779248        42028    753910   NN       material                NaN   \n",
       "779249        42028    753911   IN             on                NaN   \n",
       "779250        42028    753912   DT            the                NaN   \n",
       "779251        42028    753913   NN        history                NaN   \n",
       "779252        42028    753914   IN             of                NaN   \n",
       "779253        42028    753915   DT            the                NaN   \n",
       "779254        42028    753916   JJ        medical                NaN   \n",
       "779255        42028    753917   NN      treatment                NaN   \n",
       "779256        42028    753918   IN             of                NaN   \n",
       "779257        42028    753919   NN  homosexuality                NaN   \n",
       "779258        42028    753920    .              .                NaN   \n",
       "\n",
       "       tag_cat_personname tag_cat_contextual  \n",
       "779229                NaN                NaN  \n",
       "779230                NaN                NaN  \n",
       "779231                NaN                NaN  \n",
       "779232                NaN                NaN  \n",
       "779233                NaN                NaN  \n",
       "779234                NaN                NaN  \n",
       "779235                NaN                NaN  \n",
       "779236                NaN                NaN  \n",
       "779237                NaN                NaN  \n",
       "779238                NaN                NaN  \n",
       "779239                NaN                NaN  \n",
       "779240                NaN                NaN  \n",
       "779241                NaN                NaN  \n",
       "779242                NaN                NaN  \n",
       "779243                NaN                NaN  \n",
       "779244                NaN                NaN  \n",
       "779245                NaN                NaN  \n",
       "779246                NaN                NaN  \n",
       "779247                NaN                NaN  \n",
       "779248                NaN                NaN  \n",
       "779249                NaN                NaN  \n",
       "779250                NaN                NaN  \n",
       "779251                NaN                NaN  \n",
       "779252                NaN                NaN  \n",
       "779253                NaN                NaN  \n",
       "779254                NaN                NaN  \n",
       "779255                NaN                NaN  \n",
       "779256                NaN                NaN  \n",
       "779257                NaN                NaN  \n",
       "779258                NaN                NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMEMBER:** check that model input data created on correct subset of files - no stereotypes about homosexuality \"offences\" or \"medical treatment\" of homosexuality??? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the `tag_cat_` columns' `nan` values with `'O'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_cat_linguistic</th>\n",
       "      <th>tag_cat_personname</th>\n",
       "      <th>tag_cat_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  token_id   pos       token tag_cat_linguistic  \\\n",
       "172            5       154    IN       After                  O   \n",
       "173            5       155  PRP$         his       B-Linguistic   \n",
       "174            5       156    NN  ordination                  O   \n",
       "175            5       157   PRP          he       B-Linguistic   \n",
       "176            5       158   VBD       spent                  O   \n",
       "\n",
       "    tag_cat_personname tag_cat_contextual  \n",
       "172                  O                  O  \n",
       "173                  O                  O  \n",
       "174                  O                  O  \n",
       "175                  O                  O  \n",
       "176                  O                  O  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_cat_cols = [\"tag_cat_linguistic\", \"tag_cat_personname\", \"tag_cat_contextual\"]\n",
    "df_train[tag_cat_cols] = df_train[tag_cat_cols].fillna('O')\n",
    "df_dev[tag_cat_cols] = df_dev[tag_cat_cols].fillna('O')\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by sentence, so the token column becomes a list of tokens for each sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_cat_linguistic</th>\n",
       "      <th>tag_cat_personname</th>\n",
       "      <th>tag_cat_contextual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[O, B-Linguistic, O, B-Linguistic, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, O, B-Pers...</td>\n",
       "      <td>[O, O, B-Contextual, I-Contextual, I-Contextua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, I-Person-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Contextual, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                            tag_cat_linguistic  \\\n",
       "sentence_id                                                      \n",
       "5            [O, B-Linguistic, O, B-Linguistic, O, O, O, O,...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                            tag_cat_personname  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, B-Person-Name, I-Person-Name, O, B-Pers...   \n",
       "24           [O, O, B-Person-Name, I-Person-Name, I-Person-...   \n",
       "\n",
       "                                            tag_cat_contextual  \n",
       "sentence_id                                                     \n",
       "5            [O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...  \n",
       "11                                                   [O, O, O]  \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "18           [O, O, B-Contextual, I-Contextual, I-Contextua...  \n",
       "24           [O, O, O, O, O, O, O, O, O, O, B-Contextual, O...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train, [\"sentence_id\"])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev, [\"sentence_id\"])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, CATEGORY-TAG)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Title', 'NN', 'O'), (':', ':', 'O'), ('Papers', 'NNS', 'O')]\n",
      "[('After', 'IN', 'O'), ('his', 'PRP$', 'B-Linguistic'), ('ordination', 'NN', 'O')]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_ling = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_cat_linguistic\")\n",
    "print(train_sentences_ling[0][:3])\n",
    "dev_sentences_ling = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_cat_linguistic\")\n",
    "print(dev_sentences_ling[0][:3])\n",
    "train_sentences_pers = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_cat_personname\")\n",
    "dev_sentences_pers = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_cat_personname\")\n",
    "train_sentences_cont = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_cat_contextual\")\n",
    "dev_sentences_cont = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_cat_contextual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings\n",
    "\n",
    "Use the custom fastText word embeddings, trained on the entire dataset of descriptive metadata from the Archives (harvested in October 2020) using the Continuous Bag-of-Words (CBOW) algorithm.  Subword embeddings (for subwords from 2 to 6 characters long, inclusive) are used to infer the embeddings for out-of-vocabulary (OOV) words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the word embedding model trained on lowercased text to 100 dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = get_tmpfile(config.tokc_path+\"fasttext100_lowercased.model\")\n",
    "embedding_model = FastText.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35968\n",
      "Lowercased vocabulary size: 31335\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(df_train.token.unique())\n",
    "vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define feature dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a vector representation of a token from a fastText word embedding model\n",
    "def extractEmbedding(token, fasttext_model=embedding_model):\n",
    "    if token.isalpha():\n",
    "        token = token.lower()\n",
    "    embedding = fasttext_model.wv[token]\n",
    "    return embedding\n",
    "\n",
    "def extractTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'pos': pos,\n",
    "        'pos[:2]': pos[:2],\n",
    "        'token': token\n",
    "    }\n",
    "    \n",
    "    # Add each value in a token's word embedding as a separate feature\n",
    "    embedding = extractEmbedding(token)\n",
    "    for i,n in enumerate(embedding):\n",
    "        features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractSentenceFeatures(sentence):\n",
    "    return [extractTokenFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def extractSentenceTargets(sentence):\n",
    "    return [tag for token, pos, tag in sentence]\n",
    "\n",
    "def extractSentenceTokens(sentence):\n",
    "    return [token for token, pos, tag in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractSentenceFeatures(train_sentences[0])[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References:*\n",
    "* *https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html*\n",
    "* *https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Baseline Models\n",
    "\n",
    "### Linguistic\n",
    "\n",
    "* **Features:** part-of-speech tag, first 2 letters of part-of-speech tag abbreviation, custom fastText embeddings\n",
    "* **Target:** Linguistic label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Linguistic** category of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_ling\n",
    "dev_sentences = dev_sentences_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "# Available algorithms with sklearn_crfsuite are:\n",
    "#     'lbfgs' - Gradient descent using the L-BFGS method\n",
    "#     'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
    "#     'ap' - Averaged Perceptron\n",
    "#     'pa' - Passive Aggressive (PA)\n",
    "#     'arow' - Adaptive Regularization Of Weight Vector (AROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100) #iterations unlimited\n",
    "clf = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.1, max_iterations=100, all_possible_transitions=True)     # up to 1000 iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[3], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[4], max_iterations=100)           # max iterations allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Linguistic', 'I-Linguistic']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.678230100682343\n",
      "  - Prec: 0.7553309858774123\n",
      "  - Rec 0.6287799791449427\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_cat__linguistic_expected</th>\n",
       "      <th>tag_cat_personname</th>\n",
       "      <th>tag_cat_contextual</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[O, B-Linguistic, O, B-Linguistic, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...</td>\n",
       "      <td>[O, B-Linguistic, O, B-Linguistic, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, O, B-Pers...</td>\n",
       "      <td>[O, O, B-Contextual, I-Contextual, I-Contextua...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, I-Person-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Contextual, O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                  tag_cat__linguistic_expected  \\\n",
       "sentence_id                                                      \n",
       "5            [O, B-Linguistic, O, B-Linguistic, O, O, O, O,...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                            tag_cat_personname  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, B-Person-Name, I-Person-Name, O, B-Pers...   \n",
       "24           [O, O, B-Person-Name, I-Person-Name, I-Person-...   \n",
       "\n",
       "                                            tag_cat_contextual  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, B-Contextual, I-Contextual, I-Contextua...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, B-Contextual, O...   \n",
       "\n",
       "                                  tag_cat_linguistic_predicted  \n",
       "sentence_id                                                     \n",
       "5            [O, B-Linguistic, O, B-Linguistic, O, O, O, O,...  \n",
       "11                                                   [O, O, O]  \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "24           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_cat_linguistic\":\"tag_cat_linguistic_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_cat_linguistic_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Name\n",
    "\n",
    "* **Features:** part-of-speech tag, first 2 letters of part-of-speech tag abbreviation, custom fastText embeddings\n",
    "* **Target:** Person-Name label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_pers\n",
    "dev_sentences = dev_sentences_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100) #iterations unlimited\n",
    "clf = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.1, max_iterations=100, all_possible_transitions=True)     # up to 1000 iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[3], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[4], max_iterations=100)           # max iterations allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Person-Name', 'I-Person-Name']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.4946309099465871\n",
      "  - Prec: 0.8145205069894943\n",
      "  - Rec 0.35538592027141647\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_cat__linguistic_expected</th>\n",
       "      <th>tag_cat_personname_expected</th>\n",
       "      <th>tag_cat_contextual</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "      <th>tag_cat_personname_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[O, B-Linguistic, O, B-Linguistic, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...</td>\n",
       "      <td>[O, B-Linguistic, O, B-Linguistic, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, O, B-Pers...</td>\n",
       "      <td>[O, O, B-Contextual, I-Contextual, I-Contextua...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, I-Person-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Contextual, O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, I-Person-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                  tag_cat__linguistic_expected  \\\n",
       "sentence_id                                                      \n",
       "5            [O, B-Linguistic, O, B-Linguistic, O, O, O, O,...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                   tag_cat_personname_expected  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, B-Person-Name, I-Person-Name, O, B-Pers...   \n",
       "24           [O, O, B-Person-Name, I-Person-Name, I-Person-...   \n",
       "\n",
       "                                            tag_cat_contextual  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, B-Contextual, I-Contextual, I-Contextua...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, B-Contextual, O...   \n",
       "\n",
       "                                  tag_cat_linguistic_predicted  \\\n",
       "sentence_id                                                      \n",
       "5            [O, B-Linguistic, O, B-Linguistic, O, O, O, O,...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                  tag_cat_personname_predicted  \n",
       "sentence_id                                                     \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "11                                                   [O, O, O]  \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, B-Pers...  \n",
       "24           [O, O, B-Person-Name, I-Person-Name, I-Person-...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_cat_personname\":\"tag_cat_personname_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_cat_personname_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "### Contextual\n",
    "\n",
    "* **Features:** part-of-speech tag, first 2 letters of part-of-speech tag abbreviation, custom fastText embeddings\n",
    "* **Target:** Contextual label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Contextual** category of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_cont\n",
    "dev_sentences = dev_sentences_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "# Available algorithms with sklearn_crfsuite are:\n",
    "#     'lbfgs' - Gradient descent using the L-BFGS method\n",
    "#     'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
    "#     'ap' - Averaged Perceptron\n",
    "#     'pa' - Passive Aggressive (PA)\n",
    "#     'arow' - Adaptive Regularization Of Weight Vector (AROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100) #iterations unlimited\n",
    "clf = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.1, max_iterations=100, all_possible_transitions=True)     # up to 1000 iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[3], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[4], max_iterations=100)           # max iterations allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.1, max_iterations=100)- ## should be able to see transition probabilities (if 5 labels, matrix of 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Contextual', 'I-Contextual']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.2416623224678833\n",
      "  - Prec: 0.4977389602765763\n",
      "  - Rec 0.16080715623049718\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_cat_linguistic_expected</th>\n",
       "      <th>tag_cat_personname_expected</th>\n",
       "      <th>tag_cat_contextual_expected</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "      <th>tag_cat_personname_predicted</th>\n",
       "      <th>tag_cat_contextual_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[O, B-Linguistic, O, B-Linguistic, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...</td>\n",
       "      <td>[O, B-Linguistic, O, B-Linguistic, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, O, B-Pers...</td>\n",
       "      <td>[O, O, B-Contextual, I-Contextual, I-Contextua...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-Pers...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, I-Person-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Contextual, O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B-Person-Name, I-Person-Name, I-Person-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Contextual, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                   tag_cat_linguistic_expected  \\\n",
       "sentence_id                                                      \n",
       "5            [O, B-Linguistic, O, B-Linguistic, O, O, O, O,...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                   tag_cat_personname_expected  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, B-Person-Name, I-Person-Name, O, B-Pers...   \n",
       "24           [O, O, B-Person-Name, I-Person-Name, I-Person-...   \n",
       "\n",
       "                                   tag_cat_contextual_expected  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, B-Contextual, I-Co...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, B-Contextual, I-Contextual, I-Contextua...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, B-Contextual, O...   \n",
       "\n",
       "                                  tag_cat_linguistic_predicted  \\\n",
       "sentence_id                                                      \n",
       "5            [O, B-Linguistic, O, B-Linguistic, O, O, O, O,...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "24           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                  tag_cat_personname_predicted  \\\n",
       "sentence_id                                                      \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "11                                                   [O, O, O]   \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, B-Pers...   \n",
       "24           [O, O, B-Person-Name, I-Person-Name, I-Person-...   \n",
       "\n",
       "                                  tag_cat_contextual_predicted  \n",
       "sentence_id                                                     \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "11                                                   [O, O, O]  \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "18           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "24           [O, O, O, O, O, O, O, O, O, O, B-Contextual, I...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_cat_contextual\":\"tag_cat_contextual_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_cat_contextual_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the development data's test, the predicted labels will be deemed incorrect.\n",
    "\n",
    "As with the manual annotation evaluation, we want to evaluate the predictions more loosely, considering overlapping text spans in addition to exactly matching text spans.  Save the predictions for each token and then use IntervalTree to evaluate performance considering overlapping labels, rather than only exactly matching labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_cat_linguistic_expected</th>\n",
       "      <th>tag_cat_personname_expected</th>\n",
       "      <th>tag_cat_contextual_expected</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "      <th>tag_cat_personname_predicted</th>\n",
       "      <th>tag_cat_contextual_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id   pos       token tag_cat_linguistic_expected  \\\n",
       "sentence_id                                                          \n",
       "5                154    IN       After                           O   \n",
       "5                155  PRP$         his                B-Linguistic   \n",
       "5                156    NN  ordination                           O   \n",
       "5                157   PRP          he                B-Linguistic   \n",
       "5                158   VBD       spent                           O   \n",
       "\n",
       "            tag_cat_personname_expected tag_cat_contextual_expected  \\\n",
       "sentence_id                                                           \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "\n",
       "            tag_cat_linguistic_predicted tag_cat_personname_predicted  \\\n",
       "sentence_id                                                             \n",
       "5                                      O                            O   \n",
       "5                           B-Linguistic                            O   \n",
       "5                                      O                            O   \n",
       "5                           B-Linguistic                            O   \n",
       "5                                      O                            O   \n",
       "\n",
       "            tag_cat_contextual_predicted  \n",
       "sentence_id                               \n",
       "5                                      O  \n",
       "5                                      O  \n",
       "5                                      O  \n",
       "5                                      O  \n",
       "5                                      O  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "df_dev_exploded = df_dev_exploded.rename(columns={\"sentence\":\"token\"})\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152711, 9)\n",
      "(152711, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_dev_exploded.shape)\n",
    "print(df_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped.to_csv(config.tokc_path+\"model_output/categoryTags_crfL2sgd_POS-CustomFastText_bySentence.csv\")\n",
    "df_dev_exploded.to_csv(config.tokc_path+\"model_output/categoryTags_crfL2sgd_POS-CustomFastText_byToken.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loose Evaluation\n",
    "\n",
    "Conduct a loose evaluation of the model's performance (as the manual annotation were evaluated), considering any overlapping or envelopping expected and predicted annotations to be matches, in addition to exactly-matching expected and predicted annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(12, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>(17, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>(22, 23)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_id  sentence_id token_offsets\n",
       "0         0            0       (0, 10)\n",
       "1         1            0      (10, 11)\n",
       "2         2            0      (12, 15)\n",
       "3         3            1      (17, 22)\n",
       "4         4            1      (22, 23)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the start and end offsets of the tokens\n",
    "tok_df = pd.read_csv(config.tokc_path+\"desc_sent_ann_token_tag.csv\", usecols=[\"token_id\", \"sentence_id\", \"token_offsets\"])\n",
    "tok_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag_cat_linguistic_expected</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "      <th>tag_cat_personname_expected</th>\n",
       "      <th>tag_cat_personname_predicted</th>\n",
       "      <th>tag_cat_contextual_expected</th>\n",
       "      <th>tag_cat_contextual_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>(907, 912)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>(913, 916)</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>(917, 927)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>(928, 930)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>(931, 936)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id       token token_offsets   pos  \\\n",
       "0            5      154       After    (907, 912)    IN   \n",
       "1            5      155         his    (913, 916)  PRP$   \n",
       "2            5      156  ordination    (917, 927)    NN   \n",
       "3            5      157          he    (928, 930)   PRP   \n",
       "4            5      158       spent    (931, 936)   VBD   \n",
       "\n",
       "  tag_cat_linguistic_expected tag_cat_linguistic_predicted  \\\n",
       "0                           O                            O   \n",
       "1                B-Linguistic                 B-Linguistic   \n",
       "2                           O                            O   \n",
       "3                B-Linguistic                 B-Linguistic   \n",
       "4                           O                            O   \n",
       "\n",
       "  tag_cat_personname_expected tag_cat_personname_predicted  \\\n",
       "0                           O                            O   \n",
       "1                           O                            O   \n",
       "2                           O                            O   \n",
       "3                           O                            O   \n",
       "4                           O                            O   \n",
       "\n",
       "  tag_cat_contextual_expected tag_cat_contextual_predicted  \n",
       "0                           O                            O  \n",
       "1                           O                            O  \n",
       "2                           O                            O  \n",
       "3                           O                            O  \n",
       "4                           O                            O  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the offsets data to the dev data, keeping only the tokens included in the dev data\n",
    "df_dev_exploded = df_dev_exploded.reset_index()\n",
    "join_cols = [\"sentence_id\", \"token_id\"]\n",
    "df_pred = df_dev_exploded.join(tok_df.set_index(join_cols), on=join_cols, how=\"left\")\n",
    "df_pred = df_pred[[\"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \n",
    "                   \"tag_cat_linguistic_expected\", \"tag_cat_linguistic_predicted\",\n",
    "                   \"tag_cat_personname_expected\", \"tag_cat_personname_predicted\",\n",
    "                   \"tag_cat_contextual_expected\", \"tag_cat_contextual_predicted\"\n",
    "                  ]]\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_pred.isna().values.any() == False, \"There should be no NaN values in any of the prediction DataFrame's columns.\"\n",
    "assert df_pred.shape[0] == df_dev_exploded.shape[0], \"There should be the same number of rows as the dev DataFrame prior to the join.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the offsets to tuples of ints\n",
    "offsets = list(df_pred.token_offsets)\n",
    "offsets = [tuple(((offset_pair[1:-1]).split(\", \"))) for offset_pair in offsets]\n",
    "offsets = [(int(start_offset), int(end_offset)) for start_offset,end_offset in offsets]\n",
    "# print(type(offsets[0]), type(offsets[0][0]), type(offsets[0][1]))\n",
    "col_i = list(df_pred.columns).index(\"token_offsets\")\n",
    "df_pred = df_pred.drop(columns=[\"token_offsets\"])\n",
    "df_pred.insert((col_i-1), \"token_offsets\", offsets)\n",
    "# df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interval tree from the token offsets of the input DataFrame, columns, and tag names\n",
    "def createIntervalTree(df, offsets_col, tag_col, tag_names):\n",
    "    subdf = df.loc[df[tag_col].isin(tag_names)]\n",
    "    offsets_list = list(subdf[offsets_col])\n",
    "    return IntervalTree.from_tuples(offsets_list)\n",
    "\n",
    "# Get counts of true positives, false positives, and false negatives \n",
    "# for exactly matching, overlapping, and enveloping annotations \n",
    "def looseAgreement(tree_exp, tree_pred):\n",
    "    tp_count, fp_count, fn_count = 0, 0, 0\n",
    "    # Note: TP will actually be TN when evaluating for 'O' tags \n",
    "    for annotation in tree_exp:\n",
    "        tp_count += len(tree_pred.overlap(annotation))\n",
    "    fn_count = len(tree_exp.difference(tree_pred))\n",
    "    fp_count = len(tree_pred.difference(tree_exp))\n",
    "    return tp_count, fp_count, fn_count\n",
    "    \n",
    "# Calculate precision, recall, and F1 scores, returning\n",
    "# 1 in the case of zero division\n",
    "def precisionRecallF1(tp_count, fp_count, fn_count):\n",
    "    if tp_count+fp_count == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = (tp_count/(tp_count+fp_count))\n",
    "    if tp_count+fn_count == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = (tp_count/(tp_count+fn_count))\n",
    "    f_1 = (2*precision*recall)/(precision+recall)\n",
    "    return precision, recall, f_1\n",
    "\n",
    "# Get the true positives, false positives, and false negatives\n",
    "# for exactly matching annotations only\n",
    "# def strictAgreementPerTag(tree_exp, tree_pred):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many expected **Linguistic** tags overlap, envelop/fall within, or exactly match predicted Linguistic tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Linguistic', 'I-Linguistic']\n",
      "---------------------------------------\n",
      "TP: 2730 | FP: 314 | FN: 673\n",
      "---------------------------------------\n",
      "Precision: 0.8968462549277266\n",
      "Recall: 0.8022333235380547\n",
      "F_1 Score: 0.8469055374592834\n"
     ]
    }
   ],
   "source": [
    "# LINGUISTIC\n",
    "ling_tags = [\"B-Linguistic\", \"I-Linguistic\"]\n",
    "b_ling_exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_expected\", ling_tags)\n",
    "b_ling_pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_predicted\", ling_tags)\n",
    "tp, fp, fn = looseAgreement(b_ling_exp_tree, b_ling_pred_tree)\n",
    "print(ling_tags)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-Linguistic\n",
      "---------------------------------------\n",
      "TP: 2389 | FP: 274 | FN: 467\n",
      "---------------------------------------\n",
      "Precision: 0.8971085242208036\n",
      "Recall: 0.836484593837535\n",
      "F_1 Score: 0.8657365464758109\n"
     ]
    }
   ],
   "source": [
    "# B-LINGUISTIC\n",
    "b_ling_exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_expected\", [ling_tags[0]])\n",
    "b_ling_pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_predicted\", [ling_tags[0]])\n",
    "tp, fp, fn = looseAgreement(b_ling_exp_tree, b_ling_pred_tree)\n",
    "print(ling_tags[0])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Linguistic\n",
      "---------------------------------------\n",
      "TP: 65 | FP: 44 | FN: 212\n",
      "---------------------------------------\n",
      "Precision: 0.5963302752293578\n",
      "Recall: 0.23465703971119134\n",
      "F_1 Score: 0.3367875647668394\n"
     ]
    }
   ],
   "source": [
    "# I-LINGUISTIC\n",
    "b_ling_exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_expected\", [ling_tags[1]])\n",
    "b_ling_pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_predicted\", [ling_tags[1]])\n",
    "tp, fp, fn = looseAgreement(b_ling_exp_tree, b_ling_pred_tree)\n",
    "print(ling_tags[1])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many expected **Person Name** tags overlap, envelop/fall within, or exactly match predicted Person Name tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Person-Name', 'I-Person-Name']\n",
      "---------------------------------------\n",
      "TP: 21722 | FP: 328 | FN: 3982\n",
      "---------------------------------------\n",
      "Precision: 0.9851247165532879\n",
      "Recall: 0.8450824774354186\n",
      "F_1 Score: 0.9097457804581816\n"
     ]
    }
   ],
   "source": [
    "# PERSON NAME\n",
    "tags = [\"B-Person-Name\", \"I-Person-Name\"]\n",
    "exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_expected\", tags)\n",
    "pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_predicted\", tags)\n",
    "tp, fp, fn = looseAgreement(exp_tree, pred_tree)\n",
    "print(tags)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-Person-Name\n",
      "---------------------------------------\n",
      "TP: 4792 | FP: 199 | FN: 1594\n",
      "---------------------------------------\n",
      "Precision: 0.9601282308154678\n",
      "Recall: 0.7503914813654871\n",
      "F_1 Score: 0.8424013360288302\n"
     ]
    }
   ],
   "source": [
    "# B-PERSON-NAME\n",
    "exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_expected\", [tags[0]])\n",
    "pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_predicted\", [tags[0]])\n",
    "tp, fp, fn = looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[0])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Person-Name\n",
      "---------------------------------------\n",
      "TP: 8120 | FP: 301 | FN: 2712\n",
      "---------------------------------------\n",
      "Precision: 0.9642560266001663\n",
      "Recall: 0.7496307237813885\n",
      "F_1 Score: 0.8435049083259752\n"
     ]
    }
   ],
   "source": [
    "# I-PERSON-NAME\n",
    "exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_expected\", [tags[1]])\n",
    "pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_predicted\", [tags[1]])\n",
    "tp, fp, fn = looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[1])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many expected **Contextual** tags overlap, envelop/fall within, or exactly match predicted Person Name tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Contextual', 'I-Contextual']\n",
      "---------------------------------------\n",
      "TP: 6712 | FP: 518 | FN: 3591\n",
      "---------------------------------------\n",
      "Precision: 0.9283540802213002\n",
      "Recall: 0.6514607395904105\n",
      "F_1 Score: 0.7656419323561283\n"
     ]
    }
   ],
   "source": [
    "# CONTEXTUAL\n",
    "tags = [\"B-Contextual\", \"I-Contextual\"]\n",
    "exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_expected\", tags)\n",
    "pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_predicted\", tags)\n",
    "tp, fp, fn = looseAgreement(exp_tree, pred_tree)\n",
    "print(tags)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-Contextual\n",
      "---------------------------------------\n",
      "TP: 2262 | FP: 222 | FN: 1346\n",
      "---------------------------------------\n",
      "Precision: 0.9106280193236715\n",
      "Recall: 0.626940133037694\n",
      "F_1 Score: 0.742613263296126\n"
     ]
    }
   ],
   "source": [
    "# B-CONTEXTUAL\n",
    "exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_expected\", [tags[0]])\n",
    "pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_predicted\", [tags[0]])\n",
    "tp, fp, fn = looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[0])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Contextual\n",
      "---------------------------------------\n",
      "TP: 1775 | FP: 354 | FN: 2465\n",
      "---------------------------------------\n",
      "Precision: 0.8337247534053547\n",
      "Recall: 0.4186320754716981\n",
      "F_1 Score: 0.5573873449521118\n"
     ]
    }
   ],
   "source": [
    "# I-CONTEXTUAL\n",
    "exp_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_expected\", [tags[1]])\n",
    "pred_tree = createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_predicted\", [tags[1]])\n",
    "tp, fp, fn = looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[1])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame for each category's expected and predicted tags with a columns noting the type of agremeent or disagreement.  Use the CoNLL error types, which are:\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (gender-bias)",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

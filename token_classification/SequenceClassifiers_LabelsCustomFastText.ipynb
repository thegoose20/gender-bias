{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Biased Token Classifiers\n",
    "\n",
    "### Target: Labels\n",
    "\n",
    "### Word Embeddings: fastText (custom)\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/`\n",
    "* Sequence classification\n",
    "    * 9 lables (2 from original annotation taxonomy weren't applied during manual annotation):\n",
    "        1. Person Name: Unknown, Feminine, Masculine (Non-binary not applied)\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Occupation, Omission, Stereotype (Empowering not applied)\n",
    "    * 1 model per category\n",
    "* Word embeddings\n",
    "    * Custom fastText (word2vec with subwords, trained on Archives' descriptive metadata extracted in October 2020)  \n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "**[0.](#0) Preprocessing**\n",
    "\n",
    "**[1.](#1) Models**\n",
    "\n",
    "**[2.](#2) TO DO: Performance Evaluation**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.stats\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay#, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate rows with all but the same annotation ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that won't be used as features for the classifiers and remove any duplicate rows that remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"pos\", \"token\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[cols_to_keep]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev[cols_to_keep]\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate subsets of data for each category so they can be used with three separate models, replacing `NaN` tag values with `'O'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine' 'B-Gendered-Pronoun' 'B-Gendered-Role' 'B-Generalization'\n",
      " 'B-Masculine' 'B-Occupation' 'B-Omission' 'B-Stereotype' 'B-Unknown'\n",
      " 'I-Feminine' 'I-Gendered-Pronoun' 'I-Gendered-Role' 'I-Generalization'\n",
      " 'I-Masculine' 'I-Occupation' 'I-Omission' 'I-Stereotype' 'I-Unknown' 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = (df_train.tag.unique())\n",
    "tags.sort()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_cat_tags = ['B-Gendered-Pronoun', 'B-Gendered-Role', 'B-Generalization', 'I-Gendered-Pronoun', 'I-Gendered-Role', 'I-Generalization']\n",
    "df_train_ling = df_train.loc[df_train.tag.isin(ling_cat_tags)]\n",
    "df_dev_ling = df_dev.loc[df_dev.tag.isin(ling_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Unknown']\n",
    "df_train_pers = df_train.loc[df_train.tag.isin(pers_cat_tags)]\n",
    "df_dev_pers = df_dev.loc[df_dev.tag.isin(pers_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cat_tags = ['B-Occupation', 'B-Omission', 'B-Stereotype', 'I-Occupation', 'I-Omission', 'I-Stereotype']\n",
    "df_train_cont = df_train.loc[df_train.tag.isin(cont_cat_tags)]\n",
    "df_dev_cont = df_dev.loc[df_dev.tag.isin(cont_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.drop(columns=[\"tag\"])).drop_duplicates()\n",
    "df_dev = (df_dev.drop(columns=[\"tag\"])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"sentence_id\", \"token_id\", \"pos\", \"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train.join(df_train_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_ling = df_train_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_train_ling = df_train_ling.fillna('O')\n",
    "# df_train_ling.head()\n",
    "df_dev_ling = df_dev.join(df_dev_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_ling = df_dev_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_dev_ling = df_dev_ling.fillna('O')\n",
    "# df_dev_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pers = df_train.join(df_train_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_pers = df_train_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_train_pers = df_train_pers.fillna('O')\n",
    "df_dev_pers = df_dev.join(df_dev_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_pers = df_dev_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_dev_pers = df_dev_pers.fillna('O')\n",
    "# df_dev_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Papers</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>DT</td>\n",
       "      <td>The</td>\n",
       "      <td>B-Stereotype</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  pos   token tag_contextual\n",
       "3            1         3   NN   Title              O\n",
       "4            1         4    :       :              O\n",
       "5            1         5  NNS  Papers              O\n",
       "6            1         6   IN      of              O\n",
       "7            1         7   DT     The   B-Stereotype"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cont = df_train.join(df_train_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_cont = df_train_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_train_cont = df_train_cont.fillna('O')\n",
    "df_dev_cont = df_dev.join(df_dev_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_cont = df_dev_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_dev_cont = df_dev_cont.fillna('O')\n",
    "df_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train_ling.drop_duplicates()\n",
    "df_dev_ling = df_dev_ling.drop_duplicates()\n",
    "df_train_pers = df_train_pers.drop_duplicates()\n",
    "df_dev_pers = df_dev_pers.drop_duplicates()\n",
    "df_train_cont = df_train_cont.drop_duplicates()\n",
    "df_dev_cont = df_dev_cont.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452222 452086\n",
      "455327 452086\n",
      "453119 452086\n",
      "\n",
      "152494 152455\n",
      "153568 152455\n",
      "152768 152455\n"
     ]
    }
   ],
   "source": [
    "train_dfs = [df_train_ling, df_train_pers, df_train_cont]\n",
    "dev_dfs = [df_dev_ling, df_dev_pers, df_dev_cont]\n",
    "for df in train_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))\n",
    "print()\n",
    "for df in dev_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens can have multiple tags, so there are more rows than unique token IDs.  In order to pass the data into a CRF model, we need to have one tag per token, so we'll simply **take the first tag** when we extract features for each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings\n",
    "\n",
    "Use the custom fastText word embeddings, trained on the entire dataset of descriptive metadata from the Archives (harvested in October 2020) using the Continuous Bag-of-Words (CBOW) algorithm.  Subword embeddings (for subwords from 2 to 6 characters long, inclusive) are used to infer the embeddings for out-of-vocabulary (OOV) words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the word embedding model trained on lowercased text to 100 dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = get_tmpfile(config.tokc_path+\"fasttext100_lowercased.model\")\n",
    "embedding_model = FastText.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35968\n",
      "Lowercased vocabulary size: 31335\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(df_train.token.unique())\n",
    "vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define feature dictionaries for baseline models, using only the word embeddings and token as features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a vector representation of a token from a fastText word embedding model\n",
    "def extractEmbedding(token, fasttext_model=embedding_model):\n",
    "    if token.isalpha():\n",
    "        token = token.lower()\n",
    "    embedding = fasttext_model.wv[token]\n",
    "    return embedding\n",
    "\n",
    "def extractTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token\n",
    "    }\n",
    "    \n",
    "    # Add each value in a token's word embedding as a separate feature\n",
    "    embedding = extractEmbedding(token)\n",
    "    for i,n in enumerate(embedding):\n",
    "        features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractSentenceFeatures(sentence):\n",
    "    return [extractTokenFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def extractSentenceTargets(sentence):\n",
    "    return [tag_list[0] for token, pos, tag_list in sentence]\n",
    "\n",
    "def extractSentenceTokens(sentence):\n",
    "    return [token for token, pos, tag_list in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References:*\n",
    "* *https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html*\n",
    "* *https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Models\n",
    "\n",
    "### Linguistic\n",
    "\n",
    "* **Features:** part-of-speech tag, first 2 letters of part-of-speech tag abbreviation, custom fastText embeddings\n",
    "* **Target:** Linguistic label category IOB tags\n",
    "* **Algorithm:** L2SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_ling\n",
    "df_dev = df_dev_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_linguistic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [B-Gendered-Pronoun], [O], [B-Gendered-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                                tag_linguistic  \n",
       "sentence_id                                                     \n",
       "5            [[O], [B-Gendered-Pronoun], [O], [B-Gendered-P...  \n",
       "11                                             [[O], [O], [O]]  \n",
       "13           [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "18           [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "24           [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Title', 'NN', ['O']), (':', ':', ['O']), ('Papers', 'NNS', ['O'])]\n",
      "[('After', 'IN', ['O']), ('his', 'PRP$', ['B-Gendered-Pronoun']), ('ordination', 'NN', ['O'])]\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_ling = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_linguistic\")\n",
    "print(train_sentences_ling[0][:3])\n",
    "dev_sentences_ling = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_linguistic\")\n",
    "print(dev_sentences_ling[0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Linguistic** category of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_ling\n",
    "dev_sentences = dev_sentences_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "# Available algorithms with sklearn_crfsuite are:\n",
    "#     'lbfgs' - Gradient descent using the L-BFGS method\n",
    "#     'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
    "#     'ap' - Averaged Perceptron\n",
    "#     'pa' - Passive Aggressive (PA)\n",
    "#     'arow' - Adaptive Regularization Of Weight Vector (AROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100) #iterations unlimited\n",
    "clf = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.1, max_iterations=100, all_possible_transitions=True)     # up to 1000 iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[2], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[3], max_iterations=100)           # max iterations allowed\n",
    "# clf = sklearn_crfsuite.CRF(algorithm=algorithms[4], max_iterations=100)           # max iterations allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Gendered-Pronoun', 'B-Generalization', 'B-Gendered-Role', 'I-Generalization', 'I-Gendered-Role', 'I-Gendered-Pronoun']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.5771533871726244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s15/s1545703/miniconda3/envs/gender-bias/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Prec: 0.7035321842602965\n",
      "  - Rec 0.567853170189099\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_linguistic_expected</th>\n",
       "      <th>tag_linguistic_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [B-Gendered-Pronoun], [O], [B-Gendered-P...</td>\n",
       "      <td>[O, B-Gendered-Pronoun, O, B-Gendered-Pronoun,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                           token_id  \\\n",
       "0            5  [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "1           11                                    [308, 309, 310]   \n",
       "2           13  [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "3           18  [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "4           24  [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "1                                        [NN, :, NN]   \n",
       "2  [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "3  [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "4  [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [After, his, ordination, he, spent, three, yea...   \n",
       "1                               [Identifier, :, AA6]   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "4  [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                             tag_linguistic_expected  \\\n",
       "0  [[O], [B-Gendered-Pronoun], [O], [B-Gendered-P...   \n",
       "1                                    [[O], [O], [O]]   \n",
       "2  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "3  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "4  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "\n",
       "                            tag_linguistic_predicted  \n",
       "0  [O, B-Gendered-Pronoun, O, B-Gendered-Pronoun,...  \n",
       "1                                          [O, O, O]  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_linguistic\":\"tag_linguistic_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_linguistic_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"model_output/crf_l2sgd_baseline/\"\n",
    "Path(config.tokc_path+output_path).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_linguistic_expected</th>\n",
       "      <th>tag_linguistic_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>[B-Gendered-Pronoun]</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>[B-Gendered-Pronoun]</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id   pos    sentence tag_linguistic_expected  \\\n",
       "0            5      154    IN       After                     [O]   \n",
       "0            5      155  PRP$         his    [B-Gendered-Pronoun]   \n",
       "0            5      156    NN  ordination                     [O]   \n",
       "0            5      157   PRP          he    [B-Gendered-Pronoun]   \n",
       "0            5      158   VBD       spent                     [O]   \n",
       "\n",
       "  tag_linguistic_predicted  \n",
       "0                        O  \n",
       "0       B-Gendered-Pronoun  \n",
       "0                        O  \n",
       "0       B-Gendered-Pronoun  \n",
       "0                        O  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns)[1:])\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_l2sgd_linguistic_labels_baseline.csv\"\n",
    "df_dev_exploded.to_csv(config.tokc_path+output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Name\n",
    "\n",
    "* **Features:** part-of-speech tag, first 2 letters of part-of-speech tag abbreviation, custom fastText embeddings\n",
    "* **Target:** Person-Name label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_pers\n",
    "df_dev = df_dev_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_personname</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [B-Masculine], [I-Masculine], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [B-Masculine], [I-Masculine], [I-Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                                tag_personname  \n",
       "sentence_id                                                     \n",
       "5            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "11                                             [[O], [O], [O]]  \n",
       "13           [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "18           [[O], [O], [B-Masculine], [I-Masculine], [O], ...  \n",
       "24           [[O], [O], [B-Masculine], [I-Masculine], [I-Ma...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Title', 'NN', ['O']), (':', ':', ['O']), ('Papers', 'NNS', ['O'])]\n",
      "[('After', 'IN', ['O']), ('his', 'PRP$', ['O']), ('ordination', 'NN', ['O'])]\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_pers = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_personname\")\n",
    "print(train_sentences_pers[0][:3])\n",
    "dev_sentences_pers = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_personname\")\n",
    "print(dev_sentences_pers[0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_ling\n",
    "dev_sentences = dev_sentences_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "clf = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.1, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'I-Masculine', 'B-Masculine', 'B-Feminine', 'I-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.4204138504717144\n",
      "  - Prec: 0.5501145258620498\n",
      "  - Rec 0.3414773539077011\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_personname_expected</th>\n",
       "      <th>tag_personname_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [B-Masculine], [I-Masculine], [O], ...</td>\n",
       "      <td>[O, O, O, B-Unknown, I-Unknown, I-Unknown, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [B-Masculine], [I-Masculine], [I-Ma...</td>\n",
       "      <td>[O, O, B-Unknown, I-Unknown, I-Unknown, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                       tag_personname_expected  \\\n",
       "sentence_id                                                      \n",
       "5            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "11                                             [[O], [O], [O]]   \n",
       "13           [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "18           [[O], [O], [B-Masculine], [I-Masculine], [O], ...   \n",
       "24           [[O], [O], [B-Masculine], [I-Masculine], [I-Ma...   \n",
       "\n",
       "                                      tag_personname_predicted  \n",
       "sentence_id                                                     \n",
       "5            [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "11                                                   [O, O, O]  \n",
       "13           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "18           [O, O, O, B-Unknown, I-Unknown, I-Unknown, O, ...  \n",
       "24           [O, O, B-Unknown, I-Unknown, I-Unknown, O, O, ...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_personname\":\"tag_personname_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_personname_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = \"model_output/crf_l2sgd_baseline/\"\n",
    "# Path(config.tokc_path+output_path).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_personname_expected</th>\n",
       "      <th>tag_personname_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id   pos  \\\n",
       "sentence_id                                                            \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...    IN   \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...  PRP$   \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...    NN   \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   PRP   \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   VBD   \n",
       "\n",
       "               sentence tag_personname_expected tag_personname_predicted  \n",
       "sentence_id                                                               \n",
       "5                 After                     [O]                        O  \n",
       "5                   his                     [O]                        O  \n",
       "5            ordination                     [O]                        O  \n",
       "5                    he                     [O]                        O  \n",
       "5                 spent                     [O]                        O  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns)[1:])\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_l2sgd_personname_labels_baseline.csv\"\n",
    "df_dev_exploded.to_csv(config.tokc_path+output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "### Contextual\n",
    "\n",
    "* **Features:** part-of-speech tag, first 2 letters of part-of-speech tag abbreviation, custom fastText embeddings\n",
    "* **Target:** Contextual label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_cont\n",
    "df_dev = df_dev_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_contextual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [B-Stereotype], [I-Stereotype], [I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      token_id  \\\n",
       "sentence_id                                                      \n",
       "5            [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "11                                             [308, 309, 310]   \n",
       "13           [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "18           [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "24           [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                           pos  \\\n",
       "sentence_id                                                      \n",
       "5            [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "11                                                 [NN, :, NN]   \n",
       "13           [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "18           [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "24           [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                                      sentence  \\\n",
       "sentence_id                                                      \n",
       "5            [After, his, ordination, he, spent, three, yea...   \n",
       "11                                        [Identifier, :, AA6]   \n",
       "13           [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "18           [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "24           [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                                                tag_contextual  \n",
       "sentence_id                                                     \n",
       "5            [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "11                                             [[O], [O], [O]]  \n",
       "13           [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  \n",
       "18           [[O], [O], [B-Stereotype], [I-Stereotype], [I-...  \n",
       "24           [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Title', 'NN', ['O']), (':', ':', ['O']), ('Papers', 'NNS', ['O'])]\n",
      "[('After', 'IN', ['O']), ('his', 'PRP$', ['O']), ('ordination', 'NN', ['O'])]\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_cont = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_contextual\")\n",
    "print(train_sentences_cont[0][:3])\n",
    "dev_sentences_cont = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_contextual\")\n",
    "print(dev_sentences_cont[0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Contextual** category of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_cont\n",
    "dev_sentences = dev_sentences_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn_crfsuite.CRF(algorithm=algorithms[1], c2=0.1, max_iterations=100, all_possible_transitions=True)     # up to 1000 iterations allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Stereotype', 'I-Stereotype', 'B-Occupation', 'I-Occupation', 'B-Omission', 'I-Omission']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.2253245849929287\n",
      "  - Prec: 0.6104219492051156\n",
      "  - Rec 0.1485342019543974\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_contextual_expected</th>\n",
       "      <th>tag_contextual_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [B-Stereotype], [I-Stereotype], [I-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  sentence_id                                           token_id  \\\n",
       "0      0            5  [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "1      1           11                                    [308, 309, 310]   \n",
       "2      2           13  [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "3      3           18  [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "4      4           24  [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "1                                        [NN, :, NN]   \n",
       "2  [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "3  [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "4  [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [After, his, ordination, he, spent, three, yea...   \n",
       "1                               [Identifier, :, AA6]   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "4  [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                             tag_contextual_expected  \\\n",
       "0  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "1                                    [[O], [O], [O]]   \n",
       "2  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "3  [[O], [O], [B-Stereotype], [I-Stereotype], [I-...   \n",
       "4  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "\n",
       "                            tag_contextual_predicted  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1                                          [O, O, O]  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_contextual\":\"tag_contextual_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_contextual_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = \"model_output/crf_l2sgd_baseline/\"\n",
    "# Path(config.tokc_path+output_path).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_contextual_expected</th>\n",
       "      <th>tag_contextual_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id   pos    sentence tag_contextual_expected  \\\n",
       "0            5      154    IN       After                     [O]   \n",
       "0            5      155  PRP$         his                     [O]   \n",
       "0            5      156    NN  ordination                     [O]   \n",
       "0            5      157   PRP          he                     [O]   \n",
       "0            5      158   VBD       spent                     [O]   \n",
       "\n",
       "  tag_contextual_predicted  \n",
       "0                        O  \n",
       "0                        O  \n",
       "0                        O  \n",
       "0                        O  \n",
       "0                        O  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.drop(columns=[\"index\"])\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns)[1:])\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_l2sgd_contextual_labels_baseline.csv\"\n",
    "df_dev_exploded.to_csv(config.tokc_path+output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## TO DO: 2. Performance Evaluation\n",
    "\n",
    "### Strict Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the development data's test, the predicted labels will be deemed incorrect.\n",
    "\n",
    "As with the manual annotation evaluation, we want to evaluate the predictions more loosely, considering overlapping text spans in addition to exactly matching text spans.  Save the predictions for each token and then use IntervalTree to evaluate performance considering overlapping labels, rather than only exactly matching labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_cat_linguistic_expected</th>\n",
       "      <th>tag_cat_personname_expected</th>\n",
       "      <th>tag_cat_contextual_expected</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "      <th>tag_cat_personname_predicted</th>\n",
       "      <th>tag_cat_contextual_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id   pos       token tag_cat_linguistic_expected  \\\n",
       "sentence_id                                                          \n",
       "5                154    IN       After                           O   \n",
       "5                155  PRP$         his                B-Linguistic   \n",
       "5                156    NN  ordination                           O   \n",
       "5                157   PRP          he                B-Linguistic   \n",
       "5                158   VBD       spent                           O   \n",
       "\n",
       "            tag_cat_personname_expected tag_cat_contextual_expected  \\\n",
       "sentence_id                                                           \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "5                                     O                           O   \n",
       "\n",
       "            tag_cat_linguistic_predicted tag_cat_personname_predicted  \\\n",
       "sentence_id                                                             \n",
       "5                                      O                            O   \n",
       "5                           B-Linguistic                            O   \n",
       "5                                      O                            O   \n",
       "5                           B-Linguistic                            O   \n",
       "5                                      O                            O   \n",
       "\n",
       "            tag_cat_contextual_predicted  \n",
       "sentence_id                               \n",
       "5                                      O  \n",
       "5                                      O  \n",
       "5                                      O  \n",
       "5                                      O  \n",
       "5                                      O  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "df_dev_exploded = df_dev_exploded.rename(columns={\"sentence\":\"token\"})\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152711, 9)\n",
      "(152711, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_dev_exploded.shape)\n",
    "print(df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the grouped (one row per sentence) and exploded (one row per token) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped.to_csv(config.tokc_path+\"model_output/categoryTags_crfL2sgd_POS-fastText100_bySentence.csv\")\n",
    "df_dev_exploded.to_csv(config.tokc_path+\"model_output/categoryTags_crfL2sgd_POS-fastText100_byToken.csv\")\n",
    "# df_dev_exploded = pd.read_csv(config.tokc_path+\"model_output/categoryTags_crfL2sgd_POS-CustomFastText_byToken.csv\")\n",
    "# df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly evaluate the **Linguistic** tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_exploded = df_dev_exploded.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_cat_linguistic_expected</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "      <th>strict_agreement</th>\n",
       "      <th>match_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>TP</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>TP</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id       token tag_cat_linguistic_expected  \\\n",
       "0            5      154       After                           O   \n",
       "1            5      155         his                B-Linguistic   \n",
       "2            5      156  ordination                           O   \n",
       "3            5      157          he                B-Linguistic   \n",
       "4            5      158       spent                           O   \n",
       "\n",
       "  tag_cat_linguistic_predicted strict_agreement   match_type  \n",
       "0                            O               TN  exact_match  \n",
       "1                 B-Linguistic               TP  exact_match  \n",
       "2                            O               TN  exact_match  \n",
       "3                 B-Linguistic               TP  exact_match  \n",
       "4                            O               TN  exact_match  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = \"linguistic\"\n",
    "tags = [\"B-Linguistic\", \"I-Linguistic\"]\n",
    "subdf_pred_ling = utils.addCatAgreementAndMatchTypeCols(df_dev_exploded, category, tags)\n",
    "subdf_pred_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linguistic_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict_agreement</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>150435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  linguistic_count\n",
       "strict_agreement                  \n",
       "FN                             711\n",
       "FP                             359\n",
       "TN                          150435\n",
       "TP                            1206"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_ling_stats = subdf_pred_ling.groupby(\"strict_agreement\").count()\n",
    "subdf_pred_ling_stats = subdf_pred_ling_stats[[\"token_id\"]]\n",
    "subdf_pred_ling_stats = subdf_pred_ling_stats.rename(columns={\"token_id\":\"linguistic_count\"})\n",
    "subdf_pred_ling_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linguistic_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category_match</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_match</th>\n",
       "      <td>151641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mismatch</th>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                linguistic_count\n",
       "match_type                      \n",
       "category_match                 1\n",
       "exact_match               151641\n",
       "mismatch                    1069"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_ling_stats2 = subdf_pred_ling.groupby(\"match_type\").count()\n",
    "subdf_pred_ling_stats2 = subdf_pred_ling_stats2[[\"token_id\"]]\n",
    "subdf_pred_ling_stats2 = subdf_pred_ling_stats2.rename(columns={\"token_id\":\"linguistic_count\"})\n",
    "subdf_pred_ling_stats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly evaluate the **Person Name** tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_cat_personname_expected</th>\n",
       "      <th>tag_cat_personname_predicted</th>\n",
       "      <th>strict_agreement</th>\n",
       "      <th>match_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id       token tag_cat_personname_expected  \\\n",
       "0            5      154       After                           O   \n",
       "1            5      155         his                           O   \n",
       "2            5      156  ordination                           O   \n",
       "3            5      157          he                           O   \n",
       "4            5      158       spent                           O   \n",
       "\n",
       "  tag_cat_personname_predicted strict_agreement   match_type  \n",
       "0                            O               TN  exact_match  \n",
       "1                            O               TN  exact_match  \n",
       "2                            O               TN  exact_match  \n",
       "3                            O               TN  exact_match  \n",
       "4                            O               TN  exact_match  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = \"personname\"\n",
    "tags = [\"B-Person-Name\", \"I-Person-Name\"]\n",
    "subdf_pred_pers = utils.addCatAgreementAndMatchTypeCols(df_dev_exploded, category, tags)\n",
    "subdf_pred_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personname_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict_agreement</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>145256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>2514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  personname_count\n",
       "strict_agreement                  \n",
       "FN                            4370\n",
       "FP                             571\n",
       "TN                          145256\n",
       "TP                            2514"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_pers_stats = subdf_pred_pers.groupby(\"strict_agreement\").count()\n",
    "subdf_pred_pers_stats = subdf_pred_pers_stats[[\"token_id\"]]\n",
    "subdf_pred_pers_stats = subdf_pred_pers_stats.rename(columns={\"token_id\":\"personname_count\"})\n",
    "subdf_pred_pers_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personname_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category_match</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_match</th>\n",
       "      <td>147770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mismatch</th>\n",
       "      <td>4751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                personname_count\n",
       "match_type                      \n",
       "category_match               190\n",
       "exact_match               147770\n",
       "mismatch                    4751"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_pers_stats2 = subdf_pred_pers.groupby(\"match_type\").count()\n",
    "subdf_pred_pers_stats2 = subdf_pred_pers_stats2[[\"token_id\"]]\n",
    "subdf_pred_pers_stats2 = subdf_pred_pers_stats2.rename(columns={\"token_id\":\"personname_count\"})\n",
    "subdf_pred_pers_stats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly evaluate the **Contextual** tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_cat_contextual_expected</th>\n",
       "      <th>tag_cat_contextual_predicted</th>\n",
       "      <th>strict_agreement</th>\n",
       "      <th>match_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>TN</td>\n",
       "      <td>exact_match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id       token tag_cat_contextual_expected  \\\n",
       "0            5      154       After                           O   \n",
       "1            5      155         his                           O   \n",
       "2            5      156  ordination                           O   \n",
       "3            5      157          he                           O   \n",
       "4            5      158       spent                           O   \n",
       "\n",
       "  tag_cat_contextual_predicted strict_agreement   match_type  \n",
       "0                            O               TN  exact_match  \n",
       "1                            O               TN  exact_match  \n",
       "2                            O               TN  exact_match  \n",
       "3                            O               TN  exact_match  \n",
       "4                            O               TN  exact_match  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = \"contextual\"\n",
    "tags = [\"B-Contextual\", \"I-Contextual\"]\n",
    "subdf_pred_cont = utils.addCatAgreementAndMatchTypeCols(df_dev_exploded, category, tags)\n",
    "subdf_pred_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contextual_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict_agreement</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>3959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>147313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  contextual_count\n",
       "strict_agreement                  \n",
       "FN                            3959\n",
       "FP                             744\n",
       "TN                          147313\n",
       "TP                             695"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_cont_stats = subdf_pred_cont.groupby(\"strict_agreement\").count()\n",
    "subdf_pred_cont_stats = subdf_pred_cont_stats[[\"token_id\"]]\n",
    "subdf_pred_cont_stats = subdf_pred_cont_stats.rename(columns={\"token_id\":\"contextual_count\"})\n",
    "subdf_pred_cont_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contextual_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category_match</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact_match</th>\n",
       "      <td>148008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mismatch</th>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                contextual_count\n",
       "match_type                      \n",
       "category_match               153\n",
       "exact_match               148008\n",
       "mismatch                    4550"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_cont_stats2 = subdf_pred_cont.groupby(\"match_type\").count()\n",
    "subdf_pred_cont_stats2 = subdf_pred_cont_stats2[[\"token_id\"]]\n",
    "subdf_pred_cont_stats2 = subdf_pred_cont_stats2.rename(columns={\"token_id\":\"contextual_count\"})\n",
    "subdf_pred_cont_stats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the statistics and calculate precision, recall, and F1 scores for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strict_agreement</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linguistic_count</th>\n",
       "      <td>711</td>\n",
       "      <td>359</td>\n",
       "      <td>150435</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personname_count</th>\n",
       "      <td>4370</td>\n",
       "      <td>571</td>\n",
       "      <td>145256</td>\n",
       "      <td>2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contextual_count</th>\n",
       "      <td>3959</td>\n",
       "      <td>744</td>\n",
       "      <td>147313</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strict_agreement    FN   FP      TN    TP\n",
       "linguistic_count   711  359  150435  1206\n",
       "personname_count  4370  571  145256  2514\n",
       "contextual_count  3959  744  147313   695"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_stats = pd.concat([subdf_pred_ling_stats.T, subdf_pred_pers_stats.T, subdf_pred_cont_stats.T])\n",
    "subdf_pred_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strict_agreement</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linguistic_count</th>\n",
       "      <td>711</td>\n",
       "      <td>359</td>\n",
       "      <td>150435</td>\n",
       "      <td>1206</td>\n",
       "      <td>0.770607</td>\n",
       "      <td>0.629108</td>\n",
       "      <td>0.692705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personname_count</th>\n",
       "      <td>4370</td>\n",
       "      <td>571</td>\n",
       "      <td>145256</td>\n",
       "      <td>2514</td>\n",
       "      <td>0.814911</td>\n",
       "      <td>0.365195</td>\n",
       "      <td>0.504364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contextual_count</th>\n",
       "      <td>3959</td>\n",
       "      <td>744</td>\n",
       "      <td>147313</td>\n",
       "      <td>695</td>\n",
       "      <td>0.482974</td>\n",
       "      <td>0.149334</td>\n",
       "      <td>0.228131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strict_agreement    FN   FP      TN    TP  precision    recall       f_1\n",
       "linguistic_count   711  359  150435  1206   0.770607  0.629108  0.692705\n",
       "personname_count  4370  571  145256  2514   0.814911  0.365195  0.504364\n",
       "contextual_count  3959  744  147313   695   0.482974  0.149334  0.228131"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lprec, lrec, lf = utils.precisionRecallF1(subdf_pred_stats.TP.values[0], subdf_pred_stats.FP.values[0], subdf_pred_stats.FN.values[0])\n",
    "pprec, prec, pf = utils.precisionRecallF1(subdf_pred_stats.TP.values[1], subdf_pred_stats.FP.values[1], subdf_pred_stats.FN.values[1])\n",
    "cprec, crec, cf = utils.precisionRecallF1(subdf_pred_stats.TP.values[2], subdf_pred_stats.FP.values[2], subdf_pred_stats.FN.values[2])\n",
    "precision = [lprec, pprec, cprec]\n",
    "recall = [lrec, prec, crec]\n",
    "f_1 = [lf, pf, cf]\n",
    "subdf_pred_stats.insert(len(list(subdf_pred_stats.columns)), \"precision\", precision)\n",
    "subdf_pred_stats.insert(len(list(subdf_pred_stats.columns)), \"recall\", recall)\n",
    "subdf_pred_stats.insert(len(list(subdf_pred_stats.columns)), \"f_1\", f_1)\n",
    "subdf_pred_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>match_type</th>\n",
       "      <th>category_match</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>mismatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linguistic_count</th>\n",
       "      <td>1</td>\n",
       "      <td>151641</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personname_count</th>\n",
       "      <td>190</td>\n",
       "      <td>147770</td>\n",
       "      <td>4751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contextual_count</th>\n",
       "      <td>153</td>\n",
       "      <td>148008</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "match_type        category_match  exact_match  mismatch\n",
       "linguistic_count               1       151641      1069\n",
       "personname_count             190       147770      4751\n",
       "contextual_count             153       148008      4550"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_pred_stats2 = pd.concat([subdf_pred_ling_stats2.T, subdf_pred_pers_stats2.T, subdf_pred_cont_stats2.T])\n",
    "subdf_pred_stats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf_pred_stats.to_csv(config.tokc_path+\"model_output/strict_agreement_stats_fastText100_crf.csv\")\n",
    "subdf_pred_stats2.to_csv(config.tokc_path+\"model_output/match_types_fastText100_crf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loose Evaluation\n",
    "\n",
    "Conduct a loose evaluation of the model's performance (as the manual annotation were evaluated), considering any overlapping or envelopping expected and predicted annotations to be matches, in addition to exactly-matching expected and predicted annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(12, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>(17, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>(22, 23)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_id  sentence_id token_offsets\n",
       "0         0            0       (0, 10)\n",
       "1         1            0      (10, 11)\n",
       "2         2            0      (12, 15)\n",
       "3         3            1      (17, 22)\n",
       "4         4            1      (22, 23)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the start and end offsets of the tokens\n",
    "tok_df = pd.read_csv(config.tokc_path+\"desc_sent_ann_token_tag.csv\", usecols=[\"token_id\", \"sentence_id\", \"token_offsets\"])\n",
    "tok_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag_cat_linguistic_expected</th>\n",
       "      <th>tag_cat_linguistic_predicted</th>\n",
       "      <th>tag_cat_personname_expected</th>\n",
       "      <th>tag_cat_personname_predicted</th>\n",
       "      <th>tag_cat_contextual_expected</th>\n",
       "      <th>tag_cat_contextual_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>(907, 912)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>(913, 916)</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>(917, 927)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>(928, 930)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>B-Linguistic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>(931, 936)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id       token token_offsets   pos  \\\n",
       "0            5      154       After    (907, 912)    IN   \n",
       "1            5      155         his    (913, 916)  PRP$   \n",
       "2            5      156  ordination    (917, 927)    NN   \n",
       "3            5      157          he    (928, 930)   PRP   \n",
       "4            5      158       spent    (931, 936)   VBD   \n",
       "\n",
       "  tag_cat_linguistic_expected tag_cat_linguistic_predicted  \\\n",
       "0                           O                            O   \n",
       "1                B-Linguistic                 B-Linguistic   \n",
       "2                           O                            O   \n",
       "3                B-Linguistic                 B-Linguistic   \n",
       "4                           O                            O   \n",
       "\n",
       "  tag_cat_personname_expected tag_cat_personname_predicted  \\\n",
       "0                           O                            O   \n",
       "1                           O                            O   \n",
       "2                           O                            O   \n",
       "3                           O                            O   \n",
       "4                           O                            O   \n",
       "\n",
       "  tag_cat_contextual_expected tag_cat_contextual_predicted  \n",
       "0                           O                            O  \n",
       "1                           O                            O  \n",
       "2                           O                            O  \n",
       "3                           O                            O  \n",
       "4                           O                            O  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the offsets data to the dev data, keeping only the tokens included in the dev data\n",
    "df_dev_exploded = df_dev_exploded.reset_index()\n",
    "join_cols = [\"sentence_id\", \"token_id\"]\n",
    "df_pred = df_dev_exploded.join(tok_df.set_index(join_cols), on=join_cols, how=\"left\")\n",
    "df_pred = df_pred[[\"sentence_id\", \"token_id\", \"token\", \"token_offsets\", \"pos\", \n",
    "                   \"tag_cat_linguistic_expected\", \"tag_cat_linguistic_predicted\",\n",
    "                   \"tag_cat_personname_expected\", \"tag_cat_personname_predicted\",\n",
    "                   \"tag_cat_contextual_expected\", \"tag_cat_contextual_predicted\"\n",
    "                  ]]\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_pred.isna().values.any() == False, \"There should be no NaN values in any of the prediction DataFrame's columns.\"\n",
    "assert df_pred.shape[0] == df_dev_exploded.shape[0], \"There should be the same number of rows as the dev DataFrame prior to the join.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the offsets to tuples of ints\n",
    "offsets = list(df_pred.token_offsets)\n",
    "offsets = [tuple(((offset_pair[1:-1]).split(\", \"))) for offset_pair in offsets]\n",
    "offsets = [(int(start_offset), int(end_offset)) for start_offset,end_offset in offsets]\n",
    "# print(type(offsets[0]), type(offsets[0][0]), type(offsets[0][1]))\n",
    "col_i = list(df_pred.columns).index(\"token_offsets\")\n",
    "df_pred = df_pred.drop(columns=[\"token_offsets\"])\n",
    "df_pred.insert((col_i-1), \"token_offsets\", offsets)\n",
    "# df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many expected **Linguistic** tags overlap, envelop/fall within, or exactly match predicted Linguistic tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Linguistic', 'I-Linguistic']\n",
      "---------------------------------------\n",
      "TP: 2730 | FP: 314 | FN: 673\n",
      "---------------------------------------\n",
      "Precision: 0.8968462549277266\n",
      "Recall: 0.8022333235380547\n",
      "F_1 Score: 0.8469055374592834\n"
     ]
    }
   ],
   "source": [
    "# LINGUISTIC\n",
    "ling_tags = [\"B-Linguistic\", \"I-Linguistic\"]\n",
    "b_ling_exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_expected\", ling_tags)\n",
    "b_ling_pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_predicted\", ling_tags)\n",
    "tp, fp, fn = utils.looseAgreement(b_ling_exp_tree, b_ling_pred_tree)\n",
    "print(ling_tags)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-Linguistic\n",
      "---------------------------------------\n",
      "TP: 2389 | FP: 274 | FN: 467\n",
      "---------------------------------------\n",
      "Precision: 0.8971085242208036\n",
      "Recall: 0.836484593837535\n",
      "F_1 Score: 0.8657365464758109\n"
     ]
    }
   ],
   "source": [
    "# B-LINGUISTIC\n",
    "b_ling_exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_expected\", [ling_tags[0]])\n",
    "b_ling_pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_predicted\", [ling_tags[0]])\n",
    "tp, fp, fn = utils.looseAgreement(b_ling_exp_tree, b_ling_pred_tree)\n",
    "print(ling_tags[0])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Linguistic\n",
      "---------------------------------------\n",
      "TP: 65 | FP: 44 | FN: 212\n",
      "---------------------------------------\n",
      "Precision: 0.5963302752293578\n",
      "Recall: 0.23465703971119134\n",
      "F_1 Score: 0.3367875647668394\n"
     ]
    }
   ],
   "source": [
    "# I-LINGUISTIC\n",
    "b_ling_exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_expected\", [ling_tags[1]])\n",
    "b_ling_pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_linguistic_predicted\", [ling_tags[1]])\n",
    "tp, fp, fn = utils.looseAgreement(b_ling_exp_tree, b_ling_pred_tree)\n",
    "print(ling_tags[1])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many expected **Person Name** tags overlap, envelop/fall within, or exactly match predicted Person Name tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Person-Name', 'I-Person-Name']\n",
      "---------------------------------------\n",
      "TP: 21722 | FP: 328 | FN: 3982\n",
      "---------------------------------------\n",
      "Precision: 0.9851247165532879\n",
      "Recall: 0.8450824774354186\n",
      "F_1 Score: 0.9097457804581816\n"
     ]
    }
   ],
   "source": [
    "# PERSON NAME\n",
    "tags = [\"B-Person-Name\", \"I-Person-Name\"]\n",
    "exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_expected\", tags)\n",
    "pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_predicted\", tags)\n",
    "tp, fp, fn = utils.looseAgreement(exp_tree, pred_tree)\n",
    "print(tags)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-Person-Name\n",
      "---------------------------------------\n",
      "TP: 4792 | FP: 199 | FN: 1594\n",
      "---------------------------------------\n",
      "Precision: 0.9601282308154678\n",
      "Recall: 0.7503914813654871\n",
      "F_1 Score: 0.8424013360288302\n"
     ]
    }
   ],
   "source": [
    "# B-PERSON-NAME\n",
    "exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_expected\", [tags[0]])\n",
    "pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_predicted\", [tags[0]])\n",
    "tp, fp, fn = utils.looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[0])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Person-Name\n",
      "---------------------------------------\n",
      "TP: 8120 | FP: 301 | FN: 2712\n",
      "---------------------------------------\n",
      "Precision: 0.9642560266001663\n",
      "Recall: 0.7496307237813885\n",
      "F_1 Score: 0.8435049083259752\n"
     ]
    }
   ],
   "source": [
    "# I-PERSON-NAME\n",
    "exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_expected\", [tags[1]])\n",
    "pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_personname_predicted\", [tags[1]])\n",
    "tp, fp, fn = utils.looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[1])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many expected **Contextual** tags overlap, envelop/fall within, or exactly match predicted Person Name tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Contextual', 'I-Contextual']\n",
      "---------------------------------------\n",
      "TP: 6238 | FP: 554 | FN: 3671\n",
      "---------------------------------------\n",
      "Precision: 0.9184334511189635\n",
      "Recall: 0.6295287112725805\n",
      "F_1 Score: 0.7470211364588947\n"
     ]
    }
   ],
   "source": [
    "# CONTEXTUAL\n",
    "tags = [\"B-Contextual\", \"I-Contextual\"]\n",
    "exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_expected\", tags)\n",
    "pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_predicted\", tags)\n",
    "tp, fp, fn = utils.looseAgreement(exp_tree, pred_tree)\n",
    "print(tags)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-Contextual\n",
      "---------------------------------------\n",
      "TP: 2585 | FP: 407 | FN: 1341\n",
      "---------------------------------------\n",
      "Precision: 0.8639705882352942\n",
      "Recall: 0.6584309730005095\n",
      "F_1 Score: 0.7473258167100318\n"
     ]
    }
   ],
   "source": [
    "# B-CONTEXTUAL\n",
    "exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_expected\", [tags[0]])\n",
    "pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_predicted\", [tags[0]])\n",
    "tp, fp, fn = utils.looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[0])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-Contextual\n",
      "---------------------------------------\n",
      "TP: 1046 | FP: 207 | FN: 2586\n",
      "---------------------------------------\n",
      "Precision: 0.8347964884277733\n",
      "Recall: 0.2879955947136564\n",
      "F_1 Score: 0.4282497441146366\n"
     ]
    }
   ],
   "source": [
    "# I-CONTEXTUAL\n",
    "exp_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_expected\", [tags[1]])\n",
    "pred_tree = utils.createIntervalTree(df_pred, \"token_offsets\", \"tag_cat_contextual_predicted\", [tags[1]])\n",
    "tp, fp, fn = utils.looseAgreement(exp_tree, pred_tree)\n",
    "print(tags[1])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"TP:\",tp, \"| FP:\",fp, \"| FN:\",fn)\n",
    "print(\"---------------------------------------\")\n",
    "prec, rec, f1 = utils.precisionRecallF1(tp, fp, fn)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F_1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export summary stats of loose (where overlap, envelop, and exact match all count as correct) agreement scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (gender-bias)",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

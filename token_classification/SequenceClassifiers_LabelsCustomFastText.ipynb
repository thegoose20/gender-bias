{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Biased Sequence Classifiers\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "### Target: Labels\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/crf_l2sgd/`\n",
    "* Sequence classification\n",
    "    * 9 lables (2 from original annotation taxonomy weren't applied during manual annotation):\n",
    "        1. Person Name: Unknown, Feminine, Masculine (Non-binary not annotated with)\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Occupation, Omission, Stereotype (Empowering not annotated with)\n",
    "    * 1 model per category\n",
    "* Word embeddings\n",
    "    * Custom fastText (word2vec with subwords, trained on Archives' descriptive metadata extracted in October 2020)  \n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[0.](#0) Preprocessing\n",
    "\n",
    "  * [Hypotheses](#h)\n",
    "\n",
    "[1.](#1) Models\n",
    "\n",
    "  * [Linguistic](#ling)\n",
    "  * [Person Name](#pers)\n",
    "  * [Contextual](#cont)\n",
    "\n",
    "[2.](#2) Performance Evaluation\n",
    "\n",
    "[3.](#3) Transitions\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.stats\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay#, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate rows with all but the same annotation ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that won't be used as features for the classifiers and remove any duplicate rows that remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"pos\", \"token\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[cols_to_keep]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev[cols_to_keep]\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate subsets of data for each category so they can be used with three separate models, replacing `NaN` tag values with `'O'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine' 'B-Gendered-Pronoun' 'B-Gendered-Role' 'B-Generalization'\n",
      " 'B-Masculine' 'B-Occupation' 'B-Omission' 'B-Stereotype' 'B-Unknown'\n",
      " 'I-Feminine' 'I-Gendered-Pronoun' 'I-Gendered-Role' 'I-Generalization'\n",
      " 'I-Masculine' 'I-Occupation' 'I-Omission' 'I-Stereotype' 'I-Unknown' 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = (df_train.tag.unique())\n",
    "tags.sort()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_cat_tags = ['B-Gendered-Pronoun', 'B-Gendered-Role', 'B-Generalization', 'I-Gendered-Pronoun', 'I-Gendered-Role', 'I-Generalization']\n",
    "df_train_ling = df_train.loc[df_train.tag.isin(ling_cat_tags)]\n",
    "df_dev_ling = df_dev.loc[df_dev.tag.isin(ling_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Unknown']\n",
    "df_train_pers = df_train.loc[df_train.tag.isin(pers_cat_tags)]\n",
    "df_dev_pers = df_dev.loc[df_dev.tag.isin(pers_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cat_tags = ['B-Occupation', 'B-Omission', 'B-Stereotype', 'I-Occupation', 'I-Omission', 'I-Stereotype']\n",
    "df_train_cont = df_train.loc[df_train.tag.isin(cont_cat_tags)]\n",
    "df_dev_cont = df_dev.loc[df_dev.tag.isin(cont_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.drop(columns=[\"tag\"])).drop_duplicates()\n",
    "df_dev = (df_dev.drop(columns=[\"tag\"])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"sentence_id\", \"token_id\", \"pos\", \"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train.join(df_train_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_ling = df_train_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_train_ling = df_train_ling.fillna('O')\n",
    "# df_train_ling.head()\n",
    "df_dev_ling = df_dev.join(df_dev_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_ling = df_dev_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_dev_ling = df_dev_ling.fillna('O')\n",
    "# df_dev_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pers = df_train.join(df_train_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_pers = df_train_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_train_pers = df_train_pers.fillna('O')\n",
    "df_dev_pers = df_dev.join(df_dev_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_pers = df_dev_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_dev_pers = df_dev_pers.fillna('O')\n",
    "# df_dev_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Papers</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>DT</td>\n",
       "      <td>The</td>\n",
       "      <td>B-Stereotype</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  pos   token tag_contextual\n",
       "3            1         3   NN   Title              O\n",
       "4            1         4    :       :              O\n",
       "5            1         5  NNS  Papers              O\n",
       "6            1         6   IN      of              O\n",
       "7            1         7   DT     The   B-Stereotype"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cont = df_train.join(df_train_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_cont = df_train_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_train_cont = df_train_cont.fillna('O')\n",
    "df_dev_cont = df_dev.join(df_dev_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_cont = df_dev_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_dev_cont = df_dev_cont.fillna('O')\n",
    "df_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train_ling.drop_duplicates()\n",
    "df_dev_ling = df_dev_ling.drop_duplicates()\n",
    "df_train_pers = df_train_pers.drop_duplicates()\n",
    "df_dev_pers = df_dev_pers.drop_duplicates()\n",
    "df_train_cont = df_train_cont.drop_duplicates()\n",
    "df_dev_cont = df_dev_cont.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452222 452086\n",
      "455327 452086\n",
      "453119 452086\n",
      "\n",
      "152494 152455\n",
      "153568 152455\n",
      "152768 152455\n"
     ]
    }
   ],
   "source": [
    "train_dfs = [df_train_ling, df_train_pers, df_train_cont]\n",
    "dev_dfs = [df_dev_ling, df_dev_pers, df_dev_cont]\n",
    "for df in train_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))\n",
    "print()\n",
    "for df in dev_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens can have multiple tags, so there are more rows than unique token IDs.  In order to pass the data into a CRF model, we need to have one tag per token, so we'll simply **take the first tag** when we extract features for each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Define feature dictionaries for baseline models, using word embeddings, tokens, and part-of-speech tags as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Embeddings**\n",
    "\n",
    "Use the custom fastText word embeddings, trained on the entire dataset of descriptive metadata from the Archives (harvested in October 2020) using the Continuous Bag-of-Words (CBOW) algorithm.  Subword embeddings (for subwords from 2 to 6 characters long, inclusive) are used to infer the embeddings for out-of-vocabulary (OOV) words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the word embedding model trained on lowercased text to 100 dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = config.tokc_path+\"fasttext100_lowercased.model\"  #get_tmpfile()\n",
    "embedding_model = FastText.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35968\n",
      "Lowercased vocabulary size: 31335\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(df_train.token.unique())\n",
    "vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "# Get a vector representation of a token from a fastText word embedding model\n",
    "def extractEmbedding(token, fasttext_model=embedding_model):\n",
    "    if token.isalpha():\n",
    "        token = token.lower()\n",
    "    embedding = fasttext_model.wv[token]\n",
    "    return embedding\n",
    "\n",
    "def extractTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token,\n",
    "#         'token[-3:]': token[-3:]\n",
    "    }\n",
    "    \n",
    "    # Add each value in a token's word embedding as a separate feature\n",
    "    # Reference: https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training\n",
    "    embedding = extractEmbedding(token)\n",
    "    for i,n in enumerate(embedding):\n",
    "        features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractSentenceFeatures(sentence):\n",
    "    return [extractTokenFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def extractSentenceTargets(sentence):\n",
    "    return [tag_list[0] for token, pos, tag_list in sentence]\n",
    "\n",
    "def extractSentenceTokens(sentence):\n",
    "    return [token for token, pos, tag_list in sentence]\n",
    "\n",
    "################################################\n",
    "# For Person Name Model\n",
    "################################################\n",
    "def extractPersonNameTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token,\n",
    "        'pos': pos,\n",
    "        'pos[:2]': pos[:2],\n",
    "#         'token[-3:]': token[-3:]\n",
    "    }\n",
    "    \n",
    "    # Add each value in a token's word embedding as a separate feature\n",
    "    # Reference: https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training\n",
    "    embedding = extractEmbedding(token)\n",
    "    for i,n in enumerate(embedding):\n",
    "        features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractPersonNameSentenceFeatures(sentence):\n",
    "    return [extractPersonNameTokenFeatures(sentence, i) for i in range(len(sentence))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"h\"></a>\n",
    "#### Hypotheses:\n",
    "Note: Any features that improve a model's performance will be kept for subsequence feature engineering steps.\n",
    "\n",
    "**1. Part-of-Speech (POS) Tags**\n",
    "\n",
    "* POS tags will improve the Linguistic model's performance, raising the F1 score by over 0.1 - *countered*\n",
    "* POS tags will improve the Person Name model's performance, raising the F1 score by over 0.1 - *supported*\n",
    "* POS tags will not improve the Contextual model's performance, raising the F1 score by no more than 0.1 - *countered*\n",
    "\n",
    "**2. Token Suffixes (last 3 letters):**\n",
    "\n",
    "* Suffixes will improve the Linguistic model's F1 score by over 0.1 - *countered*\n",
    "* Suffixes will not change the Person Name model's F1 score by more than +0.1 or -0.1 - *countered (worsened performance >0.1)*\n",
    "* Suffixes will not improve the Contextual model's performance, raising the F1 score by no more than 0.1 - *supported*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Models\n",
    "<a id=\"ling\"></a>\n",
    "### Linguistic\n",
    "\n",
    "* **Features:** custom fastText embeddings, token suffixes\n",
    "* **Target:** Linguistic label category IOB tags\n",
    "* **Algorithm:** L2SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_ling\n",
    "df_dev = df_dev_ling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by token, so the all the tags for one token are recorded in a list for that token's row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by sentence, where each sentence is a list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Title', 'NN', ['O']), (':', ':', ['O']), ('Papers', 'NNS', ['O'])]\n",
      "[('After', 'IN', ['O']), ('his', 'PRP$', ['B-Gendered-Pronoun']), ('ordination', 'NN', ['O'])]\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_ling = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_linguistic\")\n",
    "# print(train_sentences_ling[0][:3])\n",
    "dev_sentences_ling = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_linguistic\")\n",
    "# print(dev_sentences_ling[0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_ling\n",
    "dev_sentences = dev_sentences_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** pa with pa_type=0 was best, however, arow with variance=0.5 also had strong performance, and is strongest with other categories, Person Name and Contextual, so we'll use arow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Linguistic** category of tags.  We'll increase the max_iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ling = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_ling.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Gendered-Pronoun', 'B-Generalization', 'B-Gendered-Role', 'I-Generalization', 'I-Gendered-Role', 'I-Gendered-Pronoun']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_ling.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_ling.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.5939825098668525\n",
      "  - Prec: 0.6556302138252653\n",
      "  - Rec 0.5489432703003337\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's scores were:\n",
    "  - F1: 0.6697698893667122\n",
    "  - Prec: 0.696012355375722\n",
    "  - Rec 0.6718576195773082\n",
    "  \n",
    "Adding part-of-speech tags seems to decrease the model's performance, **counter** to the hypothesis:\n",
    "  - F1: 0.5351115706558578\n",
    "  - Prec: 0.6588512211470845\n",
    "  - Rec 0.46051167964404893\n",
    "  \n",
    "Adding token suffixes also seems to decrease the model's performance (though not as much as adding POS tags), **counter** to the hypothesis:\n",
    "  - F1: 0.5939825098668525\n",
    "  - Prec: 0.6556302138252653\n",
    "  - Rec 0.5489432703003337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For closer inspection, save the prediction data in a directory specific to this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_linguistic\":\"tag_linguistic_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_linguistic_predicted\", y_pred)\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_linguistic_expected</th>\n",
       "      <th>tag_linguistic_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>[B-Gendered-Pronoun]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>[B-Gendered-Pronoun]</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id token_id   pos    sentence tag_linguistic_expected  \\\n",
       "0            5      154    IN       After                     [O]   \n",
       "0            5      155  PRP$         his    [B-Gendered-Pronoun]   \n",
       "0            5      156    NN  ordination                     [O]   \n",
       "0            5      157   PRP          he    [B-Gendered-Pronoun]   \n",
       "0            5      158   VBD       spent                     [O]   \n",
       "\n",
       "  tag_linguistic_predicted  \n",
       "0                        O  \n",
       "0                        O  \n",
       "0                        O  \n",
       "0       B-Gendered-Pronoun  \n",
       "0                        O  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns)[1:])\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"model_output/crf_l2sgd/\"\n",
    "Path(config.tokc_path+output_path).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"crf_l2sgd_linguistic_labels_withPOS.csv\"\n",
    "# df_dev_exploded.to_csv(config.tokc_path+output_path+filename)\n",
    "filename = \"crf_l2sgd_linguistic_labels_withSuffix.csv\"\n",
    "df_dev_exploded[[\"token_id\", \"tag_linguistic_expected\", \"tag_linguistic_predicted\"]].to_csv(config.tokc_path+output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pers\"></a>\n",
    "### Person Name\n",
    "\n",
    "* **Features:** custom fastText embeddings, POS tags, token suffixes\n",
    "* **Target:** Person-Name label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_pers\n",
    "df_dev = df_dev_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_pers = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_personname\")\n",
    "# print(train_sentences_pers[0][:3])\n",
    "dev_sentences_pers = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_personname\")\n",
    "# print(dev_sentences_pers[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_pers\n",
    "dev_sentences = dev_sentences_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=0.5 was best-performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pers = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_pers.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'I-Masculine', 'B-Masculine', 'B-Feminine', 'I-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_pers.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pers.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.4724254452794501\n",
      "  - Prec: 0.5036375286524056\n",
      "  - Rec 0.45406486640948707\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's performance scores were:\n",
    "  - F1: 0.4789287297354048\n",
    "  - Prec: 0.5381704595959792\n",
    "  - Rec 0.43620517216745247\n",
    "  \n",
    "Adding POS tags as features improves the performance of the Person Name sequence classification model, **supporting** our hypothesis:\n",
    "  - F1: 0.5011854407104209\n",
    "  - Prec: 0.5297892459718619\n",
    "  - Rec 0.4823546220888698\n",
    "  \n",
    "Adding token suffixes seems to worsen the performance of the model overall, **countering** our hypothesis:\n",
    "  - F1: 0.4724254452794501\n",
    "  - Prec: 0.5036375286524056\n",
    "  - Rec 0.45406486640948707"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further inspection, save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_personname_expected</th>\n",
       "      <th>tag_personname_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [B-Masculine], [I-Masculine], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, B-Unknown, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [B-Masculine], [I-Masculine], [I-Ma...</td>\n",
       "      <td>[O, O, B-Masculine, I-Masculine, I-Masculine, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                           token_id  \\\n",
       "0            5  [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "1           11                                    [308, 309, 310]   \n",
       "2           13  [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "3           18  [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "4           24  [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "1                                        [NN, :, NN]   \n",
       "2  [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "3  [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "4  [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [After, his, ordination, he, spent, three, yea...   \n",
       "1                               [Identifier, :, AA6]   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "4  [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                             tag_personname_expected  \\\n",
       "0  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "1                                    [[O], [O], [O]]   \n",
       "2  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "3  [[O], [O], [B-Masculine], [I-Masculine], [O], ...   \n",
       "4  [[O], [O], [B-Masculine], [I-Masculine], [I-Ma...   \n",
       "\n",
       "                            tag_personname_predicted  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1                                          [O, O, O]  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, B-Unknown, O, O, O, O, O, O, O...  \n",
       "4  [O, O, B-Masculine, I-Masculine, I-Masculine, ...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_personname\":\"tag_personname_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_personname_predicted\", y_pred)\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_personname_expected</th>\n",
       "      <th>tag_personname_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id   pos    sentence tag_personname_expected  \\\n",
       "sentence_id                                                      \n",
       "5                154    IN       After                     [O]   \n",
       "5                155  PRP$         his                     [O]   \n",
       "5                156    NN  ordination                     [O]   \n",
       "5                157   PRP          he                     [O]   \n",
       "5                158   VBD       spent                     [O]   \n",
       "\n",
       "            tag_personname_predicted  \n",
       "sentence_id                           \n",
       "5                                  O  \n",
       "5                                  O  \n",
       "5                                  O  \n",
       "5                                  O  \n",
       "5                                  O  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.set_index(\"sentence_id\")\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "# df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"crf_l2sgd_personname_labels_withPOS.csv\"\n",
    "# df_dev_exploded.to_csv(config.tokc_path+output_path+filename)\n",
    "filename = \"crf_l2sgd_personname_labels_withPOSSuffix.csv\"\n",
    "df_dev_exploded[[\"token_id\", \"tag_personname_expected\", \"tag_personname_predicted\"]].to_csv(config.tokc_path+output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "### Contextual\n",
    "\n",
    "* **Features:** custom fastText embeddings, token suffixes\n",
    "* **Target:** Contextual label category IOB tags\n",
    "* **Algorithm:** L2SGD\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_cont\n",
    "df_dev = df_dev_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_cont = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_contextual\")\n",
    "# print(train_sentences_cont[0][:3])\n",
    "dev_sentences_cont = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_contextual\")\n",
    "# print(dev_sentences_cont[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_cont\n",
    "dev_sentences = dev_sentences_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=0.5 was the best performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Contextual** category of tags.  We'll increase the maximum iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cont = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_cont.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Stereotype', 'I-Stereotype', 'B-Occupation', 'I-Occupation', 'B-Omission', 'I-Omission']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_cont.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_cont.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.4087296343564073\n",
      "  - Prec: 0.4288273306621178\n",
      "  - Rec 0.3930510314875136\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's performance scores were:\n",
    "  - F1: 0.40803990799640844\n",
    "  - Prec: 0.4124968743940007\n",
    "  - Rec 0.4091205211726384\n",
    "  \n",
    "Adding POS tags seems to decrease the model's performance, **counter** to the hypothesis:\n",
    "  - F1: 0.3848080068912827\n",
    "  - Prec: 0.41570355576471396\n",
    "  - Rec 0.358957654723127\n",
    "\n",
    "Adding token suffixes seems to have less than a 0.1 impact on the model's performance, in **support** of the hypothesis:\n",
    "  - F1: 0.4087296343564073\n",
    "  - Prec: 0.4288273306621178\n",
    "  - Rec 0.3930510314875136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further inspection, save the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_contextual_expected</th>\n",
       "      <th>tag_contextual_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>[IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...</td>\n",
       "      <td>[After, his, ordination, he, spent, three, yea...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Occupation, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>[308, 309, 310]</td>\n",
       "      <td>[NN, :, NN]</td>\n",
       "      <td>[Identifier, :, AA6]</td>\n",
       "      <td>[[O], [O], [O]]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>[321, 322, 323, 324, 325, 326, 327, 328, 329, ...</td>\n",
       "      <td>[NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...</td>\n",
       "      <td>[Scope, and, Contents, :, Sermons, and, addres...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>[498, 499, 500, 501, 502, 503, 504, 505, 506, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...</td>\n",
       "      <td>[In, 1941, Tom, Allan, married, Jane, Moore, a...</td>\n",
       "      <td>[[O], [O], [B-Stereotype], [I-Stereotype], [I-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Omission, I-O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>[649, 650, 651, 652, 653, 654, 655, 656, 657, ...</td>\n",
       "      <td>[IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...</td>\n",
       "      <td>[In, 1955, Rev, Tom, Allan, accepted, a, call,...</td>\n",
       "      <td>[[O], [O], [O], [O], [O], [O], [O], [O], [O], ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-Occupation, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                           token_id  \\\n",
       "0            5  [154, 155, 156, 157, 158, 159, 160, 161, 162, ...   \n",
       "1           11                                    [308, 309, 310]   \n",
       "2           13  [321, 322, 323, 324, 325, 326, 327, 328, 329, ...   \n",
       "3           18  [498, 499, 500, 501, 502, 503, 504, 505, 506, ...   \n",
       "4           24  [649, 650, 651, 652, 653, 654, 655, 656, 657, ...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [IN, PRP$, NN, PRP, VBD, CD, NNS, IN, DT, NN, ...   \n",
       "1                                        [NN, :, NN]   \n",
       "2  [NN, CC, NNS, :, NNS, CC, NNS, ,, JJ, ;, NNS, ...   \n",
       "3  [IN, CD, NNP, NNP, VBD, NNP, NNP, CC, PRP, VBD...   \n",
       "4  [IN, CD, NNP, NNP, NNP, VBD, DT, NN, TO, VB, N...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [After, his, ordination, he, spent, three, yea...   \n",
       "1                               [Identifier, :, AA6]   \n",
       "2  [Scope, and, Contents, :, Sermons, and, addres...   \n",
       "3  [In, 1941, Tom, Allan, married, Jane, Moore, a...   \n",
       "4  [In, 1955, Rev, Tom, Allan, accepted, a, call,...   \n",
       "\n",
       "                             tag_contextual_expected  \\\n",
       "0  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "1                                    [[O], [O], [O]]   \n",
       "2  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "3  [[O], [O], [B-Stereotype], [I-Stereotype], [I-...   \n",
       "4  [[O], [O], [O], [O], [O], [O], [O], [O], [O], ...   \n",
       "\n",
       "                            tag_contextual_predicted  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-Occupation, O...  \n",
       "1                                          [O, O, O]  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, B-Omission, I-O...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, B-Occupation, O...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag_contextual\":\"tag_contextual_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_contextual_predicted\", y_pred)\n",
    "df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_contextual_expected</th>\n",
       "      <th>tag_contextual_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id   pos    sentence tag_contextual_expected  \\\n",
       "sentence_id                                                      \n",
       "5                154    IN       After                     [O]   \n",
       "5                155  PRP$         his                     [O]   \n",
       "5                156    NN  ordination                     [O]   \n",
       "5                157   PRP          he                     [O]   \n",
       "5                158   VBD       spent                     [O]   \n",
       "\n",
       "            tag_contextual_predicted  \n",
       "sentence_id                           \n",
       "5                                  O  \n",
       "5                                  O  \n",
       "5                                  O  \n",
       "5                                  O  \n",
       "5                                  O  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.set_index(\"sentence_id\")\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"crf_l2sgd_contextual_labels_withPOS.csv\"\n",
    "# df_dev_exploded.to_csv(config.tokc_path+output_path+filename)\n",
    "filename = \"crf_l2sgd_contextual_labels_withPOSSuffixes.csv\"\n",
    "df_dev_exploded[[\"token_id\", \"tag_contextual_expected\", \"tag_contextual_predicted\"]].to_csv(config.tokc_path+output_path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## NOT YET UPDATED & RUN: 2. Performance Evaluation\n",
    "\n",
    "### Strict Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in evaluation approach is strict, so unless the model predictions' labels are on text spans that exactly match the development data's test, the predicted labels will be deemed incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"model_output/crf_l2sgd/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"contextual\"\n",
    "filename = \"crf_l2sgd_{}_labels_baseline.csv\".format(category)\n",
    "pred_cont = pd.read_csv(config.tokc_path+output_path+filename, index_col=0)\n",
    "pred_cont = utils.getColumnValuesAsLists(pred_cont, \"tag_{}_expected\".format(category))\n",
    "# pred_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"personname\"\n",
    "filename = \"crf_l2sgd_{}_labels_baseline.csv\".format(category)\n",
    "pred_pers = pd.read_csv(config.tokc_path+output_path+filename, index_col=0)\n",
    "pred_pers = utils.getColumnValuesAsLists(pred_pers, \"tag_{}_expected\".format(category))\n",
    "# pred_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"linguistic\"\n",
    "filename = \"crf_l2sgd_{}_labels_baseline.csv\".format(category)\n",
    "pred_ling = pd.read_csv(config.tokc_path+output_path+filename, index_col=0)\n",
    "pred_ling = utils.getColumnValuesAsLists(pred_ling, \"tag_{}_expected\".format(category))\n",
    "pred_ling = pred_ling.set_index(\"sentence_id\")\n",
    "# pred_ling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics for each category of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"contextual\"\n",
    "pred_cont = utils.isPredictedInExpected(pred_cont, \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), '_merge', 'O')\n",
    "# pred_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"personname\"\n",
    "pred_pers = utils.isPredictedInExpected(pred_pers, \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), '_merge', 'O')\n",
    "# pred_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"linguistic\"\n",
    "pred_ling = utils.isPredictedInExpected(pred_ling, \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), '_merge', 'O')\n",
    "# pred_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"contextual\"\n",
    "tags = ['B-Occupation', 'I-Occupation', 'B-Omission', 'I-Omission', 'B-Stereotype', 'I-Stereotype']\n",
    "pred_cont_stats = utils.getScoresByCatTags(\n",
    "    pred_cont, \"_merge\", tags[0], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_cont, \"_merge\", tags[i], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_cont_stats = pd.concat([pred_cont_stats, tag_stats])\n",
    "# pred_cont_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"personname\"\n",
    "tags = ['B-Feminine', 'I-Feminine', 'B-Masculine', 'I-Masculine', 'B-Unknown', 'I-Unknown', \"B-Nonbinary\", \"I-Nonbinary\"]\n",
    "pred_pers_stats = utils.getScoresByCatTags(\n",
    "    pred_pers, \"_merge\", tags[0], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_pers, \"_merge\", tags[i], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_pers_stats = pd.concat([pred_pers_stats, tag_stats])\n",
    "# pred_pers_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"linguistic\"\n",
    "tags = [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Generalization\", \"I-Generalization\"]\n",
    "pred_ling_stats = utils.getScoresByCatTags(\n",
    "    pred_ling, \"_merge\", tags[0], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_ling, \"_merge\", tags[i], \"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_ling_stats = pd.concat([pred_ling_stats, tag_stats])\n",
    "# pred_ling_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>270</td>\n",
       "      <td>191</td>\n",
       "      <td>350</td>\n",
       "      <td>0.646950</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.602929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>386</td>\n",
       "      <td>326</td>\n",
       "      <td>351</td>\n",
       "      <td>0.518464</td>\n",
       "      <td>0.476255</td>\n",
       "      <td>0.496464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Omission</td>\n",
       "      <td>429</td>\n",
       "      <td>546</td>\n",
       "      <td>524</td>\n",
       "      <td>0.489720</td>\n",
       "      <td>0.549843</td>\n",
       "      <td>0.518043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Omission</td>\n",
       "      <td>897</td>\n",
       "      <td>1194</td>\n",
       "      <td>522</td>\n",
       "      <td>0.304196</td>\n",
       "      <td>0.367865</td>\n",
       "      <td>0.333014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Stereotype</td>\n",
       "      <td>155</td>\n",
       "      <td>98</td>\n",
       "      <td>41</td>\n",
       "      <td>0.294964</td>\n",
       "      <td>0.209184</td>\n",
       "      <td>0.244776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Stereotype</td>\n",
       "      <td>492</td>\n",
       "      <td>360</td>\n",
       "      <td>148</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>0.231250</td>\n",
       "      <td>0.257840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>38</td>\n",
       "      <td>95</td>\n",
       "      <td>202</td>\n",
       "      <td>0.680135</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.752328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>143</td>\n",
       "      <td>149</td>\n",
       "      <td>402</td>\n",
       "      <td>0.729583</td>\n",
       "      <td>0.737615</td>\n",
       "      <td>0.733577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>236</td>\n",
       "      <td>280</td>\n",
       "      <td>456</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.658960</td>\n",
       "      <td>0.638655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>345</td>\n",
       "      <td>435</td>\n",
       "      <td>432</td>\n",
       "      <td>0.498270</td>\n",
       "      <td>0.555985</td>\n",
       "      <td>0.525547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>656</td>\n",
       "      <td>429</td>\n",
       "      <td>753</td>\n",
       "      <td>0.637056</td>\n",
       "      <td>0.534422</td>\n",
       "      <td>0.581243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>1157</td>\n",
       "      <td>818</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.606163</td>\n",
       "      <td>0.521109</td>\n",
       "      <td>0.560427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Nonbinary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Nonbinary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>29</td>\n",
       "      <td>168</td>\n",
       "      <td>715</td>\n",
       "      <td>0.809740</td>\n",
       "      <td>0.961022</td>\n",
       "      <td>0.878918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Pronoun</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>215</td>\n",
       "      <td>135</td>\n",
       "      <td>353</td>\n",
       "      <td>0.723361</td>\n",
       "      <td>0.621479</td>\n",
       "      <td>0.668561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Generalization</td>\n",
       "      <td>152</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Generalization</td>\n",
       "      <td>116</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.177305</td>\n",
       "      <td>0.243902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag(s)  false negative  false positive  true positive  \\\n",
       "0        B-Occupation             270             191            350   \n",
       "0        I-Occupation             386             326            351   \n",
       "0          B-Omission             429             546            524   \n",
       "0          I-Omission             897            1194            522   \n",
       "0        B-Stereotype             155              98             41   \n",
       "0        I-Stereotype             492             360            148   \n",
       "0          B-Feminine              38              95            202   \n",
       "0          I-Feminine             143             149            402   \n",
       "0         B-Masculine             236             280            456   \n",
       "0         I-Masculine             345             435            432   \n",
       "0           B-Unknown             656             429            753   \n",
       "0           I-Unknown            1157             818           1259   \n",
       "0         B-Nonbinary               0               0              0   \n",
       "0         I-Nonbinary               0               0              0   \n",
       "0  B-Gendered-Pronoun              29             168            715   \n",
       "0  I-Gendered-Pronoun              12               1              3   \n",
       "0     B-Gendered-Role             215             135            353   \n",
       "0     I-Gendered-Role              49              35             68   \n",
       "0    B-Generalization             152              52             58   \n",
       "0    I-Generalization             116              39             25   \n",
       "\n",
       "   precision    recall        f1  \n",
       "0   0.646950  0.564516  0.602929  \n",
       "0   0.518464  0.476255  0.496464  \n",
       "0   0.489720  0.549843  0.518043  \n",
       "0   0.304196  0.367865  0.333014  \n",
       "0   0.294964  0.209184  0.244776  \n",
       "0   0.291339  0.231250  0.257840  \n",
       "0   0.680135  0.841667  0.752328  \n",
       "0   0.729583  0.737615  0.733577  \n",
       "0   0.619565  0.658960  0.638655  \n",
       "0   0.498270  0.555985  0.525547  \n",
       "0   0.637056  0.534422  0.581243  \n",
       "0   0.606163  0.521109  0.560427  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "0   0.809740  0.961022  0.878918  \n",
       "0   0.750000  0.200000  0.315789  \n",
       "0   0.723361  0.621479  0.668561  \n",
       "0   0.660194  0.581197  0.618182  \n",
       "0   0.527273  0.276190  0.362500  \n",
       "0   0.390625  0.177305  0.243902  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.concat([pred_cont_stats, pred_pers_stats, pred_ling_stats])\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv(config.tokc_path+output_path+\"crf_l2sgd_baseline_performance_strict_alltags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotation Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loose Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the manual annotation evaluation, we want to evaluate the predictions more loosely, considering overlapping text spans in addition to exactly matching text spans.\n",
    "\n",
    "#### Token Agreement\n",
    "\n",
    "First, generalize the tokens' IOB tags to the label, and calculate agreement scores for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"contextual\"\n",
    "pred_cont_labels = pred_cont.copy()\n",
    "tag_exp = list(pred_cont_labels[\"tag_{}_expected\".format(category)])\n",
    "tag_pred = list(pred_cont_labels[\"tag_{}_predicted\".format(category)])\n",
    "label_exp = [[tag if tag == \"O\" else tag[2:] for tag in tag_exp_list] for tag_exp_list in tag_exp]\n",
    "label_pred = [tag if tag == \"O\" else tag[2:] for tag in tag_pred]\n",
    "# print(label_exp[:20])  # Looks good\n",
    "# print(label_pred[:20]) # Looks good\n",
    "pred_cont_labels = pred_cont_labels.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_cont_labels.insert(len(pred_cont_labels.columns), \"label_{}_expected\".format(category), label_exp)\n",
    "pred_cont_labels.insert(len(pred_cont_labels.columns), \"label_{}_predicted\".format(category), label_pred)\n",
    "# pred_cont_labels.head(20)  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"personname\"\n",
    "pred_pers_labels = pred_pers.copy()\n",
    "tag_exp = list(pred_pers_labels[\"tag_{}_expected\".format(category)])\n",
    "tag_pred = list(pred_pers_labels[\"tag_{}_predicted\".format(category)])\n",
    "label_exp = [[tag if tag == \"O\" else tag[2:] for tag in tag_exp_list] for tag_exp_list in tag_exp]\n",
    "label_pred = [tag if tag == \"O\" else tag[2:] for tag in tag_pred]\n",
    "pred_pers_labels = pred_pers_labels.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_pers_labels.insert(len(pred_pers_labels.columns), \"label_{}_expected\".format(category), label_exp)\n",
    "pred_pers_labels.insert(len(pred_pers_labels.columns), \"label_{}_predicted\".format(category), label_pred)\n",
    "# pred_pers_labels.loc[pred_pers_labels.label_personname_predicted == \"Feminine\"].head()  # Looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"linguistic\"\n",
    "pred_ling_labels = pred_ling.copy()\n",
    "tag_exp = list(pred_ling_labels[\"tag_{}_expected\".format(category)])\n",
    "tag_pred = list(pred_ling_labels[\"tag_{}_predicted\".format(category)])\n",
    "label_exp = [[tag if tag == \"O\" else tag[2:] for tag in tag_exp_list] for tag_exp_list in tag_exp]\n",
    "label_pred = [tag if tag == \"O\" else tag[2:] for tag in tag_pred]\n",
    "pred_ling_labels = pred_ling_labels.drop(columns=[\"tag_{}_expected\".format(category), \"tag_{}_predicted\".format(category)])\n",
    "pred_ling_labels.insert(len(pred_ling_labels.columns), \"label_{}_expected\".format(category), label_exp)\n",
    "pred_ling_labels.insert(len(pred_ling_labels.columns), \"label_{}_predicted\".format(category), label_pred)\n",
    "# pred_ling_labels.head()  # Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the agreement metrics at the label level for each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>656</td>\n",
       "      <td>481</td>\n",
       "      <td>737</td>\n",
       "      <td>0.605090</td>\n",
       "      <td>0.529074</td>\n",
       "      <td>0.564535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omission</td>\n",
       "      <td>1297</td>\n",
       "      <td>1684</td>\n",
       "      <td>1102</td>\n",
       "      <td>0.395549</td>\n",
       "      <td>0.459358</td>\n",
       "      <td>0.425072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stereotype</td>\n",
       "      <td>638</td>\n",
       "      <td>449</td>\n",
       "      <td>198</td>\n",
       "      <td>0.306028</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.267026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0  Occupation             656             481            737   0.605090   \n",
       "0    Omission            1297            1684           1102   0.395549   \n",
       "0  Stereotype             638             449            198   0.306028   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.529074  0.564535  \n",
       "0  0.459358  0.425072  \n",
       "0  0.236842  0.267026  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = \"contextual\"\n",
    "tags = ['Occupation', 'Omission', 'Stereotype']\n",
    "pred_cont_labels = pred_cont_labels.drop(columns=[\"_merge\"])\n",
    "pred_cont_labels = utils.isPredictedInExpected(pred_cont_labels, \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), '_merge', 'O')\n",
    "\n",
    "pred_cont_stats = utils.getScoresByCatTags(\n",
    "    pred_cont_labels, \"_merge\", tags[0], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_cont_labels, \"_merge\", tags[i], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_cont_stats = pd.concat([pred_cont_stats, tag_stats])\n",
    "pred_cont_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>176</td>\n",
       "      <td>210</td>\n",
       "      <td>638</td>\n",
       "      <td>0.752358</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.767750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>578</td>\n",
       "      <td>669</td>\n",
       "      <td>934</td>\n",
       "      <td>0.582658</td>\n",
       "      <td>0.617725</td>\n",
       "      <td>0.599679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1801</td>\n",
       "      <td>1105</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.660939</td>\n",
       "      <td>0.544627</td>\n",
       "      <td>0.597172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nonbinary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0   Feminine             176             210            638   0.752358   \n",
       "0  Masculine             578             669            934   0.582658   \n",
       "0    Unknown            1801            1105           2154   0.660939   \n",
       "0  Nonbinary               0               0              0   0.000000   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.783784  0.767750  \n",
       "0  0.617725  0.599679  \n",
       "0  0.544627  0.597172  \n",
       "0  0.000000  0.000000  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = \"personname\"\n",
    "tags = ['Feminine', 'Masculine', 'Unknown', \"Nonbinary\"]\n",
    "pred_pers_labels = pred_pers_labels.drop(columns=[\"_merge\"])\n",
    "pred_pers_labels = utils.isPredictedInExpected(pred_pers_labels, \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), '_merge', 'O')\n",
    "\n",
    "\n",
    "pred_pers_stats = utils.getScoresByCatTags(\n",
    "    pred_pers_labels, \"_merge\", tags[0], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_pers_labels, \"_merge\", tags[i], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_pers_stats = pd.concat([pred_pers_stats, tag_stats])\n",
    "pred_pers_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Pronoun</td>\n",
       "      <td>41</td>\n",
       "      <td>169</td>\n",
       "      <td>718</td>\n",
       "      <td>0.809470</td>\n",
       "      <td>0.945982</td>\n",
       "      <td>0.872418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered-Role</td>\n",
       "      <td>264</td>\n",
       "      <td>170</td>\n",
       "      <td>421</td>\n",
       "      <td>0.712352</td>\n",
       "      <td>0.614599</td>\n",
       "      <td>0.659875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>268</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.319392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tag(s)  false negative  false positive  true positive  precision  \\\n",
       "0  Gendered-Pronoun              41             169            718   0.809470   \n",
       "0     Gendered-Role             264             170            421   0.712352   \n",
       "0    Generalization             268              90             84   0.482759   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.945982  0.872418  \n",
       "0  0.614599  0.659875  \n",
       "0  0.238636  0.319392  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = \"linguistic\"\n",
    "tags = [\"Gendered-Pronoun\", \"Gendered-Role\", \"Generalization\"]\n",
    "pred_ling_labels = pred_ling_labels.drop(columns=[\"_merge\"])\n",
    "pred_ling_labels = utils.isPredictedInExpected(pred_ling_labels, \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), '_merge', 'O')\n",
    "\n",
    "\n",
    "pred_ling_stats = utils.getScoresByCatTags(\n",
    "    pred_ling_labels, \"_merge\", tags[0], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    ")\n",
    "for i in range(1, len(tags)):\n",
    "    tag_stats = utils.getScoresByCatTags(\n",
    "        pred_ling_labels, \"_merge\", tags[i], \"label_{}_expected\".format(category), \"label_{}_predicted\".format(category), \"token_id\"\n",
    "    )\n",
    "    pred_ling_stats = pd.concat([pred_ling_stats, tag_stats])\n",
    "pred_ling_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine and save the performance measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_stats = pd.concat([pred_cont_stats, pred_pers_stats, pred_ling_stats])\n",
    "# loose_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_stats.to_csv(config.tokc_path+output_path+\"crf_l2sgd_baseline_performance_loose_alltags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotation Agreement\n",
    "\n",
    "Calculate agreement at the annotation level, so if the model labels any word correctly from a manually annotated text span, that annotation is recorded as being correctly labeled (`true positive`).  Note whether the models' labels are an `exact_match`, `label_match`, `category_match` or `mismatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

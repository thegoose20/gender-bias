{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Bias Multilabel Token Classifiers\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: under directory `../data/token_clf_data/multilabel_model_output/`\n",
    "* Multilabel classification\n",
    "    * 3 categories of labels:\n",
    "        1. Person Name: Unknown, Feminine, Masculine (Non-binary not applied during annotation)\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Occupation, Omission, Stereotype (Empowering only applied by one annotator and too few times for training)\n",
    "* Word embeddings: custom fastText embeddings\n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[0.](#0) Preprocessing\n",
    "\n",
    "[1.](#CC) Classifier Chain Models\n",
    "\n",
    "[2.](#2) Person Name Model\n",
    "\n",
    "[3.](#3) Linguistic Model\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For embeddings\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "\n",
    "# For classification\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "# Base estimators\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Optional Preprocessing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not classifying all labels at once, consider only the rows with tags for the select subset of labels, replacing all tags not in that subset with `\"O\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463439, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "# cont_label_subset = [\"B-Stereotype\", \"I-Stereotype\", \"B-Omission\", \"I-Omission\", \"B-Occupation\", \"I-Occupation\"]\n",
    "pers_label_subset = [\"B-Unknown\", \"I-Unknown\", \"B-Feminine\", \"I-Feminine\", \"B-Masculine\", \"I-Masculine\"]#, \"B-Nonbinary\", \"I-Nonbinary\"]\n",
    "# ling_label_subset = [\"B-Generalization\", \"I-Generalization\", \"B-Gendered-Role\", \"I-Gendered-Role\", \"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"]\n",
    "df_train, df_dev = utils.selectDataForLabels(df_train, df_dev, \"tag\", pers_label_subset)\n",
    "# df_train, df_dev = utils.selectDataForLabels(df_train, df_dev, \"tag\", ling_label_subset)\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by token, so there is one row per token rather than one row per token-tag pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos  tag\n",
       "0            5       154       After    IN  [O]\n",
       "1            5       155         his  PRP$  [O]\n",
       "2            5       156  ordination    NN  [O]\n",
       "3            5       157          he   PRP  [O]\n",
       "4            5       158       spent   VBD  [O]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf_train = df_train.drop(columns=[\"description_id\", \"field\", \"subset\", \"token_offsets\"])\n",
    "subdf_dev = df_dev.drop(columns=[\"description_id\", \"field\", \"subset\", \"token_offsets\"])\n",
    "df_train_imploded = utils.implodeDataFrame(subdf_train, [\"sentence_id\", \"token_id\", \"token\", \"pos\"])\n",
    "df_train_imploded = df_train_imploded.reset_index()\n",
    "df_dev_imploded = utils.implodeDataFrame(subdf_dev, [\"sentence_id\", \"token_id\", \"token\", \"pos\"])\n",
    "df_dev_imploded = df_dev_imploded.reset_index()\n",
    "df_dev_imploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate word embeddings to the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\"50\", \"100\", \"200\", \"300\"]\n",
    "d = dimensions[1]\n",
    "file_name = config.fasttext_path+\"fasttext{}_lowercased.model\".format(d)\n",
    "embedding_model = FastText.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35968\n",
      "Lowercased vocabulary size: 31335\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(df_train.token.unique())\n",
    "vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize and binarize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"tag\"\n",
    "feature_cols = [\"token_id\", \"token\"]\n",
    "train_data = df_train_imploded\n",
    "dev_data = df_dev_imploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>NN</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>[O, B-Unknown, B-Masculine]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id   token  pos                          tag\n",
       "0            1         3   Title   NN                          [O]\n",
       "1            1         4       :    :                          [O]\n",
       "2            1         5  Papers  NNS                          [O]\n",
       "3            1         6      of   IN                          [O]\n",
       "4            1         7     The   DT  [O, B-Unknown, B-Masculine]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a vector representation of a token from a fastText word embedding model\n",
    "def extractEmbedding(token, fasttext_model=embedding_model):\n",
    "    if token.isalpha():\n",
    "        token = token.lower()\n",
    "    embedding = fasttext_model.wv[token]\n",
    "    return embedding\n",
    "\n",
    "def makeFeatureMatrix(token_data):\n",
    "    feature_list = [extractEmbedding(token) for token_id,token in token_data]\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = list(zip(train_data[feature_cols[0]], train_data[feature_cols[1]]))\n",
    "dev_tokens = list(zip(dev_data[feature_cols[0]], dev_data[feature_cols[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452086, 100) (152455, 100)\n"
     ]
    }
   ],
   "source": [
    "X_train = makeFeatureMatrix(train_tokens)\n",
    "X_dev = makeFeatureMatrix(dev_tokens)\n",
    "print(X_train.shape, X_dev.shape)  # number_of_samples, number_of_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452086, 7) (152455, 7)\n"
     ]
    }
   ],
   "source": [
    "y_train_labels = train_data[target_col]\n",
    "y_train = mlb.fit_transform(y_train_labels)\n",
    "y_dev_labels = dev_data[target_col]\n",
    "y_dev = mlb.transform(y_dev_labels)\n",
    "print(y_train.shape, y_dev.shape)  # number_of_samples, number_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabelled tokens exist, as expected.\n"
     ]
    }
   ],
   "source": [
    "for labels in y_train:\n",
    "    if sum(labels) > 1:\n",
    "        print(\"Multilabelled tokens exist, as expected.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline models, use only the tokens' embeddings as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CC\"></a>\n",
    "## 1. Classifier Chain Models\n",
    "\n",
    "*Reference: http://scikit.ml/api/skmultilearn.problem_transform.cc.html#skmultilearn.problem_transform.ClassifierChain*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=RandomForestClassifier(random_state=22),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"rf\"\n",
    "clf = ClassifierChain(\n",
    "    classifier = RandomForestClassifier(random_state=22),\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - weighted: 0.9139355112811681\n",
      "Precision - macro: 0.5117583387635518\n",
      "\n",
      "Recall - weighted: 0.9275677891204386\n",
      "Recall - macro: 0.33299717339152485\n",
      "\n",
      "F1 Score - weighted: 0.9144440009060665\n",
      "F1 Score - macro: 0.3739269852824525\n",
      "\n",
      "Accuracy - normalized: 0.9373192089469023\n",
      "Accuracy - unnormalized: 142899\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - weighted:\", metrics.precision_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"Precision - macro:\", metrics.precision_score(y_dev, predictions, average=\"macro\", zero_division=0))  # macro = mean of all labels' score\n",
    "print()\n",
    "print(\"Recall - weighted:\", metrics.recall_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"Recall - macro:\", metrics.recall_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print()\n",
    "print(\"F1 Score - weighted:\", metrics.f1_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"F1 Score - macro:\", metrics.f1_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print()\n",
    "print(\"Accuracy - normalized:\", metrics.accuracy_score(y_dev, predictions, normalize=True))  # fraction of correctly classified samples\n",
    "print(\"Accuracy - unnormalized:\", metrics.accuracy_score(y_dev, predictions, normalize=False))  # number of correctly classified samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate: Each Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos       predicted_tag\n",
       "0            5       154       After    IN                   O\n",
       "1            5       155         his  PRP$  B-Gendered-Pronoun\n",
       "2            5       156  ordination    NN                   O\n",
       "3            5       157          he   PRP  B-Gendered-Pronoun\n",
       "4            5       158       spent   VBD                   O"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = utils.makePredictionDF(predictions, dev_data, \"tag\", \"predicted_tag\", \"O\", mlb)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = dev_data.explode([\"tag\"])\n",
    "exp_df = exp_df.rename(columns={\"tag\":\"expected_tag\"})\n",
    "# exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos        expected_tag  \\\n",
       "0            5       154       After    IN                   O   \n",
       "1            5       155         his  PRP$  B-Gendered-Pronoun   \n",
       "2            5       156  ordination    NN                   O   \n",
       "3            5       157          he   PRP  B-Gendered-Pronoun   \n",
       "4            5       158       spent   VBD                   O   \n",
       "\n",
       "        predicted_tag         _merge  \n",
       "0                   O  true negative  \n",
       "1  B-Gendered-Pronoun  true positive  \n",
       "2                   O  true negative  \n",
       "3  B-Gendered-Pronoun  true positive  \n",
       "4                   O  true negative  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    exp_df, \n",
    "    pred_df, \n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\"],   # left on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"predicted_tag\"],  # right on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\", \"predicted_tag\", \"_merge\"],  # final column list\n",
    "    \"expected_tag\",\n",
    "    \"predicted_tag\", \n",
    "    \"token_id\",  # ID column\n",
    "    \"O\"          # No tag value\n",
    ")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.tokc_path+\"multilabel_model_output/\").mkdir(parents=True, exist_ok=True)\n",
    "eval_df.to_csv(config.tokc_path+\"multilabel_model_output/cc-{a}_baseline_fastText{d}_predictions.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total true positives, false positives, true negatives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_stats = utils.getAgreementStatsForAllTags(eval_df, \"_merge\", \"token_id\", \"tag(s)\", y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tags = [ \n",
    "    'B-Unknown', 'I-Unknown', 'B-Feminine', 'I-Feminine', 'B-Masculine',  'I-Masculine',\n",
    "    'B-Gendered-Pronoun', 'I-Gendered-Pronoun','B-Gendered-Role', 'I-Gendered-Role', \n",
    "    'B-Generalization', 'I-Generalization', \n",
    "    'B-Stereotype', 'I-Stereotype', 'B-Omission', 'I-Omission', 'B-Occupation', 'I-Occupation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>11310</td>\n",
       "      <td>9593</td>\n",
       "      <td>140352</td>\n",
       "      <td>4484</td>\n",
       "      <td>0.511758</td>\n",
       "      <td>0.332997</td>\n",
       "      <td>0.373927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>1321</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.753836</td>\n",
       "      <td>0.461036</td>\n",
       "      <td>0.572152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>2423</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.715165</td>\n",
       "      <td>0.345312</td>\n",
       "      <td>0.465743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>105</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.793687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>505</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>0.854271</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>0.547064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>468</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.792393</td>\n",
       "      <td>0.681199</td>\n",
       "      <td>0.732601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>1014</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>0.596306</td>\n",
       "      <td>0.308322</td>\n",
       "      <td>0.406475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>1470</td>\n",
       "      <td>0.891990</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>0.940198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Pronoun</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>140</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>870</td>\n",
       "      <td>0.845481</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.853359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Generalization</td>\n",
       "      <td>177</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>0.540773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Generalization</td>\n",
       "      <td>145</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Stereotype</td>\n",
       "      <td>228</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.275072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Stereotype</td>\n",
       "      <td>702</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.051351</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Omission</td>\n",
       "      <td>529</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>958</td>\n",
       "      <td>0.814626</td>\n",
       "      <td>0.644250</td>\n",
       "      <td>0.719489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Omission</td>\n",
       "      <td>1465</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.418079</td>\n",
       "      <td>0.048083</td>\n",
       "      <td>0.086247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>303</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0.808756</td>\n",
       "      <td>0.698507</td>\n",
       "      <td>0.749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>716</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.153664</td>\n",
       "      <td>0.252918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag(s)  false negative  false positive  true negative  \\\n",
       "0                 all           11310            9593         140352   \n",
       "0           B-Unknown            1321             369              0   \n",
       "0           I-Unknown            2423             509              0   \n",
       "0          B-Feminine             105              78              0   \n",
       "0          I-Feminine             505              58              0   \n",
       "0         B-Masculine             468             262              0   \n",
       "0         I-Masculine            1014             306              0   \n",
       "0  B-Gendered-Pronoun               9             178              0   \n",
       "0  I-Gendered-Pronoun              15               0              0   \n",
       "0     B-Gendered-Role             140             159              0   \n",
       "0     I-Gendered-Role             118               2              0   \n",
       "0    B-Generalization             177              37              0   \n",
       "0    I-Generalization             145               7              0   \n",
       "0        B-Stereotype             228              25              0   \n",
       "0        I-Stereotype             702              58              0   \n",
       "0          B-Omission             529             218              0   \n",
       "0          I-Omission            1465             103              0   \n",
       "0        B-Occupation             303             166              0   \n",
       "0        I-Occupation             716              52              0   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0           4484   0.511758  0.332997  0.373927  \n",
       "0           1130   0.753836  0.461036  0.572152  \n",
       "0           1278   0.715165  0.345312  0.465743  \n",
       "0            352   0.818605  0.770241  0.793687  \n",
       "0            340   0.854271  0.402367  0.547064  \n",
       "0           1000   0.792393  0.681199  0.732601  \n",
       "0            452   0.596306  0.308322  0.406475  \n",
       "0           1470   0.891990  0.993915  0.940198  \n",
       "0              0   0.000000  0.000000  0.000000  \n",
       "0            870   0.845481  0.861386  0.853359  \n",
       "0              0   0.000000  0.000000  0.000000  \n",
       "0            126   0.773006  0.415842  0.540773  \n",
       "0              0   0.000000  0.000000  0.000000  \n",
       "0             48   0.657534  0.173913  0.275072  \n",
       "0             38   0.395833  0.051351  0.090909  \n",
       "0            958   0.814626  0.644250  0.719489  \n",
       "0             74   0.418079  0.048083  0.086247  \n",
       "0            702   0.808756  0.698507  0.749600  \n",
       "0            130   0.714286  0.153664  0.252918  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label_tag in label_tags:\n",
    "    label_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [label_tag])\n",
    "    agmt_stats = pd.concat([agmt_stats, label_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.tokc_path+\"multilabel_model_performance/\").mkdir(parents=True, exist_ok=True)\n",
    "agmt_stats.to_csv(config.tokc_path+\"multilabel_model_performance/cc-{a}_baseline_fastText{d}_strict_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loose Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each label, where a correct prediction is a prediction with the correct annotation label (not necessarily the correct IOB tag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the evaluation DataFrame where tags are replaced by label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tags = {\n",
    "    \"Unknown\": [\"B-Unknown\", \"I-Unknown\"], \"Feminine\": [\"B-Feminine\", \"I-Feminine\"], \"Masculine\": [\"B-Masculine\", \"I-Masculine\"],\n",
    "    \"Gendered Pronoun\": [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"], \"Gendered Role\": [\"B-Gendered-Role\", \"I-Gendered-Role\"],\n",
    "    \"Generalization\": [\"B-Generalization\", \"I-Generalization\"], \n",
    "    \"Stereotype\": [\"B-Stereotype\", \"I-Stereotype\"], \"Omission\": [\"B-Omission\", \"I-Omission\"], \"Occupation\": [\"B-Occupation\", \"I-Occupation\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df = eval_df.copy()\n",
    "for label,tags in label_tags.items():\n",
    "    for tag in tags:\n",
    "        loose_eval_df[\"expected_tag\"] = loose_eval_df[\"expected_tag\"].replace(to_replace=tag, value=label)\n",
    "        loose_eval_df[\"predicted_tag\"] = loose_eval_df[\"predicted_tag\"].replace(to_replace=tag, value=label)\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df = loose_eval_df.fillna(\"O\")\n",
    "loose_eval_df = loose_eval_df.drop(columns=[\"_merge\"])\n",
    "loose_eval_df = utils.compareExpectedPredicted(loose_eval_df, \"_merge\", \"O\")\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt = pd.DataFrame.from_dict({\n",
    "        \"tag(s)\":[], \"false negative\":[], \"false positive\":[], \"true negative\":[], \n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>3744.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2408.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391417</td>\n",
       "      <td>0.562617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>610.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531490</td>\n",
       "      <td>0.694082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.494888</td>\n",
       "      <td>0.662107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered Pronoun</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.991903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered Role</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>0.870871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.439024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stereotype</td>\n",
       "      <td>930.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084646</td>\n",
       "      <td>0.156080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omission</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341044</td>\n",
       "      <td>0.508625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449487</td>\n",
       "      <td>0.620201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tag(s)  false negative  false positive  true negative  \\\n",
       "0           Unknown          3744.0             0.0            0.0   \n",
       "0          Feminine           610.0             0.0            0.0   \n",
       "0         Masculine          1482.0             0.0            0.0   \n",
       "0  Gendered Pronoun            24.0             0.0            0.0   \n",
       "0     Gendered Role           258.0             0.0            0.0   \n",
       "0    Generalization           322.0             0.0            0.0   \n",
       "0        Stereotype           930.0             0.0            0.0   \n",
       "0          Omission          1994.0             0.0            0.0   \n",
       "0        Occupation          1019.0             0.0            0.0   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0         2408.0        1.0  0.391417  0.562617  \n",
       "0          692.0        1.0  0.531490  0.694082  \n",
       "0         1452.0        1.0  0.494888  0.662107  \n",
       "0         1470.0        1.0  0.983936  0.991903  \n",
       "0          870.0        1.0  0.771277  0.870871  \n",
       "0          126.0        1.0  0.281250  0.439024  \n",
       "0           86.0        1.0  0.084646  0.156080  \n",
       "0         1032.0        1.0  0.341044  0.508625  \n",
       "0          832.0        1.0  0.449487  0.620201  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label,tags in label_tags.items():\n",
    "    labels_agmt_stats = utils.getScoresByTags(loose_eval_df, \"_merge\", [label])\n",
    "    loose_agmt = pd.concat([loose_agmt, labels_agmt_stats])\n",
    "loose_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt.to_csv(config.tokc_path+\"multilabel_model_performance/cc-{a}_baseline_fastText{d}_loose_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "## 2. Person Name Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multilabel models with the `PassiveAggressiveClassifier` for the Person Name category of labels in order to compare their performance to the sequence classifier's performance (the Passive Aggressive algorithm was top-performing for the baseline Person Name sequence classification model).\n",
    "\n",
    "Then, try the `RandomForestClassifier` since this yeilded high performance in the optimization experiments.\n",
    "\n",
    "#### Hypothesis\n",
    "* The baseline sequence classifiers will outperform (F1 score >0.1 higher) the baseline multilabel token classifiers for labels in the Person Name category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;,\n",
       "                                                       max_iter=100,\n",
       "                                                       random_state=22),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;,\n",
       "                                                       max_iter=100,\n",
       "                                                       random_state=22),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: PassiveAggressiveClassifier</label><div class=\"sk-toggleable__content\"><pre>PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;, max_iter=100, random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PassiveAggressiveClassifier</label><div class=\"sk-toggleable__content\"><pre>PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;, max_iter=100, random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=PassiveAggressiveClassifier(loss='squared_hinge',\n",
       "                                                       max_iter=100,\n",
       "                                                       random_state=22),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"pa\"\n",
    "pn_clf = ClassifierChain(classifier=PassiveAggressiveClassifier(\n",
    "        max_iter=100, \n",
    "        loss=\"squared_hinge\",  # equivalent to pa_type=2 (PA-II)\n",
    "        random_state=22,\n",
    "    )\n",
    ")\n",
    "# a = \"rf\"\n",
    "# pn_clf = ClassifierChain(classifier=RandomForestClassifier(random_state=22))\n",
    "pn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pn_clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - weighted: 0.9246753427798468\n",
      "Precision - macro: 0.29125171686438994\n",
      "\n",
      "Recall - weighted: 0.9385097847295113\n",
      "Recall - macro: 0.29917853276102013\n",
      "\n",
      "F1 Score - weighted: 0.9308920661329323\n",
      "F1 Score - macro: 0.2790846321002277\n",
      "\n",
      "Accuracy - normalized: 0.8960086582926109\n",
      "Accuracy - unnormalized: 136601\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - weighted:\", metrics.precision_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"Precision - macro:\", metrics.precision_score(y_dev, predictions, average=\"macro\", zero_division=0))  # macro = mean of all labels' score\n",
    "print()\n",
    "print(\"Recall - weighted:\", metrics.recall_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"Recall - macro:\", metrics.recall_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print()\n",
    "print(\"F1 Score - weighted:\", metrics.f1_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"F1 Score - macro:\", metrics.f1_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print()\n",
    "print(\"Accuracy - normalized:\", metrics.accuracy_score(y_dev, predictions, normalize=True))  # fraction of correctly classified samples\n",
    "print(\"Accuracy - unnormalized:\", metrics.accuracy_score(y_dev, predictions, normalize=False))  # number of correctly classified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I-Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos predicted_tag\n",
       "0            5       154       After    IN             O\n",
       "1            5       155         his  PRP$             O\n",
       "2            5       156  ordination    NN             O\n",
       "3            5       157          he   PRP     I-Unknown\n",
       "3            5       157          he   PRP             O"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = utils.makePredictionDF(predictions, dev_data, \"tag\", \"predicted_tag\", \"O\", mlb)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = dev_data.explode([\"tag\"])\n",
    "exp_df = exp_df.rename(columns={\"tag\":\"expected_tag\"})\n",
    "# exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos expected_tag predicted_tag  \\\n",
       "0            5       154       After    IN            O             O   \n",
       "1            5       155         his  PRP$            O             O   \n",
       "2            5       156  ordination    NN            O             O   \n",
       "3            5       157          he   PRP            O             O   \n",
       "4            5       158       spent   VBD            O             O   \n",
       "\n",
       "          _merge  \n",
       "0  true negative  \n",
       "1  true negative  \n",
       "2  true negative  \n",
       "3  true negative  \n",
       "4  true negative  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    exp_df, \n",
    "    pred_df, \n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\"],   # left on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"predicted_tag\"],  # right on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\", \"predicted_tag\", \"_merge\"],  # final column list\n",
    "    \"expected_tag\",\n",
    "    \"predicted_tag\", \n",
    "    \"token_id\",  # ID column\n",
    "    \"O\"          # No tag value\n",
    ")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.tokc_path+\"multilabel_model_output/\").mkdir(parents=True, exist_ok=True)\n",
    "eval_df.to_csv(config.tokc_path+\"multilabel_model_output/cc-{a}_baseline_fastText{d}_pn_predictions.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total true positives, false positives, true negatives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_stats = utils.getAgreementStatsForAllTags(eval_df, \"_merge\", \"token_id\", \"tag(s)\", y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tags = [ \n",
    "    'B-Unknown', 'I-Unknown', 'B-Feminine', 'I-Feminine', 'B-Masculine',  'I-Masculine',\n",
    "#     'B-Gendered-Pronoun', 'I-Gendered-Pronoun','B-Gendered-Role', 'I-Gendered-Role', \n",
    "#     'B-Generalization', 'I-Generalization', \n",
    "#     'B-Stereotype', 'I-Stereotype', 'B-Omission', 'I-Omission', 'B-Occupation', 'I-Occupation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>8061</td>\n",
       "      <td>9982</td>\n",
       "      <td>145151</td>\n",
       "      <td>1042</td>\n",
       "      <td>0.291252</td>\n",
       "      <td>0.299179</td>\n",
       "      <td>0.279085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>1051</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>730</td>\n",
       "      <td>0.336406</td>\n",
       "      <td>0.409882</td>\n",
       "      <td>0.369527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>2319</td>\n",
       "      <td>2247</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>0.241135</td>\n",
       "      <td>0.235410</td>\n",
       "      <td>0.238238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.512315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>382</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>0.422383</td>\n",
       "      <td>0.379870</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>431</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.280467</td>\n",
       "      <td>0.235789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>839</td>\n",
       "      <td>725</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.137718</td>\n",
       "      <td>0.146288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag(s)  false negative  false positive  true negative  true positive  \\\n",
       "0          all            8061            9982         145151           1042   \n",
       "0    B-Unknown            1051            1440              0            730   \n",
       "0    I-Unknown            2319            2247              0            714   \n",
       "0   B-Feminine             156              42              0            104   \n",
       "0   I-Feminine             382             320              0            234   \n",
       "0  B-Masculine             431             658              0            168   \n",
       "0  I-Masculine             839             725              0            134   \n",
       "\n",
       "   precision    recall        f1  \n",
       "0   0.291252  0.299179  0.279085  \n",
       "0   0.336406  0.409882  0.369527  \n",
       "0   0.241135  0.235410  0.238238  \n",
       "0   0.712329  0.400000  0.512315  \n",
       "0   0.422383  0.379870  0.400000  \n",
       "0   0.203390  0.280467  0.235789  \n",
       "0   0.155995  0.137718  0.146288  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label_tag in label_tags:\n",
    "    label_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [label_tag])\n",
    "    agmt_stats = pd.concat([agmt_stats, label_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.tokc_path+\"multilabel_model_performance/\").mkdir(parents=True, exist_ok=True)\n",
    "agmt_stats.to_csv(config.tokc_path+\"multilabel_model_performance/cc-{a}_baseline_fastText{d}_pn_strict_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loose Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each label, where a correct prediction is a prediction with the correct annotation label (not necessarily the correct IOB tag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the evaluation DataFrame where tags are replaced by label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tags = {\n",
    "    \"Unknown\": [\"B-Unknown\", \"I-Unknown\"], \"Feminine\": [\"B-Feminine\", \"I-Feminine\"], \"Masculine\": [\"B-Masculine\", \"I-Masculine\"],\n",
    "#     \"Gendered Pronoun\": [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"], \"Gendered Role\": [\"B-Gendered-Role\", \"I-Gendered-Role\"],\n",
    "#     \"Generalization\": [\"B-Generalization\", \"I-Generalization\"], \n",
    "#     \"Stereotype\": [\"B-Stereotype\", \"I-Stereotype\"], \"Omission\": [\"B-Omission\", \"I-Omission\"], \"Occupation\": [\"B-Occupation\", \"I-Occupation\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df = eval_df.copy()\n",
    "for label,tags in label_tags.items():\n",
    "    for tag in tags:\n",
    "        loose_eval_df[\"expected_tag\"] = loose_eval_df[\"expected_tag\"].replace(to_replace=tag, value=label)\n",
    "        loose_eval_df[\"predicted_tag\"] = loose_eval_df[\"predicted_tag\"].replace(to_replace=tag, value=label)\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df = loose_eval_df.fillna(\"O\")\n",
    "loose_eval_df = loose_eval_df.drop(columns=[\"_merge\"])\n",
    "loose_eval_df = utils.compareExpectedPredicted(loose_eval_df, \"_merge\", \"O\")\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt = pd.DataFrame.from_dict({\n",
    "        \"tag(s)\":[], \"false negative\":[], \"false positive\":[], \"true negative\":[], \n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.299958</td>\n",
       "      <td>0.461489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine</td>\n",
       "      <td>538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.385845</td>\n",
       "      <td>0.556837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masculine</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192112</td>\n",
       "      <td>0.322305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag(s)  false negative  false positive  true negative  true positive  \\\n",
       "0    Unknown          3370.0             0.0            0.0         1444.0   \n",
       "0   Feminine           538.0             0.0            0.0          338.0   \n",
       "0  Masculine          1270.0             0.0            0.0          302.0   \n",
       "\n",
       "   precision    recall        f1  \n",
       "0        1.0  0.299958  0.461489  \n",
       "0        1.0  0.385845  0.556837  \n",
       "0        1.0  0.192112  0.322305  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label,tags in label_tags.items():\n",
    "    labels_agmt_stats = utils.getScoresByTags(loose_eval_df, \"_merge\", [label])\n",
    "    loose_agmt = pd.concat([loose_agmt, labels_agmt_stats])\n",
    "loose_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Classifier Chain, the Random Forest estimator performs better than the Passive Aggressive estimator.\n",
    "\n",
    "Compared to the Baseline Sequence Classifier for Person Names:\n",
    "* Unknown F1: 0.597172\n",
    "* Feminine F1: 0.767750\n",
    "* Masculine F1: 0.599679\n",
    "\n",
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt.to_csv(config.tokc_path+\"multilabel_model_performance/cc-{a}_baseline_fastText{d}_pn_loose_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Linguistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multilabel models with the `PassiveAggressiveClassifier` for the Linguistic category of labels in order to compare their performance to the sequence classifier's performance (the Passive Aggressive algorithm was top-performing for the baseline Linguistic sequence classification model).\n",
    "\n",
    "Then, try the `RandomForestClassifier` since this yeilded high performance in the optimization experiments.\n",
    "\n",
    "#### Hypothesis\n",
    "* The baseline sequence classifiers will have worse performance (F1 score >=0.1 lower) than the baseline multilabel token classifiers for labels in the Linguistic category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;,\n",
       "                                                       max_iter=100,\n",
       "                                                       random_state=22),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;,\n",
       "                                                       max_iter=100,\n",
       "                                                       random_state=22),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: PassiveAggressiveClassifier</label><div class=\"sk-toggleable__content\"><pre>PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;, max_iter=100, random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PassiveAggressiveClassifier</label><div class=\"sk-toggleable__content\"><pre>PassiveAggressiveClassifier(loss=&#x27;squared_hinge&#x27;, max_iter=100, random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=PassiveAggressiveClassifier(loss='squared_hinge',\n",
       "                                                       max_iter=100,\n",
       "                                                       random_state=22),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"pa\"\n",
    "l_clf = ClassifierChain(classifier=PassiveAggressiveClassifier(\n",
    "        max_iter=100, \n",
    "        loss=\"squared_hinge\",  # equivalent to pa_type=2 (PA-II)\n",
    "        random_state=22,\n",
    "    )\n",
    ")\n",
    "# a = \"rf\"\n",
    "# l_clf = ClassifierChain(classifier = RandomForestClassifier(random_state=22))\n",
    "l_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = l_clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - weighted: 0.9908974243394203\n",
      "Precision - macro: 0.36544387681923524\n",
      "\n",
      "Recall - weighted: 0.9909878162584754\n",
      "Recall - macro: 0.3336048125286899\n",
      "\n",
      "F1 Score - weighted: 0.9908594769466269\n",
      "F1 Score - macro: 0.34610025735673317\n",
      "\n",
      "Accuracy - normalized: 0.987091272834607\n",
      "Accuracy - unnormalized: 150487\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - weighted:\", metrics.precision_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"Precision - macro:\", metrics.precision_score(y_dev, predictions, average=\"macro\", zero_division=0))  # macro = mean of all labels' score\n",
    "print()\n",
    "print(\"Recall - weighted:\", metrics.recall_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"Recall - macro:\", metrics.recall_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print()\n",
    "print(\"F1 Score - weighted:\", metrics.f1_score(y_dev, predictions, average=\"weighted\", zero_division=0))\n",
    "print(\"F1 Score - macro:\", metrics.f1_score(y_dev, predictions, average=\"macro\", zero_division=0))\n",
    "print()\n",
    "print(\"Accuracy - normalized:\", metrics.accuracy_score(y_dev, predictions, normalize=True))  # fraction of correctly classified samples\n",
    "print(\"Accuracy - unnormalized:\", metrics.accuracy_score(y_dev, predictions, normalize=False))  # number of correctly classified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>predicted_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos       predicted_tag\n",
       "0            5       154       After    IN                   O\n",
       "1            5       155         his  PRP$                   O\n",
       "2            5       156  ordination    NN                   O\n",
       "3            5       157          he   PRP  B-Gendered-Pronoun\n",
       "4            5       158       spent   VBD                   O"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = utils.makePredictionDF(predictions, dev_data, \"tag\", \"predicted_tag\", \"O\", mlb)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = dev_data.explode([\"tag\"])\n",
    "exp_df = exp_df.rename(columns={\"tag\":\"expected_tag\"})\n",
    "# exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>expected_tag</th>\n",
       "      <th>predicted_tag</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos        expected_tag  \\\n",
       "0            5       154       After    IN                   O   \n",
       "1            5       155         his  PRP$  B-Gendered-Pronoun   \n",
       "2            5       156  ordination    NN                   O   \n",
       "3            5       157          he   PRP  B-Gendered-Pronoun   \n",
       "4            5       158       spent   VBD                   O   \n",
       "\n",
       "        predicted_tag          _merge  \n",
       "0                   O   true negative  \n",
       "1                 NaN  false negative  \n",
       "2                   O   true negative  \n",
       "3  B-Gendered-Pronoun   true positive  \n",
       "4                   O   true negative  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    exp_df, \n",
    "    pred_df, \n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\"],   # left on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"predicted_tag\"],  # right on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"expected_tag\", \"predicted_tag\", \"_merge\"],  # final column list\n",
    "    \"expected_tag\",\n",
    "    \"predicted_tag\", \n",
    "    \"token_id\",  # ID column\n",
    "    \"O\"          # No tag value\n",
    ")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.tokc_path+\"multilabel_model_output/\").mkdir(parents=True, exist_ok=True)\n",
    "eval_df.to_csv(config.tokc_path+\"multilabel_model_output/cc-{a}_baselinefastText{d}_ling_predictions.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total true positives, false positives, true negatives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmt_stats = utils.getAgreementStatsForAllTags(eval_df, \"_merge\", \"token_id\", \"tag(s)\", y_dev, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tags = [ \n",
    "#     'B-Unknown', 'I-Unknown', 'B-Feminine', 'I-Feminine', 'B-Masculine',  'I-Masculine',\n",
    "    'B-Gendered-Pronoun', 'I-Gendered-Pronoun','B-Gendered-Role', 'I-Gendered-Role', \n",
    "    'B-Generalization', 'I-Generalization', \n",
    "#     'B-Stereotype', 'I-Stereotype', 'B-Omission', 'I-Omission', 'B-Occupation', 'I-Occupation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>922</td>\n",
       "      <td>844</td>\n",
       "      <td>153929</td>\n",
       "      <td>637</td>\n",
       "      <td>0.365444</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>0.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>196</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1048</td>\n",
       "      <td>0.916885</td>\n",
       "      <td>0.842444</td>\n",
       "      <td>0.878090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Pronoun</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>139</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.487085</td>\n",
       "      <td>0.621176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Generalization</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0.433180</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.475949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Generalization</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag(s)  false negative  false positive  true negative  \\\n",
       "0                 all             922             844         153929   \n",
       "0  B-Gendered-Pronoun             196              95              0   \n",
       "0  I-Gendered-Pronoun              14               8              0   \n",
       "0     B-Gendered-Role             139              22              0   \n",
       "0     I-Gendered-Role              65              22              0   \n",
       "0    B-Generalization              84             123              0   \n",
       "0    I-Generalization              44              20              0   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0            637   0.365444  0.333605  0.346100  \n",
       "0           1048   0.916885  0.842444  0.878090  \n",
       "0              0   0.000000  0.000000  0.000000  \n",
       "0            132   0.857143  0.487085  0.621176  \n",
       "0              0   0.000000  0.000000  0.000000  \n",
       "0             94   0.433180  0.528090  0.475949  \n",
       "0              0   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label_tag in label_tags:\n",
    "    label_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [label_tag])\n",
    "    agmt_stats = pd.concat([agmt_stats, label_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.tokc_path+\"multilabel_model_performance/\").mkdir(parents=True, exist_ok=True)\n",
    "agmt_stats.to_csv(config.tokc_path+\"multilabel_model_performance/cc-{a}_baselinefastText{d}_ling_strict_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loose Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each label, where a correct prediction is a prediction with the correct annotation label (not necessarily the correct IOB tag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the evaluation DataFrame where tags are replaced by label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tags = {\n",
    "#     \"Unknown\": [\"B-Unknown\", \"I-Unknown\"], \"Feminine\": [\"B-Feminine\", \"I-Feminine\"], \"Masculine\": [\"B-Masculine\", \"I-Masculine\"],\n",
    "    \"Gendered Pronoun\": [\"B-Gendered-Pronoun\", \"I-Gendered-Pronoun\"], \"Gendered Role\": [\"B-Gendered-Role\", \"I-Gendered-Role\"],\n",
    "    \"Generalization\": [\"B-Generalization\", \"I-Generalization\"], \n",
    "#     \"Stereotype\": [\"B-Stereotype\", \"I-Stereotype\"], \"Omission\": [\"B-Omission\", \"I-Omission\"], \"Occupation\": [\"B-Occupation\", \"I-Occupation\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df = eval_df.copy()\n",
    "for label,tags in label_tags.items():\n",
    "    for tag in tags:\n",
    "        loose_eval_df[\"expected_tag\"] = loose_eval_df[\"expected_tag\"].replace(to_replace=tag, value=label)\n",
    "        loose_eval_df[\"predicted_tag\"] = loose_eval_df[\"predicted_tag\"].replace(to_replace=tag, value=label)\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_eval_df = loose_eval_df.fillna(\"O\")\n",
    "loose_eval_df = loose_eval_df.drop(columns=[\"_merge\"])\n",
    "loose_eval_df = utils.compareExpectedPredicted(loose_eval_df, \"_merge\", \"O\")\n",
    "# loose_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt = pd.DataFrame.from_dict({\n",
    "        \"tag(s)\":[], \"false negative\":[], \"false positive\":[], \"true negative\":[], \n",
    "         \"true positive\":[], \"precision\":[], \"recall\":[], \"f1\":[]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered Pronoun</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833068</td>\n",
       "      <td>0.908933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gendered Role</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generalization</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.594937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tag(s)  false negative  false positive  true negative  \\\n",
       "0  Gendered Pronoun           210.0             0.0            0.0   \n",
       "0     Gendered Role           204.0             0.0            0.0   \n",
       "0    Generalization           128.0             0.0            0.0   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0         1048.0        1.0  0.833068  0.908933  \n",
       "0          132.0        1.0  0.392857  0.564103  \n",
       "0           94.0        1.0  0.423423  0.594937  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label,tags in label_tags.items():\n",
    "    labels_agmt_stats = utils.getScoresByTags(loose_eval_df, \"_merge\", [label])\n",
    "    loose_agmt = pd.concat([loose_agmt, labels_agmt_stats])\n",
    "loose_agmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a Classifier Chain, the Random Forest estimator yields better results than the Passive Aggressive estimator.\n",
    "\n",
    "Compared to the Baseline Sequence Classifier:\n",
    "* Gendered-Pronoun F1: 0.872418\n",
    "* Gendered-Role F1: 0.659875\n",
    "* Generalization F1: 0.319392\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_agmt.to_csv(config.tokc_path+\"multilabel_model_performance/cc-{a}_baseline_fastText{d}_ling_loose_agmt.csv\".format(a=a,d=d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

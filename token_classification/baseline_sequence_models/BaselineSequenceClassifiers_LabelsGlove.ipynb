{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Bias Sequence Classifiers with GloVe\n",
    "\n",
    "### Target: Labels\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/crf_l2sgd/`\n",
    "* Sequence classification\n",
    "    * 9 lables (2 from original annotation taxonomy weren't applied during manual annotation):\n",
    "        1. Person Name: Unknown, Feminine, Masculine (Non-binary not annotated with)\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Occupation, Omission, Stereotype (Empowering not annotated with enough)\n",
    "    * 1 model per category\n",
    "* Word embeddings\n",
    "    * GloVe (trained on Gigaword 5 + English Wikipedia dump)\n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[0.](#0) Preprocessing\n",
    "\n",
    "  * [Hypotheses](#h)\n",
    "\n",
    "[1.](#1) Models\n",
    "\n",
    "  * [All Labels](#all)\n",
    "  * [Linguistic](#ling)\n",
    "  * [Person Name](#pers)\n",
    "  * [Contextual](#cont)\n",
    "  * [Person Name + Occupation](#perso)\n",
    "  \n",
    "[2.](#2) Performance Evaluation\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.stats\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay#, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate rows with all but the same annotation ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that won't be used as features for the classifiers and remove any duplicate rows that remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"pos\", \"token\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[cols_to_keep]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev[cols_to_keep]\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate subsets of data for each category so they can be used with three separate models, replacing `NaN` tag values with `'O'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine' 'B-Gendered-Pronoun' 'B-Gendered-Role' 'B-Generalization'\n",
      " 'B-Masculine' 'B-Occupation' 'B-Omission' 'B-Stereotype' 'B-Unknown'\n",
      " 'I-Feminine' 'I-Gendered-Pronoun' 'I-Gendered-Role' 'I-Generalization'\n",
      " 'I-Masculine' 'I-Occupation' 'I-Omission' 'I-Stereotype' 'I-Unknown' 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = (df_train.tag.unique())\n",
    "tags.sort()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Optional Preprocessing** - if only using a subset of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_cat_tags = ['B-Gendered-Pronoun', 'B-Gendered-Role', 'B-Generalization', 'I-Gendered-Pronoun', 'I-Gendered-Role', 'I-Generalization']\n",
    "df_train_ling = df_train.loc[df_train.tag.isin(ling_cat_tags)]\n",
    "df_dev_ling = df_dev.loc[df_dev.tag.isin(ling_cat_tags)]\n",
    "category = \"linguistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pers_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Unknown']\n",
    "# df_train_pers = df_train.loc[df_train.tag.isin(pers_cat_tags)]\n",
    "# df_dev_pers = df_dev.loc[df_dev.tag.isin(pers_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cont_cat_tags = ['B-Occupation', 'B-Omission', 'B-Stereotype', 'I-Occupation', 'I-Omission', 'I-Stereotype']\n",
    "# df_train_cont = df_train.loc[df_train.tag.isin(cont_cat_tags)]\n",
    "# df_dev_cont = df_dev.loc[df_dev.tag.isin(cont_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perso_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Occupation', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Occupation', 'I-Unknown']\n",
    "# df_train_perso = df_train.loc[df_train.tag.isin(perso_cat_tags)]\n",
    "# df_dev_perso = df_dev.loc[df_dev.tag.isin(perso_cat_tags)]\n",
    "# category = \"pers_o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.drop(columns=[\"tag\"])).drop_duplicates()\n",
    "df_dev = (df_dev.drop(columns=[\"tag\"])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"sentence_id\", \"token_id\", \"pos\", \"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train.join(df_train_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_ling = df_train_ling.fillna('O')\n",
    "# df_train_ling.head()\n",
    "df_dev_ling = df_dev.join(df_dev_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_ling = df_dev_ling.fillna('O')\n",
    "# df_dev_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_train_pers = df_train.join(df_train_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_train_pers = df_train_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "# df_train_pers = df_train_pers.fillna('O')\n",
    "# df_dev_pers = df_dev.join(df_dev_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_dev_pers = df_dev_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "# df_dev_pers = df_dev_pers.fillna('O')\n",
    "# # df_dev_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_train_cont = df_train.join(df_train_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_train_cont = df_train_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "# df_train_cont = df_train_cont.fillna('O')\n",
    "# df_dev_cont = df_dev.join(df_dev_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_dev_cont = df_dev_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "# df_dev_cont = df_dev_cont.fillna('O')\n",
    "# df_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_perso = df_train.join(df_train_perso.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_train_perso = df_train_perso.fillna('O')\n",
    "# df_dev_perso = df_dev.join(df_dev_perso.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "# df_dev_perso = df_dev_perso.fillna('O')\n",
    "# # df_dev_perso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train_ling.drop_duplicates()\n",
    "df_dev_ling = df_dev_ling.drop_duplicates()\n",
    "# df_train_pers = df_train_pers.drop_duplicates()\n",
    "# df_dev_pers = df_dev_pers.drop_duplicates()\n",
    "# df_train_cont = df_train_cont.drop_duplicates()\n",
    "# df_dev_cont = df_dev_cont.drop_duplicates()\n",
    "# df_train_perso = df_train_perso.drop_duplicates()\n",
    "# df_dev_perso = df_dev_perso.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train_dfs = [df_train_ling, df_train_pers, df_train_cont]\n",
    "# dev_dfs = [df_dev_ling, df_dev_pers, df_dev_cont]\n",
    "# for df in train_dfs:\n",
    "#     print(df.shape[0], len(df.token_id.unique()))\n",
    "# print()\n",
    "# for df in dev_dfs:\n",
    "#     print(df.shape[0], len(df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens can have multiple tags, so there are more rows than unique token IDs.  In order to pass the data into a CRF model, we need to have one tag per token, so we'll simply **take the first tag** when we extract features for each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings\n",
    "\n",
    "Get GloVe word embeddings (which were trained on English Wikipedia entries) for the vocabulary of the dataset (the unique tokens in the training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\"50\", \"100\", \"200\", \"300\"]\n",
    "d = dimensions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = utils.getGloveEmbeddings(d)\n",
    "# print(glove[\"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35968\n",
      "Lowercased vocabulary size: 31335\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(df_train.token.unique())\n",
    "vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = utils.getEmbeddingsForTokens(glove, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(word_embeddings[0], glove[vocabulary[0].lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = dict(zip(vocabulary, word_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict_keys = list(embedding_dict.keys())\n",
    "for token in vocabulary:\n",
    "    assert token in embedding_dict_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "# Get a vector representation of a token from a GloVe word embedding\n",
    "def extractEmbedding(token, embedding_dict=glove, dimensions=int(d)):\n",
    "    if token.isalpha():\n",
    "        token = token.lower()\n",
    "    try:\n",
    "        embedding = embedding_dict[token]\n",
    "    except KeyError:\n",
    "        embedding = np.zeros((dimensions,))\n",
    "    return embedding.reshape(-1,1)\n",
    "\n",
    "def extractTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token,\n",
    "    }\n",
    "    \n",
    "    # Add each value in a token's word embedding as a separate feature\n",
    "    # Reference: https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training\n",
    "    embedding = extractEmbedding(token)\n",
    "    for i,n in enumerate(embedding):\n",
    "        features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractSentenceFeatures(sentence):\n",
    "    return [extractTokenFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def extractSentenceTargets(sentence):\n",
    "    return [tag_list[0] for token, pos, tag_list in sentence]\n",
    "\n",
    "def extractSentenceTokens(sentence):\n",
    "    return [token for token, pos, tag_list in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"h\"></a>\n",
    "#### Hypothesis:\n",
    "The three multiclass baseline sequence classifiers with GloVe word embeddings as features will have higher F1 scores than the same models with custom fastText embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"all\"></a>\n",
    "## Custom Label Selection\n",
    "\n",
    "* **Features:** custom fastText embeddings\n",
    "* **Algorithm:** AROW, variance=1\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_ling #df_train_perso\n",
    "df_dev = df_dev_ling #df_dev_perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences = utils.zipFeaturesAndTarget(df_train_grouped, \"tag\")\n",
    "dev_sentences = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=1 was best-performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with 50 maximum iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn_crfsuite.CRF(algorithm='arow', variance=1, max_iterations=50, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Gendered-Pronoun', 'B-Generalization', 'B-Gendered-Role', 'I-Generalization', 'I-Gendered-Role', 'I-Gendered-Pronoun']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Summary (with O label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Macro:\n",
      "  - F1: 0.4018151141437465\n",
      "  - Prec: 0.5644738220880121\n",
      "  - Rec 0.3439536665778246\n",
      "  Micro:\n",
      "  - F1: 0.49202578893790294\n",
      "  - Prec: 0.6309834638816362\n",
      "  - Rec 0.4032258064516129\n",
      "  Per Label:\n",
      "  - F1: [0.45490196 0.24347826 0.65107577 0.25660377 0.5826087  0.22222222]\n",
      "  - Prec: [0.81978799 0.336      0.69047619 0.28099174 0.59292035 0.66666667]\n",
      "  - Rec [0.31478969 0.19090909 0.6159292  0.23611111 0.57264957 0.13333333]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(clf.algorithm, clf.c1, clf.c2, clf.pa_type, clf.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag\":\"tag_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_predicted\", y_pred)\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_expected</th>\n",
       "      <th>tag_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id   pos    sentence        tag_expected tag_predicted\n",
       "sentence_id                                                             \n",
       "5                154    IN       After                   O             O\n",
       "5                155  PRP$         his  B-Gendered-Pronoun             O\n",
       "5                156    NN  ordination                   O             O\n",
       "5                157   PRP          he  B-Gendered-Pronoun             O\n",
       "5                158   VBD       spent                   O             O"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.set_index([\"sentence_id\"])\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "# df_dev_exploded.head()\n",
    "df_dev_exploded = df_dev_exploded.explode([\"tag_expected\"])\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_exploded = df_dev_exploded.fillna(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_exploded = df_dev_exploded.rename(columns={\"sentence\":\"token\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_dev_exploded.drop(columns=[\"tag_predicted\"]).reset_index()\n",
    "pred_df = df_dev_exploded.drop(columns=[\"tag_expected\"]).reset_index()\n",
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag_expected</th>\n",
       "      <th>tag_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>159</td>\n",
       "      <td>three</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token  pos tag_expected tag_predicted  \\\n",
       "0            5       154       After   IN            O             O   \n",
       "2            5       156  ordination   NN            O             O   \n",
       "4            5       158       spent  VBD            O             O   \n",
       "5            5       159       three   CD            O             O   \n",
       "6            5       160       years  NNS            O             O   \n",
       "\n",
       "          _merge  \n",
       "0  true negative  \n",
       "2  true negative  \n",
       "4  true negative  \n",
       "5  true negative  \n",
       "6  true negative  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    exp_df, \n",
    "    pred_df, \n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_expected\"],   # left on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_predicted\"],  # right on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_expected\", \"tag_predicted\", \"_merge\"],  # final column list\n",
    "    \"tag_expected\",\n",
    "    \"tag_predicted\", \n",
    "    \"token_id\",  # ID column\n",
    "    \"O\"          # No tag value\n",
    ")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_arow_var1_{c}_baseline_GloVe{d}_predictions.csv\".format(d=d, c=category)\n",
    "eval_df.to_csv(config.tokc_path+\"sequence_model_output/\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['B-Gendered-Pronoun', 'I-Gendered-Pronoun', 'B-Gendered-Role', 'I-Gendered-Role', 'B-Generalization', 'I-Generalization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.995851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Pronoun</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>0.997230</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.996540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.981685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Generalization</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Generalization</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.931507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag(s)  false negative  false positive  true negative  \\\n",
       "0  B-Gendered-Pronoun               4               0              0   \n",
       "0  I-Gendered-Pronoun               3               0              0   \n",
       "0     B-Gendered-Role               3               2              0   \n",
       "0     I-Gendered-Role               3               2              0   \n",
       "0    B-Generalization              15               5              0   \n",
       "0    I-Generalization               3               7              0   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0            480   1.000000  0.991736  0.995851  \n",
       "0              4   1.000000  0.571429  0.727273  \n",
       "0            720   0.997230  0.995851  0.996540  \n",
       "0            134   0.985294  0.978102  0.981685  \n",
       "0             88   0.946237  0.854369  0.897959  \n",
       "0             68   0.906667  0.957746  0.931507  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_stats = pd.DataFrame()\n",
    "for tag in targets:\n",
    "#     getScoresByTags(df, eval_col, tags, exp_col=\"expected_tag\", pred_col=\"predicted_tag\"):\n",
    "    tag_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [tag], exp_col=\"tag_expected\", pred_col=\"tag_predicted\")\n",
    "    agmt_stats = pd.concat([agmt_stats, tag_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_arow_var1_{c}_baseline_GloVe{d}_agreement.csv\".format(d=d, c=category)\n",
    "agmt_stats.to_csv(config.tokc_path+\"sequence_model_performance/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

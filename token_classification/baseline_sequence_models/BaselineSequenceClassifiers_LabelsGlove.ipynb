{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Gender Bias Sequence Classifiers with GloVe\n",
    "\n",
    "### Target: Labels\n",
    "\n",
    "* Supervised learning\n",
    "    * Train, Validate, and (Blind) Test Data: under directory `../data/token_clf_data/model_input/`\n",
    "    * Prediction Data: Data: under directory `../data/token_clf_data/model_output/crf_l2sgd/`\n",
    "* Sequence classification\n",
    "    * 9 lables (2 from original annotation taxonomy weren't applied during manual annotation):\n",
    "        1. Person Name: Unknown, Feminine, Masculine (Non-binary not annotated with)\n",
    "        2. Linguistic: Generalization, Gendered Pronoun, Gendered Role\n",
    "        3. Contextual: Occupation, Omission, Stereotype (Empowering not annotated with enough)\n",
    "    * 1 model per category\n",
    "* Word embeddings\n",
    "    * GloVe (trained on Gigaword 5 + English Wikipedia dump)\n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[0.](#0) Preprocessing\n",
    "\n",
    "  * [Hypotheses](#h)\n",
    "\n",
    "[1.](#1) Models\n",
    "\n",
    "  * [All Labels](#all)\n",
    "  * [Linguistic](#ling)\n",
    "  * [Person Name](#pers)\n",
    "  * [Contextual](#cont)\n",
    "  * [Person Name + Occupation](#perso)\n",
    "  \n",
    "[2.](#2) Performance Evaluation\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom functions and variables\n",
    "import utils, config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "\n",
    "# For creating directories\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.stats\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim import utils as gensim_utils\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# For classification\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay#, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation (dev) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467564, 10) (157740, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_offsets</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>field</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>Title</td>\n",
       "      <td>(17, 22)</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>(22, 23)</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>5</td>\n",
       "      <td>Papers</td>\n",
       "      <td>(24, 30)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>of</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14384</td>\n",
       "      <td>7</td>\n",
       "      <td>The</td>\n",
       "      <td>(34, 37)</td>\n",
       "      <td>DT</td>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>Title</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id  sentence_id  ann_id  token_id   token token_offsets  pos  \\\n",
       "3               1            1   99999         3   Title      (17, 22)   NN   \n",
       "4               1            1   99999         4       :      (22, 23)    :   \n",
       "5               1            1   99999         5  Papers      (24, 30)  NNS   \n",
       "6               1            1   99999         6      of      (31, 33)   IN   \n",
       "7               1            1   14384         7     The      (34, 37)   DT   \n",
       "\n",
       "         tag  field subset  \n",
       "3          O  Title  train  \n",
       "4          O  Title  train  \n",
       "5          O  Title  train  \n",
       "6          O  Title  train  \n",
       "7  B-Unknown  Title  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.tokc_path+\"model_input/token_train.csv\", index_col=0)\n",
    "df_dev = pd.read_csv(config.tokc_path+\"model_input/token_validate.csv\", index_col=0)\n",
    "print(df_train.shape, df_dev.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate rows with all but the same annotation ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463441, 9) (156146, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=[\"ann_id\"])\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev.drop(columns=[\"ann_id\"])\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-binary labels as these were mistaken labels identified early on that were meant to be excluded, and because only one token has this label, it prevents the data from being input into the models with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train.tag != \"B-Nonbinary\"]\n",
    "df_train = df_train.loc[df_train.tag != \"I-Nonbinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463439, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that won't be used as features for the classifiers and remove any duplicate rows that remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\"sentence_id\", \"token_id\", \"pos\", \"token\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[cols_to_keep]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_dev = df_dev[cols_to_keep]\n",
    "df_dev = df_dev.drop_duplicates()\n",
    "# df_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate subsets of data for each category so they can be used with three separate models, replacing `NaN` tag values with `'O'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Feminine' 'B-Gendered-Pronoun' 'B-Gendered-Role' 'B-Generalization'\n",
      " 'B-Masculine' 'B-Occupation' 'B-Omission' 'B-Stereotype' 'B-Unknown'\n",
      " 'I-Feminine' 'I-Gendered-Pronoun' 'I-Gendered-Role' 'I-Generalization'\n",
      " 'I-Masculine' 'I-Occupation' 'I-Omission' 'I-Stereotype' 'I-Unknown' 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = (df_train.tag.unique())\n",
    "tags.sort()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Optional Preprocessing** - if only using a subset of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_cat_tags = ['B-Gendered-Pronoun', 'B-Gendered-Role', 'B-Generalization', 'I-Gendered-Pronoun', 'I-Gendered-Role', 'I-Generalization']\n",
    "df_train_ling = df_train.loc[df_train.tag.isin(ling_cat_tags)]\n",
    "df_dev_ling = df_dev.loc[df_dev.tag.isin(ling_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Unknown']\n",
    "df_train_pers = df_train.loc[df_train.tag.isin(pers_cat_tags)]\n",
    "df_dev_pers = df_dev.loc[df_dev.tag.isin(pers_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cat_tags = ['B-Occupation', 'B-Omission', 'B-Stereotype', 'I-Occupation', 'I-Omission', 'I-Stereotype']\n",
    "df_train_cont = df_train.loc[df_train.tag.isin(cont_cat_tags)]\n",
    "df_dev_cont = df_dev.loc[df_dev.tag.isin(cont_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "perso_cat_tags = ['B-Feminine', 'B-Masculine', 'B-Occupation', 'B-Unknown', 'I-Feminine', 'I-Masculine', 'I-Occupation', 'I-Unknown']\n",
    "df_train_perso = df_train.loc[df_train.tag.isin(perso_cat_tags)]\n",
    "df_dev_perso = df_dev.loc[df_dev.tag.isin(perso_cat_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (df_train.drop(columns=[\"tag\"])).drop_duplicates()\n",
    "df_dev = (df_dev.drop(columns=[\"tag\"])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"sentence_id\", \"token_id\", \"pos\", \"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ling = df_train.join(df_train_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_ling = df_train_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_train_ling = df_train_ling.fillna('O')\n",
    "# df_train_ling.head()\n",
    "df_dev_ling = df_dev.join(df_dev_ling.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_ling = df_dev_ling.rename(columns={\"tag\":\"tag_linguistic\"})\n",
    "df_dev_ling = df_dev_ling.fillna('O')\n",
    "# df_dev_ling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pers = df_train.join(df_train_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_pers = df_train_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_train_pers = df_train_pers.fillna('O')\n",
    "df_dev_pers = df_dev.join(df_dev_pers.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_pers = df_dev_pers.rename(columns={\"tag\":\"tag_personname\"})\n",
    "df_dev_pers = df_dev_pers.fillna('O')\n",
    "# df_dev_pers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NN</td>\n",
       "      <td>Title</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Papers</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>DT</td>\n",
       "      <td>The</td>\n",
       "      <td>B-Stereotype</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  pos   token tag_contextual\n",
       "3            1         3   NN   Title              O\n",
       "4            1         4    :       :              O\n",
       "5            1         5  NNS  Papers              O\n",
       "6            1         6   IN      of              O\n",
       "7            1         7   DT     The   B-Stereotype"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cont = df_train.join(df_train_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_cont = df_train_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_train_cont = df_train_cont.fillna('O')\n",
    "df_dev_cont = df_dev.join(df_dev_cont.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_cont = df_dev_cont.rename(columns={\"tag\":\"tag_contextual\"})\n",
    "df_dev_cont = df_dev_cont.fillna('O')\n",
    "df_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_perso = df_train.join(df_train_perso.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_train_perso = df_train_perso.rename(columns={\"tag\":\"tag_pno\"})\n",
    "df_train_perso = df_train_perso.fillna('O')\n",
    "df_dev_perso = df_dev.join(df_dev_perso.set_index(join_cols), on=join_cols, how=\"outer\")\n",
    "df_dev_perso = df_dev_perso.rename(columns={\"tag\":\"tag_pno\"})\n",
    "df_dev_perso = df_dev_perso.fillna('O')\n",
    "# df_dev_perso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_ling = df_train_ling.drop_duplicates()\n",
    "# df_dev_ling = df_dev_ling.drop_duplicates()\n",
    "# df_train_pers = df_train_pers.drop_duplicates()\n",
    "# df_dev_pers = df_dev_pers.drop_duplicates()\n",
    "# df_train_cont = df_train_cont.drop_duplicates()\n",
    "# df_dev_cont = df_dev_cont.drop_duplicates()\n",
    "df_train_perso = df_train_perso.drop_duplicates()\n",
    "df_dev_perso = df_dev_perso.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452222 452086\n",
      "455327 452086\n",
      "453119 452086\n",
      "\n",
      "152494 152455\n",
      "153568 152455\n",
      "152768 152455\n"
     ]
    }
   ],
   "source": [
    "train_dfs = [df_train_ling, df_train_pers, df_train_cont]\n",
    "dev_dfs = [df_dev_ling, df_dev_pers, df_dev_cont]\n",
    "for df in train_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))\n",
    "print()\n",
    "for df in dev_dfs:\n",
    "    print(df.shape[0], len(df.token_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens can have multiple tags, so there are more rows than unique token IDs.  In order to pass the data into a CRF model, we need to have one tag per token, so we'll simply **take the first tag** when we extract features for each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings\n",
    "\n",
    "Get GloVe word embeddings (which were trained on English Wikipedia entries) for the vocabulary of the dataset (the unique tokens in the training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\"50\", \"100\", \"200\", \"300\"]\n",
    "d = dimensions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = utils.getGloveEmbeddings(d)\n",
    "# print(glove[\"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 35968\n",
      "Lowercased vocabulary size: 31335\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(df_train.token.unique())\n",
    "vocabulary_lowercased = [token.lower() for token in vocabulary]\n",
    "vocabulary_lowercased = list(set(vocabulary_lowercased))\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Lowercased vocabulary size:\", len(vocabulary_lowercased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = utils.getEmbeddingsForTokens(glove, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(word_embeddings[0], glove[vocabulary[0].lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = dict(zip(vocabulary, word_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict_keys = list(embedding_dict.keys())\n",
    "for token in vocabulary:\n",
    "    assert token in embedding_dict_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "# Get a vector representation of a token from a GloVe word embedding\n",
    "def extractEmbedding(token, embedding_dict=glove, dimensions=int(d)):\n",
    "    if token.isalpha():\n",
    "        token = token.lower()\n",
    "    try:\n",
    "        embedding = embedding_dict[token]\n",
    "    except KeyError:\n",
    "        embedding = np.zeros((dimensions,))\n",
    "    return embedding.reshape(-1,1)\n",
    "\n",
    "def extractTokenFeatures(sentence, i):\n",
    "    token = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token,\n",
    "    }\n",
    "    \n",
    "    # Add each value in a token's word embedding as a separate feature\n",
    "    # Reference: https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training\n",
    "    embedding = extractEmbedding(token)\n",
    "    for i,n in enumerate(embedding):\n",
    "        features['e{}'.format(i)] = n\n",
    "    \n",
    "    # Record whether a token is the first or last token of a sentence\n",
    "    if i == 0:\n",
    "        features['START'] = True\n",
    "    elif i == (len(sentence) - 1):\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extractSentenceFeatures(sentence):\n",
    "    return [extractTokenFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "def extractSentenceTargets(sentence):\n",
    "    return [tag_list[0] for token, pos, tag_list in sentence]\n",
    "\n",
    "def extractSentenceTokens(sentence):\n",
    "    return [token for token, pos, tag_list in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"h\"></a>\n",
    "#### Hypothesis:\n",
    "The three multiclass baseline sequence classifiers with GloVe word embeddings as features will have higher F1 scores than the same models with custom fastText embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"all\"></a>\n",
    "## All Labels\n",
    "\n",
    "* **Features:** custom fastText embeddings\n",
    "* **Target:** Person-Name label category IOB tags\n",
    "* **Algorithm:** AROW, variance=1\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences = utils.zipFeaturesAndTarget(df_train_grouped, \"tag\")\n",
    "dev_sentences = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=1 was best-performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn_crfsuite.CRF(algorithm='arow', variance=1, max_iterations=50, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'I-Stereotype', 'I-Masculine', 'B-Masculine', 'B-Stereotype', 'B-Occupation', 'I-Occupation', 'B-Gendered-Pronoun', 'B-Omission', 'B-Generalization', 'B-Gendered-Role', 'B-Feminine', 'I-Omission', 'I-Generalization', 'I-Feminine', 'I-Gendered-Role', 'I-Gendered-Pronoun']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Summary (with O label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Macro:\n",
      "  - F1: 0.3448072001994752\n",
      "  - Prec: 0.3280949779307769\n",
      "  - Rec 0.3718758583588562\n",
      "  Micro:\n",
      "  - F1: 0.38332083645755227\n",
      "  - Prec: 0.35861262665627436\n",
      "  - Rec 0.4116857551896922\n",
      "  Per Label:\n",
      "  - F1: [0.42539683 0.43977055 0.16512456 0.29272811 0.30212014 0.17391304\n",
      " 0.59833333 0.49354005 0.8297456  0.13043478 0.2893617  0.50815217\n",
      " 0.44311377 0.14482201 0.2364532  0.36917866 0.36434109 0.        ]\n",
      "  - Prec: [0.45995423 0.44384408 0.13875598 0.24515128 0.28547579 0.15483871\n",
      " 0.61472603 0.47869674 0.77372263 0.10700132 0.31775701 0.51944444\n",
      " 0.43529412 0.11949266 0.18604651 0.33538462 0.29012346 0.        ]\n",
      "  - Rec [0.39566929 0.43577113 0.20386643 0.36321839 0.32082552 0.19834711\n",
      " 0.58279221 0.50933333 0.89451477 0.16701031 0.265625   0.49734043\n",
      " 0.45121951 0.18377823 0.32432432 0.41054614 0.48958333 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(clf.algorithm, clf.c1, clf.c2, clf.pa_type, clf.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strict Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped = df_dev_grouped.rename(columns={\"tag\":\"tag_expected\"})\n",
    "df_dev_grouped.insert(len(df_dev_grouped.columns), \"tag_predicted\", y_pred)\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag_expected</th>\n",
       "      <th>tag_predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154</td>\n",
       "      <td>IN</td>\n",
       "      <td>After</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>his</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>NN</td>\n",
       "      <td>ordination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157</td>\n",
       "      <td>PRP</td>\n",
       "      <td>he</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token_id   pos    sentence        tag_expected       tag_predicted\n",
       "sentence_id                                                                   \n",
       "5                154    IN       After                   O                   O\n",
       "5                155  PRP$         his  B-Gendered-Pronoun  B-Gendered-Pronoun\n",
       "5                156    NN  ordination                   O                   O\n",
       "5                157   PRP          he  B-Gendered-Pronoun  B-Gendered-Pronoun\n",
       "5                158   VBD       spent                   O                   O"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_grouped = df_dev_grouped.set_index([\"sentence_id\"])\n",
    "df_dev_exploded = df_dev_grouped.explode(list(df_dev_grouped.columns))\n",
    "# df_dev_exploded.head()\n",
    "df_dev_exploded = df_dev_exploded.explode([\"tag_expected\"])\n",
    "df_dev_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_exploded = df_dev_exploded.fillna(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_exploded = df_dev_exploded.rename(columns={\"sentence\":\"token\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = df_dev_exploded.drop(columns=[\"tag_predicted\"]).reset_index()\n",
    "pred_df = df_dev_exploded.drop(columns=[\"tag_expected\"]).reset_index()\n",
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag_expected</th>\n",
       "      <th>tag_predicted</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>After</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>ordination</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>spent</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id       token   pos        tag_expected  \\\n",
       "0            5       154       After    IN                   O   \n",
       "1            5       155         his  PRP$  B-Gendered-Pronoun   \n",
       "2            5       156  ordination    NN                   O   \n",
       "3            5       157          he   PRP  B-Gendered-Pronoun   \n",
       "4            5       158       spent   VBD                   O   \n",
       "\n",
       "        tag_predicted         _merge  \n",
       "0                   O  true negative  \n",
       "1  B-Gendered-Pronoun  true positive  \n",
       "2                   O  true negative  \n",
       "3  B-Gendered-Pronoun  true positive  \n",
       "4                   O  true negative  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = utils.makeEvaluationDataFrame(\n",
    "    exp_df, \n",
    "    pred_df, \n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_expected\"],   # left on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_predicted\"],  # right on\n",
    "    [\"sentence_id\", \"token_id\", \"token\", \"pos\", \"tag_expected\", \"tag_predicted\", \"_merge\"],  # final column list\n",
    "    \"tag_expected\",\n",
    "    \"tag_predicted\", \n",
    "    \"token_id\",  # ID column\n",
    "    \"O\"          # No tag value\n",
    ")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_arow_var1_baseline_GloVe{d}_predictions.csv\".format(d=d)\n",
    "eval_df.to_csv(config.tokc_path+\"sequence_model_output/\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and F1 score at the token level for each tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag(s)</th>\n",
       "      <th>false negative</th>\n",
       "      <th>false positive</th>\n",
       "      <th>true negative</th>\n",
       "      <th>true positive</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Unknown</td>\n",
       "      <td>1182</td>\n",
       "      <td>654</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.746708</td>\n",
       "      <td>0.619936</td>\n",
       "      <td>0.677442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Unknown</td>\n",
       "      <td>1772</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "      <td>3244</td>\n",
       "      <td>0.697334</td>\n",
       "      <td>0.646730</td>\n",
       "      <td>0.671080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Stereotype</td>\n",
       "      <td>585</td>\n",
       "      <td>728</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>0.309298</td>\n",
       "      <td>0.357849</td>\n",
       "      <td>0.331807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Masculine</td>\n",
       "      <td>801</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>1352</td>\n",
       "      <td>0.595857</td>\n",
       "      <td>0.627961</td>\n",
       "      <td>0.611488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Masculine</td>\n",
       "      <td>676</td>\n",
       "      <td>357</td>\n",
       "      <td>0</td>\n",
       "      <td>1110</td>\n",
       "      <td>0.756646</td>\n",
       "      <td>0.621501</td>\n",
       "      <td>0.682447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Stereotype</td>\n",
       "      <td>222</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.319392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Occupation</td>\n",
       "      <td>283</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>816</td>\n",
       "      <td>0.793003</td>\n",
       "      <td>0.742493</td>\n",
       "      <td>0.766917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Occupation</td>\n",
       "      <td>389</td>\n",
       "      <td>422</td>\n",
       "      <td>0</td>\n",
       "      <td>824</td>\n",
       "      <td>0.661316</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.670191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Pronoun</td>\n",
       "      <td>85</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.895105</td>\n",
       "      <td>0.943068</td>\n",
       "      <td>0.918461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Omission</td>\n",
       "      <td>834</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.488971</td>\n",
       "      <td>0.524655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Generalization</td>\n",
       "      <td>201</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Gendered-Role</td>\n",
       "      <td>317</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1056</td>\n",
       "      <td>0.907997</td>\n",
       "      <td>0.769119</td>\n",
       "      <td>0.832808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Feminine</td>\n",
       "      <td>175</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Omission</td>\n",
       "      <td>1194</td>\n",
       "      <td>1230</td>\n",
       "      <td>0</td>\n",
       "      <td>1194</td>\n",
       "      <td>0.492574</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.496259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Generalization</td>\n",
       "      <td>120</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.329670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Feminine</td>\n",
       "      <td>406</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "      <td>752</td>\n",
       "      <td>0.645494</td>\n",
       "      <td>0.649396</td>\n",
       "      <td>0.647439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Role</td>\n",
       "      <td>62</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-Gendered-Pronoun</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag(s)  false negative  false positive  true negative  \\\n",
       "0           B-Unknown            1182             654              0   \n",
       "0           I-Unknown            1772            1408              0   \n",
       "0        I-Stereotype             585             728              0   \n",
       "0         I-Masculine             801             917              0   \n",
       "0         B-Masculine             676             357              0   \n",
       "0        B-Stereotype             222             136              0   \n",
       "0        B-Occupation             283             213              0   \n",
       "0        I-Occupation             389             422              0   \n",
       "0  B-Gendered-Pronoun              85             165              0   \n",
       "0          B-Omission             834             612              0   \n",
       "0    B-Generalization             201              88              0   \n",
       "0     B-Gendered-Role             317             107              0   \n",
       "0          B-Feminine             175              77              0   \n",
       "0          I-Omission            1194            1230              0   \n",
       "0    I-Generalization             120             124              0   \n",
       "0          I-Feminine             406             413              0   \n",
       "0     I-Gendered-Role              62             106              0   \n",
       "0  I-Gendered-Pronoun              15              14              0   \n",
       "\n",
       "   true positive  precision    recall        f1  \n",
       "0           1928   0.746708  0.619936  0.677442  \n",
       "0           3244   0.697334  0.646730  0.671080  \n",
       "0            326   0.309298  0.357849  0.331807  \n",
       "0           1352   0.595857  0.627961  0.611488  \n",
       "0           1110   0.756646  0.621501  0.682447  \n",
       "0             84   0.381818  0.274510  0.319392  \n",
       "0            816   0.793003  0.742493  0.766917  \n",
       "0            824   0.661316  0.679308  0.670191  \n",
       "0           1408   0.895105  0.943068  0.918461  \n",
       "0            798   0.565957  0.488971  0.524655  \n",
       "0            102   0.536842  0.336634  0.413793  \n",
       "0           1056   0.907997  0.769119  0.832808  \n",
       "0            350   0.819672  0.666667  0.735294  \n",
       "0           1194   0.492574  0.500000  0.496259  \n",
       "0             60   0.326087  0.333333  0.329670  \n",
       "0            752   0.645494  0.649396  0.647439  \n",
       "0            166   0.610294  0.728070  0.664000  \n",
       "0              0   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmt_stats = pd.DataFrame()\n",
    "for tag in targets:\n",
    "#     getScoresByTags(df, eval_col, tags, exp_col=\"expected_tag\", pred_col=\"predicted_tag\"):\n",
    "    tag_agmt_stats = utils.getScoresByTags(eval_df, \"_merge\", [tag], exp_col=\"tag_expected\", pred_col=\"tag_predicted\")\n",
    "    agmt_stats = pd.concat([agmt_stats, tag_agmt_stats])\n",
    "agmt_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crf_arow_var1_baseline_GloVe{d}_agreement.csv\".format(d=d)\n",
    "stats.to_csv(config.tokc_path+\"sequence_model_performance/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ling\"></a>\n",
    "### Linguistic\n",
    "\n",
    "* **Features:** custom fastText embeddings, token suffixes\n",
    "* **Target:** Linguistic label category IOB tags\n",
    "* **Algorithm:** AROW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_ling\n",
    "df_dev = df_dev_ling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by token, so the all the tags for one token are recorded in a list for that token's row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by sentence, where each sentence is a list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_ling = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_linguistic\")\n",
    "# print(train_sentences_ling[0][:3])\n",
    "dev_sentences_ling = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_linguistic\")\n",
    "# print(dev_sentences_ling[0][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_ling\n",
    "dev_sentences = dev_sentences_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** pa with pa_type=0 was best, however, arow with variance=0.5 also had strong performance, and is strongest with other categories, Person Name and Contextual, so we'll use arow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Linguistic** category of tags.  We'll increase the max_iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ling = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_ling.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Gendered-Pronoun', 'B-Generalization', 'B-Gendered-Role', 'I-Generalization', 'I-Gendered-Role', 'I-Gendered-Pronoun']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_ling.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_ling.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.46127525476481473\n",
      "  - Prec: 0.6776789299424809\n",
      "  - Rec 0.35706340378198\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's scores with GloVe embeddings of 100 dimensions were:\n",
    "\n",
    "The baseline model's scores with GloVe embeddings of 50 dimensions were:\n",
    "  - F1: 0.6682632094564904\n",
    "  - Prec: 0.6397609767051633\n",
    "  - Rec 0.7057842046718577\n",
    "  \n",
    "Which is a slightly lower performance than the baseline model with custom fastText embeddings:\n",
    "  - F1: 0.6697698893667122\n",
    "  - Prec: 0.696012355375722\n",
    "  - Rec 0.6718576195773082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pers\"></a>\n",
    "### Person Name\n",
    "\n",
    "* **Features:** custom fastText embeddings\n",
    "* **Target:** Person-Name label category IOB tags\n",
    "* **Algorithm:** AROW\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_pers\n",
    "df_dev = df_dev_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_pers = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_personname\")\n",
    "# print(train_sentences_pers[0][:3])\n",
    "dev_sentences_pers = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_personname\")\n",
    "# print(dev_sentences_pers[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_pers\n",
    "dev_sentences = dev_sentences_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=0.5 was best-performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pers = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_pers.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'I-Masculine', 'B-Masculine', 'B-Feminine', 'I-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_pers.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pers.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.45720798958795417\n",
      "  - Prec: 0.45011745722056856\n",
      "  - Rec 0.4673524789255608\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's performance scores were:\n",
    "  - F1: 0.45688362747838485\n",
    "  - Prec: 0.44852949944619963\n",
    "  - Rec 0.4783540505786541\n",
    "\n",
    "Compared to the baseline model with custom fastText embeddings:\n",
    "  - F1: 0.4789287297354048\n",
    "  - Prec: 0.5381704595959792\n",
    "  - Rec 0.43620517216745247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "### Contextual\n",
    "\n",
    "* **Features:** custom fastText embeddings, token suffixes\n",
    "* **Target:** Contextual label category IOB tags\n",
    "* **Algorithm:** AROW\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_cont\n",
    "df_dev = df_dev_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_cont = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_contextual\")\n",
    "# print(train_sentences_cont[0][:3])\n",
    "dev_sentences_cont = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_contextual\")\n",
    "# print(dev_sentences_cont[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_cont\n",
    "dev_sentences = dev_sentences_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=0.5 was the best performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Contextual** category of tags.  We'll increase the maximum iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cont = sklearn_crfsuite.CRF(algorithm='arow', variance=0.5, max_iterations=100, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_cont.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Stereotype', 'I-Stereotype', 'B-Occupation', 'I-Occupation', 'B-Omission', 'I-Omission']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_cont.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_cont.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - F1: 0.4043437926935072\n",
      "  - Prec: 0.4144046520219574\n",
      "  - Rec 0.3993485342019544\n"
     ]
    }
   ],
   "source": [
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"weighted\", zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model's performance scores were:\n",
    "  - F1: 0.3896210891326545\n",
    "  - Prec: 0.40701772348045956\n",
    "  - Rec 0.3752442996742671\n",
    "  \n",
    "Compared to the baseline model with custom fastText embeddings:\n",
    "  - F1: 0.40803990799640844\n",
    "  - Prec: 0.4124968743940007\n",
    "  - Rec 0.4091205211726384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"perso\"></a>\n",
    "### Person Name + Occupation\n",
    "\n",
    "* **Features:** custom fastText embeddings\n",
    "* **Target:** Person-Name label category IOB tags\n",
    "* **Algorithm:** AROW, variance=1\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_perso\n",
    "df_dev = df_dev_perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_token_groups = utils.implodeDataFrame(df_train, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_dev_token_groups = utils.implodeDataFrame(df_dev, ['token_id', 'sentence_id', 'pos', 'token'])\n",
    "df_train_token_groups = df_train_token_groups.reset_index()\n",
    "df_dev_token_groups = df_dev_token_groups.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = utils.implodeDataFrame(df_train_token_groups, ['sentence_id'])\n",
    "df_dev_grouped = utils.implodeDataFrame(df_dev_token_groups, ['sentence_id'])\n",
    "df_train_grouped = df_train_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "df_dev_grouped = df_dev_grouped.rename(columns={\"token\":\"sentence\"})\n",
    "# df_dev_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the POS and category tags together with the tokens so each sentence item is a tuple: `(TOKEN, POS-TAG, TAG_LIST)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_dev_grouped = df_dev_grouped.reset_index()\n",
    "train_sentences_perso = utils.zipFeaturesAndTarget(df_train_grouped, \"tag_pno\")\n",
    "dev_sentences_perso = utils.zipFeaturesAndTarget(df_dev_grouped, \"tag_pno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_sentences_perso\n",
    "dev_sentences = dev_sentences_perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = [extractSentenceFeatures(sentence) for sentence in train_sentences]\n",
    "X_dev = [extractSentenceFeatures(sentence) for sentence in dev_sentences]\n",
    "# Target\n",
    "y_train = [extractSentenceTargets(sentence) for sentence in train_sentences]\n",
    "y_dev = [extractSentenceTargets(sentence) for sentence in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Optimization of Baseline Model:** arow with variance=1 was best-performing algorithm/parameter combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Train a Conditional Random Field (CRF) model with the default parameters on the **Person Name** category of tags.  We'll increase the max iterations to 100 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pers = sklearn_crfsuite.CRF(algorithm='arow', variance=1, max_iterations=50, all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66059532/attributeerror-crf-object-has-no-attribute-keep-tempfiles\n",
    "try:\n",
    "    clf_pers.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `'O'` tags from the targets list since we are interested in the ability to apply the gendered and gender biased language related tags, and the `'O'` tags far outnumber the tags for gendered and gender biased language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Unknown', 'I-Unknown', 'I-Masculine', 'B-Masculine', 'B-Occupation', 'I-Occupation', 'B-Feminine', 'I-Feminine']\n"
     ]
    }
   ],
   "source": [
    "targets = list(clf_pers.classes_)\n",
    "targets.remove('O')\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pers.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "##### Strict Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arow None None None 1\n",
      "  Macro:\n",
      "  - F1: 0.5243867381337348\n",
      "  - Prec: 0.5403350348885592\n",
      "  - Rec 0.5144901877709556\n",
      "  Micro:\n",
      "  - F1: 0.49842427238460113\n",
      "  - Prec: 0.5195156511657865\n",
      "  - Rec 0.478978622327791\n",
      "  Per Label:\n",
      "  - F1: [0.50196335 0.48682946 0.37071173 0.46112957 0.63591433 0.54187192\n",
      " 0.66090713 0.53576642]\n",
      "  - Prec: [0.55660377 0.52335676 0.37052201 0.44316731 0.6819788  0.59875583\n",
      " 0.67105263 0.47724317]\n",
      "  - Rec [0.45709178 0.4550683  0.37090164 0.48060942 0.59567901 0.49485861\n",
      " 0.65106383 0.61064892]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(clf_pers.algorithm, clf_pers.c1, clf_pers.c2, clf_pers.pa_type, clf_pers.variance)\n",
    "print(\"  Macro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"macro\", zero_division=0, labels=targets))\n",
    "print(\"  Micro:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=\"micro\", zero_division=0, labels=targets))\n",
    "print(\"  Per Label:\")\n",
    "print(\"  - F1:\", metrics.flat_f1_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Prec:\", metrics.flat_precision_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))\n",
    "print(\"  - Rec\", metrics.flat_recall_score(y_dev, y_pred, average=None, zero_division=0, labels=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias",
   "language": "python",
   "name": "gender-bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
